syntax = "proto3";

package api;

// TODO use google/protobuf/duration.proto when those issues are resolved?
// https://github.com/grpc-ecosystem/grpc-gateway/issues/160
// https://github.com/grpc-ecosystem/grpc-gateway/issues/400
// import "google/protobuf/duration.proto";

import "google/api/annotations.proto";

message LabelPair {
    // Label name
    string name = 1;

    // Label value
    string value = 2;
}

message StaticConfig {
    // Hostnames or IPs followed by an optional port number: "1.2.3.4:9090"
    repeated string targets = 1;

    // Labels assigned to all metrics scraped from the targets
    repeated LabelPair labels = 2;
}

message BasicAuth {
    string username = 1;
    string password = 2;
}

message TLSConfig {
    // TODO
    // string ca_file = 1;
    // string cert_file = 2;
    // string key_file = 3;
    // string server_name = 4;

    bool insecure_skip_verify = 5;
}

message ScrapeConfig {
    // The job name assigned to scraped metrics by default: "example-job" (required)
    string job_name = 1;

    // How frequently to scrape targets from this job: "10s"
    string scrape_interval = 2;

    // Per-scrape timeout when scraping this job: "5s"
    string scrape_timeout = 3;

    // The HTTP resource path on which to fetch metrics from targets: "/metrics"
    string metrics_path = 4;

    // Configures the protocol scheme used for requests: "http" or "https"
    string scheme = 5;

    // Sets the `Authorization` header on every scrape request with the configured username and password
    BasicAuth basic_auth = 6;

    // Configures the scrape request's TLS settings
    TLSConfig tls_config = 7;

    // List of labeled statically configured targets for this job
    repeated StaticConfig static_configs = 8;
}

// ScrapeTargetHealth represents Prometheus scrape target health: unknown, down, or up.
message ScrapeTargetHealth {
    // Original scrape job name
    string job_name = 1;

    // "job" label value, may be different from job_name due to relabeling
    string job = 2;

    // Original target
    string target = 3;

    // "instance" label value, may be different from target due to relabeling
    string instance = 4;

    // Target health : unknown, down, or up.
    enum Health {
        UNKNOWN = 0;
        DOWN = 1;
        UP = 2;
    }
    Health health = 5;
}

message ScrapeConfigsListRequest {
}

message ScrapeConfigsListResponse {
    repeated ScrapeConfig scrape_configs = 1;

    // Scrape targets health for all managed scrape jobs
    repeated ScrapeTargetHealth scrape_targets_health = 2;
}

message ScrapeConfigsGetRequest {
    string job_name = 1;
}

message ScrapeConfigsGetResponse {
    ScrapeConfig scrape_config = 1;

    // Scrape targets health for this scrape job
    repeated ScrapeTargetHealth scrape_targets_health = 2;
}

message ScrapeConfigsCreateRequest {
    ScrapeConfig scrape_config = 1;

    // Check that added targets can be scraped from PMM Server
    bool check_reachability = 2;
}

message ScrapeConfigsCreateResponse {
}

message ScrapeConfigsDeleteRequest {
    string job_name = 1;
}

message ScrapeConfigsDeleteResponse {
}

message ScrapeConfigsAddStaticTargetsRequest {
    string job_name = 1;

    // Hostnames or IPs followed by an optional port number: "1.2.3.4:9090"
    repeated string targets = 2;

    // Check that added targets can be scraped from PMM Server
    bool check_reachability = 3;
}

message ScrapeConfigsAddStaticTargetsResponse {
}

message ScrapeConfigsRemoveStaticTargetsRequest {
    string job_name = 1;

    // Hostnames or IPs followed by an optional port number: "1.2.3.4:9090"
    repeated string targets = 2;
}

message ScrapeConfigsRemoveStaticTargetsResponse {
}

service ScrapeConfigs {
    // List returns all scrape configs.
    rpc List(ScrapeConfigsListRequest) returns (ScrapeConfigsListResponse) {
        option (google.api.http) = {
            get: "/v0/scrape-configs"
        };
    }

    // Get returns a scrape config by job name.
    // Errors: NotFound(5) if no such scrape config is present.
    rpc Get(ScrapeConfigsGetRequest) returns (ScrapeConfigsGetResponse) {
        option (google.api.http) = {
            get: "/v0/scrape-configs/{job_name}"
        };
    }

    // Create creates a new scrape config.
    // Errors: InvalidArgument(3) if some argument is not valid,
    // AlreadyExists(6) if scrape config with that job name is already present,
    // FailedPrecondition(9) if reachability check was requested and some scrape target can't be reached.
    rpc Create(ScrapeConfigsCreateRequest) returns (ScrapeConfigsCreateResponse) {
        option (google.api.http) = {
            post: "/v0/scrape-configs",
            body: "*"
        };
    }

    // Delete removes existing scrape config by job name.
    // Errors: NotFound(5) if no such scrape config is present.
    rpc Delete(ScrapeConfigsDeleteRequest) returns (ScrapeConfigsDeleteResponse) {
        option (google.api.http) = {
            delete: "/v0/scrape-configs/{job_name}"
        };
    }

    // Add static targets to existing scrape config.
    // Errors: NotFound(5) if no such scrape config is present,
    // FailedPrecondition(9) if reachability check was requested and some scrape target can't be reached.
    rpc AddStaticTargets(ScrapeConfigsAddStaticTargetsRequest) returns (ScrapeConfigsAddStaticTargetsResponse) {
        option (google.api.http) = {
            post: "/v0/scrape-configs/{job_name}/static-targets",
            body: "*"
        };
    }

    // Remove static targets from existing scrape config.
    // Errors: NotFound(5) if no such scrape config is present.
    rpc RemoveStaticTargets(ScrapeConfigsRemoveStaticTargetsRequest) returns (ScrapeConfigsRemoveStaticTargetsResponse) {
        option (google.api.http) = {
            delete: "/v0/scrape-configs/{job_name}/static-targets",
            body: "*"
        };
    }
}
