{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome","text":"<p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It allows you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and perform database management operations no matter where they are located on-prem or in the cloud.</p> <ul> <li> <p>PMM collects thousands of out-of-the-box performance metrics from databases and their hosts.</p> </li> <li> <p>The PMM web UI visualizes data in dashboards.</p> </li> <li> <p>Additional features include advisors for database health assessments.</p> </li> </ul> <p>This is the documentation for the latest PMM 2 release, PMM 2.44.0 (Release Notes). PMM 2 is no longer actively developed. For the latest features, security updates, and improvements, we strongly recommend using PMM 3.</p> <p>Here\u2019s how the home page looks on our free, live demo system.</p> <p> </p> <p>PMM runs in the cloud, on-prem, or across hybrid platforms. It\u2019s supported by our legendary expertise in open source databases, and by a vibrant developer and user community.</p> <p>A minimal PMM set-up comprises one server and a client agent on every system you want to monitor.</p>"},{"location":"index.html#start-here","title":"Start here","text":"<ul> <li> <p>An easy install script, which you download, make executable and run. The script installs Docker and runs PMM Server as a container.</p> </li> <li> <p>The Quickstart install guide shows how to run PMM Server as a Docker container, and how to install PMM Client on Ubuntu or Red Hat Linux hosts.</p> </li> <li> <p>Setting Up explains in detail how to set up PMM Server, clients, and how to add services.</p> </li> </ul>"},{"location":"index.html#read-more","title":"Read more","text":""},{"location":"index.html#links-to-popular-sections","title":"Links to popular sections","text":""},{"location":"index.html#for-system-administrators","title":"For System Administrators","text":"<ul> <li>Setting up</li> <li>How to configure</li> <li>How to upgrade</li> <li>pmm-admin</li> <li>Architecture</li> </ul>"},{"location":"index.html#for-users","title":"For Users","text":"<ul> <li>User interface</li> <li>Using Query Analytics</li> <li>Using Percona Alerting</li> <li>Dashboards reference</li> </ul> Full section map (click to show/hide) <p><p> Commands Dashboards API pmm-admin pmm-agent Architecture User Interface components VictoriaMetrics Glossary Details Render dashboard images Annotate Optimize Secure Upgrade Configure Manage Users Extend metrics Troubleshoot How to DBaaS Advisors Query Analytics Backup and Restore Percona  Alerting User Interface Get started MySQL MongoDB PostgreSQL ProxySQL Amazon RDS Microsoft Azure Linux External Services HA Proxy Remote Instances Google Cloud Platform Client Server Network Docker Virtual appliance AWS Marketplace Easy-install script DBaaS Setting up Welcome </p></p>"},{"location":"copyright.html","title":"Copyright and licensing information","text":""},{"location":"copyright.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Monitoring and Management documentation is (C)2009-2024 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"faq.html","title":"FAQ","text":""},{"location":"faq.html#how-can-i-contact-the-developers","title":"How can I contact the developers?","text":"<ul> <li>Community forum.</li> <li>PMM project in JIRA.</li> </ul>"},{"location":"faq.html#what-are-the-minimum-system-requirements","title":"What are the minimum system requirements?","text":"<ul> <li>Server:<ul> <li>Disk: 1 GB per monitored database (1 week data retention)</li> <li>Memory: 2 GB per monitored database</li> <li>CPU: Supports <code>SSE4.2</code></li> </ul> </li> <li>Client:<ul> <li>Disk: 100 MB</li> </ul> </li> </ul> <p>See also</p> <ul> <li>Setting up PMM Server</li> <li>Setting up PMM Client</li> </ul>"},{"location":"faq.html#how-can-i-upgrade-from-version-1","title":"How can I upgrade from version 1?","text":"<p>There is no direct software upgrade path.</p> <p>You must set up PMM 2 and connect your existing clients to it.</p> <p>When all data is registered in PMM2 and expired in PMM1, decommission your PMM1 instance.</p> <p>See also</p> <ul> <li>Upgrade from PMM1</li> <li>Percona blog: Running PMM1 and PMM2 Clients on the Same Host</li> </ul>"},{"location":"faq.html#retention","title":"How to control data retention?","text":"<p>Go to  Configuration \u2192  Settings \u2192 Advanced Settings \u2192 Data retention to adjust the value in days.</p> <p>See also</p> <p>Configure data retention</p>"},{"location":"faq.html#how-are-pmm-server-logs-rotated","title":"How are PMM Server logs rotated?","text":"<p>PMM Server embeds multiple components, like Victoria Metrics, Query Analytics, Grafana, <code>managed</code>, PostgreSQL, ClickHouse, etc. (components). All PMM Server component logs are rotated by <code>supervisord</code>. The components\u2019 log rotation settings are stored in <code>*.ini</code> files within the <code>/etc/supervisord.d</code> directory. Those settings define both the maximum size of a log file and the number of log files to keep. The log rotation takes place once the log file reaches its maximum size.</p>"},{"location":"faq.html#what-privileges-are-required-to-monitor-a-mysql-instance","title":"What privileges are required to monitor a MySQL instance?","text":"<pre><code>SELECT, PROCESS, SUPER, REPLICATION CLIENT, RELOAD\n</code></pre> <p>See also</p> <p>Setting Up/Client/MySQL.</p>"},{"location":"faq.html#can-i-monitor-multiple-service-instances","title":"Can I monitor multiple service instances?","text":"<p>Yes.</p> <p>You can add multiple instances of MySQL or any other service to be monitored from the same PMM Client.</p> <p>To do this, you provide a unique port and IP address, or a socket for each instance, and specify a unique name for each. (If a name is not provided, PMM uses the name of the PMM Client host.)</p> <p>For example, to add MySQL monitoring for two local MySQL servers:</p> <pre><code>pmm-admin add mysql --username root --password root instance-01 127.0.0.1:3001\npmm-admin add mysql --username root --password root instance-02 127.0.0.1:3002\n</code></pre> <p>See also</p> <p><code>pmm-admin add mysql</code></p>"},{"location":"faq.html#can-i-rename-instances","title":"Can I rename instances?","text":"<p>Yes, by removing and re-adding with a different name.</p> <p>When you remove a monitoring service, previously collected data remains available in Grafana.  However, the metrics are tied to the instance name.  So if you add the same instance back with a different name, it will be considered a new instance with a new set of metrics.  So if you are re-adding an instance and want to keep its previous data, add it with the same name.</p>"},{"location":"faq.html#can-i-add-an-aws-rds-mysql-or-aurora-mysql-instance-from-a-non-default-aws-partition","title":"Can I add an AWS RDS MySQL or Aurora MySQL instance from a non-default AWS partition?","text":"<p>By default, the RDS discovery works with the default <code>aws</code> partition. But you can switch to special regions, like the GovCloud one, with the alternative AWS partitions (e.g. <code>aws-us-gov</code>) adding them to the Settings via the PMM Server API.</p> <p></p> <p>To specify other than the default value, or to use several, use the JSON Array syntax: <code>[\"aws\", \"aws-cn\"]</code>.</p>"},{"location":"faq.html#what-resolution-is-used-for-metrics","title":"What resolution is used for metrics?","text":"<p>The default values (in seconds):</p> Preset Low Medium High Rare 300 180 60 Standard 60 10 5 Frequent 30 5 1 Custom (defaults) 60 10 5 <p>See also</p> <p>Metrics resolution</p>"},{"location":"faq.html#how-do-i-set-up-alerting","title":"How do I set up Alerting?","text":"<p>When a monitored service metric reaches a defined threshold, PMM Server can trigger alerts for it using embedded Grafana Alerting functionality.</p> <p>For this, you must configure alerting rules that define conditions under which an alert should be triggered, and the contact points used to send the alert (e.g. email).</p> <p>Percona templated alerts enable you to create alerts based on built-in or custom templates to simplify the alert setup process. Grafana managed alerts allows attaching rules to your dashboard panel and enables you to create more sophisticated alerting rules. In addition, it can be easier to manage installations with a large number of hosts. This additional flexibility comes at the expense of simplicity.</p> <p>See also</p> <p>Grafana Alerting</p>"},{"location":"faq.html#how-do-i-use-a-custom-prometheus-configuration-file","title":"How do I use a custom Prometheus configuration file?","text":"<p>Normally, PMM Server fully manages the Prometheus configuration file.</p> <p>However, some users may want to change the generated configuration to add additional scrape jobs, configure remote storage, etc.</p> <p>From version 2.4.0, when <code>pmm-managed</code> starts the Prometheus file generation process, it tries to load the <code>/srv/prometheus/prometheus.base.yml</code> file first, to use it as a base for the <code>prometheus.yml</code> file.</p> <p>The <code>prometheus.yml</code> file can be regenerated by restarting the PMM Server container, or by using the <code>SetSettings</code> API call with an empty body.</p> <p>See also</p> <ul> <li>API</li> <li>Percona blog: Extending PMM\u2019s Prometheus Configuration</li> </ul>"},{"location":"faq.html#how-to-troubleshoot-an-update","title":"How to troubleshoot an Update?","text":"<p>See Troubleshoot update.</p>"},{"location":"faq.html#what-are-my-login-credentials-when-i-try-to-connect-to-a-prometheus-exporter","title":"What are my login credentials when I try to connect to a Prometheus Exporter?","text":"<ul> <li>User name: <code>pmm</code></li> <li>Password: Agent ID</li> </ul> <p>PMM protects an exporter\u2019s output from unauthorized access by adding an authorization layer. To access an exporter, you can use <code>pmm</code> as a user name and the Agent ID as a password. You can find the Agent ID corresponding to a given exporter by running <code>pmm-admin list</code>.</p> <p>See also</p> <p><code>pmm-admin list</code></p>"},{"location":"faq.html#how-to-provision-pmm-server-with-non-default-admin-password","title":"How to provision PMM Server with non-default admin password?","text":"<p>Currently, there is no API available to change the <code>admin</code> password. If you\u2019re deploying through Docker, you can use the following code snippet to change the password after starting the Docker container:</p> <pre><code>PMM_PASSWORD=\"mypassword\"\necho \"Waiting for PMM to initialize to set password...\"\nuntil [ \"`docker inspect -f {{.State.Health.Status}} pmm-server`\" = \"healthy\" ]; do sleep 1; done\ndocker exec -t pmm-server bash -c \u00a0\"grafana-cli --homepath /usr/share/grafana admin reset-admin-password $PMM_PASSWORD\"\n</code></pre> <p>(This example assumes your Docker container is named <code>pmm-server</code>.)</p>"},{"location":"faq.html#how-to-change-the-pmm-password-for-a-default-admin-user","title":"How to change the PMM password for a default admin user?","text":"<p>If you\u2019re deploying through Docker, you can change the default password for an admin user after starting the Docker container as follows:</p> <ul> <li>For PMM versions 2.27.0 and later:</li> </ul> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> <ul> <li>For PMM versions prior to 2.27.0:</li> </ul> <pre><code>docker exec -t pmm-server bash -c 'grafana-cli --homepath /usr/share/grafana --configOverrides cfg:default.paths.data=/srv/grafana admin reset-admin-password newpass'\n</code></pre>"},{"location":"faq.html#how-to-use-a-non-default-listen-port-for-pmm-admin","title":"How to use a non-default listen-port for pmm-admin?","text":"<p>If you configure the PMM agent to use a non-default listen-port, for pmm-admin to communicate with the agent, use the global flag <code>--pmm-agent-listen-port=LISTEN_PORT</code>.</p> <pre><code>--pmm-agent-listen-port=LISTEN_PORT\n</code></pre> <p>Example: To use the listen-port 8000</p> <p><pre><code>pmm-admin --pmm-agent-listen-port=8000 add postgresql --username=pmm-agent --password=pmm-agent-password --query-source=pgstatmonitor nameofpostgres\n</code></pre> If you are using OVF/AMI, you can change the default password through SSH by using the following command:</p> <pre><code>change-admin-password &lt;new_password&gt;\n</code></pre>"},{"location":"faq.html#how-does-pmm-handle-personal-and-confidential-data","title":"How does PMM handle personal and confidential data?","text":"<p>Read our Privacy Policy to learn how PMM manages personal and confidential data. More technical details can be found in Data handling in PMM.</p>"},{"location":"faq.html#why-am-i-getting-a-user-already-exists-error-when-logging-back-into-pmm","title":"Why am I getting a \u201cUser already exists\u201d error when logging back into PMM?","text":"<p>Following CVE fix 2023-3128 in the 2.38 release, PMM increases security by only allowing authentications based on the unique user ID provided by the identity provider.</p> <p>If you are trying to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, PMM 2.38 and later will show this error on second and subsequent authentications.</p> <p>Solution: we recommend logging into PMM using a Percona Account, as this is a highly secure authentication method. Workaround: if you need to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, you can use the following workaround to log into PMM:</p> <ul> <li>pass the <code>GF_AUTH_OAUTH_ALLOW_INSECURE_EMAIL_LOOKUP=1</code> environment variable to the PMM container OR</li> <li>set the <code>oauth_allow_insecure_email_lookup</code> config key in the auth section of the <code>grafana.ini</code> file. Keep in mind that any changes you make to this file are lost when upgrading PMM, so make sure to manually update this file after each upgrade.</li> </ul> <p>Important</p> <p>We do not recommend using the above workaround for an extended period. Instead, ensure user uniqueness across multiple identity providers, while also encouraging your identity provider to support a unique ID field, or choose a provider who does.</p>"},{"location":"get-help.html","title":"Get help from Percona","text":"<p>Our documentation guides are packed with information, but they can\u2019t cover everything you need to know about Percona Monitoring and Management (PMM). They also won\u2019t cover every scenario you might come across. Don\u2019t be afraid to try things out and ask questions when you get stuck.</p>"},{"location":"get-help.html#perconas-community-forum","title":"Percona\u2019s Community Forum","text":"<p>Be a part of a space where you can tap into a wealth of knowledge from other database enthusiasts and experts who work with Percona\u2019s software every day. While our service is entirely free, keep in mind that response times can vary depending on the complexity of the question. You are engaging with people who genuinely love solving database challenges.</p> <p>Visit the PMM Community Forum. It\u2019s an excellent place for discussions, technical insights, and support around Percona database software. If you\u2019re new and feeling a bit unsure, our FAQ and Guide for new users can ease you in.</p> <p>If you have thoughts, feedback, or ideas, the community team would like to hear from you at Any ideas on how to make the forum better?. We\u2019re always excited to connect and improve everyone\u2019s experience.</p>"},{"location":"get-help.html#percona-experts","title":"Percona Experts","text":"<p>Percona Experts bring years of experience in tackling tough database performance issues and design challenges. We understand your challenges when managing complex database environments. That\u2019s why we offer various services to help you simplify your operations and achieve your goals.</p> Service description 24/7 Expert support Our dedicated team of database experts is available 24/7 to assist you with any database issues. We provide flexible support plans tailored to your specific needs. Hands-on database management Our managed services team can take over the day-to-day management of your database infrastructure, freeing up your time to focus on other priorities. Expert consulting Our experienced consultants provide guidance on database topics like architecture design, migration planning, performance optimization, and security best practices. Comprehensive training Our training programs help your team develop skills to manage databases effectively, offering virtual and in-person courses. <p>We\u2019re here to help you every step of the way. Whether you need a quick fix or a long-term partnership, we\u2019re ready to provide your expertise and support.</p>"},{"location":"trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p>"},{"location":"dbaas/index.html","title":"Introduction to Database as a service (DBaaS)","text":"<p>Do not use for mission-critical workloads</p> <ul> <li>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</li> <li>DBaaS feature is available for PMM Admin users.</li> </ul> <p>Database as a service (DBaaS) feature of Percona Monitoring and Management (PMM) is an open source solution to run MySQL and MongoDB clusters on Kubernetes.</p> <p>It allows you to utilize the benefits of Kubernetes and Percona\u2019s operators to run and manage database clusters.</p>"},{"location":"dbaas/index.html#start-here","title":"Start here","text":"<ul> <li>Architecture and how DBaaS works</li> <li>Setting up</li> <li>Getting started with DBaaS</li> <li>Registering and managing Kubernetes clusters</li> <li>Creating and managing database clusters</li> <li>Creating or updating a database cluster from a DBaaS template</li> </ul>"},{"location":"dbaas/DBaaS_template.html","title":"Database cluster Templates","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>Database clusters can be created from templates using PMM. Database cluster Template allows operators to customize Database Clusters based on their requirements, environments, or infrastructure.</p> <p>Examples</p> <ul> <li> <p>Data clusters: Different load patterns, such as simple reads, heavy writes, 50%/50% read/write, and the number of connections.</p> </li> <li> <p>Infrastructure - Different parameters and tuning for the resulting cluster: such as network configuration (load balancing, exposure), storage classes/types, etc.</p> </li> <li> <p>Environment: Combination of database cluster and infrastructure that will affect the database cluster configuration.</p> </li> </ul>"},{"location":"dbaas/DBaaS_template.html#customize-pxc-db-configuration","title":"Customize PXC DB configuration","text":"<p>The following example shows how DBaaS users can create PXC DB clusters from a template that sets a custom MySQL configuration. The default MySQL configuration is the following:</p> <pre><code>[mysqld]\nwsrep_provider_options=\"gcache.size=600M\"\n</code></pre> <p>Note</p> <p>PXC DB configuration can be customized based on your needs. This can be accomplished by creating a template and changing that field.</p>"},{"location":"dbaas/DBaaS_template.html#create-custom-resource-definition-crd-template","title":"Create Custom Resource Definition (CRD) template","text":"<p>To create a template, do the following:</p> <ol> <li> <p>Identify the field(s) of interest by reading the PXC operator documentation and the PXC CRD. In this case, you have to change the <code>spec.pxc.configuration</code> field.</p> </li> <li> <p>Create a template CRD <code>pxctpl-crd-pxc-configuration.yaml</code> with just those small subset of fields.</p> <pre><code>    apiVersion: apiextensions.k8s.io/v1\n    kind: CustomResourceDefinition\n    metadata:\n    annotations:\n        controller-gen.kubebuilder.io/version: v0.8.0\n    creationTimestamp: null\n    name: pxctemplatepxcconfiguration.dbaas.percona.com\n    labels:\n        dbaas.percona.com/template: \"yes\"\n        dbaas.percona.com/engine: \"pxc\"\n    spec:\n    group: dbaas.percona.com\n    names:\n        kind: PXCTemplatePXCConfiguration\n        listKind: PXCTemplatePXCConfigurationList\n        plural: pxctemplatepxcconfiguration\n        singular: pxctemplatepxcconfiguration\n    scope: Namespaced\n    versions:\n    - name: v1\n        schema:\n        openAPIV3Schema:\n            properties:\n            apiVersion:\n                type: string\n            kind:\n                type: string\n            metadata:\n                type: object\n            spec:\n                properties:\n                pxc:\n                    properties:\n                    configuration:\n                        type: string\n                    type: object\n                type: object\n            status:\n                type: object\n            type: object\n        served: true\n        storage: true\n</code></pre> </li> <li> <p>Run the following command.</p> </li> </ol> <pre><code>kubectl apply -f pxctpl-crd-upgrade-options.yaml\n</code></pre> <p>For more information, see DatabaseCluster templates.</p>"},{"location":"dbaas/DBaaS_template.html#add-read-permissions-for-dbaas-operator","title":"Add read permissions for dbaas-operator","text":"<p>In order for the dbaas-operator to apply the template it needs access to the template CRs:</p> <pre><code>DBAAS_OPERATOR_MANAGER_ROLE=$(kubectl get clusterroles | grep dbaas-operator | grep -v metrics | grep -v proxy | cut -f 1 -d ' '); kubectl get clusterroles/\"$DBAAS_OPERATOR_MANAGER_ROLE\" -o yaml &gt; dbaas-operator-manager-role.yaml\ncat &lt;&lt;EOF &gt;&gt;dbaas-operator-manager-role.yaml\n- apiGroups:\n  - dbaas.percona.com\n  resources:\n  - pxctemplatepxcconfiguration\n  verbs:\n  - get\n  - list\nEOF\n</code></pre> <p>Run the following command:</p> <pre><code>kubectl apply -f dbaas-operator-manager-role.yaml\n</code></pre>"},{"location":"dbaas/DBaaS_template.html#create-pxctemplatepxcconfiguration-template-cr","title":"Create PXCTemplatePXCConfiguration Template CR","text":"<ol> <li> <p>Create a corresponding CR <code>pxctpl-pxc-config-max-connection-789.yaml</code> with the required values.</p> <p><pre><code>apiVersion: dbaas.percona.com/v1\nkind: PXCTemplatePXCConfiguration\nmetadata:\nname: pxc-config-max-connections-789\nlabels:\n    dbaas.percona.com/template: \"yes\"\n    dbaas.percona.com/engine: \"pxc\"\nspec:\npxc:\n    configuration: |\n    [mysqld]\n    max_connections = 789\n</code></pre> 2. Run the following command:</p> <pre><code>kubectl apply -f pxctpl-pxc-config-max-connection-789.yaml\n</code></pre> </li> </ol>"},{"location":"dbaas/DBaaS_template.html#create-a-db-cluster-from-template","title":"Create a DB cluster from template","text":"<p>To create a DB cluster from a template, do the following:</p> <ol> <li> <p>From the main menu navigate to  DBaaS \u2192 Create DB Cluster.</p> </li> <li> <p>On the Advanced Settings panel, select the template from the Templates drop-down.</p> <p></p> </li> <li> <p>Click <code>Create</code>.</p> </li> </ol>"},{"location":"dbaas/architecture.html","title":"DBaaS architecture","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>DBaaS is built on top of PMM and Kubernetes and the high-level architecture is shown below:</p> <p></p> <p>In DBaaS, the role of PMM is as follows:</p> <ol> <li>Expose Public REST API</li> <li>Provision Kubernetes cluster and install the following operators:<ol> <li>OLM (Operator Lifecycle Manager)</li> <li>Percona Operator for MongoDB</li> <li>Percona Operator for MySQL</li> <li>DBaaS operator</li> </ol> </li> </ol>"},{"location":"dbaas/architecture.html#operator-lifecycle-manager-olm","title":"Operator Lifecycle Manager (OLM)","text":"<p>DBaaS uses OLM to install and update operators. PMM installs OLM and Operator Catalog during the registration of the Kubernetes cluster.</p> <p>An Operator catalog is a repository of metadata that Operator Lifecycle Manager (OLM) can query to discover and install Operators and their dependencies on a cluster. OLM always installs Operators from the latest version of a catalog and if a new version of an operator becomes available, OLM can upgrade it once the user has accepted the upgrade. DBaaS uses its own catalog for OLM that has the following operators:</p> <ol> <li>DBaaS operator</li> <li>PXC operator</li> <li>PSMDB operator</li> <li>Victoria Metrics operator</li> </ol> <p></p> <p>Percona Catalog is an OLM catalog that stores ClusterServiceVersions and CustomResourceDefinitions for creation in a cluster, and stores metadata about packages and channels. It\u2019s a source of truth for the available versions of operators ready to use in DBaaS</p> <p>The installation of operators looks the following way</p> <p></p>"},{"location":"dbaas/architecture.html#dbaas-operator","title":"DBaaS operator","text":"<p>DBaaS operator is responsible for creating and managing databases following operator pattern and depends on underlying operators for running database clusters. It provides a simplified API to manage database clusters via <code>kubectl</code>.</p>"},{"location":"dbaas/backup_restore.html","title":"DBaaS backup and restore","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>You can add a backup schedule while creating DB clusters in DBaaS. This feature is a fusion of backup management and DBaaS in PMM. Currently, DBaaS only supports scheduled backups, which can only be enabled when a database cluster is created.</p> <p>To create a scheduled backup do the following:</p> <p>Prerequisites</p> <ol> <li> <p>Enable Backup management: </p> <p>From the main menu, navigate to  Configuration \u2192  Settings \u2192 Advanced Settings \u2192 Backup  Management to enable Backup management.</p> </li> <li> <p>Add a backup storage location:</p> <p>Note</p> <p>Currently, only S3 is supported.</p> <p>From the main menu, navigate to Backups \u2192 Storage Locations \u2192 Add storage location and enter all the required information to add a backup storage location. For details, see Prepare a storage location.</p> </li> </ol>"},{"location":"dbaas/backup_restore.html#create-a-backup-schedule","title":"Create a backup schedule","text":"<p>To create a backup schedule do the following:</p> <ol> <li> <p>From the main menu navigate to  DBaaS \u2192 DB Cluster.</p> </li> <li> <p>Click  toggle in the Enable backups panel.</p> <p></p> </li> <li> <p>In the Backup Information panel, enter the backup details.</p> </li> <li> <p>Set the schedule for when scheduled backups should take place:</p> <p>From the drop-down select the Scheduled time when you want the backup to take place.</p> </li> <li> <p>Click Create.</p> </li> </ol>"},{"location":"dbaas/backup_restore.html#restore-backup","title":"Restore backup","text":"<p>You can create a DBaaS cluster from a backup stored on S3. You can use backups from an existing cluster to spin up a new database cluster from this backup. </p> <p>To restore backup, do the following:</p> <ol> <li> <p>From the main menu navigate to  DBaaS \u2192 DB Cluster.</p> </li> <li> <p>Click  toggle in the Enable restore panel.</p> <p></p> </li> <li> <p>Enter the information on the Enable restore panel.</p> </li> <li> <p>Click Create.</p> </li> </ol>"},{"location":"dbaas/databases.html","title":"Databases","text":""},{"location":"dbaas/databases.html#db-clusters","title":"DB clusters","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p>"},{"location":"dbaas/databases.html#add-a-db-cluster","title":"Add a DB Cluster","text":"<p>In order to create a database cluster you must have at least one Kubernetes cluster registered to PMM.  Start here if you haven\u2019t done that yet.  </p> <p>Important</p> <p>In order for PMM to collect metrics from your DB clusters, you must first set the public address of your PMM server.</p> <p>You can create a DB cluster with the click of a button! We have populated all needed fields with suitable defaults but you can customize many aspects of your DB cluster\u2019s configuration.  </p> <p>To create a DB cluster, do the following:</p> <ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Click Create DB Cluster.</p> </li> <li> <p>From the drop-down menu, select the values for the following:</p> <ul> <li>Kubernetes Cluster</li> <li>Database Type</li> <li>Database Version</li> </ul> </li> <li> <p>Optionally expand Advanced Settings panel for further customization.</p> <ol> <li> <p>Select the number of nodes. (1 is the minimum)</p> </li> <li> <p>Select a preset Resources per Node.</p> <p>Small, Medium and Large are fixed preset values for Memory, CPU, and Disk.</p> <p>Values for the Custom preset can be edited.</p> <p>Beside each resource type is an estimate of the required and available resources represented numerically in absolute and percentage values, and graphically as a colored, segmented bar showing the projected ratio of used to available resources. A red warning triangle  is shown if the requested resources exceed those available.</p> <p></p> </li> <li> <p>Enter the following on the Database Configurations panel:</p> </li> <li> <p>Storage Class - Select the storage class from the drop-down. Storage classes allow dynamic provisioning of persistent storage for PMM. Using storage classes, you can create and attach volumes on-demand without manually managing the underlying storage infrastructure.</p> </li> <li> <p>Database configuration- Enter the config string into the Configuration text box to configure the database engine.</p> <p></p> </li> <li> <p>Enter the following on the Network and Security panel:</p> </li> <li> <p>Expose - Select this checkbox to make this DB cluster available outside of the kubernetes cluster.</p> </li> <li>Internet Facing - Select this checkbox if you want the cluster to be accessible on the Internet.</li> <li>Source Range - For security, you can control the exposure level by providing the IP address in the Source Range field. This allows you to choose the IP addresses that can access your DB cluster. To add more than one source range, click Add New.</li> </ol> </li> <li> <p>Click Create Cluster to create your cluster.</p> </li> <li> <p>A row appears with information on your cluster:</p> <p></p> <ul> <li>Name: The cluster name.</li> <li>Database: The cluster database type and version.</li> <li>Connection:<ul> <li>Host: The hostname.</li> <li>Port: The port number.</li> <li>Username: The connection username.</li> <li>Password: The connection password (click the eye icon  to reveal).</li> </ul> </li> <li>DB Cluster Parameters:<ul> <li>K8s cluster name: The Kubernetes cluster name.</li> <li>CPU: The number of CPUs allocated to the cluster.</li> <li>Memory: The amount of memory allocated to the cluster.</li> <li>Disk: The amount of disk space allocated to the cluster.</li> </ul> </li> <li>Cluster Status:<ul> <li>PENDING: The cluster is being created.</li> <li>ACTIVE: The cluster is active.</li> <li>FAILED: The cluster could not be created.</li> <li>DELETING: The cluster is being deleted.</li> <li>UPDATING: The cluster is being updated.</li> </ul> </li> </ul> </li> </ol>"},{"location":"dbaas/databases.html#delete-a-db-cluster","title":"Delete a DB Cluster","text":"<ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Find the row with the database cluster you want to delete.</p> </li> <li> <p>In the Actions column, open the  menu and click Delete.</p> </li> <li> <p>Confirm the action by clicking Proceed, or abandon by clicking Cancel.</p> <p></p> </li> </ol> <p>Danger</p> <p>Deleting a cluster also deletes any attached volumes.  Please proceed with caution. </p>"},{"location":"dbaas/databases.html#edit-a-db-cluster","title":"Edit a DB Cluster","text":"<ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Find the row with the database cluster you want to change.</p> </li> <li> <p>In the Actions column, open the  menu and click Edit.</p> </li> </ol> <p>A paused cluster can\u2019t be edited.</p>"},{"location":"dbaas/databases.html#restart-a-db-cluster","title":"Restart a DB Cluster","text":"<ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Identify the database cluster to be changed.</p> </li> <li> <p>In the Actions column, open the  menu and click Restart.</p> </li> </ol>"},{"location":"dbaas/databases.html#suspend-or-resume-a-db-cluster","title":"Suspend or resume a DB Cluster","text":"<ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Identify the DB cluster to suspend or resume.</p> </li> <li> <p>In the Actions column, open the  menu and click the required action:</p> <ul> <li> <p>For active clusters, click Suspend.</p> <p></p> </li> <li> <p>For paused clusters, click Resume.</p> <p></p> </li> </ul> </li> </ol>"},{"location":"dbaas/databases.html#update-a-db-cluster","title":"Update a DB Cluster","text":"<ol> <li> <p>Select the DB Cluster tab.</p> </li> <li> <p>Identify the DB cluster to update.</p> </li> <li> <p>In the Actions column, open the  menu and click Update:</p> <p></p> </li> <li> <p>Confirm the update by clicking on Update, or abandon by clicking Cancel.</p> <p></p> </li> </ol> <p>See also</p> <p>Setting up a development environment for DBaaS</p>"},{"location":"dbaas/get-started.html","title":"Getting started with DBaaS","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>The DBaaS dashboard is where you add, remove, and operate on Kubernetes and database clusters.</p>"},{"location":"dbaas/get-started.html#activate-dbaas","title":"Activate DBaaS","text":"<p>The DBaaS feature is turned off by default. To turn it on:</p> <ol> <li> <p>Go to  Configuration \u2192  Settings \u2192 Advanced Settings.</p> </li> <li> <p>Click the  toggle in the Technical preview features section of the page.</p> </li> </ol>"},{"location":"dbaas/get-started.html#open-the-dbaas-dashboard","title":"Open the DBaaS dashboard","text":"<p>From the left menu, select  DBaaS.</p> <p></p>"},{"location":"dbaas/get-started.html#kubernetes-clusters","title":"Kubernetes clusters","text":""},{"location":"dbaas/get-started.html#add-a-kubernetes-cluster-automatically","title":"Add a Kubernetes cluster automatically","text":"<p>Availability</p> <p>Automatic addition of k8s cluster in PMM is available starting with PMM 2.34.0.</p> <p>In order to simplify DBaaS, k8s clusters can now be automatically added to PMM as follows:</p> <p>Prerequisites: Helm Chart/Manifest installed</p> <ol> <li> <p>Use Helm to install PMM server on Kubernetes clusters. For more information, see documentation.     <pre><code>helm install pmm --set service.type=\"LoadBalancer\" --set image.repository=percona/pmm-server --set image.tag=2.34.0 --set secret.pmm_password=admin percona/pmm\n</code></pre></p> </li> <li> <p>Log in to PMM.</p> </li> <li> <p>Enable PMM in DBaaS.</p> </li> <li> <p>You should see the default k8s cluster added in DBaaS.</p> </li> </ol>"},{"location":"dbaas/get-started.html#add-a-kubernetes-cluster","title":"Add a Kubernetes cluster","text":"<p>Caution</p> <p>Ensure that you set PMM Public Address under  Configuration \u2192  Settings \u2192 Advanced Settings before creating a Kubernetes cluster. Otherwise, PMM would not monitor the Kubernetes cluster along with the associated database clusters.</p> <p>Percona Operator for MySQL and [Percona Operator for MongoDB](https://docs.percona.com/percona-operator-for-mongodb/index.html are installed as part of the Kubernetes cluster registration process. It enables you to deploy database clusters into the Kubernetes cluster.</p> <p>If a public address is set the VictoriaMetrics Operator is also installed as part of the Kubernetes cluster registration process. It lets you monitor a kubernetes cluster via PMM.</p> <ol> <li> <p>Click Register new Kubernetes Cluster.</p> </li> <li> <p>Copy the value of Kubeconfig file and click Paste from clipboard to copy the content of the kubeconfig file in the corresponding field. The value of Kubernetes Cluster Name gets auto-populated from the contents of the kubeconfig file.</p> </li> </ol> <p>Availability</p> <p>This feature is available starting with PMM 2.30.0.</p> <p>This feature is available only in secure contexts (HTTPS) and some supporting browsers.</p> <p></p> <p>For a Kubernetes cluster, when using Amazon Elastic Kubernetes Service (EKS) and the kubeconfig file does not contain the AWS access key ID and AWS secret access key. Select the Using Amazon Elastic Kubernetes Service (EKS) checkbox and enter the access key ID and secret access key in the respective fields. Please refer to the AWS documentation for instructions on how to get these.</p> <p></p> <ol> <li> <p>Click Register.</p> </li> <li> <p>A message will momentarily display telling you whether the registration was successful or not.</p> <p></p> </li> </ol>"},{"location":"dbaas/get-started.html#unregister-a-kubernetes-cluster","title":"Unregister a Kubernetes cluster","text":"<p>Important</p> <p>You can\u2019t unregister a Kubernetes cluster if there DB clusters associated with it.</p> <ol> <li> <p>Click Unregister.</p> </li> <li> <p>Confirm the action by clicking Proceed, or abandon by clicking Cancel.</p> </li> </ol>"},{"location":"dbaas/get-started.html#view-a-kubernetes-clusters-configuration","title":"View a Kubernetes cluster\u2019s configuration","text":"<ol> <li> <p>Find the row with the Kubernetes cluster you want to see.</p> </li> <li> <p>In the Actions column, open the  menu and click Show configuration.</p> </li> </ol>"},{"location":"dbaas/get-started.html#manage-allowed-component-versions","title":"Manage allowed component versions","text":"<p>Administrators can select allowed and default versions of components for each cluster.</p> <ol> <li> <p>Find the row with the Kubernetes cluster you want to manage.</p> </li> <li> <p>In the Actions column, open the  menu and click Manage versions.</p> <p></p> </li> <li> <p>Select an Operator and Component from the drop-down menus.</p> <p></p> </li> <li> <p>Activate or deactivate allowed versions, and select a default in the Default menu.</p> </li> <li> <p>Click Save.</p> </li> </ol>"},{"location":"dbaas/get-started.html#kubernetes-operator-status","title":"Kubernetes operator status","text":"<p>The Kubernetes Cluster tab shows the status of operators.</p> <p></p>"},{"location":"dbaas/get-started.html#kubernetes-operator-update","title":"Kubernetes operator update","text":"<p>When a new version of the operator is available the Operators column shows a message with this information. Click the message to go to the operator release notes to find out more about the update.</p> <p></p> <p>To update the cluster:</p> <ol> <li> <p>Find the row with the operator you want to update.</p> </li> <li> <p>Click the Update button in front of the operator.</p> </li> <li> <p>Confirm the action by clicking Update, or abandon by clicking Cancel.</p> <p></p> </li> </ol>"},{"location":"dbaas/setting-up.html","title":"Setting up DBaaS","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>To use the Database as a Service (DBaaS) solution in PMM there are a few things that need to be setup first including a suitable Kubernetes Cluster.  If you\u2019ve already got a kubernetes cluster you can jump ahead and enable DBaaS in PMM.</p> <p>If you don\u2019t have a Kubernetes cluster available you can use the free K8s provided by Percona for evaluation which will allow you to play around with DBaaS for 3 hours before the cluster expires. For a Kubernetes cluster that doesn\u2019t expire you can use our \u201ceasy script\u201d, you can find the instructions here.</p> <p>In the sections that follow we\u2019ll try to outline the steps to create your own Kubernetes cluster in a few popular ways.</p>"},{"location":"dbaas/setting-up.html#red-hat-centos","title":"Red Hat, CentOS","text":"<pre><code>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum -y install docker-ce\nusermod -a -G docker centos\nsystemctl enable docker\nsystemctl start docker\n</code></pre>"},{"location":"dbaas/setting-up.html#debian-ubuntu","title":"Debian, Ubuntu","text":"<pre><code>apt-add-repository https://download.docker.com/linux/centos/docker-ce.repo\nsystemctl enable docker\nsystemctl start docker\n</code></pre>"},{"location":"dbaas/setting-up.html#minikube","title":"minikube","text":"<p>Please follow minikube\u2019s documentation to install it.</p>"},{"location":"dbaas/setting-up.html#red-hat-centos_1","title":"Red Hat, CentOS","text":"<pre><code>yum -y install curl\ncurl -Lo /usr/local/sbin/minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nchmod +x /usr/local/sbin/minikube\nln -s /usr/local/sbin/minikube /usr/sbin/minikube\nalias kubectl='minikube kubectl --'\n</code></pre>"},{"location":"dbaas/setting-up.html#start-pmm-server-and-activate-a-dbaas-feature","title":"Start PMM server and activate a DBaaS feature","text":"<ul> <li>To start a fully-working 3 node XtraDB cluster, consisting of sets of 3x HAProxy, 3x PXC and 6x PMM Client containers, you will need at least 9 vCPU available for minikube. (1x vCPU for HAProxy and PXC and 0.5vCPU for each pmm-client containers).</li> <li>DBaaS does not depend on PMM Client.</li> <li>You can pass the environment variable <code>--env ENABLE_DBAAS=1</code> to force the DBaaS feature when starting up pmm-server container. You can omit the variable and enable the feature later using PMM UI, please follow the link in step 3. below.</li> <li>Add the option <code>--network minikube</code> if you run PMM Server and minikube in the same Docker instance. (This will share a single network and the kubeconfig will work.)</li> <li>Add the options <code>--env PMM_DEBUG=1</code> and/or <code>--env PMM_TRACE=1</code> if you need extended debug details</li> </ul> <ol> <li> <p>Start PMM server:</p> <pre><code>docker run --detach --publish 80:80 --publish 443:443 --name pmm-server percona/pmm-server:2\n</code></pre> </li> <li> <p>Change the default administrator credentials:</p> <p>(This step is optional, because the same can be done from the web interface of PMM on first login.)</p> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> </li> </ol> <p>Important</p> <p>You must activate DBaaS using the PMM UI if you omitted <code>--env ENABLE_DBAAS=1</code> when starting up the container.</p>"},{"location":"dbaas/setting-up.html#create-a-kubernetes-cluster","title":"Create a Kubernetes cluster","text":"<p>The DBaaS feature uses Kubernetes clusters to deploy database clusters. You must first create a Kubernetes cluster and then add it to PMM using <code>kubeconfig</code> to get a successful setup.  </p> <p>Here are links to the current Kubernetes versions supported by DBaaS:</p> <ul> <li>Percona Server for MySQL</li> <li>Percona Server for MongoDB</li> </ul>"},{"location":"dbaas/setting-up.html#minikube_1","title":"Minikube","text":"<ol> <li> <p>Configure and start minikube:</p> <pre><code>minikube start --cpus=16 --memory=32G\n</code></pre> </li> <li> <p>Get your kubeconfig details from <code>minikube</code>. (You need these to register your Kubernetes cluster with PMM Server):</p> <pre><code>minikube kubectl -- config view --flatten --minify\n</code></pre> <p>You will need to copy this output to your clipboard and continue with adding a Kubernetes cluster to PMM.</p> </li> </ol>"},{"location":"dbaas/setting-up.html#amazon-aws-eks","title":"Amazon AWS EKS","text":"<ol> <li> <p>Create your cluster via <code>eksctl</code> or the Amazon AWS interface. For example:</p> <p><pre><code>eksctl create cluster --write-kubeconfig --name=your-cluster-name --zones=us-west-2a,us-west-2b --kubeconfig &lt;PATH_TO_KUBECONFIG&gt;\n</code></pre> 2. Copy the resulting kubeconfig and follow these instructions to register a Kubernetes cluster to PMM.</p> </li> </ol>"},{"location":"dbaas/setting-up.html#google-gke","title":"Google GKE","text":"<ol> <li> <p>Create your cluster either with Google Cloud Console or <code>gcloud</code> command line tool:</p> <p>The command below assumes that your <code>gcloud</code> command line tool is properly configured and your user authenticated and authorized to manage GKE Clusters. This example creates a minimal zonal cluster using preemptive node machines, ideal for testing the DBaaS functionality.</p> <pre><code>gcloud container clusters create --zone europe-west3-c pmm-dbaas-cluster --cluster-version 1.19 --machine-type e2-standard-4 --preemptible --num-nodes=3\ngcloud container clusters get-credentials pmm-dbaas-cluster --zone=europe-west3-c\nkubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=&lt;&lt;your_user@your_company.com&gt;&gt;\n</code></pre> </li> <li> <p>Create <code>ServiceAccount</code>, <code>ClusterRole</code> and <code>RoleBindings</code> (required Roles are deployed automatically when PMM deploys Operators) using the following command:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: percona-dbaas-cluster-operator\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: service-account-percona-server-dbaas-xtradb-operator\nsubjects:\n- kind: ServiceAccount\n  name: percona-dbaas-cluster-operator\nroleRef:\n  kind: Role\n  name: percona-xtradb-cluster-operator\n  apiGroup: rbac.authorization.k8s.io\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: service-account-percona-server-dbaas-psmdb-operator\nsubjects:\n- kind: ServiceAccount\n  name: percona-dbaas-cluster-operator\nroleRef:\n  kind: Role\n  name: percona-server-mongodb-operator\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: service-account-percona-server-dbaas-admin\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: service-account-percona-server-dbaas-operator-admin\nsubjects:\n- kind: ServiceAccount\n  name: percona-dbaas-cluster-operator\n  namespace: default\nroleRef:\n  kind: ClusterRole\n  name: service-account-percona-server-dbaas-admin\n  apiGroup: rbac.authorization.k8s.io\nEOF\n</code></pre> </li> <li> <p>Extract variables required to generate a kubeconfig:</p> <pre><code>name=`kubectl get serviceAccounts percona-dbaas-cluster-operator -o json | jq  -r '.secrets[].name'`\ncertificate=`kubectl get secret $name -o json | jq -r  '.data.\"ca.crt\"'`\ntoken=`kubectl get secret $name -o json | jq -r  '.data.token' | base64 -d`\nserver=`kubectl cluster-info | grep 'Kubernetes control plane' | cut -d ' ' -f 7`\n</code></pre> </li> <li> <p>Generate your kubeconfig file (copy the output):</p> <pre><code>echo \"\napiVersion: v1\nkind: Config\nusers:\n- name: percona-dbaas-cluster-operator\n  user:\n    token: $token\nclusters:\n- cluster:\n    certificate-authority-data: $certificate\n    server: $server\n  name: self-hosted-cluster\ncontexts:\n- context:\n    cluster: self-hosted-cluster\n    user: percona-dbaas-cluster-operator\n  name: svcs-acct-context\ncurrent-context: svcs-acct-context\n\"\n</code></pre> </li> <li> <p>Follow the instructions on How to add a Kubernetes cluster with kubeconfig from the previous step.</p> </li> </ol>"},{"location":"dbaas/setting-up.html#deleting-clusters","title":"Deleting clusters","text":"<p>If a Public Address is set in PMM Settings, for each DB cluster an API Key is created which can be found on the page <code>/graph/org/apikeys</code>. You should not delete them (for now, until issue PMM-8045 is fixed) \u2013 once a DB cluster is removed from DBaaS, the related API Key is also removed.</p> <p>For example, if you only run <code>eksctl delete cluster</code> to delete an Amazon EKS cluster without cleaning up the cluster first, there will be a lot of orphaned resources such as Cloud Formations, Load Balancers, EC2 instances, Network interfaces, etc. The same applies for Google GKE clusters.</p>"},{"location":"dbaas/setting-up.html#cleaning-up-kubernetes-cluster","title":"Cleaning up Kubernetes cluster","text":"<ol> <li> <p>You should delete all database clusters, backups and restores.</p> <pre><code>kubectl delete perconaxtradbclusterbackups.pxc.percona.com --all\nkubectl delete perconaxtradbclusters.pxc.percona.com --all\nkubectl delete perconaxtradbclusterrestores.pxc.percona.com --all\n\nkubectl delete perconaservermongodbbackups.psmdb.percona.com --all\nkubectl delete perconaservermongodbs.psmdb.percona.com --all\nkubectl delete perconaservermongodbrestores.psmdb.percona.com --all\n</code></pre> </li> <li> <p>In the <code>dbaas-controller</code> repository, in the deploy directory there are manifests we use to deploy operators. Use them to delete operators and related resources from the cluster.</p> <p>Important</p> <ul> <li>Do NOT execute this step before all database clusters, backups and restores are deleted in the previous step. It may result in not being able to delete the namespace DBaaS lives in.</li> <li>Also be careful with this step if you are running DBaaS in more than one namespace as it deletes cluster level CustomResourceDefinitions needed to run DBaaS. This would break DBaaS in other namespaces. Delete just operators deployments in that case.</li> </ul> <pre><code># Delete the PXC operator and related resources.\ncurl https://raw.githubusercontent.com/percona-platform/dbaas-controller/7a5fff023994cecf6bde15705365114004b50b41/deploy/pxc-operator.yaml | kubectl delete -f -\n\n# Delete the PSMDB operator and related resources.\ncurl https://raw.githubusercontent.com/percona-platform/dbaas-controller/7a5fff023994cecf6bde15705365114004b50b41/deploy/psmdb-operator.yaml | kubectl delete -f -\n</code></pre> </li> <li> <p>Delete the name space where the DBaaS is running, this will delete all remaining name space level resources if any are left.</p> <pre><code>kubectl delete namespace &lt;your-namespace&gt;\n</code></pre> </li> <li> <p>Delete the Kubernetes cluster. The method depends on your cloud provider:</p> <ul> <li>Delete GKE cluster.</li> <li>Delete Amazon EKS cluster.</li> </ul> </li> </ol>"},{"location":"dbaas/setting-up.html#run-pmm-server-as-a-docker-container-for-dbaas","title":"Run PMM Server as a Docker container for DBaaS","text":"<ol> <li> <p>Start PMM server from a feature branch:</p> <pre><code>docker run --detach --name pmm-server --publish 80:80 --publish 443:443 --env ENABLE_DBAAS=1  percona/pmm-server:2;\n</code></pre> <p>Important</p> <ul> <li>Use <code>--network minikube</code> if running PMM Server and minikube in the same Docker instance. This way they will share single network and the kubeconfig will work.</li> <li>Use Docker variables <code>--env PMM_DEBUG=1 --env PMM_TRACE=1</code> to see extended debug details.</li> </ul> </li> <li> <p>Change the default administrator credentials:</p> <p>This step is optional, because the same can be done from the web interface of PMM on the first login.</p> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> </li> <li> <p>Set the public address for PMM Server in PMM settings UI</p> </li> <li> <p>Follow the steps for Add a Kubernetes cluster.</p> </li> <li> <p>Follow the steps for Add a DB Cluster.</p> </li> <li> <p>Get the IP address to connect your app/service:</p> <pre><code>minikube kubectl get services\n</code></pre> </li> </ol>"},{"location":"dbaas/setting-up.html#exposing-psmdb-and-xtradb-clusters-for-access-by-external-clients","title":"Exposing PSMDB and XtraDB clusters for access by external clients","text":"<p>To make services visible externally, you create a LoadBalancer service or manually run commands to expose ports:</p> <pre><code>kubectl expose deployment hello-world --type=NodePort.\n</code></pre> <p>See also</p> <ul> <li>DBaaS Dashboard</li> <li>Install minikube</li> <li>Setting up a Standalone MYSQL Instance on Kubernetes &amp; exposing it using Nginx Ingress Controller</li> <li>Use a Service to Access an Application in a Cluster</li> <li>Exposing applications using services</li> </ul>"},{"location":"dbaas/troubleshoot-kubernetes.html","title":"Troubleshoot kubernetes","text":""},{"location":"dbaas/troubleshoot-kubernetes.html#troubleshooting-kubernetes-provisioning","title":"Troubleshooting Kubernetes provisioning","text":"<p>Do not use for mission-critical workloads</p> <p>DBaaS feature is deprecated. We encourage you to use Percona Everest instead. Check our Migration guide.</p> <p>There are two things that might go wrong during the provisioning:</p> <ol> <li>OLM installation</li> <li>Operators installation</li> </ol>"},{"location":"dbaas/troubleshoot-kubernetes.html#troubleshooting-olm-installation","title":"Troubleshooting OLM installation","text":"<p>By default OLM installs its operators and catalogs into <code>olm</code> namespace. Here\u2019s the example of successful installation of OLM</p> <pre><code>kubectl get pods -n olm\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncatalog-operator-67bcbb4f5d-jmdhv                                 1/1     Running     0          16h\nolm-operator-d9f76fdc9-7vdx2                                      1/1     Running     0          16h\noperatorhubio-catalog-4gzfk                                       1/1     Running     0          74s\npackageserver-877948445-swdq5                                     1/1     Running     0          16h\npackageserver-877948445-sz44r                                     1/1     Running     0          16h\npercona-dbaas-catalog-777hb                                       1/1     Running     0          16h\n</code></pre> <p>Note: the output may be longer but it shows what needs to be installed automatically</p> <ol> <li>OLM Operator is responsible for deploying applications defined by CSV resources after the required resources specified in the CSV are present in the cluster.</li> <li>The Catalog Operator is responsible for resolving and installing CSVs and the required resources they specify. It is also responsible for watching CatalogSources for updates to packages in channels and upgrading them (optionally automatically) to the latest available versions.</li> <li>Packageserver is responsible for providing metadata to the operators like ClusterServiceVersion that is used for installing/upgrading operators.</li> <li>percona-dbaas-catalog is Percona\u2019s managed catalog that defines which operators\u2019 versions are available. This component has information about tested and supported versions of operators.</li> </ol> <p>You can use <code>kubectl describe pod -n olm podName</code> to understand what went wrong during the installation.</p>"},{"location":"dbaas/troubleshoot-kubernetes.html#troubleshooting-operators-installation","title":"Troubleshooting operators installation","text":"<p>Once OLM is installed, PMM does the following actions to install each operator:</p> <ol> <li>Creates a subscription for an operator</li> <li>Approves the first available install plan automatically</li> </ol> <p>Once the install plan is approved OLM will create a corresponding ClusterServiceVersion automatically and install the operator.</p> <p>During this process the following steps might go wrong</p> <ol> <li>Subscription was not created</li> <li>Install plan was not created</li> <li>Installation of CSV failed</li> </ol>"},{"location":"dbaas/troubleshoot-kubernetes.html#listing-subscriptions","title":"Listing subscriptions","text":"<p><pre><code> kubectl get sub\nNAME                              PACKAGE                           SOURCE                  CHANNEL\ndbaas-operator                    dbaas-operator                    percona-dbaas-catalog   stable-v0\npercona-server-mongodb-operator   percona-server-mongodb-operator   percona-dbaas-catalog   stable-v1\npercona-xtradb-cluster-operator   percona-xtradb-cluster-operator   percona-dbaas-catalog   stable-v1\nvictoriametrics-operator          victoriametrics-operator          percona-dbaas-catalog   stable-v0\n</code></pre> Note: Names may may vary depending on the version of PMM you\u2019re using</p>"},{"location":"dbaas/troubleshoot-kubernetes.html#listing-install-plans","title":"Listing install plans","text":"<p>Once subscriptions are created and the catalog operator found a CSV to be installed it creates install plans for each operator which are approved by PMM automatically during the provisioning process. The upgrading process should be approved by a user.</p> <pre><code>kubectl get ip\nNAME            CSV                                       APPROVAL   APPROVED\ninstall-6gp4k   percona-xtradb-cluster-operator.v1.11.0   Manual     true\ninstall-77jtx   victoriametrics-operator.v0.29.1          Manual     true\ninstall-7lgsj   victoriametrics-operator.v0.29.1          Manual     true\ninstall-bjmvj   victoriametrics-operator.v0.29.1          Manual     true\n</code></pre>"},{"location":"dbaas/troubleshoot-kubernetes.html#listing-csv-or-how-to-be-sure-that-operators-were-installed","title":"Listing CSV or how to be sure that operators were installed","text":"<pre><code>kubectl get csv\nNAME                                      DISPLAY                                                      VERSION   REPLACES                                  PHASE\ndbaas-operator.v0.0.19                    DBaaS operator                                               0.0.19                                              Succeeded\npercona-server-mongodb-operator.v1.11.0   Percona Distribution for MongoDB Operator                    1.11.0    percona-server-mongodb-operator.v1.10.0   Succeeded\npercona-xtradb-cluster-operator.v1.11.0   Percona Operator for MySQL based on Percona XtraDB Cluster   1.11.0    percona-xtradb-cluster-operator.v1.10.0   Succeeded\nvictoriametrics-operator.v0.29.1          VictoriaMetrics Operator                                     0.29.1    victoriametrics-operator.v0.27.2          Succeeded\n</code></pre>"},{"location":"details/index.html","title":"Details","text":"<ul> <li> <p>Architecture: High-level architecture and main components.</p> </li> <li> <p>User interface components: Descriptions of the main menus and icons.</p> </li> <li> <p>PMM components and versions: PMM components and their version used in PMM.</p> </li> <li> <p>Data handling in PMM: Personal and confidential data handling in PMM.</p> </li> <li> <p>QAN under the hood: The Query Analytics dashboard provides insights into query execution and time allocation, helping you analyze database queries over time. It enables you to optimize database performance and identify and resolve issues at their source.</p> </li> <li> <p>Developing Advisor checks: Database health assessments.</p> </li> <li> <p>Dashboards reference: A complete list of dashboards by category, with screenshots.</p> </li> <li> <p>Commands:</p> </li> <li> <p>pmm-admin: The manual page for the PMM administration tool.</p> </li> <li> <p>pmm-agent: The manual page for the PMM Client agent program.</p> </li> <li> <p>API: How to access the Swagger API.</p> </li> <li> <p>VictoriaMetrics: The monitoring solution and time-series database that replaced Prometheus in PMM 2.12.0.</p> </li> <li> <p>ClickHouse:  A third-party column-oriented database management system (DBMS) that facilitates the Query Analytics functionality.</p> </li> <li> <p>PostgreSQL:  An open source object-relational database management system used as the primary data store.</p> </li> <li> <p>Glossary: A list of obscure terms and definitions.</p> </li> </ul>"},{"location":"details/api.html","title":"API","text":""},{"location":"details/api.html#interactive-api-documentation","title":"Interactive API documentation","text":"<p>To integrate your applications or CI/CD, you can use our online interactive documentation.</p>"},{"location":"details/api.html#swagger-api-documentation","title":"Swagger API documentation","text":"<p>PMM Server lets you visually interact with API resources representing all objects within PMM. You can browse the API using the Swagger UI, accessible at the <code>/swagger</code> endpoint URL:</p> <p></p> <p>Clicking on an object lets you examine objects and execute requests on them:</p> <p></p> <p>The objects visible are nodes, services, and agents:</p> <ul> <li> <p>A Node can be a bare metal server, a virtual machine, a Docker container, or a more specific type such as an Amazon RDS Node. A node runs zero or more Services and Agents, and has zero or more Agents providing insights for it.</p> </li> <li> <p>A Service is generally a database running on the Node: Amazon Aurora MySQL, MySQL, MongoDB, PostgreSQL, etc. It runs on zero (Amazon Aurora Serverless), single (MySQL), or several (Percona XtraDB Cluster) Nodes. It also has zero or more Agents providing insights for it.</p> </li> <li> <p>An Agent is an executable binary, that runs on the Node. It is not useful by itself, but instead provides insights (metrics, query performance data, etc.) about Nodes and/or Services. An agent always runs on the single Node (except External Exporters), and provides insights for zero or more Services and Nodes.</p> </li> </ul> <p>Nodes, Services, and Agents have Types which define their specific properties, and their specific logic.</p> <p>Nodes and Services are external by nature \u2013 we do not manage them (create, destroy), but merely maintain their inventory (add to inventory, remove from inventory) in <code>pmm-managed</code>. Most Agents are started and stopped by <code>pmm-agent</code>. One exception is the External Exporter Type which is started externally.</p>"},{"location":"details/api.html#api-keys-and-authentication","title":"API Keys and authentication","text":"<p>API keys are used to control access to the PMM server components and resources. With an API key, you are authenticated to the PMM server, have access to PMM server components and resources, and perform various actions on them. You can use API keys as a replacement for basic authentication.</p>"},{"location":"details/api.html#generate-api-keys","title":"Generate API keys","text":"<p>PMM uses the Grafana API keys for authentication. Following are the steps to generate the API keys:</p> <ol> <li>Login to PMM.</li> <li>From the side menu, click Configuration  \u2192 API keys.</li> <li>On the Configuration page, click Add API Key.</li> <li>Add API key dialog box opens.</li> <li> <p>Enter  the following to generate an API key:</p> <ul> <li>key name (you can give any desired name)</li> <li>Select the Role from the drop-down </li> <li>Enter a value in the Time to live text box (hover on the tooltip for more information). </li> <li>Click Add.</li> </ul> </li> <li> <p>API Key Created window displays your newly created key. Make sure to copy your key and keep it secure. </p> </li> </ol>"},{"location":"details/api.html#authenticate","title":"Authenticate","text":"<p>You can authenticate your request using the HTTPS header.</p> <p>Important</p> <p>Use the <code>-k</code> or <code>--insecure</code> parameter to force cURL to ignore invalid and self-signed SSL certificate errors. The option will skip the SSL verification process, and you can bypass any SSL errors while still having SSL-encrypted communication. However, using the <code>--insecure</code>  parameter is not recommended. Although the data transfer is encrypted, it is not entirely secure. For enhanced security of your PMM installation, you need valid SSL certificates. For information on validating SSL certificates, refer to: SSL certificates.</p> <pre><code>curl -H \"Authorization: Bearer &lt;api_key&gt;\" https://127.0.0.1/v1/version\n</code></pre>"},{"location":"details/api.html#use-an-api-key-in-basic-auth","title":"Use an API key in basic auth","text":"<p>You can use the API key for basic authentication in a REST API call in the following format. Replace <code>API_KEY</code> with your API key.</p> <p>Example</p> <pre><code>curl -X GET https://api_key:API_KEY@127.0.0.1/v1/version\n</code></pre>"},{"location":"details/architecture.html","title":"Architecture","text":"<p>PMM is a client/server application built by Percona comprising its own and third-party components and tools.</p> <p></p>"},{"location":"details/architecture.html#pmm-server","title":"PMM Server","text":"<p>PMM Server is the heart of PMM. It receives data from clients, collects it, and stores it. Metrics are drawn as tables, charts and graphs within dashboards, each a part of the web-based user interface.</p>"},{"location":"details/architecture.html#pmm-client","title":"PMM Client","text":"<p>PMM Client is a collection of agents and exporters that run on the host being monitored.</p> <p>PMM Client runs on every database host or node you want to monitor. The client collects server metrics, general system metrics, query analytics and sends it to the server. Except when monitoring AWS RDS instances, a PMM Client must be running on the host to be monitored.</p>"},{"location":"details/architecture.html#percona-platform","title":"Percona Platform","text":"<p>Percona Platform provides value-added services for PMM.</p>"},{"location":"details/architecture.html#pmm-context","title":"PMM context","text":"<p>The PMM Client package provides:</p> <ul> <li>Exporters for each database and service type. When an exporter runs, it connects to the database or service instance, runs the metrics collection routines, and sends the results to PMM Server.</li> <li><code>pmm-agent</code>: Run as a daemon process, it starts and stops exporters when instructed.</li> <li><code>vmagent</code>: A VictoriaMetrics daemon process that sends metrics data (pushes) to PMM Server.</li> </ul> <p>The PMM Server package provides:</p> <ul> <li><code>pmm-managed</code></li> <li>Query Analytics</li> <li>Grafana</li> <li>VictoriaMetrics</li> </ul>"},{"location":"details/architecture.html#pmm-server_1","title":"PMM Server","text":"<p>PMM Server includes the following tools:</p> <ul> <li> <p>Query Analytics (QAN) enables you to analyze database query performance over periods of time. In addition to the client-side QAN agent, it includes the following:</p> <ul> <li>QAN API is the back-end for storing and accessing query data collected by the QAN agent running on a PMM Client.</li> <li>QAN App is a web application for visualizing collected Query Analytics data, which is part of the PMM Server\u2019s UI.</li> </ul> </li> <li> <p>Metrics Monitor provides a historical view of metrics that are critical to a MySQL or MongoDB server instance. It includes the following:</p> </li> <li> <p>VictoriaMetrics, a scalable time-series database. (Replaced Prometheus in PMM 2.12.0.)</p> </li> <li>ClickHouse is a third-party column-oriented database that facilitates the Query Analytics functionality.</li> <li>Grafana is a third-party dashboard and graph builder for visualizing data aggregated (by VictoriaMetrics or Prometheus) in an intuitive web interface.</li> <li>Percona Dashboards is a set of dashboards for Grafana developed by Percona.</li> </ul>"},{"location":"details/architecture.html#pmm-client_1","title":"PMM Client","text":"<p>The PMM Client package consists of the following:</p> <ul> <li> <p><code>pmm-admin</code> is a command-line tool for managing PMM Client, for example, adding and removing database instances that you want to monitor. (Read more).</p> </li> <li> <p><code>pmm-agent</code> is a client-side component of a minimal command-line interface, which is a central entry point in charge of bringing the client functionality: it carries on client\u2019s authentication, gets the client configuration stored on the PMM Server, manages exporters and other agents.</p> </li> <li> <p><code>node_exporter</code> is an exporter that collects general system metrics.</p> </li> <li> <p><code>mysqld_exporter</code> is an exporter that collects MySQL server metrics.</p> </li> <li> <p><code>mongodb_exporter</code> is an exporter that collects MongoDB server metrics.</p> </li> <li> <p><code>postgres_exporter</code> is an exporter that collects PostgreSQL performance metrics.</p> </li> <li> <p><code>proxysql_exporter</code> is an exporter that collects ProxySQL performance metrics.</p> </li> <li> <p><code>rds_exporter</code> is an exporter that collects Amazon RDS performance metrics.</p> </li> <li> <p><code>azure_database_exporter</code> is an exporter that collects Azure database performance metrics.</p> </li> </ul> <p>To make data transfer from PMM Client to PMM Server secure, all exporters are able to use SSL/TLS encrypted connections, and their communication with PMM server is protected by the HTTP basic authentication.</p> <p></p>"},{"location":"details/clickhouse%202.html","title":"ClickHouse","text":"<p>You can use an external ClickHouse database instance outside the PMM Server container running on other hosts.</p>"},{"location":"details/clickhouse%202.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use ClickHouse parameters as environment variables:</p> <p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production.</p> <p>To use ClickHouse as an external database instance, use the following environment variables: </p> <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> -&gt; hostname:port Name of the host and port of the external ClickHouse database instance.  <p>Optional environment variables</p> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> -&gt; database name Database name of the external ClickHouse database instance. <code>\u200b\u200bPERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> -&gt; pool size The maximum number of threads in the current connection thread pool. This value cannot be bigger than max_thread_pool_size. <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> -&gt; max block size The number of rows to load from tables in one block for this connection. <p>Example</p> <p>To use ClickHouse as an external database instance, start the PMM docker with the specified variables for external ClickHouse: \u200b\u200b</p> <pre><code>-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=$ADDRESS:$PORT\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=$DB\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=1 \n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=65000\n</code></pre>"},{"location":"details/clickhouse%202.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the ClickHouse troubleshooting documentation.</p>"},{"location":"details/clickhouse.html","title":"ClickHouse","text":"<p>You can use an external ClickHouse database instance outside the PMM Server container running on other hosts.</p>"},{"location":"details/clickhouse.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use ClickHouse parameters as environment variables:</p> <p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production.</p> <p>To use ClickHouse as an external database instance, use the following environment variables: </p> <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> -&gt; hostname:port Name of the host and port of the external ClickHouse database instance.  <p>Optional environment variables</p> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> -&gt; database name Database name of the external ClickHouse database instance. <code>\u200b\u200bPERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> -&gt; pool size The maximum number of threads in the current connection thread pool. This value cannot be bigger than max_thread_pool_size. <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> -&gt; max block size The number of rows to load from tables in one block for this connection. <p>Example</p> <p>To use ClickHouse as an external database instance, start the PMM docker with the specified variables for external ClickHouse: \u200b\u200b</p> <pre><code>-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=$ADDRESS:$PORT\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=$DB\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=1 \n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=65000\n</code></pre>"},{"location":"details/clickhouse.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the ClickHouse troubleshooting documentation.</p>"},{"location":"details/glossary.html","title":"Glossary","text":""},{"location":"details/glossary.html#glossary","title":"Glossary","text":""},{"location":"details/glossary.html#annotation","title":"Annotation","text":"<p>A way of showing a mark on dashboards signifying an important point in time.</p>"},{"location":"details/glossary.html#dimension","title":"Dimension","text":"<p>In the Query Analytics dashboard, to help focus on the possible source of performance issues, you can group queries by dimension, one of: Query, Service Name, Database, Schema, User Name, Client Host</p>"},{"location":"details/glossary.html#ebs","title":"EBS","text":"<p>Amazon\u2019s Elastic Block Store.</p>"},{"location":"details/glossary.html#fingerprint","title":"Fingerprint","text":"<p>A normalized statement digest\u2014a query string with values removed that acts as a template or typical example for a query.</p>"},{"location":"details/glossary.html#iam","title":"IAM","text":"<p>Identity and Access Management (for Amazon AWS).</p>"},{"location":"details/glossary.html#mm","title":"MM","text":"<p>Metrics Monitor.</p>"},{"location":"details/glossary.html#numa","title":"NUMA","text":"<p>Non-Uniform Memory Access.</p>"},{"location":"details/glossary.html#pem","title":"PEM","text":"<p>Privacy Enhanced Mail.</p>"},{"location":"details/glossary.html#qps","title":"QPS","text":"<p>Queries Per Second. A measure of the rate of queries being monitored.</p>"},{"location":"details/glossary.html#query-analytics","title":"Query Analytics","text":"<p>Component of PMM Server that enables you to analyze MySQL query performance over periods of time.</p>"},{"location":"details/glossary.html#advisors","title":"Advisors","text":"<p>Automated checks that you can run against connected databases to identify any potential security threats, configuration problems, performance concerns, policy non-compliance issues etc. </p>"},{"location":"details/glossary.html#technical-preview","title":"Technical Preview","text":"<p>Releases intended for public preview and feedback, but with no support or service level agreement (SLA). Should not be used on production or business-critical systems. May contain breaking changes to UI, API, CLI. (Read more.)</p>"},{"location":"details/glossary.html#vg","title":"VG","text":"<p>Volume Group.</p>"},{"location":"details/interface.html","title":"UI components","text":"<p>Key</p> <ol> <li>Main menu (also Grafana menu, side menu)</li> <li>Navigation bar</li> <li>View controls</li> <li>View selectors (dynamic contents)</li> <li>Shortcut menu (dynamic contents)</li> </ol>"},{"location":"details/interface.html#main-menu","title":"Main menu","text":"<p>The main menu is part of the Grafana framework and is visible on every page.</p> Item (Top) Name Description Home Link to home dashboard. Search Search dashboards by name. Starred Mark your favorite dashboards. Dashboards Create dashboards or folders, manage dashboards, import dashboards, create playlists, manage snapshots. Operating System (OS) Operating System dashboard MySQL MySQL dashboard MongoDB MongoDB dashboard PostgreSQL PostgreSQL dashboard ProxySQL ProxySQL dashboard HAproxy HAproxy dashboard Query Analytics (QAN) Query Analytics Explore Run queries with PromQL. Percona Alerting Alerting, Create new alerts and manage your alert rules and alert templates. Configuration Entitlements This tab is displayed after connecting PMM to Percona Portal, and shows all your Percona Platform account information. Support Tickets Shows the list of tickets opened across your organization. This tab is only available after you connect PMM to Percona Platform. Environment Overview This tab is displayed after connecting PMM to Percona Portal. Shows the name and email of the Customer Success Manager assigned to your organization, who can help with any PMM queries. This tab will soon be populated with more useful information about your PMM environment. Server Admin Backup Management Backup management and storage location configuration. PMM Advisor Checks Run health assessment checks against your connected databases and check any failed checks. DBaaS <p>Tip</p> <p>The DBaaS icon appears only if a server feature flag has been set.</p> <p>The Backup Management icon appears when Backup Management is activated in  Configuration \u2192  Settings \u2192 Advanced Settings.</p> Icon (Bottom) Description (Profile icon) User menu Help"},{"location":"details/interface.html#navigation-bar","title":"Navigation bar","text":"Item (left) Description (Display only.) (Name) / (Optional) Folder name. (Name) Dashboard name. Mark as favorite. Share dashboard."},{"location":"details/interface.html#view-controls","title":"View controls","text":"Item (right) Description Dashboard settings. Cycle view mode.  (time range) Time range selector. Time range zoom out. Refresh dashboard. (Time interval) Refresh period."},{"location":"details/interface.html#view-selectors","title":"View selectors","text":"<p>This menu bar is context-sensitive; it changes according to the page you are on. (With wide menus on small screens, items may wrap to the next row.)</p> <p></p> Item Description Interval Data interval. Region Filter by region. Environment Filter by environment. Cluster Filter by cluster. Replication Set Filter by replication set. Node Name Filter by node name. Service Name Filter by service name. PMM Annotations View annotations."},{"location":"details/interface.html#shortcut-menu","title":"Shortcut menu","text":"<p>This menu contains shortcuts to other dashboards. The list changes according to the page you\u2019re on.</p> <p>This menu will be removed in future releases. Its function will be replaced by the  PMM Dashboards main menu entry.</p> Item Description  Home Home dashboard.  Query Analytics Query Analytics.  Compare Nodes compare. (Service Type) Service type menu (see Services menu).  HA HA dashboards.  Services Services menu.  PMM PMM menu. <p>Tip</p> <p>The Compare menu links to the Instances Overview dashboard for the current service type.</p>"},{"location":"details/interface.html#services-menu","title":"Services menu","text":"<p>The Services menu choice determines the Service Type menu.</p> Menu Item Service type menu Description Services MongoDB Instances Overview  MongoDB MongoDB dashboards. MySQL Instances Overview  MySQL MySQL dashboards. Nodes Overview  OS OS dashboards. PostgreSQL Instances Overview  PostgreSQL PostgreSQL dashboards. <p>Note</p> <ul> <li>You can easily access all dashboards for monitored services from the Main menu via Other Dashboards in the Services sub menu.</li> <li>Only the services being monitored by PMM will appear on the main menu.</li> </ul>"},{"location":"details/interface.html#pmm-menu","title":"PMM menu","text":"<p>This item lists shortcuts to utility pages.</p> Menu Item PMM PMM Add Instance PMM Advisor Checks PMM Inventory PMM Settings"},{"location":"details/personal_data_handling.html","title":"Data handling in PMM","text":"<p>The following questions are being answered related to personal and confidential data handling in PMM:</p> <ol> <li> <p>Which type of data is transmitted?</p> Data collection source Data collected DB host to PMM Database performance metrics  SQL query examples for query analytics (optional). PMM to DB Host DSN and credentials for database access. A separate DB user is used (limited access) to retreive metrics from the database. DB Host to S3 compatible storage location Database backup - optional if PMM Administrator configures it with Public Cloud (AWS, GCP, etc) as a possible storage location. PMM Server to Percona Cloud Telemetry data is collected.  PMM Server collects varying amounts of data from version to version, and no personal or confidential information is collected. See here for details on the data being transmitted. </li> <li> <p>Where is the data obtained from the DB host transmitted?</p> <p>All data gathered from the DB Host is transmitted to the PMM Server. It is possible to transmit DB backups to Cloud S3 storage (optional). </p> <p>Telemetry data is sent to Percona Cloud. This does not contain any sensitive or personally identifiable information.</p> </li> <li> <p>What is the purpose and nature of data processing?</p> <p>As per our Privacy Policy, the data collection purposes are to provide the services and product enhancements.</p> <p>Although, PMM does not collect nor transfer personal data explicitly, in case query analytics is enabled and query examples collection is not disabled, we gather SQL query examples with real data and personal data may appear there if it is stored in DB.  All QAN data always remains within the PMM server, and is never transmitted anywhere else.</p> </li> <li> <p>What is the frequency and volume of processed data?</p> <p>By default, metrics data is gathered every 5, 10 or 60 minutes. In case Query Analytics is enabled and SQL query examples are gathered every minute, we don\u2019t use any special processing for personal or confidential data. PMM server has no clue about the meaning of the data inside the SQL query.</p> <p>So it is processed as usual, which is to store inside the PMM server and present on the PMM UI by request.</p> <p>Other than email addresses for Grafana users, PMM does not directly ask or collect any other personal data. For more information about the telemetry data that is collected, please refer to the Percona Privacy Policy. </p> </li> <li> <p>What applications or third parties can access the data created and processed by the cloud service?</p> <p>Third parties or other applications are not able to access the data gathered by the PMM server.</p> </li> <li> <p>Is Personal Data processed for other applications or parties, and should the data that is processed in the cloud service be available to other applications or 3<sup>rd</sup> parties?</p> <p>PMM server doesn\u2019t pass any gathered, personal or confidential data to any third party or other applications nor to Percona Cloud.</p> </li> <li> <p>How safe is the encryption? </p> <p>It\u2019s a must to encrypt all connections to and from the cloud including the data in the cloud storage and PMM does so by default. </p> <p>We use TLS (v1.2 at least) for connections between:</p> <ul> <li> <p>Database host to PMM Server (optionally, depending on user configuration)</p> </li> <li> <p>PMM Server to Percona Cloud</p> </li> <li>PMM Server to remote database (optionally, depending on user configuration)</li> <li>End-user to PMM Server web interface/api (self-signed by default)</li> </ul> <p>For more information about Percona security posture, please refer to our Trust Center here.</p> </li> </ol>"},{"location":"details/pmm_components_and_versions.html","title":"PMM components and versions","text":"<p>The following table lists all the PMM client/server components and their versions:</p> PMM client/server component Version Documentation Location on GitHub Grafana 9.2.20* Grafana Documentation Github Grafana VictoriaMetrics 1.93.4 VictoriaMetrics Documentation Github VictoriaMetrics Nginx 1.20.1 Nginx Documentation Github Nginx Percona Distribution for PostgreSQL 14.5 Percona Distribution for PostgreSQL 14 Documentation Clickhouse 23.8.2.7 ClickHouse Documentation Documentation Github ClickHouse PerconaToolkit 3.4.0 Percona Toolkit Documentation Github Percona Toolkit Alertmanager 0.22.0 Alertmanager Documentation Github Alertmanager MongoDB exporter 0.37.0 Github MongoDB Exporter MySQL exporter v0.14.0* MySQL Server Exporter Documentation Github MySQL Server Exporter PostgreSQL exporter v0.14.0* Github PostgreSQL Server Exporter RDS exporter 0.7.2 Github RDS Exporter Node exporter v1.4.0* Node Exporter Documentation Github Node Exporter Azure exporter 2.30.0 Github Azure Metrics Exporter <p>* - Original upstream version along with some changes authored by Percona</p>"},{"location":"details/postgresql.html","title":"PostgreSQL","text":"<p>You can use an external PostgreSQL database instance outside the PMM Server container running on the same or other hosts.</p>"},{"location":"details/postgresql.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use PostgreSQL parameters as environment variables:</p> <p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production. The minimum supported PostgreSQL server version is 14.</p> <p>To use PostgreSQL as an external database instance, use the following environment variables:</p> Environment variable Flag Description PERCONA_TEST_POSTGRES_ADDR postgres-addr Hostname and port for external PostgreSQL database. PERCONA_TEST_POSTGRES_DBNAME postgres-name Database name for external or internal PostgreSQL database. PERCONA_TEST_POSTGRES_USERNAME postgres-username PostgreSQL user name to connect as. PERCONA_TEST_POSTGRES_DBPASSWORD postgres-password Password to be used for database authentication. PERCONA_TEST_POSTGRES_SSL_MODE postgres-ssl-mode This option determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the database. Currently supported: <code>disable</code>, <code>require</code>, <code>verify-ca</code>, <code>verify-full</code>. PERCONA_TEST_POSTGRES_SSL_CA_PATH postgres-ssl-ca-path This parameter specifies the name of a file containing SSL certificate authority (CA) certificate(s). PERCONA_TEST_POSTGRES_SSL_KEY_PATH postgres-ssl-key-path This parameter specifies the location for the secret key used for the client certificate. PERCONA_TEST_POSTGRES_SSL_CERT_PATH postgres-ssl-cert-path This parameter specifies the file name of the client SSL certificate. PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES Environment variable to disable built-in PMM server database. Note that Grafana depends on built-in PostgreSQL. And if the value of this variable is \u201ctrue\u201d, then it is necessary to pass all the parameters associated with Grafana to use external PostgreSQL. <p>By default, communication between the PMM server and the database is not encrypted. To secure a connection, follow PostgeSQL SSL instructions and provide <code>POSTGRES_SSL_*</code> variables.</p> <p>To use grafana with external PostgreSQL add <code>GF_DATABASE_*</code> environment variables accordingly.</p> <p>Example</p> <p>To use PostgreSQL as an external database:</p> <ol> <li>Generate all necessary SSL certificates.</li> <li>Deploy PMM Server with certificates under read-only permissions and Grafana user and Grafana group. <pre><code>/pmm-server-certificates# la -la\ndrwxr-xr-x 1 root    root    4096 Apr  5 12:43 .\ndrwxr-xr-x 1 root    root    4096 Apr  5 12:43 ..\n-rw------- 1 grafana grafana 1391 Apr  5 12:38 certificate_authority.crt\n-rw------- 1 grafana grafana 1257 Apr  5 12:38 pmm_server.crt\n-rw------- 1 grafana grafana 1708 Apr  5 12:38 pmm_server.key\n</code></pre></li> <li>Attach <code>pg_hba.conf</code> and certificates to the PostgreSQL image. <pre><code>/external-postgres-configuration# cat pg_hba.conf \nlocal     all         all                                    trust\nhostnossl all         example_user all                       reject\nhostssl   all         example_user all                       cert\n</code></pre> <pre><code>/external-postgres-certificates# ls -la\ndrwxr-xr-x 1 root     root     4096 Apr  5 12:38 .\ndrwxr-xr-x 1 root     root     4096 Apr  5 12:43 ..\n-rw------- 1 postgres postgres 1391 Apr  5 12:38 certificate_authority.crt\n-rw------- 1 postgres postgres 1407 Apr  5 12:38 external_postgres.crt\n-rw------- 1 postgres postgres 1708 Apr  5 12:38 external_postgres.key\n</code></pre></li> <li>Create <code>user</code> and <code>database</code> for pmm-server to use. Set appropriate rights and access.</li> <li>Install <code>pg_stat_statements</code> in PostgreSQL in order to have all metrics according to this handy document.</li> <li>Run PostgreSQL server. <pre><code>docker run\n--name external-postgres\n-e POSTGRES_PASSWORD=secret\n&lt;image_id&gt;\npostgres\n-c shared_preload_libraries=pg_stat_statements\n-c pg_stat_statements.max=10000\n-c pg_stat_statements.track=all\n-c pg_stat_statements.save=off\n-c ssl=on\n-c ssl_ca_file=$CA_PATH\n-c ssl_key_file=$KEY_PATH\n-c ssl_cert_file=$CERT_PATH\n-c hba_file=$HBA_PATH\n</code></pre></li> <li>Run PMM server. <pre><code>docker run \n--name pmm-server \n-e PERCONA_TEST_POSTGRES_ADDR=$ADDRESS:$PORT\n-e PERCONA_TEST_POSTGRES_DBNAME=$DBNAME\n-e PERCONA_TEST_POSTGRES_USERNAME=$USER\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=$PASSWORD\n-e PERCONA_TEST_POSTGRES_SSL_MODE=$SSL_MODE\n-e PERCONA_TEST_POSTGRES_SSL_CA_PATH=$CA_PATH\n-e PERCONA_TEST_POSTGRES_SSL_KEY_PATH=$KEY_PATH\n-e PERCONA_TEST_POSTGRES_SSL_CERT_PATH=$CERT_PATH \n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=true\n-e GF_DATABASE_URL=$GF_DATABASE_URL\n-e GF_DATABASE_SSL_MODE=$GF_SSL_MODE\n-e GF_DATABASE_CA_CERT_PATH=$GF_CA_PATH\n-e GF_DATABASE_CLIENT_KEY_PATH=$GF_KEY_PATH\n-e GF_DATABASE_CLIENT_CERT_PATH=$GF_CERT_PATH\npercona/pmm-server:2\n</code></pre></li> </ol>"},{"location":"details/query-analytics.html","title":"Query Analytics under the hood","text":""},{"location":"details/query-analytics.html#components","title":"Components","text":"<p>QAN consists of three main components:</p> <ol> <li>Filters Panel</li> <li>Overview Panel</li> <li>Details Panel</li> </ol>"},{"location":"details/query-analytics.html#how-qan-collects-data","title":"How QAN collects data?","text":"<ul> <li> <p>QAN collects data every minute, on the minute (e.g. 8:15:00 and next at 8:16:00, etc.).</p> </li> <li> <p>The collected data is represented by \u201cbuckets.\u201d</p> </li> </ul>"},{"location":"details/query-analytics.html#understanding-buckets","title":"Understanding buckets","text":"<ul> <li> <p>A bucket contains all the data captured during a one-minute interval.</p> </li> <li> <p>Once a bucket is created, it is sent to the PMM Server, where it is parsed and saved in the ClickHouse database. All QAN-related data is stored in ClickHouse, which can be either part of the PMM Server or an external instance.</p> </li> <li> <p>Queries in buckets are aggregated by query ID, which means that all queries with the same query ID are represented by a single row in the Overview panel.</p> </li> <li>Query IDs are calculated differently depending on the database technology and query source.</li> </ul>"},{"location":"details/query-analytics.html#mysql","title":"MySQL","text":"<ul> <li> <p>For MySQL, the query ID is based on the DIGEST value (for Performance Schema) or the MD5 checksum of the fingerprint (for slow log).</p> </li> <li> <p>DIGEST (Performance Schema) and fingerprint (Slow Log) are both methods of representing a query without its sensitive data. In the case below, both queries will have the same query ID because the DIGEST value is generated from the query text after removing the sensitive data.     <pre><code>INSERT INTO people VALUES ('Joe', 'Doe'); \nINSERT INTO people VALUES ('John', 'Smith'); \n</code></pre></p> </li> </ul>"},{"location":"details/query-analytics.html#perfschema","title":"Perfschema","text":"<ul> <li> <p>The query ID is based on the DIGEST (fingerprint) value from the <code>events_statements_summary_by_digest</code> table in the mysql database.</p> </li> <li> <p>The DIGEST value for the same query may differ across MySQL versions. </p> </li> <li>The DIGEST is generated from the query text without sensitive data (DIGEST_TEXT).</li> <li>In MySQL 8.0 and higher, you can use the STATEMENT_DIGEST(\u201cyour query\u201d) function to obtain the DIGEST (query ID) for a given query. See the MySQL official documentation for more details.</li> </ul>"},{"location":"details/query-analytics.html#slowlog","title":"Slowlog","text":"<ul> <li>The query ID is the MD5 checksum of the query fingerprint.</li> </ul>"},{"location":"details/query-analytics.html#sources-for-data","title":"Sources for data","text":"<ul> <li>MySQL Performance Schema: The <code>events_statements_summary_by_digest</code> and <code>events_statements_history</code> tables in the <code>mysql</code> database.</li> <li>MySQL Slow Log: The slow log file specified during MySQL configuration.</li> <li>PostgreSQL pg_stat_statements (PGSS): The <code>pg_stat_statements</code> view in the required database.</li> <li>PostgreSQL pg_stat_monitor (PGSM): The <code>pg_stat_monitor</code> view in the required database.</li> </ul>"},{"location":"details/query-analytics.html#examples","title":"Examples","text":""},{"location":"details/query-analytics.html#example-1-mysql-with-performance-schema-or-slow-log","title":"Example 1: MySQL with Performance Schema or Slow Log","text":"<p>Timeline 8:05:05: You start the pmm-agent.</p> <p>8:05:20: You execute the following queries: <pre><code>CREATE TABLE people (FirstName varchar(255), LastName varchar(255));\nINSERT INTO people VALUES ('Joe', 'Doe');\nINSERT INTO people VALUES ('John', 'Smith');\n</code></pre> 8:05:25: The queries finish executing.</p> <p>8:06:00: The buckets are collected and sent to the PMM Server.  8:06:10: Head back to QAN. Here, you should see two rows in the QAN Overview Panel (depending on the filter settings and time range):  </p> <p>Let\u2019s answer some questions about the image above.  Question: Why does the query look slightly different in the Overview list? Answer: The query is the same, but sensitive data (e.g., \u2018Joe\u2019, \u2018John\u2019) is replaced by placeholders like \u201c?\u201d, \u201c?+\u201d, or \u201c\u2026\u201d in the Overview list.</p> <p>Question: We triggered two INSERT queries, but there is only one row in the list overview. Why? Answer: For the executed queries below, query ID will be the same which is why they are aggregated into a single row in the Overview list. However, in the Details panel, you should still see the actual count of how many times the query was executed. As you can see in the image below, the count for the INSERT query is 2 in the Details panel, which matches the number of times we executed the INSERT query.</p> <p><pre><code>INSERT INTO people VALUES ('Joe', 'Doe');\nINSERT INTO people VALUES ('John', 'Smith');\n</code></pre> </p>"},{"location":"details/query-analytics.html#example-2-mysql-with-performance-schema-or-slow-log-query-execution-split-across-two-buckets","title":"Example 2: MySQL with Performance Schema or Slow Log, Query Execution Split Across Two Buckets","text":"<p>Timeline 8:05:55: You start pmm-agent. </p> <p>8:05:59: You execute the following queries:  <pre><code>CREATE TABLE people (FirstName varchar(255), LastName varchar(255));\nINSERT INTO people VALUES ('Joe', 'Doe');\nINSERT INTO people VALUES ('John', 'Smith'); \n</code></pre> 8:06:00: The first bucket is collected and sent to the PMM Server. The queries executed so far are included in this bucket and can be found in QAN for the time range 8:05:00-8:06:00.</p> <p>8:06:01: The queries finish executing.</p> <p>8:07:00: The second bucket is collected and sent to the PMM Server. The remaining executed queries are included in this bucket and are now visible in QAN.</p> <p>8:07:10: You should see two rows in the QAN Overview Panel (depending on the filter settings and time range): Now let\u2019s take a look at results with different time range filters.</p> <ol> <li>QAN with default time range filter (Last 12 hours) - two rows in overview (one for CREATE query, another for INSERT). In the Details panel, the count for the INSERT query is 2.</li> <li>Range 8:05:00 - 8:06:00 - one row in the Overview list for the CREATE query, because none of the INSERT queries were executed by that time</li> <li>Range 8:06:00 - 8:07:00 - One row in the Overview panel for the INSERT query because the CREATE query was sent in the previous bucket. In the Details Panel, the count for the INSERT query is 2 since both queries were executed in this range. \u00df Remember that it may take up to 2 minutes for all the data to be visible in QAN after the queries have finished executing.</li> </ol> <p>In the future, we will include examples covering more technologies (e.g., PostgreSQL, MongoDB) in this topic.</p>"},{"location":"details/victoria-metrics.html","title":"VictoriaMetrics","text":"<p>VictoriaMetrics is a third-party monitoring solution and time-series database that replaced Prometheus in PMM 2.12.0.</p>"},{"location":"details/victoria-metrics.html#pushpull-modes","title":"Push/Pull modes","text":"<p>VictoriaMetrics metrics data can be both \u2018pushed\u2019 to the server and \u2018pulled\u2019 by the server. When setting up services, you can decide which mode to use.</p> <p>The \u2018push\u2019 mode is now default for newly-added services. (In PMM 2.12.0 the default mode was \u2018pull\u2019.)</p> <p>The mode (push/pull) is controlled by the <code>--metrics-mode</code> flag for the <code>pmm-admin config</code> and <code>pmm-admin add</code> commands.</p> <p>If you need to change the metrics mode for an existing Service, you must remove it and re-add it with the same name and the required flags. (You cannot update a service.)</p>"},{"location":"details/victoria-metrics.html#remapped-targets-for-direct-prometheus-paths","title":"Remapped targets for direct Prometheus paths","text":"<p>Direct Prometheus paths return structured information directly from Prometheus, bypassing the PMM application.</p> <p>They are accessed by requesting a URL of the form <code>&lt;PMM SERVER URL&gt;/prometheus/&lt;PATH&gt;</code>.</p> <p>As a result of the move to VictoriaMetrics some direct Prometheus paths are no longer available.</p> Prometheus path VictoriaMetrics equivalent <code>/prometheus/alerts</code> No change. <code>/prometheus/config</code> No equivalent, but there is some information at <code>/prometheus/targets</code>. <code>/prometheus/flags</code> The <code>flag</code> metrics at <code>/prometheus/metrics</code>. <code>/prometheus/graph</code> <code>/graph/explore</code> (Grafana) or <code>graph/d/prometheus-advanced/advanced-data-exploration</code> (PMM dashboard). <code>/prometheus/rules</code> No change. <code>/prometheus/service-discovery</code> No equivalent. <code>/prometheus/status</code> Some information at <code>/prometheus/metrics</code>. High cardinality metrics information at <code>/prometheus/api/v1/status/tsdb</code>. <code>/prometheus/targets</code> <code>/victoriametrics/targets</code>"},{"location":"details/victoria-metrics.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow users to set all other VictoriaMetrics parameters as environment variables:</p> <p>The environment variable must be prepended with <code>VM_</code>.</p> <p>Example</p> <p>To set downsampling, use the <code>downsampling.period</code> parameter as follows:</p> <pre><code>-e VM_downsampling_period=20d:10m,120d:2h\n</code></pre> <p>This instructs VictoriaMetrics to deduplicate samples older than 20 days with 10 minute intervals and samples older than 120 days with two hour intervals.</p>"},{"location":"details/victoria-metrics.html#using-victoriametrics-external-database-instance","title":"Using VictoriaMetrics external database instance","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for evaluation purposes only.</p> <p>Starting with PMM 2.40.0, you can now use an external VictoriaMetrics database for monitoring in PMM.</p> <p>The environment variable <code>PMM_VM_URL</code> has been added, which should point to the external VictoriaMetrics database and should have the following format:</p> <pre><code>http(s)://hostname:port/path.\n</code></pre> <p>If the external VictoriaMetrics database requires basic authentication, the following environment variables should be used:</p> <p><pre><code>VMAGENT_remoteWrite_basicAuth_username={username}\nVMAGENT_remoteWrite_basicAuth_password={password}\n</code></pre> If other authentication methods are used on the VictoriaMetrics side, users can use any of the <code>vmagent</code> environment variables by prepending <code>VMAGENT_ prefix</code>.</p> <p>When external VictoriaMetrics is configured, internal VictoriaMetrics stops. In this case, VM Agent on PMM Server pulls metrics from agents configured in the <code>pull metrics mode</code> and from remote nodes. Data is then pushed to external VictoriaMetrics.</p> <p>Note</p> <p>VM Agents run by PMM Clients push data directly to external VictoriaMetrics. </p> <p>Ensure that they can connect to external VictoriaMetrics.</p>"},{"location":"details/victoria-metrics.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the VictoriaMetrics troubleshooting documentation.</p> <p>You can also contact the VictoriaMetrics team via:</p> <ul> <li>Google Groups</li> <li>Slack</li> <li>Reddit</li> <li>Telegram</li> </ul>"},{"location":"details/commands/index.html","title":"Commands","text":"<ul> <li><code>pmm-admin</code> \u2013 Command line tool for configuring and administering PMM</li> <li><code>pmm-agent</code> \u2013 Daemon process, communicating between PMM Client and PMM Server</li> </ul>"},{"location":"details/commands/pmm-admin.html","title":"pmm-admin - PMM Administration Tool","text":""},{"location":"details/commands/pmm-admin.html#name","title":"NAME","text":"<p><code>pmm-admin</code> - Administer PMM</p>"},{"location":"details/commands/pmm-admin.html#synopsis","title":"SYNOPSIS","text":"<p><code>pmm-admin [FLAGS]</code></p> <p><code>pmm-admin config [FLAGS] --server-url=server-url</code></p> <p><code>pmm-admin add DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p>DATABASE:= [MongoDB | MySQL | PostgreSQL | ProxySQL]</p> <p><code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add haproxy [FLAGS] [NAME]</code></p> <p><code>pmm-admin add external [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add external-serverless [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin remove [FLAGS] service-type [service-name]</code></p> <p><code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]</code></p> <p><code>pmm-admin list [FLAGS] [node-address]</code></p> <p><code>pmm-admin status [FLAGS] [node-address]</code></p> <p><code>pmm-admin summary [FLAGS] [node-address]</code></p> <p><code>pmm-admin annotate [--node|--service] [--tags &lt;tags&gt;] [node-name|service-name]</code></p> <p><code>pmm-admin help [COMMAND]</code></p>"},{"location":"details/commands/pmm-admin.html#description","title":"DESCRIPTION","text":"<p><code>pmm-admin</code> is a command-line tool for administering PMM using a set of COMMAND keywords and associated FLAGS.</p> <p>PMM communicates with the PMM Server via a PMM agent process.</p>"},{"location":"details/commands/pmm-admin.html#common-flags","title":"COMMON FLAGS","text":"<code>-h</code>, <code>--help</code> Show help and exit. <code>--help-long</code> Show extended help and exit. <code>--help-man</code> Generate <code>man</code> page. (Use <code>pmm-admin --help-man | man -l -</code> to view.) <code>--debug</code> Enable debug logging. <code>--trace</code> Enable trace logging (implies debug). <code>--log-level</code> (This parameter is available starting with PMM 2.29.0.) Set the level for the logs as per your requirement such as INFO, WARNING, ERROR, and FATAL. <code>--json</code> Enable JSON output. <code>--version</code> Show the application version and exit. <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--group=&lt;group-name&gt;</code> Group name for external services. Default: <code>external</code> <code>--expose-exporter</code> (This flag is availble starting with PMM 2.41.0.) If you enable this flag, any IP address on the local network and anywhere on the internet can access exporter endpoints. If the flag is disabled/not present, exporter endpoints can be accessed only locally. The flag is disabled by default"},{"location":"details/commands/pmm-admin.html#commands","title":"COMMANDS","text":""},{"location":"details/commands/pmm-admin.html#general-commands","title":"GENERAL COMMANDS","text":"<code>pmm-admin help [COMMAND]</code> Show help for <code>COMMAND</code>."},{"location":"details/commands/pmm-admin.html#information-commands","title":"INFORMATION COMMANDS","text":"<code>pmm-admin list --server-url=server-url [FLAGS]</code> Show Services and Agents running on this Node, and the agent mode (push/pull). <code>pmm-admin status --server-url=server-url [FLAGS]</code> <p>Show the following information about a local pmm-agent, and its connected server and clients:</p> <ul> <li>Agent: Agent ID, Node ID.</li> <li>PMM Server: URL and version.</li> <li>PMM Client: connection status, time drift, latency, <code>vmagent</code> status, <code>pmm-admin</code> version.</li> <li>Agents: Agent ID path and client name.</li> </ul> <p>FLAGS:</p> <code>--wait=&lt;period&gt;&lt;unit&gt;</code> Time to wait for a successful response from pmm-agent. period is an integer. unit is one of <code>ms</code> for milliseconds, <code>s</code> for seconds, <code>m</code> for minutes, <code>h</code> for hours. <code>pmm-admin summary --server-url=server-url [FLAGS]</code> <p>Creates an archive file in the current directory with default file name <code>summary_&lt;hostname&gt;_&lt;year&gt;_&lt;month&gt;_&lt;date&gt;_&lt;hour&gt;_&lt;minute&gt;_&lt;second&gt;.zip</code>. The contents are two directories, <code>client</code> and <code>server</code> containing diagnostic text files.</p> <p>FLAGS:</p> <code>--filename=\"filename\"</code> The Summary Archive filename. <code>--skip-server</code> Skip fetching <code>logs.zip</code> from PMM Server. <code>--pprof</code> (This parameter is available starting with PMM 2.29.0) Include performance profiling data in the summary."},{"location":"details/commands/pmm-admin.html#configuration-commands","title":"CONFIGURATION COMMANDS","text":"pmm-admin configpmm-admin registerpmm-admin addpmm-admin removepmm-admin annotate <p>Configure a local <code>pmm-agent</code>.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--node-model=node-model</code> Node model. <code>--region=region</code> Node region. <code>--az=availability-zone</code> Node availability zone. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values:   - <code>auto</code>: chosen by server (default).   - <code>push</code>: agent will push metrics.   - <code>pull</code>: server scrapes metrics from agent. <code>--paths-base=dir</code> Base path where all binaries, tools and collectors of PMM client are located <code>--agent-password=password</code> Custom agent password. (This parameter is available starting with PMM 2.29.0.) <p>Register the current Node with the PMM Server.</p> <pre><code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]\n</code></pre> <p>FLAGS:</p> <ul> <li> <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. </li> <li> <code>--machine-id=\"/machine_id/9812826a1c45454a98ba45c56cc4f5b0\"</code> Node machine-id (default is auto-detected). </li> <li> <code>--distro=\"linux\"</code> Node OS distribution (default is auto-detected). </li> <li> <code>--container-id=container-id</code> Container ID. </li> <li> <code>--container-name=container-name</code> Container name. </li> <li> <code>--node-model=node-model</code> Node model. </li> <li> <code>--region=region</code> Node region. </li> <li> <code>--az=availability-zone</code> Node availability zone. </li> <li> <code>--custom-labels=labels</code> Custom user-assigned labels. </li> <li> <code>--agent-password=password</code> Custom agent password. (Available starting with PMM 2.29.0.) </li> </ul> <p>Configure the PMM agent with a listen port.</p> <pre><code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]\n</code></pre> <ul> <li><code>--pmm-agent-listen-port=LISTEN_PORT</code>: The PMM agent listen port.</li> </ul> <p>DATABASE:= MongoDB | MySQL | PostgreSQL | ProxySQL</p> <p>Remove Service from monitoring.</p> <pre><code>pmm-admin remove [FLAGS] service-type [service-name]\n</code></pre> <p>FLAGS:</p> <ul> <li><code>--service-id=service-id</code>: Service ID.</li> <li><code>--force</code>: Remove service with that name or ID and all dependent services and agents.</li> </ul> <p>Note: When you remove a service, collected data remains on PMM Server for the specified retention period.</p> <p>Annotate an event. (Read more)</p> <pre><code>pmm-admin annotate [--node|--service] &lt;annotation&gt; [--tags &lt;tags&gt;] [--node-name=&lt;node&gt;] [--service-name=&lt;service&gt;]\n</code></pre> <ul> <li><code>&lt;annotation&gt;</code>: The annotation string. If it contains spaces, it should be quoted.</li> <li><code>--node</code>: Annotate the current node or that specified by <code>--node-name</code>.</li> <li><code>--service</code>: Annotate all services running on the current node, or that specified by <code>--service-name</code>.</li> <li><code>--tags</code>: A quoted string that defines one or more comma-separated tags for the annotation. Example: <code>\"tag 1,tag 2\"</code>.</li> <li><code>--node-name</code>: The node name being annotated.</li> <li><code>--service-name</code>: The service name being annotated.</li> </ul> <p>Combining flags</p> <p>Flags may be combined in various ways. For example:</p> <ul> <li><code>--node</code>: Current node.</li> <li><code>--node-name</code>: Node with name.</li> <li><code>--node --node-name=NODE_NAME</code>: Node with name.</li> <li><code>--node --service-name</code>: Current node and service with name.</li> <li><code>--node --node-name --service-name</code>: Node with name and service with name.</li> <li><code>--node --service</code>: Current node and all services of current node.</li> <li><code>-node --node-name --service --service-name</code>: Service with name and node with name.</li> <li><code>--service</code>: All services of the current node.</li> <li><code>--service-name</code>: Service with name.</li> <li><code>--service --service-name</code>: Service with name.</li> <li><code>--service --node-name</code>: All services of current node and node with name.</li> <li><code>--service-name --node-name</code>: Service with name and node with name.</li> <li><code>--service --service-name -node-name</code>: Service with name and node with name.</li> </ul> <p>Tip</p> <p>If node or service name is specified, they are used instead of other parameters.</p>"},{"location":"details/commands/pmm-admin.html#database-commands","title":"DATABASE COMMANDS","text":""},{"location":"details/commands/pmm-admin.html#mongodb","title":"MongoDB","text":"<code>pmm-admin add mongodb [FLAGS] [node-name] [node-address]</code> Add MongoDB to monitoring."},{"location":"details/commands/pmm-admin.html#flags","title":"FLAGS:","text":"<pre><code>`--node-id=node-id`\n:  Node ID (default is auto-detected).\n\n`--pmm-agent-id=pmm-agent-id`\n:  The pmm-agent identifier which runs this instance (default is auto-detected).\n\n`--username=username`\n:  MongoDB username.\n\n`--password=password`\n:  MongoDB password.\n\n`--agent-password=password`\n:  Override the default password for accessing the `/metrics` endpoint. (Username is `pmm` and default password is the agent ID.)\n\n    !!! caution \"\"\n        Avoid using special characters like '\\', ';' and '$' in the custom password.\n\n`--query-source=profiler`\n:  Source of queries, one of: `profiler`, `none` (default: `profiler`).\n\n`--environment=environment`\n:  Environment name.\n\n`--cluster=cluster`\n:  Cluster name.\n\n`--replication-set=replication-set`\n:  Replication set name.\n\n`--custom-labels=custom-labels`\n:  Custom user-assigned labels.\n\n`--skip-connection-check`\n:  Skip connection check.\n\n`--tls`\n:  Use TLS to connect to the database.\n\n`--tls-skip-verify`\n:  Skip TLS certificates validation.\n\n`--tls-certificate-key-file=PATHTOCERT`\n: Path to TLS certificate file.\n\n`--tls-certificate-key-file-password=IFPASSWORDTOCERTISSET`\n: Password for TLS certificate file.\n\n`--tls-ca-file=PATHTOCACERT`\n: Path to certificate authority file.\n\n`--metrics-mode=mode`\n: Metrics flow mode for agents node-exporter. Allowed values:\n    - `auto`: chosen by server (default).\n    - `push`: agent will push metrics.\n    - `pull`: server scrapes metrics from agent.\n\n`--max-query-length=NUMBER` (This parameter is available starting with PMM 2.32.0.)\n: Limit query length in QAN. Allowed values:\n    - -1: No limit.\n    -  0: Default value. The default value is 2048 chars.\n    - &gt;0: Query will be truncated after &lt;NUMBER&gt; chars.\n\n    !!! caution \"\"\n        Ensure you do not set the value of `max-query-length` to 1, 2, or 3. Otherwise, the PMM agent will get terminated.\n</code></pre>"},{"location":"details/commands/pmm-admin.html#collectors","title":"COLLECTORS","text":"<p>MongoDB exporter includes the following collectors:</p> <ul> <li><code>diagnosticdata</code></li> <li><code>replicasetstatus</code></li> <li><code>collstats</code></li> <li><code>dbstats</code></li> <li><code>indexstats</code></li> <li><code>topmetrics</code></li> <li><code>currentop</code>: This only collects operations running for longer than one minute and ignores operations in the admin and local databases.</li> <li><code>fcv</code> (Feature Compatibility Version)</li> </ul>"},{"location":"details/commands/pmm-admin.html#advanced-options","title":"Advanced options","text":"<p>PMM starts the MongoDB exporter by default only with <code>diagnosticdata</code> and <code>replicasetstatus</code> collectors enabled.</p> <p>FLAGS:</p> <code>--enable-all-collectors</code> Enable all collectors. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter. <code>--max-collections-limit=-1</code> <p>Disable collstats, dbstats, topmetrics and indexstats if there are more than  collections. 0: No limit. Default is -1, PMM automatically sets this value. <p>A very high limit of <code>max-collections-limit</code> could impact the CPU and Memory usage. Check <code>--stats-collections</code> to limit the scope of collections and DB\u2019s metrics to be fetched.</p> <code>--stats-collections=db1,db2.col1</code> Collections for collstats &amp; indexstats. Default configurationEnable all collectorsLimit dbStats, collStats, indexStats &amp; currentopmetricsDisable some collectors <p>To add MongoDB with default collectors (<code>diagnosticdata</code> and <code>replicasetstatus</code> and <code>fcv</code> (Feature Compatibility Version) collectors:</p> <pre><code>pmm-admin add mongodb --username=admin --password=admin_pass mongodb_srv_1 127.0.0.1:27017\n</code></pre> <p>This command adds MongoDB to PMM monitoring with only the default collectors enabled. It\u2019s the simplest way to start monitoring a MongoDB instance without enabling additional collectors.</p> <p>Warning</p> <p>Before using <code>--enable-all-collectors</code> with MongoDB Service, be aware that the MongoDB exporter\u2019s memory usage may increase significantly when monitoring MongoDB clusters, especially with sharding and multiple collections. If you frequently create new collections or work with many collections, disable the <code>collstats</code>collector to prevent memory consumption issues.</p> <p>To enable all collectors, pass the parameter <code>--enable-all-collectors</code> in the <code>pmm-admin add mongodb</code> command. This will enable <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, <code>topmetrics</code>, <code>currentopmetrics</code> and <code>fcv</code> collectors.</p> <p>Examples: </p> <ol> <li> <p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, <code>currentopmetrics</code>, <code>topmetrics</code> and <code>fcv</code>) with default limit detected by PMM (currently &lt;=200 collections, but subject to change):</p> <pre><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors mongodb_srv_1 127.0.0.1:27017\n</code></pre> </li> <li> <p>To enable all the collectors with an unlimited number of collections monitored:</p> <pre><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 mongodb_srv_1 127.0.0.1:27017\n</code></pre> </li> </ol> <p>By default, PMM decides the limit for the number of collections to monitor the <code>collStats</code> and <code>indexStats</code> collectors.</p> <p>You can also set an additional limit for the <code>collStats</code>, <code>indexStats</code>, <code>dbStats</code>, <code>currentopmetrics</code> and <code>topmetrics</code> collectors with the <code>--max-collections-limit</code> parameter.</p> <p>Set the value of the parameter <code>--max-collections-limit</code> to:</p> <ul> <li>0: which indicates that <code>collStats</code> and <code>indexStats</code> can handle unlimited collections.</li> <li>n, which indicates that <code>collStats</code> and <code>indexStats</code> can handle &lt;=n collections. If the limit is crossed - exporter stops collecting monitoring data for the <code>collStats</code> and <code>indexStats</code> collectors.</li> <li>-1 (default) doesn\u2019t need to be explicitly set. It indicates that PMM decides how many collections it would monitor, currently &lt;=200 (subject to change).</li> </ul> <p>To further refine the scope of monitored collections: 1. Use the <code>--stats-collections</code> parameter to specify which databases and collections <code>collStats</code> and <code>indexStats</code> will monitor. 2. The parameter accepts a comma-separated list of namespaces in the format <code>database[.collection]</code>.</p> <p>Examples:</p> <ol> <li> <p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, <code>currentopmetrics</code>, <code>topmetrics</code> and <code>fcv) with</code>max-collections-limit` set to 1000:</p> <pre><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=1000 mongodb_srv_1 127.0.0.1:27017\n</code></pre> </li> <li> <p>If <code>--stats-collections=db1,db2.col1</code> then the collectors are run as follows:</p> Database Collector is run on <code>db1</code> All the collections <code>db2</code> Only for collection <code>col1</code> </li> <li> <p>Enable all collectors and limit monitoring for <code>dbstats</code>, <code>indexstats</code>, <code>collstats</code> and <code>topmetrics</code> for all collections in <code>db1</code> and <code>col1</code> collection in <code>db2</code>, without limiting <code>max-collections-limit</code> for a number of collections in <code>db1</code>:</p> <pre><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --stats-collections=db1,db2.col1 mongodb_srv_1 127.0.0.1:27017\n</code></pre> </li> </ol> <p>To enable only some collectors, pass the parameter <code>--enable-all-collectors</code> along with the parameter <code>--disable-collectors</code>.</p> <p>Examples: </p> <ol> <li> <p>If you want all collectors except <code>topmetrics</code>, specify  <code>--enable-all-collectors --disable-collectors=topmetrics</code></p> </li> <li> <p>To disable <code>collstats</code> collector and enable all the others without limiting <code>max-collections-limit</code>:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --disable-collectors=collstats mongodb_srv_1 127.0.0.1:27017</code></p> </li> </ol>"},{"location":"details/commands/pmm-admin.html#resolutions","title":"Resolutions","text":"<p>PMM collects metrics in two resolutions to decrease CPU and Memory usage: high and low resolutions.</p> <p>In high resolution we collect metrics from collectors which work fast: - <code>diagnosticdata</code> - <code>replicasetstatus</code> - <code>topmetrics</code></p> <p>In low resolution we collect metrics from collectors which could take some time: - <code>dbstats</code> - <code>indexstats</code> - <code>collstats</code></p>"},{"location":"details/commands/pmm-admin.html#mysql","title":"MySQL","text":"<code>pmm-admin add mysql [FLAGS] node-name node-address | [--name=service-name] --address=address[:port] | --socket</code> <p>Add MySQL to monitoring.</p> <p>FLAGS:</p> <code>--address</code> MySQL address and port (default: 127.0.0.1:3306). <code>--socket=socket</code> Path to MySQL socket. (Find the socket path with <code>mysql -u root -p -e \"select @@socket\"</code>.) <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> MySQL username. <code>--password=password</code> MySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=slowlog</code> Source of SQL queries, one of: <code>slowlog</code>, <code>perfschema</code>, <code>none</code> (default: <code>slowlog</code>). For <code>slowlog</code> query source, you need change permissions for specific files. Root permissions are needed for this. <code>--size-slow-logs=N</code> <p>Rotate slow log file at this size. If <code>0</code>, use server-defined default. Negative values disable log rotation. A unit suffix must be appended to the number and can be one of:</p> <ul> <li><code>KiB</code>, <code>MiB</code>, <code>GiB</code>, <code>TiB</code> for base 2 units (1024, 1048576, etc).</li> </ul> <code>--disable-queryexamples</code> Disable collection of query examples. <code>--disable-tablestats</code> <p>Disable table statistics collection.</p> <p>Excluded collectors for low-resolution time intervals:</p> <ul> <li><code>--collect.auto_increment.columns</code></li> <li><code>--collect.info_schema.tables</code></li> <li><code>--collect.info_schema.tablestats</code></li> <li><code>--collect.perf_schema.indexiowaits</code></li> <li><code>--collect.perf_schema.tableiowaits</code></li> <li><code>--collect.perf_schema.file_instances</code></li> </ul> <p>Excluded collectors for medium-resolution time intervals:</p> <ul> <li><code>--collect.perf_schema.tablelocks</code></li> </ul> <code>--disable-tablestats-limit=disable-tablestats-limit</code> Table statistics collection will be disabled if there are more than specified number of tables (default: server-defined). 0=no limit. Negative value disables collection. <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-cert-file=PATHTOCERT</code> Path to TLS client certificate file. <code>--tls-key=PATHTOCERTKEY</code> Key for TLS client certificate file. <code>--tls-ca-file=PATHTOCACERT</code> Path to certificate authority file. <code>--ssl-ca=PATHTOCACERT</code> The path name of the Certificate Authority (CA) certificate file. If used, must specify the same certificate used by the server. (-ssl-capath is similar, but specifies the path name of a directory of CA certificate files.) <code>--ssl-cert=PATHTOCERTKEY</code> The path name of the client public key certificate file. <code>--ssl-key</code> The path name of the client private key file. <code>--ssl-skip-verify</code> Skip SSL certificate verification. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> (This parameter is available starting with PMM 2.32.0.) <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled."},{"location":"details/commands/pmm-admin.html#postgresql","title":"PostgreSQL","text":"<code>pmm-admin add postgresql [FLAGS] [node-name] [node-address]</code> <p>Add PostgreSQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=&lt;node id&gt;</code> Node ID (default is auto-detected). <code>--pmm-agent-id=&lt;pmm agent id&gt;</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=&lt;username&gt;</code> PostgreSQL username. <code>--password=&lt;password&gt;</code> PostgreSQL password. <code>--database=&lt;database&gt;</code> PostgreSQL database (default: postgres). <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=&lt;query source&gt;</code> Source of SQL queries, one of: <code>pgstatements</code>, <code>pgstatmonitor</code>, <code>none</code> (default: <code>pgstatements</code>). <code>--disable-queryexamples</code> Disable collection of query examples. Applicable only if <code>query-source</code> is set to <code>pgstatmonitor</code>. <code>--environment=&lt;environment&gt;</code> Environment name. <code>--cluster=&lt;cluster&gt;</code> Cluster name. <code>--replication-set=&lt;replication set&gt;</code> Replication set name. <code>--custom-labels=&lt;custom labels&gt;</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-ca-file</code> TLS CA certificate file. <code>--tls-cert-file</code> TLS certificate file. <code>--tls-key-file</code> TLS certificate key file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> (This parameter is available starting with PMM 2.32.0.) <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled."},{"location":"details/commands/pmm-admin.html#proxysql","title":"ProxySQL","text":"<code>pmm-admin add proxysql [FLAGS] [node-name] [node-address]</code> <p>Add ProxySQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> ProxySQL username. <code>--password=password</code> ProxySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter."},{"location":"details/commands/pmm-admin.html#haproxy","title":"HAProxy","text":"<code>pmm-admin add haproxy [FLAGS] [NAME]</code> <p>Add HAProxy to monitoring.</p> <p>FLAGS:</p> <code>--server-url=SERVER-URL</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--username=USERNAME</code> HAProxy username. <code>--password=PASSWORD</code> HAProxy password. <code>--scheme=SCHEME</code> Scheme to generate URI to exporter metrics endpoints (http or https). <code>--metrics-path=METRICS-PATH</code> Path under which metrics are exposed, used to generate URI (default: /metrics). <code>--listen-port=LISTEN-PORT</code> Listen port of haproxy exposing the metrics for scraping metrics (Required). <code>--service-node-id=SERVICE-NODE-ID</code> Node ID where service runs (default is auto-detected). <code>--environment=ENVIRONMENT</code> Environment name like \u2018production\u2019 or \u2018qa\u2019. <code>--cluster=CLUSTER</code> Cluster name. <code>--replication-set=REPLICATION-SET</code> Replication set name. <code>--custom-labels=CUSTOM-LABELS</code> Custom user-assigned labels. Example: region=east,app=app1. <code>--metrics-mode=MODE</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--skip-connection-check</code> Skip connection check."},{"location":"details/commands/pmm-admin.html#other-commands","title":"OTHER COMMANDS","text":"<code>pmm-admin add external [FLAGS]</code> <p>Add External source of data (like a custom exporter running on a port) to be monitored.</p> <p>FLAGS:</p> <code>--service-name=\"current-hostname\"</code> Service name (autodetected defaults to the hostname where <code>pmm-admin</code> is running). <code>--agent-node-id=AGENT-NODE-ID</code> Node ID where agent runs (default is autodetected). <code>--username=USERNAME</code> External username. <code>--password=PASSWORD</code> External password. <code>--scheme=http or https</code> Scheme to generate URI to exporter metrics endpoints. <code>--metrics-path=/metrics</code> Path under which metrics are exposed, used to generate URI. <code>--listen-port=LISTEN-PORT</code> Listen port of external exporter for scraping metrics. (Required.) <code>--service-node-id=SERVICE-NODE-ID</code> Node ID where service runs (default is autodetected). <code>--environment=prod</code> Environment name like \u2018production\u2019 or \u2018qa\u2019. <code>--cluster=east-cluster</code> Cluster name. <code>--replication-set=rs1</code> Replication set name. <code>--custom-labels=CUSTOM-LABELS</code> Custom user-assigned labels. Example: <code>region=east,app=app1</code>. <code>--metrics-mode=auto</code> Metrics flow mode, can be <code>push</code>: agent will push metrics, <code>pull</code>: server scrape metrics from agent or <code>auto</code>: chosen by server. <code>--group=\"external\"</code> Group name of external service. (Default: <code>external</code>.) <code>pmm-admin add external-serverless [FLAGS]</code> <p>Add External Service on Remote node to monitoring.</p> <p>Usage example: <code>pmm-admin add external-serverless --url=http://1.2.3.4:9093/metrics</code>.</p> <p>Also, individual parameters can be set instead of <code>--url</code> like: <code>pmm-admin add external-serverless --scheme=http --host=1.2.3.4 --listen-port=9093 --metrics-path=/metrics --container-name=ddd --external-name=e125</code>.</p> <p>Note that some parameters are mandatory depending on the context. For example, if you specify <code>--url</code>, <code>--schema</code> and other related parameters are not mandatory. But if you specify <code>--host</code> you must provide all other parameters needed to build the destination URL, or you can specify <code>--address</code> instead of host and port as individual parameters.</p> <p>FLAGS:</p> <code>--url=URL</code> Full URL to exporter metrics endpoints. <code>--scheme=https</code> Scheme to generate URL to exporter metrics endpoints. <code>--username=USERNAME</code> External username. <code>--password=PASSWORD</code> External password. <code>--address=1.2.3.4:9000</code> External exporter address and port. <code>--host=1.2.3.4</code> External exporters hostname or IP address. <code>--listen-port=9999</code> Listen port of external exporter for scraping metrics. <code>--metrics-path=/metrics</code> Path under which metrics are exposed, used to generate URL. <code>--environment=testing</code> Environment name. <code>--cluster=CLUSTER</code> Cluster name. <code>--replication-set=rs1</code> Replication set name. <code>--custom-labels='app=myapp,region=s1'</code> Custom user-assigned labels. <code>--group=\"external\"</code> Group name of external service. (Default: <code>external</code>.) <code>--machine-id=MACHINE-ID</code> Node machine-id. <code>--distro=DISTRO</code> Node OS distribution. <code>--container-id=CONTAINER-ID</code> Container ID. <code>--container-name=CONTAINER-NAME</code> Container name. <code>--node-model=NODE-MODEL</code> Node model. <code>--region=REGION</code> Node region. <code>--az=AZ</code> Node availability zone."},{"location":"details/commands/pmm-admin.html#examples","title":"EXAMPLES","text":"<pre><code>pmm-admin add mysql --query-source=slowlog --username=pmm --password=pmm sl-mysql 127.0.0.1:3306\n</code></pre> <pre><code>MySQL Service added.\nService ID  : /service_id/a89191d4-7d75-44a9-b37f-a528e2c4550f\nService name: sl-mysql\n</code></pre> <pre><code>pmm-admin add mysql --username=pmm --password=pmm --service-name=ps-mysql --host=127.0.0.1 --port=3306\n</code></pre> <pre><code>pmm-admin status\npmm-admin status --wait=30s\n</code></pre> <pre><code>Agent ID: /agent_id/c2a55ac6-a12f-4172-8850-4101237a4236\nNode ID : /node_id/29b2cc24-3b90-4892-8d7e-4b44258d9309\nPMM Server:\n URL : https://x.x.x.x:443/\n Version: 2.5.0\nPMM Client:\n Connected : true\n Time drift: 2.152715ms\n Latency : 465.658\u00b5s\n pmm-admin version: 2.5.0\n pmm-agent version: 2.5.0\nAgents:\n /agent_id/aeb42475-486c-4f48-a906-9546fc7859e8 mysql_slowlog_agent Running\n</code></pre>"},{"location":"details/commands/pmm-admin.html#disable-collectors","title":"Disable collectors","text":"<pre><code>pmm-admin add mysql --disable-collectors='heartbeat,global_status,info_schema.innodb_cmp' --username=pmm --password=pmm --service-name=db1-mysql --host=127.0.0.1 --port=3306\n</code></pre> <p>For other collectors that you can disable with the <code>--disable-collectors</code> option, please visit the official repositories for each exporter:</p> <ul> <li><code>node_exporter</code></li> <li><code>mysqld_exporter</code></li> <li><code>mongodb_exporter</code></li> <li><code>postgres_exporter</code></li> <li><code>proxysql_exporter</code></li> </ul>"},{"location":"details/commands/pmm-agent.html","title":"pmm-agent - PMM Client agent","text":""},{"location":"details/commands/pmm-agent.html#name","title":"NAME","text":"<p><code>pmm-agent</code> - The PMM Client daemon program.</p>"},{"location":"details/commands/pmm-agent.html#synopsis","title":"SYNOPSIS","text":"<p><code>pmm-agent [command] [options]</code></p>"},{"location":"details/commands/pmm-agent.html#description","title":"DESCRIPTION","text":"<p><code>pmm-agent</code>, part of the PMM Client package, runs as a daemon process on all monitored hosts.</p>"},{"location":"details/commands/pmm-agent.html#commands","title":"COMMANDS","text":"<code>pmm-agent run</code> Run pmm-agent (default). <code>pmm-agent setup [node-address] [node-type] [node-name]</code> Configure local pmm-agent (requires root permissions) <code>pmm-agent help [command]</code> Show help (for command) and exit."},{"location":"details/commands/pmm-agent.html#options-and-environment","title":"OPTIONS AND ENVIRONMENT","text":"<p>Most options can be set via environment variables (shown in parentheses).</p> Option Environment variable Description <code>--server-password=SERVER-PASSWORD</code> <code>PMM_AGENT_SERVER_PASSWORD</code> Password to connect to PMM Server. <code>--server-username=SERVER-USERNAME</code> <code>PMM_AGENT_SERVER_USERNAME</code> Username to connect to PMM Server. <code>--server-address=host:port</code> <code>PMM_AGENT_SERVER_ADDRESS</code> PMM Server address and port number. <code>--server-insecure-tls</code> <code>PMM_AGENT_SERVER_INSECURE_TLS</code> Skip PMM Server TLS certificate validation. <code>--az=AZ</code> <code>PMM_AGENT_SETUP_AZ</code> Node availability zone. <code>--config-file=path_to/pmm-agent.yaml</code> <code>PMM_AGENT_CONFIG_FILE</code> Configuration file path and name. <code>--container-id=CONTAINER-ID</code> <code>PMM_AGENT_SETUP_CONTAINER_ID</code> Container ID. <code>--container-name=CONTAINER-NAME</code> <code>PMM_AGENT_SETUP_CONTAINER_NAME</code> Container name. <code>--debug</code> <code>PMM_AGENT_DEBUG</code> Enable debug output. <code>--distro=distro</code> <code>PMM_AGENT_SETUP_DISTRO</code> Node OS distribution (default is auto-detected). <code>--force</code> <code>PMM_AGENT_SETUP_FORCE</code> Remove Node with that name and all dependent Services and Agents (if existing). <code>--id=/agent_id/...</code> <code>PMM_AGENT_ID</code> ID of this pmm-agent. <code>--listen-address=LISTEN-ADDRESS</code> <code>PMM_AGENT_LISTEN_ADDRESS</code> Agent local API address. <code>--listen-port=LISTEN-PORT</code> <code>PMM_AGENT_LISTEN_PORT</code> Agent local API port. <code>--machine-id=machine-id</code> <code>PMM_AGENT_SETUP_MACHINE_ID</code> Node machine ID (default is auto-detected). <code>--metrics-mode=auto</code> <code>PMM_AGENT_SETUP_METRICS_MODE</code> Metrics flow mode for agents node-exporter. Can be <code>push</code> (agent will push metrics), <code>pull</code> (server scrapes metrics from agent) or <code>auto</code> (chosen by server). <code>--node-model=NODE-MODEL</code> <code>PMM_AGENT_SETUP_NODE_MODEL</code> Node model. <code>--paths-base=PATH</code> <code>PMM_AGENT_PATHS_BASE</code> Base path for PMM client, where all binaries, tools and collectors are located. If not set, default is <code>/usr/local/percona/pmm2</code>. <code>--paths-exporters_base=PATH</code> <code>PMM_AGENT_PATHS_EXPORTERS_BASE</code> Base path for exporters to use. If not set, or set to a relative path, uses value of <code>--paths-base</code> prepended to it. <code>--paths-mongodb_exporter=PATH</code> <code>PMM_AGENT_PATHS_MONGODB_EXPORTER</code> Path to <code>mongodb_exporter</code>. <code>--paths-mysqld_exporter=PATH</code> <code>PMM_AGENT_PATHS_MYSQLD_EXPORTER</code> Path to <code>mysqld_exporter</code>. <code>--paths-node_exporter=PATH</code> <code>PMM_AGENT_PATHS_NODE_EXPORTER</code> Path to <code>node_exporter</code>. <code>--paths-postgres_exporter=PATH</code> <code>PMM_AGENT_PATHS_POSTGRES_EXPORTER</code> Path to <code>postgres_exporter</code>. <code>--paths-proxysql_exporter=PATH</code> <code>PMM_AGENT_PATHS_PROXYSQL_EXPORTER</code> Path to <code>proxysql_exporter</code>. <code>--paths-pt-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_SUMMARY</code> Path to <code>pt-summary</code>. <code>--paths-pt-mysql-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_MYSQL_SUMMARY</code> Path to <code>pt-mysql-summary</code>. <code>--paths-pt-pg-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_PG_SUMMARY</code> Path to <code>pt-pg-summary</code>. <code>--paths-tempdir=PATH</code> <code>PMM_AGENT_PATHS_TEMPDIR</code> Temporary directory for exporters. <code>--ports-max=PORTS-MAX</code> <code>PMM_AGENT_PORTS_MAX</code> Highest allowed port number for listening sockets. <code>--ports-min=PORTS-MIN</code> <code>PMM_AGENT_PORTS_MIN</code> Lowest allowed port number for listening sockets. <code>--region=REGION</code> <code>PMM_AGENT_SETUP_REGION</code> Node region. <code>--skip-registration</code> <code>PMM_AGENT_SETUP_SKIP_REGISTRATION</code> Skip registration on PMM Server. <code>--trace</code> <code>PMM_AGENT_TRACE</code> Enable trace output (implies <code>--debug</code>). <code>-h</code>, <code>--help</code> Show help (synonym for <code>pmm-agent help</code>). <code>--version</code> Show application version, PMM version, time-stamp, git commit hash and branch. <code>--expose-exporter</code> (This flag is available starting with PMM 2.41.0.) If you enable this flag, any IP address on the local network and anywhere on the internet can access node exporter endpoints. If the flag is disabled, node exporter endpoints can be accessed only locally."},{"location":"details/commands/pmm-agent.html#usage-and-examples-of-paths-base-flag","title":"USAGE AND EXAMPLES OF <code>paths-base</code> FLAG","text":"<p>Since 2.23.0 this flag could be used for easier setup of pmm agent. With this flag, the root permissions for PMM client aren\u2019t needed anymore, and it will be</p> <p>Since 2.23.0 this flag could be used for easier setup of PMM agent. With this flag the root permissions for PMM client aren\u2019t needed anymore and it will be fully working.</p> <p>Examples:</p> <ul> <li> <p>Case 1: There are no root permissions for <code>/usr/local/percona/pmm2</code> folder or there is a need to change default folder for PMM files. Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm2 --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: /agent_id/be568008-b1b4-4bd9-98c7-392d1f4b724e\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm2\n    exporters_base: /home/user/custom/pmm2/exporters\n    node_exporter: /home/user/custom/pmm2/exporters/node_exporter\n    mysqld_exporter: /home/user/custom/pmm2/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/custom/pmm2/exporters/mongodb_exporter\n    postgres_exporter: /home/user/custom/pmm2/exporters/postgres_exporter\n    proxysql_exporter: /home/user/custom/pmm2/exporters/proxysql_exporter\n    rds_exporter: /home/user/custom/pmm2/exporters/rds_exporter\n    azure_exporter: /home/user/custom/pmm2/exporters/azure_exporter\n    vmagent: /home/user/custom/pmm2/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm2/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm2/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm2/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm2/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above, base for all exporters and tools was changed only by setting <code>--paths-base</code>. With this tag the folder for PMM that doesn\u2019t require root access could be specified.</p> </li> <li> <p>Case 2: The older <code>--paths-exporters_base</code> flag could be passed along with the <code>--paths-base</code> Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm2 --paths-exporters_base=/home/user/exporters --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: /agent_id/afce1917-8836-4857-b3e5-ad372c2ddbe5\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm2\n    exporters_base: /home/user/exporters\n    node_exporter: /home/user/exporters/node_exporter\n    mysqld_exporter: /home/user/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/exporters/mongodb_exporter\n    postgres_exporter: /home/user/exporters/postgres_exporter\n    proxysql_exporter: /home/user/exporters/proxysql_exporter\n    rds_exporter: /home/user/exporters/rds_exporter\n    azure_exporter: /home/user/exporters/azure_exporter\n    vmagent: /home/user/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm2/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm2/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm2/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm2/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above the behavior for the <code>--paths-base</code> was the same, but paths for all exporters were overwritten by the <code>--paths-exporter_base</code> flag.</p> </li> </ul> <p>Summary: Flag <code>--paths-base</code> will set path for all exporters and tools, but each one could be overridden by specific flag (like <code>--paths-mongodb_exporter</code>, <code>--paths-pt-mysql-summary</code> and etc).</p>"},{"location":"details/commands/pmm-agent.html#logging","title":"LOGGING","text":"<p>By default, pmm-agent sends messages to stderr and to the system log (<code>syslogd</code> or <code>journald</code> on Linux).</p> <p>To get a separate log file, edit the <code>pmm-agent</code> start-up script.</p> <p><code>systemd</code>-based systems</p> <ul> <li>Script file: <code>/usr/lib/systemd/system/pmm-agent.service</code></li> <li>Parameter: <code>StandardError</code></li> <li>Default value: <code>file:/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>StandardError=file:/var/log/pmm-agent.log\n</code></pre> <p><code>initd</code>-based systems</p> <ul> <li>Script file: <code>/etc/init.d/pmm-agent</code></li> <li>Parameter: <code>pmm_log</code></li> <li>Default value: <code>/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>pmm_log=\"/var/log/pmm-agent.log\"\n</code></pre>"},{"location":"details/dashboards/index.html","title":"Dashboards","text":"Category Dashboard Elements Kubernetes Kubernetes Cluster Summary 7 Kubernetes Kubernetes Pods Status 26 Kubernetes Kubernetes Volumes 57 Insight Advanced Data Exploration 7 Insight Home Dashboard 26 Insight Prometheus Exporter Status 57 Insight Prometheus Exporters Overview 27 Insight VictoriaMetrics 52 Insight VictoriaMetrics Agents Overview 58 PMM Environment Overview 0 PMM Environment Summary 0 DBaaS DB Cluster Summary 0 OS CPU Utilization Details 21 OS Disk Details 34 OS Network Details 70 OS Memory Details 116 OS Node Temperature Details 6 OS Nodes Compare 74 OS Nodes Overview 115 OS Node Summary 67 OS NUMA Details 72 OS Processes Details 35 Prometheus Prometheus Exporter Status 57 Prometheus Prometheus Exporters Overview 27 MySQL MySQL Amazon Aurora Details 20 MySQL MySQL Command/Handler Counters Compare 11 MySQL MySQL InnoDB Compression Details 41 MySQL MySQL InnoDB Details 339 MySQL MySQL MyISAM/Aria Details 55 MySQL MySQL MyRocks Details 101 MySQL MySQL Instance Summary 90 MySQL MySQL Instances Compare 70 MySQL MySQL Instances Overview 96 MySQL MySQL Wait Event Analyses Details 42 MySQL MySQL Performance Schema Details 48 MySQL MySQL Query Response Time Details 49 MySQL MySQL Replication Summary 50 MySQL MySQL Group Replication Summary 18 MySQL MySQL Table Details 45 MySQL MySQL User Details 62 MongoDB MongoDB Collection Overview 100 MongoDB Experimental MongoDB Collection Details 100 MongoDB MongoDB Oplog Details 100 MongoDB MongoDB Sharded Cluster Summary 55 MongoDB MongoDB Cluster Summary (OLD) 55 MongoDB Experimental MongoDB Router Summary 55 MongoDB MongoDB ReplSet Summary 130 MongoDB MongoDB ReplSet Summary (OLD) 130 MongoDB MongoDB Instance Summary 42 MongoDB MongoDB Instances Overview 42 MongoDB MongoDB Instances Compare 19 MongoDB MongoDB InMemory Details 46 MongoDB MongoDB MMAPv1 Details 52 MongoDB MongoDB WiredTiger Details 54 PostgreSQL PostgreSQL Instances Overview 114 PostgreSQL Experimental PostgreSQL Vacuum Monitoring 114 PostgreSQL PostgreSQL Instance Summary 67 PostgreSQL PostgreSQL Instances Compare 89 ProxySQL ProxySQL Instance Summary 55 High-availability PXC/Galera Node Summary 32 High-availability PXC/Galera Cluster Summary 19 High-availability Experimental PXC/Galera Cluster Summary 7 High-availability PXC/Galera Nodes Compare 55 High-availability HAProxy Instance Summary 113"},{"location":"details/dashboards/dashboard-advanced-data-exploration.html","title":"Advanced Data Exploration","text":"<p>The Advanced Data Exploration dashboard provides detailed information about the progress of a single Prometheus metric across one or more hosts.</p>"},{"location":"details/dashboards/dashboard-advanced-data-exploration.html#view-actual-metric-values-gauge","title":"View actual metric values (Gauge)","text":"<p>A gauge is a metric that represents a single numerical value that can arbitrarily go up and down.</p> <p>Gauges are typically used for measured values like temperatures or current memory usage, but also \u201ccounts\u201d that can go up and down, like the number of running goroutines.</p>"},{"location":"details/dashboards/dashboard-advanced-data-exploration.html#view-metric-rate-of-change-counter","title":"View Metric Rate of Change (Counter)","text":"<p>A counter is a cumulative metric that represents a single numerical value that only ever goes up. A counter is typically used to count requests served, tasks completed, errors occurred, etc. Counters should not be used to expose current counts of items whose number can also go down, e.g. the number of currently running goroutines. Use gauges for this use case.</p>"},{"location":"details/dashboards/dashboard-advanced-data-exploration.html#metric-rates","title":"Metric Rates","text":"<p>Shows the number of samples Per second stored for a given interval in the time series.</p> <p>This dashboard supports metrics related to NUMA. The names of all these metrics start with <code>node_memory_numa</code>.</p> <p></p>"},{"location":"details/dashboards/dashboard-cluster-summary.html","title":"DB Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>This Dashboard is a part of DBaaS solution inside PMM.</p> <p>This Dashboard is designed to show the resource consumption inside Kubernetes (K8s) Cluster.</p>"},{"location":"details/dashboards/dashboard-cpu-utilization-details.html","title":"CPU Utilization Details","text":""},{"location":"details/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-utilization","title":"Overall CPU Utilization","text":"<p>The Overall CPU Utilization metric shows how much of the overall CPU time is used by the server. It has these components:</p> Max Core Utilization No description System This component the proportion of time the CPUs spent inside the Linux kernel for operations like context switching, memory allocation and queue handling. User This component is the time spent in the user space.  Normally, most of the MySQL CPU time is in user space. A high value of user time indicates a CPU bound workload. Softirq This component is the portion of time the CPU spent servicing software interrupts generated by the device drivers.  A high value of softirq may indicates a poorly configured device.  The network devices are generally the main source of high softirq values. Steal When multiple virtual machines share the same physical host, some virtual machines may be allowed to use more of their share of CPU and that CPU time is accounted as Steal by the virtual machine from which the time is taken. Iowait This component is the time the CPU spent waiting for disk IO requests to complete.  A high value of iowait indicates a disk bound load. Nice No description <p>In addition, sampling of the Max utilization of a single core is shown.</p> <p>This metric presents global values: while there may be a lot of unused CPU, a single core may be saturated.  Look at the Max Core Utilization to see if any core is reaching close to 100%.</p>"},{"location":"details/dashboards/dashboard-cpu-utilization-details.html#current-cpu-threads-utilization","title":"Current CPU Threads Utilization","text":"<p>This shows the total utilization of each CPU core along with the average utilization of all CPU cores.  Watch for any core close to 100% utilization and investigate the root cause.</p>"},{"location":"details/dashboards/dashboard-cpu-utilization-details.html#cpu-threads-frequency","title":"CPU Threads Frequency","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-cpu-utilization-details.html#current-cpu-cores-temperature","title":"Current CPU Cores Temperature","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-threads-utilization-details","title":"Overall CPU Threads Utilization Details","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-disk-details.html","title":"Disk Details","text":""},{"location":"details/dashboards/dashboard-disk-details.html#mount-point-usage","title":"mount point Usage","text":"<p>Shows the percentage of disk space utilization for every mount point defined on the system. Having some of the mount points close to 100% space utilization is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where the mount point is close to 100% consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#mount-point","title":"mount point","text":"<p>Shows information about the disk space usage of the specified mount point.</p> <p>Used is the amount of space used.</p> <p>Free is the amount of space not in use.</p> <p>Used+Free is the total disk space allocated to the mount point.</p> <p>Having Free close to 0 B is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where Free is close to 0 B consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-latency","title":"Disk Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-operations","title":"Disk Operations","text":"<p>Shows amount of physical IOs (reads and writes) different devices are serving. Spikes in number of IOs served often corresponds to performance problems due to IO subsystem overload.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-bandwidth","title":"Disk Bandwidth","text":"<p>Shows volume of reads and writes the storage is handling. This can be better measure of IO capacity usage for network attached and SSD storage as it is often bandwidth limited.  Amount of data being written to the disk can be used to estimate Flash storage life time.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-load","title":"Disk Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows disk Utilization as percent of the time when there was at least one IO request in flight. It is designed to match utilization available in iostat tool. It is not very good measure of true IO Capacity Utilization. Consider looking at IO latency and Disk Load Graphs instead.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#avg-disks-operations-merge-ratio","title":"Avg Disks Operations Merge Ratio","text":"<p>Shows how effectively Operating System is able to merge logical IO requests into physical requests.  This is a good measure of the IO locality which can be used for workload characterization.</p>"},{"location":"details/dashboards/dashboard-disk-details.html#disk-io-size","title":"Disk IO Size","text":"<p>Shows average size of a single disk operation.</p>"},{"location":"details/dashboards/dashboard-env-overview.html","title":"Environment Overview","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Dashboard provides the user with a high-level view of all the environments in PMM.</p>"},{"location":"details/dashboards/dashboard-environent-summary.html","title":"Environment Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Environment Summary Dashboard provides an at-a-glance view specific to the selected environment in PMM, including an overview of the services and nodes running in that environment.</p>"},{"location":"details/dashboards/dashboard-haproxy-instance-summary.html","title":"HAProxy Instance Summary","text":"<p>No description.</p>"},{"location":"details/dashboards/dashboard-home.html","title":"Home Dashboard","text":"<p>Availability</p> <p>The new Home dashboard is available starting with PMM 2.32.0.</p> <p>The Home Dashboard provides a high-level overview of your environment, such as the services, infrastructure, and critical issues (if any). It is the starting page of PMM from which you can open the tools of PMM and browse online resources.</p> <p>This Home Dashboard displays data that is organized in panels as given below.</p> <p></p>"},{"location":"details/dashboards/dashboard-home.html#overview","title":"Overview","text":"<p>This panel lists all added hosts along with essential information about their performance. For each host, you can find the current values of the following metrics:</p> <ul> <li>Monitored DB Services</li> <li>Monitored DB Instances</li> <li>Monitored Nodes</li> <li>Memory Available</li> <li>Disk Reads</li> <li>Disk Writes</li> <li>Network IO</li> <li>DB Connections</li> <li>DB QPS</li> <li>Virtual CPUs</li> <li>RAM</li> <li>Host Uptime</li> <li>DB Uptime</li> <li>Advisors check</li> </ul> <p>This panel also displays the current version number. Use Upgrade to X.X.X version to upgrade to the most recent version of PMM.</p>"},{"location":"details/dashboards/dashboard-home.html#anomaly-detection","title":"Anomaly Detection","text":"<p>The Anomaly Detection panel lists all the anomalies in your environment. Color-coded states on the panels provide a quick visual representation of the problem areas.</p> <p>The following anomalies are displayed on this panel:</p> <ul> <li>CPU anomalies (high as well as low)</li> <li>High CPU servers</li> <li>Low CPU servers</li> <li>Disk Queue anomalies</li> <li>High disk queue</li> <li>High Memory Used</li> </ul>"},{"location":"details/dashboards/dashboard-home.html#command-center","title":"Command Center","text":"<p>You can find critical information such as CPU utlization, memory utilization, anomalies, read and write latency, etc., about your environment on the Command Center panel. </p> <p>The information is represented graphically on the Command Center panel. In this panel, the graphs for the last hour and the previous week are displayed adjacently, making it easy to identify the trends.</p> <p>The following information is displayed on the Command Center for the Top 20 nodes:</p> <ul> <li>CPU usage</li> <li>Disk queue</li> <li>Disk Write latency</li> <li>Disk Read latency</li> <li>Memory usage</li> </ul> <p>Command Center lists the </p>"},{"location":"details/dashboards/dashboard-home.html#service-summary","title":"Service Summary","text":"<p>The Service Summary panel provides the following information for the services being monitored:</p> <ul> <li>DB connections</li> <li>DB QPS (Query per sec)</li> <li>DB uptime</li> </ul>"},{"location":"details/dashboards/dashboard-inventory.html","title":"PMM Inventory","text":"<p>The Inventory dashboard is a high-level overview of all objects registered in PMM.</p> <p>To check your inventory list, go to  Configuration \u2192 Inventory.</p> <p></p> <p>Inventory objects form a hierarchy with Node at the top, then Service and Agents assigned to a Node. This information is detailed in the two tabs available on this page.</p>"},{"location":"details/dashboards/dashboard-inventory.html#services-tab","title":"Services tab","text":"<p>The Services tab displays the individual services, the nodes on which they run, and the Agents that help collect the service metrics along with the following information:</p> <p>You can check Query Analytics information and the Service Overview Dashboard for each service by clicking on the  icon in the Options column.</p> <p>From here you can also check additional information about the service, by clicking on the  icon. This expands the service entry to show reference information like service labels and IDs.</p> Column Name Description Service name The name or identifier associated with the service being monitored. Node name Name or identifier associated with a specific node. Monitoring status The Monitoring column summarizes the status of all the Agents assigned to the service. Address The IP address or DNS where the service is currently running. Port The port number on which the service is running. Options * You can check QAN information and the Dashboard for each service by clicking on the  icon   * You can also check additional information about the service, by clicking on the  icon. This expands the service entry to show reference information like service labels and IDs. <p></p>"},{"location":"details/dashboards/dashboard-inventory.html#attributes","title":"Attributes","text":"<p>These are some of the atributes for a service:</p> <ul> <li> <p>Each instance of a service gets a <code>service_type</code> attribute so one can clearly tell what type of database it is, for instance: <code>mysql</code>, <code>postgresql</code>, <code>mongodb</code>, etc. </p> </li> <li> <p>Every service is related to a certain node via its <code>node_id</code> attribute. This feature allows to support monitoring of multiple instances on a single node, with different service names, e.g. <code>mysql1-3306</code>, and <code>mysql1-3307</code>.</p> </li> <li> <p>Starting with PMM 2.41.0, each instance of a service gets a <code>version</code> attribute to the response of the endpoint that provides a list of services being monitored by PMM. This makes it easy to visualize the database server version.</p> <p>However, following are the imitations:</p> <ul> <li>The version is not captured for the internal PostgreSQL database.</li> <li>The version is only captured when a new service is being added to PMM and the agent installed on the client side is equal to or greater than v2.41.0.</li> <li>When a database is upgraded, you will not see the database version updated automatically. It will be updated if you remove and then re-add the service.</li> </ul> </li> </ul>"},{"location":"details/dashboards/dashboard-inventory.html#agents","title":"Agents","text":"<p>Each binary (exporter, agent) running on a client will get an <code>agent_type</code> value. </p> <p>Example</p> <ul> <li><code>pmm-agent</code> is at the top of the tree, assigned to PMM Agent itself</li> <li><code>node_exporter</code> is assigned to an agent that extracts the node metrics</li> <li><code>mysqld_exporter</code> and <code>qan-mysql-perfschema-agent</code> are assigned to agents that extract metrics from mysql and its performance schema respectively.</li> </ul> <p>To view the agents running on a service and their health status, click OK or Failed under the Monitoring column. Furthermore, you can also check the properties of a particular agent by clicking the  icon under the Options column.</p> <p></p>"},{"location":"details/dashboards/dashboard-inventory.html#node-service-relationship","title":"Node-service relationship","text":"<p>Starting with PMM 2.40.0, you can click on the link in the Node Name column to view the node on which a specific service is running and analyze how node-level resource utilization impacts the performance of those services.</p> <p>Understanding the relationship between nodes and services is key to gaining insights into the distribution and performance of individual services across nodes.</p> <ul> <li> <p>Deployment: Services within PMM are deployed on nodes and rely on them for resources, such as CPU, memory, and storage, to execute tasks.</p> </li> <li> <p>Resource allocation: It is essential to know which nodes host which services to allocate resources appropriately to avoid underuse or overload.</p> </li> <li> <p>Performance optimization: By analyzing node and service-level metrics, you can pinpoint and resolve issues that impede service performance, such as resource limitations and performance bottlenecks.</p> </li> <li> <p>Incident response: When an issue or incident occurs, understanding the node-service relationship helps in troubleshooting. You can quickly identify which nodes and services are affected and focus your efforts on resolving the problem.</p> </li> </ul>"},{"location":"details/dashboards/dashboard-inventory.html#editing-labels-for-a-service","title":"Editing labels for a service","text":"<p>You can edit the labels as follows:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Inventory.</p> </li> <li> <p>Click on the three dots next to the service you want to edit labels for.</p> </li> <li> <p>Click Edit. The Edit Service page opens.</p> </li> <li> <p>Edit the labels as per your requirement and click Save Changes. The editing service dialogue box opens.</p> <p></p> </li> <li> <p>Click Confirm and save changes. You will be taken back to the Inventory/Services page.</p> </li> </ol>"},{"location":"details/dashboards/dashboard-inventory.html#effect-of-editing-labels-for-a-service","title":"Effect of editing labels for a service","text":"<p>Editing existing labels can impact the following PMM functions:</p> <ul> <li> <p>Alerting </p> <p>Editing labels without updating alerting rules can lead to missed alerts. If an alert rule is based on specific labels that are changed or no longer apply, the alert may not trigger when it should.</p> <p>Update the alert rules promptly after editing the labels for a smooth alerting experience.</p> </li> <li> <p>Scheduled backups: Editing the cluster label will remove all scheduled backups for the imapcted service or cluster.</p> <p>To prevent any issues, make sure to recreate your backups once you\u2019ve configured the cluster.</p> </li> <li> <p>Dashboard data: Edited labels do not affect the existing time-series(metrics). It will only affect the new time-series(metrics).</p> </li> </ul>"},{"location":"details/dashboards/dashboard-inventory.html#cluster-view","title":"Cluster view","text":"<p>Disclaimer</p> <p>This feature is still technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Starting with PMM 2.40.0, you can choose to view a group of services as a single cluster  with the Organize by Clusters toggle. PMM uses the <code>cluster</code> label to display services under the same cluster.</p> <p></p> <p>Click the downward arrow to view cluster details, including the services running on that cluster, agents, and labels.</p> <p></p> <p>Furthermore, you can filter the clusters by criteria such as Cluster name, Status, Service name, Node name, Monitoring, Address, and Port. </p> <p></p>"},{"location":"details/dashboards/dashboard-inventory.html#nodes-tab","title":"Nodes tab","text":"<p>Shows where the service and agents run.</p> <p>Each <code>node_id</code> is associated with a <code>machine_id</code> (from <code>/etc/machine-id</code>). Nodes also have <code>node_type</code> attributes, which give an idea about their nature. Some examples are: generic, container, remote, remote_rds, etc.</p> <p>By expanding the entry from the options column, you can check the node labels and attributes.</p> <p>Starting with PMM 2.38.0, you can see the number of agents running on any particular node. When you click on any node, the UI navigates to the view of agents, which is filtered to display only agents related to that specific node.</p> <p>Furthermore, starting with PMM 2.40.0, you can see the service running on that specific node when you click on the link in the Services column.</p> <p>To see the details of the agents running, do the following:</p> <ol> <li> <p>On the Nodes tab, under the Monitoring column, click OK or Failed depending on the status of the node that you have selected. A page that provides the user with crucial information regarding the total number of agents deployed on that node is displayed.    </p> </li> <li> <p>Click on the  icon under the Options column to view the properties of a specific agent.</p> </li> <li> <p>On the Nodes tab, under the Options column, click on the  icon for the selected node to check the properties and the current health status of an agent. </p> </li> </ol>"},{"location":"details/dashboards/dashboard-inventory.html#removing-items-from-the-inventory","title":"Removing items from the inventory","text":"<p>To remove items from the inventory:</p> <ol> <li> <p>Go to  Configuration \u2192  Inventory.</p> </li> <li> <p>In the first column, select the items to be removed.    </p> </li> <li>Click Delete and confirm the removal.</li> </ol>"},{"location":"details/dashboards/dashboard-manage-dashboards.html","title":"Manage dashboards","text":"<p>This section describes how to manage your PMM dashboards and the widgets on those dashboards, including:</p> <ul> <li> <p>Creating dashboard folders</p> </li> <li> <p>Managing dashboard folders</p> </li> <li> <p>Setting custom Home dashboard</p> </li> </ul>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#create-dashboard-folders","title":"Create dashboard folders","text":"<p>Folders help you organize and group PMM dashboards, which is crucial when you have multiple dashboards or teams using the same PMM instance.</p> <p>Note</p> <p>To create a dashboard folder, you must have PMM\u2019s Admin privileges.</p> <p>To create a dashboard folder:</p> <ol> <li> <p>On the PMM dashboards page, from the side menu, go to  Dashboards &gt; New folder.</p> </li> <li> <p>Enter a unique name for your folder and click Create.</p> </li> </ol>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#managing-dashboard-folders","title":"Managing dashboard folders","text":"<p>This section describes how to delete multiple dashboards, move dashboards from one folder to another and navigate to a folder page where you can assign folder and dashboard permissions.</p>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#delete-multiple-dashboards","title":"Delete multiple dashboards","text":"<p>To delete multiple dashboards at once:</p> <p>From the side menu, go to  Dashboards &gt; Browse and check the dashboards that you want to delete, and click Delete.</p> <p></p>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#move-dashboards-from-one-folder-to-another","title":"Move dashboards from one folder to another","text":"<p>You can move dashboards from one folder to another in the following two ways:</p> <ol> <li> <p>From the side menu, go to  Dashboards &gt; Browse and check the dashboards that you want to move. Click Move.</p> <p></p> </li> <li> <p>On the Choose Dashboard Folder dialog box select the dashboards that you want to move from the drop-down. Click Move.</p> </li> </ol> <p>The other way of moving dashboards from one folder to another is:</p> <ol> <li>Open the dashboard that you want to move to another folder.</li> <li>Click on  icon to open Dashboard Settings.</li> <li> <p>On the General page, under Folder select the folder name that you want to move from the dropdown.</p> <p></p> </li> <li> <p>Click Save Dashboard on the the left to save the change.</p> </li> </ol> <p>Note</p> <p>You should have atleast an Editor role to move a dashboard.</p>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#navigate-to-a-dashboard-folder-page-to-assign-permissions","title":"Navigate to a dashboard folder page to assign permissions","text":"<ol> <li>From the side menu, go to  Dashboards &gt; Browse and hover over the dashboard folder whose permissions you want to set. Click Go to Folder.</li> <li> <p>Go to the Permissions tab and select the requisite permission from the drop-down for the various roles.</p> <p></p> </li> </ol>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#setting-custom-home-dashboard","title":"Setting custom Home Dashboard","text":"<p>The home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account. </p>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#set-home-dashboard-for-your-organization","title":"Set home dashboard for your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users</p> <ol> <li>Navigate to the dashboard that you want to set as the home dashboard.</li> <li>Click the  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>Hover your cursor over  Configuration</li> <li>Click Preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#set-home-dashboard-for-your-team","title":"Set home dashboard for your team","text":"<p>Organization and team Admins can set the home dashboard for their team as follows:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard to mark the dashboard as a favorite.</li> <li>On the main menu, hover your cursor over  Configuration. </li> <li>Click Teams. Grafana displays the team list.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"details/dashboards/dashboard-manage-dashboards.html#set-your-personal-home-dashboard","title":"Set your Personal Home Dashboard","text":"<ol> <li>From the main menu, go to  Dashboards &gt; Browse and select the dashboard you want to set as your home dashboard.</li> <li> <p>Click the  star next to the dashboard title to mark it as a favorite.</p> <p></p> </li> <li> <p>From the side menu go to  Configuration &gt; Preferences. In the Home Dashboard field, select the dashboard that you want to set as your home dashboard. </p> <p></p> </li> <li> <p>Click Save.</p> </li> </ol>"},{"location":"details/dashboards/dashboard-memory-details.html","title":"Memory Details","text":""},{"location":"details/dashboards/dashboard-memory-details.html#memory-usage","title":"Memory Usage","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html","title":"MongoDB Cluster Summary (OLD)","text":"Dashboard update notice <p>A new version of the MongoDB Sharded Cluster Summary dashboard is available.   This older version will be deprecated and removed from PMM in the near future. We encourage you to start using the new dashboard to benefit from its enhanced monitoring capabilities.</p> <p></p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#current-connections-per-shard","title":"Current Connections Per Shard","text":"<p>TCP connections (Incoming) in mongod processes.</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#total-connections","title":"Total Connections","text":"<p>Incoming connections to mongos nodes.</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#cursors-per-shard","title":"Cursors Per Shard","text":"<p>The Cursor is a MongoDB Collection of the document which is returned upon the find method execution.</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#mongos-cursors","title":"Mongos Cursors","text":"<p>The Cursor is a MongoDB Collection of the document which is returned upon the find method execution.</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#operations-per-shard","title":"Operations Per Shard","text":"<p>Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#total-mongos-operations","title":"Total Mongos Operations","text":"<p>Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#change-log-events","title":"Change Log Events","text":"<p>Count, over last 10 minutes, of all types of configuration db changelog events.</p>"},{"location":"details/dashboards/dashboard-mongodb-cluster-summary-old.html#oplog-range-by-set","title":"Oplog Range by Set","text":"<p>Timespan \u2018window\u2019 between oldest and newest ops in the Oplog collection.</p>"},{"location":"details/dashboards/dashboard-mongodb-experimental_collection_details.html","title":"Experimental MongoDB Collection Details","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>Availability</p> <p>This experimental dashboard is available starting with PMM 2.30.0.</p> <p>This realtime experimental dashboard provides detailed information about the top collections by document count, size, and document read for MongoDB databases.</p> <p></p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html","title":"MongoDB InMemory Details","text":""},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-transactions","title":"InMemory Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-capacity","title":"InMemory Capacity","text":"<p>Configured max and current size of the WiredTiger cache.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-sessions","title":"InMemory Sessions","text":"<p>Internal WiredTiger storage engine cursors and sessions currently open.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-pages","title":"InMemory Pages","text":"<p>Pages in the WiredTiger cache</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-concurrency-tickets","title":"InMemory Concurrency Tickets","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cTickets available\u201d = hard coded high value - \u201cTickets Out\u201d.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-cache-eviction","title":"InMemory Cache Eviction","text":"<p>This panel shows the number of pages that have been evicted from the WiredTiger cache for the given time period. The InMemory storage engine only evicts modified pages which signals a compaction of the data and removal of the dirty pages.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"details/dashboards/dashboard-mongodb-inmemory-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html","title":"MongoDB Instance Summary","text":""},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#command-operations","title":"Command Operations","text":"<p>Ops or Replicated Ops/sec classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>). And (from the internal TTL threads) the docs deletes/sec by TTL indexes.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#latency-detail","title":"Latency Detail","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#connections","title":"Connections","text":"<p>TCP connections (Incoming)</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#cursors","title":"Cursors","text":"<p>Open cursors. Includes idle cursors.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#document-operations","title":"Document Operations","text":"<p>Docs per second inserted, updated, deleted or returned. (not 1-to-1 with operation counts.)</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Ratio of Documents returned or Index entries scanned / full documents scanned</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-time","title":"<code>getLastError</code> Write Time","text":"<p>Legacy driver operation: Number of, and Sum of time spent, per second executing <code>getLastError</code> commands to confirm write concern.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-operations","title":"<code>getLastError</code> Write Operations","text":"<p>Legacy driver operation: Number of <code>getLastError</code> commands that timed out trying to confirm write concern.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#assert-events","title":"Assert Events","text":"<p>This panel shows the number of assert events per second on average over the given time period. In most cases assertions are trivial, but you would want to check your log files if this counter spikes or is consistently high.</p>"},{"location":"details/dashboards/dashboard-mongodb-instance-summary.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html","title":"MongoDB Instances Compare","text":""},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#connections","title":"Connections","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#cursors","title":"Cursors","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#latency","title":"Latency","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#scan-ratios","title":"Scan Ratios","text":"<p>Ratio of index entries scanned or whole docs scanned / number of documents returned</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#index-filtering-effectiveness","title":"Index Filtering Effectiveness","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#requests","title":"Requests","text":"<p>Ops/sec (classified by (legacy) wire protocol request type)</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#document-operations","title":"Document Operations","text":"<p>Documents inserted/updated/deleted or returned per sec</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#queued-operations","title":"Queued Operations","text":"<p>The number of operations that are currently queued and waiting for a lock</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-compare.html#used-memory","title":"Used Memory","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html","title":"MongoDB Instances Overview","text":"<p>This dashboard provides basic information about MongoDB instances.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#command-operations","title":"Command Operations","text":"<p>Shows how many times a command is executed per second on average during the selected interval.</p> <p>Look for peaks and drops and correlate them with other graphs.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#connections","title":"Connections","text":"<p>Keep in mind the hard limit on the maximum number of connections set by your distribution.</p> <p>Anything over 5,000 should be a concern, because the application may not close connections correctly.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#cursors","title":"Cursors","text":"<p>Helps identify why connections are increasing.  Shows active cursors compared to cursors being automatically killed after 10 minutes due to an application not closing the connection.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#document-operations","title":"Document Operations","text":"<p>When used in combination with Command Operations, this graph can help identify write amplification.  For example, when one <code>insert</code> or <code>update</code> command actually inserts or updates hundreds, thousands, or even millions of documents.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#queued-operations","title":"Queued Operations","text":"<p>Any number of queued operations for long periods of time is an indication of possible issues.  Find the cause and fix it before requests get stuck in the queue.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#getlasterror-write-time-getlasterror-write-operations","title":"<code>getLastError</code> Write Time, <code>getLastError</code> Write Operations","text":"<p>This is useful for write-heavy workloads to understand how long it takes to verify writes and how many concurrent writes are occurring.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#asserts","title":"Asserts","text":"<p>Asserts are not important by themselves, but you can correlate spikes with other graphs.</p>"},{"location":"details/dashboards/dashboard-mongodb-instances-overview.html#memory-faults","title":"Memory Faults","text":"<p>Memory faults indicate that requests are processed from disk either because an index is missing or there is not enough memory for the data set.  Consider increasing memory or sharding out.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html","title":"MongoDB MMAPv1 Details","text":""},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#document-activity","title":"Document Activity","text":"<p>Docs per second inserted, updated, deleted or returned. Also showing replicated write ops and internal TTL index deletes.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-lock-wait-time","title":"MMAPv1 Lock Wait Time","text":"<p>Time spent per second waiting to acquire locks.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-page-faults","title":"MMAPv1 Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-write-activity","title":"MMAPv1 Journal Write Activity","text":"<p>MB processed through the journal in memory.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-commit-activity","title":"MMAPv1 Journal Commit Activity","text":"<p>MB committed to disk for the journal.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-background-flushing-time","title":"MMAPv1 Background Flushing Time","text":"<p>Average time in ms, over full uptime of <code>mongod</code> process, the MMAP background flushes have taken.</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#queued-operations","title":"Queued Operations","text":"<p>Queue size of ops waiting to be submitted to storage engine layer. (see WiredTiger concurrency tickets for number of ops being processed simultaneously in storage engine layer.)</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#client-operations","title":"Client Operations","text":"<p>Ops and Replicated Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"details/dashboards/dashboard-mongodb-mmapv1-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html","title":"MongoDB ReplSet Summary (OLD)","text":"Dashboard update notice <p>A new version of the MongoDB ReplSet Summary dashboard is available. This older version will be deprecated and removed from PMM in the near future. We encourage you to start using the new dashboard to benefit from its enhanced monitoring capabilities.</p> <p></p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#replication-lag","title":"Replication Lag","text":"<p>MongoDB replication lag occurs when the secondary node cannot replicate data fast enough to keep up with the rate that data is being written to the primary node. It could be caused by something as simple as network latency, packet loss within your network, or a routing issue.</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#operations-by-service-name","title":"Operations - by service name","text":"<p>Operations are classified by legacy wire protocol type (insert, update, and delete only).</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#max-member-ping-time-by-service-name","title":"Max Member Ping Time - by service name","text":"<p>This metric can show a correlation with the replication lag value.</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#max-heartbeat-time","title":"Max Heartbeat Time","text":"<p>Time span between now and last heartbeat from replicaset members.</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#elections","title":"Elections","text":"<p>Count of elections. Usually zero; 1 count by each healthy node will appear in each election. Happens when the primary role changes due to either normal maintenance or trouble events.</p>"},{"location":"details/dashboards/dashboard-mongodb-replset-summary-old.html#oplog-recovery-window-by-service-name","title":"Oplog Recovery Window - by service name","text":"<p>Timespan \u2018window\u2019 between newest and the oldest op in the Oplog collection.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html","title":"Experimental MongoDB Router Summary","text":"<p>This dashboard is available starting from PMM 2.43 and is specifically designed for monitoring MongoS (router) nodes in sharded MongoDB clusters.</p> <p></p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#overview","title":"Overview","text":"<p>For each MongoS in the cluster, this section includes main monitoring metrics like CPU, memory and disk usage. Uptime and MongoS version are reported as well.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#cpu-usage","title":"CPU Usage","text":"<p>Shows CPU usage as a percentage from 0% to 100%. It updates every minute, turning from green to red when usage exceeds 80%. This helps quickly spot high CPU load, which could affect system performance, and monitor how hard the CPU is working at a glance.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#memory-used","title":"Memory Used","text":"<p>Displays the percentage of total system memory currently in use. It updates regularly, showing green up to 80% of usage and red beyond that threshold.</p> <p>Use this for a quick visual indicator of memory consumption to monitor available memory without swapping as it\u2019s an easy way to assess how close the system is to its memory limits.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows how busy the disk is handling read/write requests. The meter turns red above 80%, warning of potential slowdowns. It updates regularly, giving administrators a quick way to check if the disk is keeping up with demand or if it\u2019s becoming a bottleneck in system performance.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#disk-space-utilization","title":"Disk Space Utilization","text":"<p>Shows how much of the total disk space is currently in use. The meter turns red when usage exceeds 80%, warning of low free space. It updates regularly, giving you a quick way to check if the disk is nearing capacity. This helps prevent \u201cdisk full\u201d errors that could disrupt services or system operation.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#disk-iops","title":"Disk IOPS","text":"<p>Shows how many read and write operations the disk performs each second. The blue color helps spot spikes in disk activity. These spikes could mean the disk is struggling to keep up, which might slow down the system. It\u2019s a quick way for you to check if the disk is working too hard.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#network-traffic","title":"Network Traffic","text":"<p>Combines both incoming (received) and outgoing (transmitted) data, excluding local traffic. It gives you a quick view of overall network activity, helping spot unusual spikes or drops in data flow that might affect system performance.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#uptime","title":"Uptime","text":"<p>Shows how long the system has been running without a restart. As uptime increases, the color changes from red to orange to green, giving a quick visual indicator of system stability. Red indicates very recent restarts (less than 5 minutes), orange shows short uptimes (5 minutes to 1 hour), and green represents longer uptimes (over 1 hour). This helps you easily spot recent system restarts or confirm continuous operation.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#version","title":"Version","text":"<p>Displays the current version of MongoDB running on the system. This information is crucial for ensuring the system is running the intended version and for quickly identifying any nodes that might need updates.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#node-states","title":"Node States","text":"<p>Shows the status of all MongoDB Shard (MongoS) nodes in the selected cluster over time. It uses a color-coded timeline: green bars mean a node is \u201cUP\u201d and working, while red bars show it\u2019s \u201cDOWN\u201d or unreachable. This simple view helps you quickly spot which nodes are active, see any recent status changes, and identify patterns in node availability.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#details","title":"Details","text":"<p>This section includes additional information like \u201cCommand Operations\u201d, \u201cConnections\u201d, \u201cQuery execution times\u201d and \u201cQuery efficiency\u201d.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#command-operations","title":"Command Operations","text":"<p>Shows MongoDB command operations over time, displaying rates for inserts, updates, deletes, queries, and TTL deletions per second.</p> <p>Use this to monitor overall database workload, compare operation types, spot peak usage and unusual patterns, assess replication activity, and track automatic data cleanup.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#connections","title":"Connections","text":"<p>Displays MongoDB connection metrics over time, showing both current and available connections. Use this to monitor connection usage trends, identify periods of high demand, and ensure the database isn\u2019t reaching its connection limits.</p> <p>By comparing current to available connections, it\u2019s easy to spot potential bottlenecks or capacity issues before they impact performance.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#query-execution-times","title":"Query execution times","text":"<p>Shows the average execution times for MongoDB queries over time, categorized into read, write, and other command operations.</p> <p>Use this to identify slow queries, performance bottlenecks, and unusual spikes in execution times. Comparing latencies across operation types can also guide decisions on indexing strategies and query optimizations.</p>"},{"location":"details/dashboards/dashboard-mongodb-router-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Visualizes MongoDB query efficiency over time, displaying the ratio of scanned documents or index entries to returned documents, along with operation latencies.</p> <p>A ratio near 1 indicates highly efficient queries, while higher values (e.g., 100) suggest inefficiency.</p> <p>Compare document scans, index scans, and operation latencies to quickly identify poorly performing queries, and ensure that queries execute as efficiently as possible.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html","title":"MongoDB WiredTiger Details","text":""},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-transactions","title":"WiredTiger Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-activity","title":"WiredTiger Cache Activity","text":"<p>Data volume transferred per second between the WT cache and data files. Writes out always imply disk; Reads are often from OS file buffer cache already in RAM, but disk if not.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-block-activity","title":"WiredTiger Block Activity","text":"<p>Data volume handled by the WT block manager per second</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-sessions","title":"WiredTiger Sessions","text":"<p>Internal WT storage engine cursors and sessions currently open</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-concurrency-tickets-available","title":"WiredTiger Concurrency Tickets Available","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cAvailable\u201d = hard-coded high value - \u201cOut\u201d.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-checkpoint-time","title":"WiredTiger Checkpoint Time","text":"<p>The time spent in WT checkpoint phase. Warning: This calculation averages the cyclical event (default: 1 min) execution to a per-second value.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-eviction","title":"WiredTiger Cache Eviction","text":"<p>Least-recently used pages being evicted due to WT cache becoming full.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-capacity","title":"WiredTiger Cache Capacity","text":"<p>Configured max and current size of the WT cache.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-pages","title":"WiredTiger Cache Pages","text":""},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-operations","title":"WiredTiger Log Operations","text":"<p>WT internal write-ahead log operations.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-activity","title":"WiredTiger Log Activity","text":"<p>Data volume moved per second in WT internal write-ahead log.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-records","title":"WiredTiger Log Records","text":"<p>Number of records appended per second in WT internal log.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"details/dashboards/dashboard-mongodb-wiredtiger-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"details/dashboards/dashboard-mongodb_collection_overview.html","title":"MongoDB Collections Overview","text":"<p>This realtime dashboard contains panels of data about the Hottest Collections in the MongoDB database.</p> <p>The Instance level includes two panels, one for the Hottest Collections by Read (Total) and the Hottest Collections by Write (total).</p> <p>The next panel displays data at the Database Level, where you can view MongoDB metrics such as Commands, Inserts, Updates, Removes, and Getmore.</p> <p>The last panel shows the number of operations in the chosen database.</p> <p></p>"},{"location":"details/dashboards/dashboard-mongodb_oplog.html","title":"MongoDB Oplog Details","text":"<p>This realtime dashboard contains Oplog details such as Recovery Window, Processing Time, Buffer Capacity, and Oplog Operations.</p> <p></p>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html","title":"MySQL Amazon Aurora Details","text":""},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-transaction-commits","title":"Amazon Aurora Transaction Commits","text":"<p>This graph shows the number of Commits which Amazon Aurora engine performed as well as average commit latency. Graph Latency does not always correlate with the number of performed commits and can be quite high in certain situations.</p> <ul> <li> <p>Number of Amazon Aurora Commits: The average number of commit operations per second.</p> </li> <li> <p>Amazon Aurora Commit avg Latency: The average amount of latency for commit operations</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-load","title":"Amazon Aurora Load","text":"<p>This graph shows us what statements contribute most load on the system as well as what load corresponds to Amazon Aurora transaction commit.</p> <ul> <li> <p>Write Transaction Commit Load: Load in Average Active Sessions per second for COMMIT operations</p> </li> <li> <p>UPDATE load: Load in Average Active Sessions per second for UPDATE queries</p> </li> <li> <p>SELECT load: Load in Average Active Sessions per second for SELECT queries</p> </li> <li> <p>DELETE load: Load in Average Active Sessions per second for DELETE queries</p> </li> <li> <p>INSERT load: Load in Average Active Sessions per second for INSERT queries</p> </li> </ul> <p>An active session is a connection that has submitted work to the database engine and is waiting for a response from it. For example, if you submit an SQL query to the database engine, the database session is active while the database engine is processing that query.</p>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#aurora-memory-used","title":"Aurora Memory Used","text":"<p>This graph shows how much memory is used by Amazon Aurora lock manager as well as amount of memory used by Amazon Aurora to store Data Dictionary.</p> <ul> <li> <p>Aurora Lock Manager Memory: the amount of memory used by the Lock Manager, the module responsible for handling row lock requests for concurrent transactions.</p> </li> <li> <p>Aurora Dictionary Memory: the amount of memory used by the Dictionary, the space that contains metadata used to keep track of database objects, such as tables and indexes.</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-statement-latency","title":"Amazon Aurora Statement Latency","text":"<p>This graph shows average latency for the most important types of statements. Latency spikes are often indicative of the instance overload.</p> <ul> <li> <p>DDL Latency: Average time to execute DDL queries</p> </li> <li> <p>DELETE Latency: Average time to execute DELETE queries</p> </li> <li> <p>UPDATE Latency: Average time to execute UPDATE queries</p> </li> <li> <p>SELECT Latency: Average time to execute SELECT queries</p> </li> <li> <p>INSERT Latency: Average time to execute INSERT queries</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-special-command-counters","title":"Amazon Aurora Special Command Counters","text":"<p>Amazon Aurora MySQL allows a number of commands which are not available in standard MySQL. This graph shows usage of such commands.  Regular <code>unit_test</code> calls can be seen in default Amazon Aurora install, the rest will depend on your workload.</p> <ul> <li> <p><code>show_volume_status</code>: The number of executions per second of the command SHOW VOLUME STATUS. The SHOW VOLUME STATUS query returns two server status variables, Disks and Nodes. These variables represent the total number of logical blocks of data and storage nodes, respectively, for the DB cluster volume.</p> </li> <li> <p><code>awslambda</code>: The number of AWS Lambda calls per second. AWS Lambda is an event-drive, server-less computing platform provided by AWS. It is a compute service that run codes in response to an event. You can run any kind of code from Aurora invoking Lambda from a stored procedure or a trigger.</p> </li> <li> <p><code>alter_system</code>: The number of executions per second of the special query ALTER SYSTEM, that is a special query to simulate an instance crash, a disk failure, a disk congestion or a replica failure. It\u2019s a useful query for testing the system.</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-problems","title":"Amazon Aurora Problems","text":"<p>This graph shows different kinds of Internal Amazon Aurora MySQL Problems which general should be zero in normal operation.</p> <p>Anything non-zero is worth examining in greater depth.</p>"},{"location":"details/dashboards/dashboard-mysql-command-handler-counters-compare.html","title":"MySQL Command/Handler Counters Compare","text":"<p>This dashboard shows server status variables. On this dashboard, you may select multiple servers and compare their counters simultaneously.</p> <p>Server status variables appear in two sections: Commands and Handlers. Choose one or more variables in the Command and Handler fields in the top menu to select the variables which will appear in the COMMANDS or HANDLERS section for each host. Your comparison may include from one up to three hosts.</p> <p>By default or if no item is selected in the menu, PMM displays each command or handler respectively.</p>"},{"location":"details/dashboards/dashboard-mysql-group-replication-summary.html","title":"MySQL Group Replication Summary","text":""},{"location":"details/dashboards/dashboard-mysql-group-replication-summary.html#overview","title":"Overview","text":"<ul> <li>PRIMARY Service</li> <li>Group Replication Service States</li> <li>Replication Group Members</li> <li>Replication Lag</li> <li>Replication Delay</li> <li>Transport Time</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-group-replication-summary.html#transactions","title":"Transactions","text":"<ul> <li>Transaction Details</li> <li>Applied Transactions</li> <li>Sent Transactions</li> <li>Checked Transactions</li> <li>Rolled Back Transactions</li> <li>Transactions Row Validating</li> <li>Transactions in the Queue for Checking</li> <li>Received Transactions Queue</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-group-replication-summary.html#conflicts","title":"Conflicts","text":"<ul> <li>Detected Conflicts</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-innodb-compression-details.html","title":"MySQL InnoDB Compression Details","text":"<p>This dashboard helps you analyze the efficiency of InnoDB compression.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-compression-details.html#compression-level-and-failure-rate-threshold","title":"Compression level and failure rate threshold","text":"InnoDB Compression Level The level of zlib compression to use for InnoDB compressed tables and indexes. InnoDB Compression Failure Threshold The compression failure rate threshold for a table. Compression Failure Rate Threshold The maximum percentage that can be reserved as free space within each compressed page, allowing room to reorganize the data and modification log within the page when a compressed table or index is updated and the data might be recompressed. Write Pages to the Redo Log Specifies whether images of re-compressed pages are written to the redo log. Re-compression may occur when changes are made to compressed data."},{"location":"details/dashboards/dashboard-mysql-innodb-compression-details.html#statistic-of-compression-operations","title":"Statistic of compression operations","text":"Compress Attempts Number of compression operations attempted. Pages are compressed whenever an empty page is created or the space for the uncompressed modification log runs out. Uncompressed Attempts Number of uncompression operations performed. Compressed InnoDB pages are uncompressed whenever compression fails, or the first time a compressed page is accessed in the buffer pool and the uncompressed page does not exist."},{"location":"details/dashboards/dashboard-mysql-innodb-compression-details.html#cpu-core-usage","title":"CPU Core Usage","text":"CPU Core Usage for Compression Shows the time in seconds spent by InnoDB Compression operations. CPU Core Usage for Uncompression Shows the time in seconds spent by InnoDB Uncompression operations."},{"location":"details/dashboards/dashboard-mysql-innodb-compression-details.html#buffer-pool-total","title":"Buffer Pool Total","text":"Total Used Pages Shows the total amount of used compressed pages into the InnoDB Buffer Pool split by page size. Total Free Pages Shows the total amount of free compressed pages into the InnoDB Buffer Pool split by page size."},{"location":"details/dashboards/dashboard-mysql-innodb-details.html","title":"MySQL InnoDB Details","text":"<p>Tip</p> <p>If metrics are missing, try running: <code>SET GLOBAL innodb_monitor_enable=all;</code> in the MySQL client.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-activity","title":"InnoDB Activity","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#writes-rows","title":"Writes (Rows)","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#writes-transactions","title":"Writes (Transactions)","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rows-read-per-trx","title":"Rows Read Per Trx","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-space-per-trx","title":"Log Space per Trx","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rollbacks","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#bp-reqs-per-row","title":"BP Reqs Per Row","text":"<p>Number of Buffer Pool requests per Row Access. High numbers here indicate going through long undo chains, deep trees and other inefficient data access.  It can be less than zero due to several rows being read from single page.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-fsync-per-trx","title":"Log Fsync Per Trx","text":"<p>Log Fsync Per Transaction.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-reads","title":"InnoDB Row Reads","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-writes","title":"InnoDB Row Writes","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations_1","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-read-only-transactions","title":"InnoDB Read-Only Transactions","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-read-write-transactions","title":"InnoDB Read-Write Transactions","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-transactions-information-rw","title":"InnoDB Transactions Information (RW)","text":"<p>The InnoDB Transactions Information graph shows details about the recent transactions.  Transaction IDs Assigned represents the total number of transactions initiated by InnoDB.  RW Transaction Commits are the number of transactions not read-only. Insert-Update Transactions Commits are transactions on the Undo entries.  Non Locking RO Transaction Commits are transactions commit from select statement in auto-commit mode or transactions explicitly started with \u201cstart transaction read only\u201d.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#misc-innodb-transactions-information","title":"Misc InnoDB Transactions Information","text":"<p>Additional InnoDB Transaction Information</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-storage-summary","title":"InnoDB Storage Summary","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-tables","title":"InnoDB Tables","text":"<p>Current Number of InnoDB Tables in database</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#data-buffer-pool-fit","title":"Data Buffer Pool Fit","text":"<p>Buffer Pool Size as Portion of the Data</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#avg-row-size","title":"Avg Row Size","text":"<p>Amount of Data Per Row</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#index-size-per-row","title":"Index Size Per Row","text":"<p>Index Size Per Row shows how much space we\u2019re using for indexes on per row basics</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-data-summary","title":"InnoDB Data Summary","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#space-allocated","title":"Space Allocated","text":"<p>Total Amount of Space Allocated. May not exactly match amount of space used on file system but provided great guidance.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#space-used","title":"Space Used","text":"<p>Space used in All InnoDB Tables. Reported Allocated Space Less Free Space.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#data-length","title":"Data Length","text":"<p>Space Used by Data (Including Primary Key).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#index-length","title":"Index Length","text":"<p>Space Used by Secondary Indexes.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#estimated-rows","title":"Estimated Rows","text":"<p>Estimated number of Rows in InnoDB Storage Engine. It is not exact value and it can change abruptly as information is updated.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#indexing-overhead","title":"Indexing Overhead","text":"<p>How Much Indexes Take Compared to Data.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#free-space-percent","title":"Free Space Percent","text":"<p>How Much Space is Free. Too high value wastes space on disk.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#free","title":"Free","text":"<p>Allocated Space not currently used by Data or Indexes.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-file-per-table","title":"InnoDB File Per Table","text":"<p>If Enabled, By Default every Table will have its own Tablespace represented as its own <code>.idb</code> file  rather than all tables stored in single system tablespace.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-disk-io","title":"InnoDB Disk IO","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-page-size","title":"InnoDB Page Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#avg-data-read-rq-size","title":"Avg Data Read Rq Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#avg-data-write-rq-size","title":"Avg Data Write Rq Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#avg-log-write-rq-size","title":"Avg Log Write Rq Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#data-written-per-fsync","title":"Data Written Per Fsync","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-written-per-fsync","title":"Log Written Per Fsync","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#data-read-per-row-read","title":"Data Read Per Row Read","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#data-written-per-row-written","title":"Data Written Per Row Written","text":"<p>Due to difference in timing of Row Write and Data Write the value may be misleading on short intervals.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-data-io","title":"InnoDB Data I/O","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of fsync() operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-data-bandwidth","title":"InnoDB Data Bandwidth","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-log-io","title":"InnoDB Log IO","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of <code>fsync()</code> operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-fsyncs","title":"InnoDB FSyncs","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-io","title":"InnoDB Pending IO","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-fsyncs","title":"InnoDB Pending Fsyncs","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-extend-increment","title":"InnoDB Auto Extend Increment","text":"<p>When Growing InnoDB System Tablespace extend it by this size at the time.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-double-write","title":"InnoDB Double Write","text":"<p>Whether InnoDB Double Write Buffer is enabled. Doing so doubles amount of writes InnoDB has to do to storage but is required to avoid potential data corruption during the crash on most storage subsystems.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-fast-shutdown","title":"InnoDB Fast Shutdown","text":"<p>Fast Shutdown means InnoDB will not perform complete Undo Space and Change Buffer cleanup on shutdown, which is faster but may interfere with certain major upgrade operations.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-open-files","title":"InnoDB Open Files","text":"<p>Maximum Number of Files InnoDB is Allowed to use.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-file-use","title":"InnoDB File Use","text":"<p>Portion of Allowed InnoDB Open Files Use.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-io-objects","title":"InnoDB IO Objects","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-io-targets-write-load","title":"InnoDB IO Targets Write Load","text":"<p>Write Load Includes both Write and fsync (referred as misc).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool","title":"InnoDB Buffer Pool","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size","title":"Buffer Pool Size","text":"<p>InnoDB Buffer Pool Size</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size-of-total-ram","title":"Buffer Pool Size of Total RAM","text":"<p>InnoDB Buffer Pool Size % of Total RAM</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#numa-interleave","title":"NUMA Interleave","text":"<p>Interleave Buffer Pool between NUMA zones to better support NUMA systems.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-activity","title":"Buffer Pool Activity","text":"<p>Combined value of Buffer Pool Read and Write requests.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#bp-data","title":"BP Data","text":"<p>Percent of Buffer Pool Occupied by Cached Data.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#bp-data-dirty","title":"BP Data Dirty","text":"<p>Percent of Data which is Dirty.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#bp-miss-ratio","title":"BP Miss Ratio","text":"<p>How often buffer pool read requests have to do read from the disk. Keep this percent low for good performance.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#bp-write-buffering","title":"BP Write Buffering","text":"<p>Number of Logical Writes to Buffer Pool Per logical Write.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-lru-sub-chain-churn","title":"InnoDB Buffer Pool LRU Sub-Chain Churn","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-chunk-size","title":"Buffer Pool Chunk Size","text":"<p>Size of the \u201cChunk\u201d for buffer pool allocation.  Allocation of buffer pool will be rounded by this number. It also affects the performance impact of online buffer pool resize.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-instances","title":"Buffer Pool Instances","text":"<p>Number of Buffer Pool Instances. Higher values allow to reduce contention but also increase overhead.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#read-ahead-io-percent","title":"Read Ahead IO Percent","text":"<p>Percent of Reads Caused by InnoDB Read Ahead.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#read-ahead-wasted","title":"Read Ahead Wasted","text":"<p>Percent of Pages Fetched by Read Ahead Evicted Without Access.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#dump-buffer-pool-on-shutdown","title":"Dump Buffer Pool on Shutdown","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#load-buffer-pool-at-startup","title":"Load Buffer Pool at Startup","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#portion-of-buffer-pool-to-dumpload","title":"Portion of Buffer Pool To Dump/Load","text":"<p>Larger Portion increases dump/load time but get more of original buffer pool content and hence may reduce warmup time.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#include-buffer-pool-in-core-dump","title":"Include Buffer Pool in Core Dump","text":"<p>Whenever to Include Buffer Pool in Crash Core Dumps.  Doing so may dramatically increase core dump file slow down restart.  Only makes a difference if core dumping on crash is enabled.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks","title":"InnoDB Old Blocks","text":"<p>Percent of The Buffer Pool To be Reserved for \u201cOld Blocks\u201d - which has been touched repeatedly over period of time.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks-time","title":"InnoDB Old Blocks Time","text":"<p>The Time which has to pass between multiple touches for the block for it to qualify as old block.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead","title":"InnoDB Random Read Ahead","text":"<p>Is InnoDB Random ReadAhead Enabled.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead_1","title":"InnoDB Random Read Ahead","text":"<p>The Threshold (in Pages) to trigger Linear Read Ahead.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-read-io-threads","title":"InnoDB Read IO Threads","text":"<p>Number of Threads used to Schedule Reads.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-write-io-threads","title":"InnoDB Write IO Threads","text":"<p>Number of Threads used to Schedule Writes.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-native-aio-enabled","title":"InnoDB Native AIO Enabled","text":"<p>Whether Native Asynchronous IO is enabled.  Strongly recommended for optimal performance.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-replacement-management","title":"InnoDB Buffer Pool - Replacement Management","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-scan-depth","title":"LRU Scan Depth","text":"<p>InnoDB LRU Scan Depth</p> <p>This variable defines InnoDB Free Page Target per buffer pool. When number of free pages falls below this number this number page cleaner will make required amount of pages free, flushing or evicting pages from the tail of LRU as needed.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-clean-page-searches","title":"LRU Clean Page Searches","text":"<p>When Page is being read (or created)  the Page need to be allocated in Buffer Pool.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#free-list-miss-rate","title":"Free List Miss Rate","text":"<p>The most efficient way to get a clean page is to grab one from free list.  However if no pages are available in Free List the LRU scan needs to be performed.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-loops","title":"LRU Get Free Loops","text":"<p>If Free List was empty LRU Get Free Loop will be performed.  It may perform LRU scan or may use some other heuristics and shortcuts to get free page.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-scans","title":"LRU Scans","text":"<p>If Page could not be find any Free list and other shortcuts did not work, free page will be searched by scanning LRU chain which is not efficient.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-in-lru-scans","title":"Pages Scanned in LRU Scans","text":"<p>Pages Scanned Per Second while doing LRU scans.  If this value is large (thousands) it means a lot of resources are wasted.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-lru-scan","title":"Pages scanned per LRU Scan","text":"<p>Number of pages scanned per LRU scan in Average. Large number of scans can consume a lot of resources and also introduce significant addition latency to queries.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-waits","title":"LRU Get Free Waits","text":"<p>If InnoDB could not find a free page in LRU list and had to sleep. Should be zero.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpointing-and-flushing","title":"InnoDB Checkpointing and Flushing","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-from-flush-list","title":"Pages Flushed from Flush List","text":"<p>Number of Pages Flushed from \u201cFlush List\u201d  This combines Pages Flushed through Adaptive Flush and Background Flush.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#page-flush-batches-executed","title":"Page Flush Batches Executed","text":"<p>InnoDB Flush Cycle typically Runs on 1 second intervals.  If too far off from this number it can indicate an issue.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-per-batch","title":"Pages Flushed Per Batch","text":"<p>How many pages are flushed per Batch.  Large Batches can \u201cchoke\u201d IO subsystem and starve other IO which needs to happen.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing-enabled","title":"Neighbor Flushing Enabled","text":"<p>Neighbor Flushing is Optimized for Rotational Media  and unless you\u2019re Running spinning disks you should disable it.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpoint-age","title":"InnoDB Checkpoint Age","text":"<p>InnoDB Checkpoint Age</p> <p>The maximum checkpoint age is determined by the total length of all transaction log files (<code>innodb_log_file_size</code>).</p> <p>When the checkpoint age reaches the maximum checkpoint age, blocks are flushed synchronously. The rules of the thumb is to keep one hour of traffic in those logs and let the check-pointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-adaptive","title":"Pages Flushed (Adaptive)","text":"<p>Adaptive Flush  Flushes pages from Flush List based on the need to advance Checkpoint (driven by Redo Generation Rate) and by maintaining number of dirty pages within set limit.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#adaptive-flush-batches-executed","title":"Adaptive Flush Batches Executed","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-adaptive","title":"Pages Per Batch (Adaptive)","text":"<p>Pages Flushed Per Adaptive Batch.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing","title":"Neighbor Flushing","text":"<p>To optimize IO for rotational Media InnoDB may flush neighbor pages. It can cause significant wasted IO for flash storage.    Generally for flash you should run with <code>innodb_flush_neighbors=0</code> but otherwise this shows how much IO you\u2019re wasting.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-lru","title":"Pages Flushed (LRU)","text":"<p>Flushing from the tail of the LRU list is needed to keep readily-available free pages for new data to be read when data does not fit in the buffer pool.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lru-flush-batches-executed","title":"LRU Flush Batches Executed","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-lru","title":"Pages Per Batch (LRU)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lsn-age-flush-batch-target","title":"LSN Age Flush Batch Target","text":"<p>Target for Pages to Flush due to LSN Age.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-neighbor","title":"Pages Flushed (Neighbor)","text":"<p>Number of Neighbor pages flushed (If neighbor flushing is enabled)  from Flush List and LRU List Combined.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#neighbor-flush-batches-executed","title":"Neighbor Flush Batches Executed","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-neighbor","title":"Pages Per Batch (Neighbor)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#sync-flush-waits","title":"Sync Flush Waits","text":"<p>If InnoDB could not keep up with Checkpoint Flushing and had to trigger Sync flush.  This should never happen.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-background","title":"Pages Flushed (Background)","text":"<p>Pages Flushed by Background Flush which is activated when server is considered to be idle.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#background-flush-batches-executed","title":"Background Flush Batches Executed","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-background","title":"Pages Per Batch (Background)","text":"<p>Pages Flushed Per Background Batch.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo) is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-flushing-by-type","title":"InnoDB Flushing by Type","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-lru","title":"Pages Evicted (LRU)","text":"<p>This correspond to number of clean pages which were evicted (made free) from the tail of LRU buffer.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#page-eviction-batches","title":"Page Eviction Batches","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-per-batch","title":"Pages Evicted per Batch","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#max-log-space-used","title":"Max Log Space Used","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#single-page-flushes","title":"Single Page Flushes","text":"<p>Single Page flushes happen in rare case, then clean page could not be found in LRU list. It should be zero for most workloads.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#single-page-flush-pages-scanned","title":"Single Page Flush Pages Scanned","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-single-page-flush","title":"Pages Scanned Per Single Page Flush","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity","title":"InnoDB IO Capacity","text":"<p>Estimated number of IOPS storage system can provide.  Is used to scale background activities. Do not set it to actual storage capacity.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity-max","title":"InnoDB IO Capacity Max","text":"<p>InnoDB IO Capacity to use when falling behind and need to catch up with Flushing.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-logging","title":"InnoDB Logging","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#total-log-space","title":"Total Log Space","text":"<p>Number of InnoDB Log Files Multiplied by Their Size.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-buffer-size","title":"Log Buffer Size","text":"<p>InnoDB Log Buffer Size</p> <p>The size of buffer InnoDB uses for buffering writes to log files.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#at-transaction-commit","title":"At Transaction Commit","text":"<p>What to do with Log file At Transaction Commit. Do nothing and wait for timeout to  flush the data from Log Buffer,  Flush it to OS Cache but not FSYNC or Flush only.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#flush-transaction-log-every","title":"Flush Transaction Log Every","text":"<p>Every Specified Number of Seconds Flush Transaction Log.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-write-ahead-block-size","title":"InnoDB Write Ahead Block Size","text":"<p>This variable can be seen as minimum IO alignment InnoDB will use for Redo log file.  High Values cause waste, low values can make IO less efficient.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-write-amplification","title":"Log Write Amplification","text":"<p>How much Writes to Log Are Amplified compared to how much Redo is Generated.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-fsync-rate","title":"Log Fsync Rate","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#redo-generated-per-trx","title":"Redo Generated per Trx","text":"<p>Amount of Redo Generated Per Write Transaction.  This is a good indicator of transaction size.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-usage-hourly","title":"InnoDB Log File Usage Hourly","text":"<p>InnoDB Log File Usage Hourly</p> <p>Along with the buffer pool size, <code>innodb_log_file_size</code> is the most important setting when we are working with InnoDB. This graph shows how much data was written to InnoDB\u2019s redo logs over each hour. When the InnoDB log files are full, InnoDB needs to flush the modified pages from memory to disk.</p> <p>The rules of the thumb is to keep one hour of traffic in those logs and let the checkpointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p> <p>This graph can help guide you in setting the correct <code>innodb_log_file_size</code>.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-padding-written","title":"Log Padding Written","text":"<p>Amount of Log Padding Written.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-size","title":"InnoDB Log File Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-log-files","title":"InnoDB Log Files","text":"<p>Number of InnoDB Redo Log Files.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#log-bandwidth","title":"Log Bandwidth","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate_1","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo)  is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-group-commit-batch-size","title":"InnoDB Group Commit Batch Size","text":"<p>The InnoDB Group Commit Batch Size graph shows how many bytes were written to the InnoDB log files per attempt to write. If many threads are committing at the same time, one of them will write the log entries of all the waiting threads and flush the file. Such process reduces the number of disk operations needed and enlarge the batch size.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-locking","title":"InnoDB Locking","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#lock-wait-timeout","title":"Lock Wait Timeout","text":"<p>InnoDB Lock Wait Timeout</p> <p>How long to wait for row lock before timing out.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-deadlock-detection","title":"InnoDB Deadlock Detection","text":"<p>If Disabled InnoDB Will not detect deadlocks but rely on timeouts.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-increment-lock-mode","title":"InnoDB Auto Increment Lock Mode","text":"<p>Will Define How much locking will come from working with Auto Increment Columns.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rollback-on-timeout","title":"Rollback on Timeout","text":"<p>Whenever to rollback all transaction on timeout or just last statement.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#row-lock-blocking","title":"Row Lock Blocking","text":"<p>Percent of Active Sections which are blocked due to waiting on InnoDB Row Locks.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx_1","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rollbacks_1","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-activity","title":"InnoDB Row Lock Wait Activity","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-time","title":"InnoDB Row Lock Wait Time","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-load","title":"InnoDB Row Lock Wait Load","text":"<p>Average Number of Sessions blocked from proceeding due to waiting on row level lock.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-row-locks-activity","title":"InnoDB Row Locks Activity","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-table-lock-activity","title":"InnoDB Table Lock Activity","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#current-locks","title":"Current Locks","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-and-purging","title":"InnoDB Undo Space and Purging","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#undo-tablespaces","title":"Undo Tablespaces","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#max-undo-log-size","title":"Max Undo Log Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-log-truncate","title":"InnoDB Undo Log Truncate","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#purge-threads","title":"Purge Threads","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag","title":"Max Purge Lag","text":"<p>Maximum number of  Unpurged Transactions, if this number exceeded delay will be introduced to incoming DDL statements.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag-delay","title":"Max Purge Lag Delay","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#current-purge-delay","title":"Current Purge Delay","text":"<p>The Delay Injected due to Purge Thread(s) unable to keep up with purge progress.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rollback-segments","title":"Rollback Segments","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-activity","title":"InnoDB Purge Activity","text":"<p>The InnoDB Purge Performance graph shows metrics about the page purging process.  The purge process removed the undo entries from the history list and cleanup the pages of the old versions of modified rows and effectively remove deleted rows.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#transactions-and-undo-records","title":"Transactions and Undo Records","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-usage","title":"InnoDB Undo Space Usage","text":"<p>The InnoDB Undo Space Usage graph shows the amount of space used by the Undo segment.  If the amount of space grows too much, look for long running transactions holding read views opened in the InnoDB status.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#transaction-history","title":"Transaction History","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-throttling","title":"InnoDB Purge Throttling","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#records-per-undo-log-page","title":"Records Per Undo Log Page","text":"<p>How Many Undo Operations Are Handled Per Each Undo Log Page.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#purge-invoked","title":"Purge Invoked","text":"<p>How Frequently Purge Operation is Invoked.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#ops-per-purge","title":"Ops Per Purge","text":"<p>Home Many Purge Actions are done Per invocation.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#undo-slots-used","title":"Undo Slots Used","text":"<p>Number of Undo Slots Used.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#max-transaction-history-length","title":"Max Transaction History Length","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#purge-batch-size","title":"Purge Batch Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rseg-truncate-frequency","title":"Rseg Truncate Frequency","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-page-operations","title":"InnoDB Page Operations","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-page-splits-and-merges","title":"InnoDB Page Splits and Merges","text":"<p>The InnoDB Page Splits graph shows the InnoDB page maintenance activity related to splitting and merging pages.  When an InnoDB page, other than the top most leaf page, has too much data to accept a row update or a row insert, it has to be split in two.  Similarly, if an InnoDB page, after a row update or delete operation, ends up being less than half full, an attempt is made to merge the page with a neighbor page. If the resulting page size is larger than the InnoDB page size, the operation fails.  If your workload causes a large number of page splits, try lowering the <code>innodb_fill_factor</code> variable (5.7+).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#page-merge-success-ratio","title":"Page Merge Success Ratio","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorg-attempts","title":"InnoDB Page Reorg Attempts","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorgs-failures","title":"InnoDB Page Reorgs Failures","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-fill-factor","title":"InnoDB Fill Factor","text":"<p>The portion of the page to fill then doing sorted Index Build.   Lowering this value will worsen space utilization but will reduce need to split pages when new data is inserted in the index.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-hash-index","title":"InnoDB Adaptive Hash Index","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-enabled","title":"Adaptive Hash Index Enabled","text":"<p>Adaptive Hash Index helps to optimize index Look-ups but can be severe hotspot for some workloads.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-partitions","title":"Adaptive Hash Index Partitions","text":"<p>How many Partitions Used for Adaptive Hash Index (to reduce contention).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#percent-of-pages-hashed","title":"Percent of Pages Hashed","text":"<p>Number of Pages Added to AHI vs Number of Pages Added to Buffer Pool.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#ahi-miss-ratio","title":"AHI Miss Ratio","text":"<p>Percent of Searches which could not be resolved through AHI.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#rows-added-per-page","title":"Rows Added Per Page","text":"<p>Number of Rows \u201cHashed\u201d  Per Each Page which needs to be added to AHI.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#ahi-roi","title":"AHI ROI","text":"<p>How Many Successful Searches using AHI are performed per each row maintenance operation.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-usage","title":"InnoDB AHI Usage","text":"<p>The InnoDB AHI Usage graph shows the search operations on the InnoDB adaptive hash index and its efficiency.  The adaptive hash index is a search hash designed to speed access to InnoDB pages in memory.  If the Hit Ratio is small, the working data set is larger than the buffer pool, the AHI should likely be disabled.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-miss-ratio","title":"InnoDB AHI Miss Ratio","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-rows","title":"InnoDB AHI Churn - Rows","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-pages","title":"InnoDB AHI Churn - Pages","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer","title":"InnoDB Change Buffer","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (as Percent of Buffer Pool Size).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size_1","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (Bytes).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer-merge-load","title":"InnoDB Change Buffer Merge Load","text":"<p>Number of Average of Active Merge Buffer Operations in Process.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-contention","title":"InnoDB Contention","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-concurrency","title":"InnoDB Thread Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-commit-concurrency","title":"InnoDB Commit Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time during Commit Stage.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-sleep-delay","title":"InnoDB Thread Sleep Delay","text":"<p>The Time the thread will Sleep before Re-Entering InnoDB Kernel if high contention.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-max-sleep-delay","title":"InnoDB Adaptive Max Sleep Delay","text":"<p>If Set to Non-Zero Value InnoDB Thread Sleep Delay will be adjusted automatically depending on the load up to the value specified by this variable.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-concurrency-tickets","title":"InnoDB Concurrency Tickets","text":"<p>Number of low level operations InnoDB can do after it entered InnoDB kernel before it is forced to exit and yield to another thread waiting.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-delay","title":"InnoDB Spin Wait Delay","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-pause-multiplier","title":"InnoDB Spin Wait Pause Multiplier","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-sync-spin-loops","title":"InnoDB Sync Spin Loops","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-os-waits","title":"InnoDB Contention - OS Waits","text":"<p>The InnoDB Contention - OS Waits graph shows the number of time an OS wait operation was required while waiting to get the lock.  This happens once the spin rounds are exhausted.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-spin-rounds","title":"InnoDB Contention - Spin Rounds","text":"<p>The InnoDB Contention - Spin Rounds graph shows the number of spin rounds executed to get a lock.  A spin round is a fast retry to get the lock in a loop.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-misc","title":"InnoDB Misc","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-main-thread-utilization","title":"InnoDB Main Thread Utilization","text":"<p>The InnoDB Main Thread Utilization graph shows the portion of time the InnoDB main thread spent at various task.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-activity_1","title":"InnoDB Activity","text":"<p>The InnoDB Activity graph shows a measure of the activity of the InnoDB threads.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-dedicated-server","title":"InnoDB Dedicated Server","text":"<p>InnoDB automatically optimized for Dedicated Server Environment (auto scaling cache and some other variables).</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-sort-buffer-size","title":"InnoDB Sort Buffer Size","text":"<p>This Buffer is used for Building InnoDB Indexes using Sort algorithm.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-stats-auto-recalc","title":"InnoDB Stats Auto Recalc","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#update-stats-when-metadata-queried","title":"Update Stats when Metadata Queried","text":"<p>Refresh InnoDB Statistics when meta-data queries by <code>SHOW TABLE STATUS</code> or <code>INFORMATION_SCHEMA</code> queries.  If Enabled can cause severe performance issues.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#index-condition-pushdown-icp","title":"Index Condition Pushdown (ICP)","text":"<p>Index Condition Pushdown (ICP) is an optimization for the case where MySQL retrieves rows from a table using an index. Without ICP, the storage engine traverses the index to locate rows in the base table and returns them to the MySQL server which evaluates the\u00a0WHERE condition for the rows. With ICP enabled, and if parts of the\u00a0WHERE\u00a0condition can be evaluated by using only columns from the index, the MySQL server pushes this part of the\u00a0WHERE\u00a0condition down to the storage engine. The storage engine then evaluates the pushed index condition by using the index entry and only if this is satisfied is the row read from the table. ICP can reduce the number of times the storage engine must access the base table and the number of times the MySQL server must access the storage engine.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-statistics","title":"InnoDB Persistent Statistics","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-sample-pages","title":"InnoDB Persistent Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Enabled.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-transient-sample-pages","title":"InnoDB Transient Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Disabled.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-online-operations-mariadb","title":"InnoDB Online Operations (MariaDB)","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-defragmentation","title":"InnoDB Defragmentation","text":"<p>The InnoDB Defragmentation graph shows the status information related to the InnoDB online defragmentation feature of MariaDB for the optimize table command.  To enable this feature, the variable <code>innodb-defragment</code> must be set to 1 in the configuration file.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#innodb-online-ddl","title":"InnoDB Online DDL","text":"<p>The InnoDB Online DDL graph shows the state of the online DDL (alter table) operations in InnoDB.  The progress metric is estimate of the percentage of the rows processed by the online DDL.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-summary","title":"MySQL Summary","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-uptime","title":"MySQL Uptime","text":"<p>MySQL Uptime</p> <p>The amount of time since the last restart of the MySQL server process.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#current-qps","title":"Current QPS","text":"<p>Current QPS</p> <p>Based on the queries reported by MySQL\u2019s <code>SHOW STATUS</code> command, it is the number of statements executed by the server within the last second. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count <code>COM_PING</code> or <code>COM_STATISTICS</code> commands.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#file-handlers-used","title":"File Handlers Used","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-miss-ratio","title":"Table Open Cache Miss Ratio","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-size","title":"Table Open Cache Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#table-definition-cache-size","title":"Table Definition Cache Size","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-connections","title":"MySQL Connections","text":"<p>Max Connections</p> <p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that mysqld requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p>mysqld actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":"<p>MySQL Active Threads</p> <p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-handlers","title":"MySQL Handlers","text":"<p>MySQL Handlers</p> <p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#top-command-counters","title":"Top Command Counters","text":"<p>Top Command Counters</p> <p>The <code>Com_{{ xxx }}</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count <code>DELETE</code> and <code>UPDATE</code> statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to <code>DELETE</code> and <code>UPDATE</code> statements that use multiple-table syntax.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#mysql-network-traffic","title":"MySQL Network Traffic","text":"<p>MySQL Network Traffic</p> <p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#node-summary","title":"Node Summary","text":""},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#system-uptime","title":"System Uptime","text":"<p>The parameter shows how long a system has been up and running without a shut down or restart.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#load-average","title":"Load Average","text":"<p>The system load is a measurement of the computational work the system is performing. Each running process either using or waiting for CPU resources adds 1 to the load.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#ram","title":"RAM","text":"<p>RAM (Random Access Memory) is the hardware in a computing device where the operating system, application programs and data in current use are kept so they can be quickly reached by the device\u2019s processor.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#memory-available","title":"Memory Available","text":"<p>Percent of Memory Available</p> <p>On Modern Linux Kernels amount of Memory Available for application is not the same as Free+Cached+Buffers.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#virtual-memory","title":"Virtual Memory","text":"<p>RAM + SWAP</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#disk-space","title":"Disk Space","text":"<p>Sum of disk space on all partitions.</p> <p>It can be significantly over-reported in some installations.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#min-space-available","title":"Min Space Available","text":"<p>Lowest percent of the disk space available.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p> <p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"details/dashboards/dashboard-mysql-innodb-details.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html","title":"MySQL Instance Summary","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-connections","title":"MySQL Connections","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#max-connections","title":"Max Connections","text":"<p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that <code>mysqld</code> requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p><code>mysqld</code> actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-aborted-connections","title":"MySQL Aborted Connections","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#aborted-connections","title":"Aborted Connections","text":"<p>When a given host connects to MySQL and the connection is interrupted in the middle (for example due to bad credentials), MySQL keeps that info in a system table (since 5.6 this table is exposed in <code>performance_schema</code>).</p> <p>If the amount of failed requests without a successful connection reaches the value of <code>max_connect_errors</code>, <code>mysqld</code> assumes that something is wrong and blocks the host from further connection.</p> <p>To allow connections from that host again, you need to issue the <code>FLUSH HOSTS</code> statement.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-active-threads","title":"MySQL Active Threads","text":"<p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache","title":"MySQL Thread Cache","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache_1","title":"MySQL Thread Cache","text":"<p>The <code>thread_cache_size</code> variable sets how many threads the server should cache to reuse. When a client disconnects, the client\u2019s threads are put in the cache if the cache is not full. It is auto-sized in MySQL 5.6.8 and above (capped to 100). Requests for threads are satisfied by reusing threads taken from the cache if possible, and only when the cache is empty is a new thread created.</p> <ul> <li><code>threads_created</code>: The number of threads created to handle connections.</li> <li><code>threads_cached</code>: The number of threads in the thread cache.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries","title":"MySQL Slow Queries","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries_1","title":"MySQL Slow Queries","text":"<p>Slow queries are defined as queries being slower than the <code>long_query_time</code> setting. For example, if you have <code>long_query_time</code> set to 3, all queries that take longer than 3 seconds to complete will show on this graph.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types","title":"MySQL Select Types","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types_1","title":"MySQL Select Types","text":"<p>As with most relational databases, selecting based on indexes is more efficient than scanning an entire table\u2019s data. Here we see the counters for selects not done with indexes.</p> <ul> <li>Select Scan is how many queries caused full table scans, in which all the data in the table had to be read and either discarded or returned.</li> <li>Select Range is how many queries used a range scan, which means MySQL scanned all rows in a given range.</li> <li>Select Full Join is the number of joins that are not joined on an index, this is usually a huge performance hit.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts","title":"MySQL Sorts","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts_1","title":"MySQL Sorts","text":"<p>Due to a query\u2019s structure, order, or other requirements, MySQL sorts the rows before returning them. For example, if a table is ordered 1 to 10 but you want the results reversed, MySQL then has to sort the rows to return 10 to 1.</p> <p>This graph also shows when sorts had to scan a whole table or a given range of a table to return the results and which could not have been sorted via an index.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-table-locks","title":"MySQL Table Locks","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#table-locks","title":"Table Locks","text":"<p>MySQL takes a number of different locks for varying reasons. In this graph we see how many Table level locks MySQL has requested from the storage engine. In the case of InnoDB, many times the locks could actually be row locks as it only takes table level locks in a few specific cases.</p> <p>It is most useful to compare Locks Immediate and Locks Waited. If Locks waited is rising, it means you have lock contention. Otherwise, Locks Immediate rising and falling is normal activity.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-questions","title":"MySQL Questions","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-questions_1","title":"MySQL Questions","text":"<p>The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries used in the QPS calculation.</p> <p>This variable does not count the following commands:</p> <ul> <li><code>COM_PING</code></li> <li><code>COM_STATISTICS</code></li> <li><code>COM_STMT_PREPARE</code></li> <li><code>COM_STMT_CLOSE</code></li> <li><code>COM_STMT_RESET</code></li> </ul>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic","title":"MySQL Network Traffic","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic_1","title":"MySQL Network Traffic","text":"<p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly","title":"MySQL Network Usage Hourly","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly_1","title":"MySQL Network Usage Hourly","text":"<p>Here we can see how much network traffic is generated by MySQL per hour. You can use the bar graph to compare data sent by MySQL and data received by MySQL.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-internal-memory-overview","title":"MySQL Internal Memory Overview","text":"<p>System Memory: Total Memory for the system.</p> <p>InnoDB Buffer Pool Data: InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.</p> <p>TokuDB Cache Size: Similar in function to the InnoDB Buffer Pool, TokuDB will allocate 50% of the installed RAM for its own cache.</p> <p>Key Buffer Size: Index blocks for MyISAM tables are buffered and are shared by all threads. <code>key_buffer_size</code> is the size of the buffer used for index blocks.</p> <p>Adaptive Hash Index Size: When InnoDB notices that some index values are being accessed very frequently, it builds a hash index for them in memory on top of B-Tree indexes.</p> <p>Query Cache Size: The query cache stores the text of a SELECT statement together with the corresponding result that was sent to the client. The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time.</p> <p>InnoDB Dictionary Size: The data dictionary is InnoDB\u2019s internal catalog of tables. InnoDB stores the data dictionary on disk, and loads entries into memory while the server is running.</p> <p>InnoDB Log Buffer Size: The MySQL InnoDB log buffer allows transactions to run without having to write the log to disk before the transactions commit.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#top-command-counters","title":"Top Command Counters","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#top-command-counters_1","title":"Top Command Counters","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly","title":"Top Command Counters Hourly","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly_1","title":"Top Command Counters Hourly","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers","title":"MySQL Handlers","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers_1","title":"MySQL Handlers","text":"<p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory","title":"MySQL Query Cache Memory","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory_1","title":"MySQL Query Cache Memory","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity","title":"MySQL Query Cache Activity","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity_1","title":"MySQL Query Cache Activity","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status","title":"MySQL Table Open Cache Status","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status_1","title":"MySQL Table Open Cache Status","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables","title":"MySQL Open Tables","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables_1","title":"MySQL Open Tables","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache","title":"MySQL Table Definition Cache","text":""},{"location":"details/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache_1","title":"MySQL Table Definition Cache","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"details/dashboards/dashboard-mysql-instances-compare.html","title":"MySQL Instances Compare","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mysql-instances-overview.html","title":"MySQL Instances Overview","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mysql-myisam-aria-details.html","title":"MySQL MyISAM/Aria Details","text":""},{"location":"details/dashboards/dashboard-mysql-myisam-aria-details.html#myisam-key-buffer-performance","title":"MyISAM Key Buffer Performance","text":"<p>The <code>Key Read Ratio</code>  (<code>Key_reads</code> / <code>Key_read_requests</code>) ratio should normally be less than 0.01.</p> <p>The  <code>Key Write Ratio</code> (<code>Key_writes</code> / <code>Key_write_requests</code>) ratio is usually near 1 if you are using mostly updates and deletes, but might be much smaller if you tend to do updates that affect many rows at the same time or if you are using the <code>DELAY_KEY_WRITE</code> table option.</p>"},{"location":"details/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-readswrites","title":"Aria Pagecache Reads/Writes","text":"<p>This graph is similar to InnoDB buffer pool reads/writes. <code>aria-pagecache-buffer-size</code> is the main cache for the Aria storage engine. If you see high reads/writes (physical IO), i.e. reads are close to read requests and/or writes are close to write requests you may need to increase the <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p>"},{"location":"details/dashboards/dashboard-mysql-myisam-aria-details.html#aria-transaction-log-syncs","title":"Aria Transaction Log Syncs","text":"<p>This is similar to InnoDB log file syncs. If you see lots of log syncs and want to relax the durability settings you can change <code>aria_checkpoint_interval</code> (in seconds) from 30 (default) to a higher number. It is good to look at the disk IO dashboard as well.</p>"},{"location":"details/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-blocks","title":"Aria Pagecache Blocks","text":"<p>This graph shows the utilization for the Aria pagecache. This is similar to InnoDB buffer pool graph. If you see all blocks are used you may consider increasing <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p>"},{"location":"details/dashboards/dashboard-mysql-myrocks-details.html","title":"MySQL MyRocks Details","text":"<p>The MyRocks storage engine developed by Facebook based on the RocksDB storage engine is applicable to systems which primarily interact with the database by writing data to it rather than reading from it. RocksDB also features a good level of compression, higher than that of the InnoDB storage engine, which makes it especially valuable when optimizing the usage of hard drives.</p> <p>PMM collects statistics on the MyRocks storage engine for MySQL in the Metrics Monitor information for this dashboard comes from the Information Schema tables.</p>"},{"location":"details/dashboards/dashboard-mysql-myrocks-details.html#metrics","title":"Metrics","text":"<ul> <li>MyRocks cache</li> <li>MyRocks cache data bytes R/W</li> <li>MyRocks cache index hit rate</li> <li>MyRocks cache index</li> <li>MyRocks cache filter hit rate</li> <li>MyRocks cache filter</li> <li>MyRocks cache data bytes inserted</li> <li>MyRocks bloom filter</li> <li>MyRocks memtable</li> <li>MyRocks memtable size</li> <li>MyRocks number of keys</li> <li>MyRocks cache L0/L1</li> <li>MyRocks number of DB ops</li> <li>MyRocks R/W</li> <li>MyRocks bytes read by iterations</li> <li>MyRocks write ops</li> <li>MyRocks WAL</li> <li>MyRocks number reseeks in iterations</li> <li>RocksDB row operations</li> <li>MyRocks file operations</li> <li>RocksDB stalls</li> <li>RocksDB stops/slowdowns</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-performance-schema-details.html","title":"MySQL Performance Schema Details","text":"<p>The MySQL Performance Schema dashboard helps determine the efficiency of communicating with Performance Schema. This dashboard contains the following metrics:</p> <ul> <li>Performance Schema file IO (events)</li> <li>Performance Schema file IO (load)</li> <li>Performance Schema file IO (Bytes)</li> <li>Performance Schema waits (events)</li> <li>Performance Schema waits (load)</li> <li>Index access operations (load)</li> <li>Table access operations (load)</li> <li>Performance Schema SQL and external locks (events)</li> <li>Performance Schema SQL and external locks (seconds)</li> </ul>"},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html","title":"MySQL Query Response Time Details","text":""},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time","title":"Average Query Response Time","text":"<p>The Average Query Response Time graph shows information collected using the Response Time Distribution plugin sourced from table <code>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</code>. It computes this value across all queries by taking the sum of seconds divided by the count of queries.</p>"},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html#query-response-time-distribution","title":"Query Response Time Distribution","text":"<p>Query response time counts (operations) are grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time_1","title":"Average Query Response Time","text":"<p>Available only in Percona Server for MySQL, provides  visibility of the split of READ vs WRITE query response time.</p>"},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html#read-query-response-time-distribution","title":"Read Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates READ query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-query-response-time-details.html#write-query-response-time-distribution","title":"Write Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates WRITE query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html","title":"MySQL Replication Summary","text":""},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#io-thread-running","title":"IO Thread Running","text":"<p>This metric shows if the IO Thread is running or not. It only applies to a secondary host.</p> <p>SQL Thread is a process that runs on a secondary host in the replication environment. It reads the events from the local relay log file and applies them to the secondary server.</p> <p>Depending on the format of the binary log it can read query statements in plain text and re-execute them or it can read raw data and apply them to the local host.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#possible-values","title":"Possible values","text":"Yes The thread is running and is connected to a replication primary No The thread is not running because it is not launched yet or because an error has occurred connecting to the primary host Connecting The thread is running but is not connected to a replication primary No value The host is not configured to be a replication secondary <p>IO Thread Running is one of the parameters that the command <code>SHOW SLAVE STATUS</code> returns.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#sql-thread-running","title":"SQL Thread Running","text":"<p>This metric shows if the SQL thread is running or not. It only applies to a secondary host.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#possible-values_1","title":"Possible values","text":"Yes SQL Thread is running and is applying events from the relay log to the local secondary host No SQL Thread is not running because it is not launched yet or because of an error occurred while applying an event to the local secondary host"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#replication-error-no","title":"Replication Error No","text":"<p>This metric shows the number of the last error in the SQL Thread encountered which caused replication to stop.</p> <p>One of the more common errors is Error: 1022 Duplicate Key Entry. In such a case replication is attempting to update a row that already exists on the secondary. The SQL Thread will stop replication to avoid data corruption.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#read-only","title":"Read only","text":"<p>This metric indicates whether the host is configured to be in Read Only mode or not.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#possible-values_2","title":"Possible values","text":"Yes <p>The secondary host permits no client updates except from users who have the SUPER privilege or the REPLICATION SLAVE privilege.</p> <p>This kind of configuration is typically used for secondary hosts in a replication environment to avoid a user can inadvertently or voluntarily modify data causing inconsistencies and stopping the replication process.</p> No The secondary host is not configured in Read Only mode."},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#mysql-replication-delay","title":"MySQL Replication Delay","text":"<p>This metric shows the number of seconds the secondary host is delayed in replication applying events compared to when the primary host applied them, denoted by the <code>Seconds_Behind_Master</code> value, and only applies to a secondary host.</p> <p>Since the replication process applies the data modifications on the secondary asynchronously, it could happen that the secondary replicates events after some time. The main reasons are:</p> <ul> <li> <p>Network round trip time - high latency links will lead to non-zero replication lag values.</p> </li> <li> <p>Single threaded nature of replication channels - primary servers have the advantage of applying changes in parallel, whereas secondary ones are only able to apply changes in serial, thus limiting their throughput. In some cases Group Commit can help but is not always applicable.</p> </li> <li> <p>High number of changed rows or computationally expensive SQL - depending on the replication format (<code>ROW</code> vs <code>STATEMENT</code>), significant changes to the database through high volume of rows modified, or expensive CPU will all contribute to secondary servers lagging behind the primary.</p> </li> </ul> <p>Generally adding more CPU or Disk resources can alleviate replication lag issues, up to a point.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#binlog-size","title":"Binlog Size","text":"<p>This metric shows the overall size of the binary log files, which can exist on both primary and secondary servers.</p> <p>The binary log (also known as the binlog) contains events that describe database changes: <code>CREATE TABLE</code>, <code>ALTER TABLE</code>, updates, inserts, deletes and other statements or database changes.</p> <p>The binlog file is read by secondaries via their IO Thread process to replicate database changes modification on the data and on the table structures. There can be more than one binlog file depending on the binlog rotation policy (for example using the configuration variables <code>max_binlog_size</code> and <code>expire_logs_days</code>) or because of server reboots.</p> <p>When planning the disk space, take care of the overall dimension of binlog files and adopt a good rotation policy or think about having a separate mount point or disk to store the binlog data.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#binlog-data-written-hourly","title":"Binlog Data Written Hourly","text":"<p>This metric shows the amount of data written hourly to the binlog files during the last 24 hours. This metric can give you an idea of how big is your application in terms of data writes (creation, modification, deletion).</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#binlog-count","title":"Binlog Count","text":"<p>This metric shows the overall count of binary log files, on both primary and secondary servers.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#binlogs-created-hourly","title":"Binlogs Created Hourly","text":"<p>This metric shows the number of binlog files created hourly during the last 24 hours.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#relay-log-space","title":"Relay Log Space","text":"<p>This metric shows the overall size of the relay log files. It only applies to a secondary host.</p> <p>The relay log consists of a set of numbered files containing the events to be executed on the secondary host to replicate database changes.</p> <p>The relay log has the same format as the binlog.</p> <p>There can be multiple relay log files depending on the rotation policy adopted (using the configuration variable <code>max_relay_log_size</code>).</p> <p>As soon as the SQL thread completes to execute all events in the relay log file, the file is deleted.</p> <p>If this metric contains a high value, the variable <code>max_relay_log_file</code> is high too. Generally, this not a serious issue. If the value of this metric is constantly increased, the secondary is delaying too much in applying the events.</p> <p>Treat this metric in the same way as the MySQL Replication Delay metric.</p>"},{"location":"details/dashboards/dashboard-mysql-replication-summary.html#relay-log-written-hourly","title":"Relay Log Written Hourly","text":"<p>This metric shows the amount of data written hourly into relay log files during the last 24 hours.</p>"},{"location":"details/dashboards/dashboard-mysql-table-details.html","title":"MySQL Table Details","text":""},{"location":"details/dashboards/dashboard-mysql-table-details.html#largest-tables","title":"Largest Tables","text":"Largest Tables by Row Count The estimated number of rows in the table from <code>information_schema.tables</code>. Largest Tables by Size The size of the table components from <code>information_schema.tables</code>."},{"location":"details/dashboards/dashboard-mysql-table-details.html#pie","title":"Pie","text":"Total Database Size The total size of the database: as data + index size, so freeable one. Most Fragmented Tables by Freeable Size The list of 5 most fragmented tables ordered by their freeable size"},{"location":"details/dashboards/dashboard-mysql-table-details.html#table-activity","title":"Table Activity","text":"<p>The next two graphs are available only for Percona Server and MariaDB and require <code>userstat</code> variable turned on.</p>"},{"location":"details/dashboards/dashboard-mysql-table-details.html#rows-read","title":"Rows read","text":"<p>The number of rows read from the table, shown for the top 5 tables.</p>"},{"location":"details/dashboards/dashboard-mysql-table-details.html#rows-changed","title":"Rows Changed","text":"<p>The number of rows changed in the table, shown for the top 5 tables.</p>"},{"location":"details/dashboards/dashboard-mysql-table-details.html#auto-increment-usage","title":"Auto Increment Usage","text":"<p>The current value of an <code>auto_increment</code> column from <code>information_schema</code>, shown for the top 10 tables.</p>"},{"location":"details/dashboards/dashboard-mysql-tokudb-details.html","title":"MySQL TokuDB Details","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-mysql-user-details.html","title":"MySQL User Details","text":"<p>This dashboard requires Percona Server for MySQL 5.1+ or MariaDB 10.1/10.2 with XtraDB. Also <code>userstat</code> should be enabled, for example with the <code>SET GLOBAL userstat=1</code> statement. See Setting up MySQL.</p> <p>Data is displayed for the 5 top users.</p> Top Users by Connections Created The number of times user\u2019s connections connected using SSL to the server. Top Users by Traffic The number of bytes sent to the user\u2019s connections. Top Users by Rows Fetched/Read The number of rows fetched by the user\u2019s connections. Top Users by Rows Updated The number of rows updated by the user\u2019s connections. Top Users by Busy Time The cumulative number of seconds there was activity on connections from the user. Top Users by CPU Time The cumulative CPU time elapsed, in seconds, while servicing connections of the user."},{"location":"details/dashboards/dashboard-mysql-wait-event-analyses-details.html","title":"MySQL Wait Event Analyses Details","text":"<p>This dashboard helps to analyze Performance Schema wait events. It plots the following metrics for the chosen (one or more) wait events:</p> <ul> <li>Count - Performance Schema Waits</li> <li>Load - Performance Schema Waits</li> <li>Avg Wait Time - Performance Schema Waits</li> </ul>"},{"location":"details/dashboards/dashboard-network-details.html","title":"Network Details","text":""},{"location":"details/dashboards/dashboard-network-details.html#last-hour-statistic","title":"Last Hour Statistic","text":"<p>This section reports the inbound speed, outbound speed, traffic errors and drops, and retransmit rate.</p>"},{"location":"details/dashboards/dashboard-network-details.html#network-traffic","title":"Network Traffic","text":"<p>This section contains the Network traffic and network utilization hourly metrics.</p>"},{"location":"details/dashboards/dashboard-network-details.html#network-traffic-details","title":"Network Traffic Details","text":"<p>This section offers the following metrics:</p> <ul> <li>Network traffic by packets</li> <li>Network traffic errors</li> <li>Network traffic drop</li> <li>Network traffic multicast</li> </ul>"},{"location":"details/dashboards/dashboard-network-details.html#network-netstat-tcp","title":"Network Netstat TCP","text":"<p>This section offers the following metrics:</p> <ul> <li>Timeout value used for retransmitting</li> <li>Min TCP retransmission timeout</li> <li>Max TCP retransmission timeout</li> <li>Netstat: TCP</li> <li>TCP segments</li> </ul>"},{"location":"details/dashboards/dashboard-network-details.html#network-netstat-udp","title":"Network Netstat UDP","text":"<p>In this section, you can find the following metrics:</p> <ul> <li>Netstat: UDP</li> <li>UDP Lite</li> </ul> <p>The graphs in the UDP Lite metric give statistics about:</p> <code>InDatagrams</code> Packets received <code>OutDatagrams</code> Packets sent <code>InCsumErrors</code> Datagrams with checksum errors <code>InErrors</code> Datagrams that could not be delivered to an application <code>RcvbufErrors</code> Datagrams for which not enough socket buffer memory to receive <code>SndbufErrors</code> Datagrams for which not enough socket buffer memory to transmit <code>NoPorts</code> Datagrams received on a port with no listener"},{"location":"details/dashboards/dashboard-network-details.html#icmp","title":"ICMP","text":"<p>This section has the following metrics:</p> <ul> <li>ICMP Errors</li> <li>Messages/Redirects</li> <li>Echos</li> <li>Timestamps/Mask Requests</li> </ul>"},{"location":"details/dashboards/dashboard-network-details.html#icmp-errors","title":"ICMP Errors","text":"<code>InErrors</code> Messages which the entity received but determined as having ICMP-specific errors (bad ICMP checksums, bad length, etc.) <code>OutErrors</code> Messages which this entity did not send due to problems discovered within ICMP, such as a lack of buffers <code>InDestUnreachs</code> Destination Unreachable messages received <code>OutDestUnreachs</code> Destination Unreachable messages sent <code>InType3</code> Destination unreachable <code>OutType3</code> Destination unreachable <code>InCsumErrors</code> Messages with ICMP checksum errors <code>InTimeExcds</code> Time Exceeded messages received"},{"location":"details/dashboards/dashboard-network-details.html#messagesredirects","title":"Messages/Redirects","text":"<code>InMsgs</code> Messages which the entity received. Note that this counter includes all those counted by <code>icmpInErrors</code> <code>InRedirects</code> Redirect messages received <code>OutMsgs</code> Messages which this entity attempted to send. Note that this counter includes all those counted by <code>icmpOutErrors</code> <code>OutRedirects</code> Redirect messages sent. For a host, this object will always be zero, since hosts do not send redirects"},{"location":"details/dashboards/dashboard-network-details.html#echos","title":"Echos","text":"<code>InEchoReps</code> Echo Reply messages received <code>InEchos</code> Echo (request) messages received <code>OutEchoReps</code> Echo Reply messages sent <code>OutEchos</code> Echo (request) messages sent"},{"location":"details/dashboards/dashboard-network-details.html#timestampsmask-requests","title":"Timestamps/Mask Requests","text":"<code>InAddrMaskReps</code> Address Mask Reply messages received <code>InAddrMasks</code> Address Mask Request messages received <code>OutAddrMaskReps</code> Address Mask Reply messages sent <code>OutAddrMasks</code> Address Mask Request messages sent <code>InTimestampReps</code> Timestamp Reply messages received <code>InTimestamps</code> Timestamp Request messages received <code>OutTimestampReps</code> Timestamp Reply messages sent <code>OutTimestamps</code> Timestamp Request messages sent"},{"location":"details/dashboards/dashboard-node-summary.html","title":"Node Summary","text":""},{"location":"details/dashboards/dashboard-node-summary.html#system-summary","title":"System Summary","text":"<p>The output from <code>pt-summary</code>, one of the Percona Toolkit utilities.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#interrupts-and-context-switches","title":"Interrupts and Context Switches","text":"<p>Interrupt is an input signal to the processor indicating an event that needs immediate attention. An interrupt signal alerts the processor and serves as a request for the processor to interrupt the currently executing code, so that the event can be processed in a timely manner.</p> <p>Context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point. This allows multiple processes to share a single CPU, and is an essential feature of a multitasking operating system.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#processes","title":"Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#memory-utilization","title":"Memory Utilization","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#virtual-memory-utilization","title":"Virtual Memory Utilization","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#swap-space","title":"Swap Space","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#swap-activity","title":"Swap Activity","text":"<p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#io-activity","title":"I/O Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#global-file-descriptors-usage","title":"Global File Descriptors Usage","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#disk-io-latency","title":"Disk IO Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#disk-io-load","title":"Disk IO Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"details/dashboards/dashboard-node-summary.html#network-utilization-hourly","title":"Network Utilization Hourly","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-node-summary.html#local-network-errors","title":"Local Network Errors","text":"<p>Total Number of Local Network Interface Transmit Errors, Receive Errors and Drops.  Should be  Zero</p>"},{"location":"details/dashboards/dashboard-node-summary.html#tcp-retransmission","title":"TCP Retransmission","text":"<p>Retransmission, essentially identical with Automatic repeat request (ARQ), is the resending of packets which have been either damaged or lost. Retransmission is one of the basic mechanisms used by protocols operating over a packet switched computer network to provide reliable communication (such as that provided by a reliable byte stream, for example TCP).</p>"},{"location":"details/dashboards/dashboard-node-temperature-details.html","title":"Node Temperature Details","text":"<p>The Node Temperature Details dashboard exposes hardware monitoring and sensor data obtained through the <code>sysfs</code> virtual file system of the node.</p> <p>Hardware monitoring devices attached to the CPU and/or other chips on the motherboard let you monitor the hardware health of a system. Most modern systems include several of such devices. The actual list can include temperature sensors, voltage sensors, fan speed sensors, and various additional features, such as the ability to control the rotation speed of the fans.</p>"},{"location":"details/dashboards/dashboard-node-temperature-details.html#cpu-cores-temperatures","title":"CPU Cores Temperatures","text":"<p>Presents data taken from the temperature sensors of the CPU</p>"},{"location":"details/dashboards/dashboard-node-temperature-details.html#chips-temperatures","title":"Chips Temperatures","text":"<p>Presents data taken from the temperature sensors connected to other system controllers</p>"},{"location":"details/dashboards/dashboard-node-temperature-details.html#fan-rotation-speeds","title":"Fan Rotation Speeds","text":"<p>Fan rotation speeds reported in RPM (rotations per minute).</p>"},{"location":"details/dashboards/dashboard-node-temperature-details.html#fan-power-usage","title":"Fan Power Usage","text":"<p>Describes the pulse width modulation of the PWN-equipped fans. PWM operates like a switch that constantly cycles on and off, thereby regulating the amount of power the fan gains: 100% makes it rotate at full speed, while lower percentage slows rotation down proportionally.</p>"},{"location":"details/dashboards/dashboard-nodes-compare.html","title":"Nodes Compare","text":"<p>This dashboard lets you compare a wide range of parameters. Parameters of the same type are shown side by side for all servers, grouped into the following sections:</p> <ul> <li>System Information</li> <li>CPU</li> <li>Memory</li> <li>Disk Partitions</li> <li>Disk Performance</li> <li>Network</li> </ul> <p>The System Information section shows the System Info summary of each server, as well as System Uptime, CPU Cores, RAM, Saturation Metrics, and Load Average gauges.</p> <p>The CPU section offers the CPU Usage, Interrupts, and Context Switches metrics.</p> <p>In the Memory section, you can find the Memory Usage, Swap Usage, and Swap Activity metrics.</p> <p>The Disk Partitions section encapsulates two metrics, Mountpoint Usage and Free Space.</p> <p>The Disk Performance section contains the I/O Activity, Disk Operations, Disk Bandwidth, Disk IO Utilization, Disk Latency, and Disk Load metrics.</p> <p>Finally, Network section shows Network Traffic, and Network Utilization Hourly metrics.</p>"},{"location":"details/dashboards/dashboard-nodes-overview.html","title":"Nodes Overview","text":"<p>The Nodes Overview dashboard provides details about the efficiency of work of the following components. Each component is represented as a section in the dashboard.</p> <ul> <li>CPU</li> <li>Memory &amp; Swap</li> <li>Disk</li> <li>Network</li> </ul> <p>The CPU section offers the CPU Usage, CPU Saturation and Max Core Usage, Interrupts and Context Switches, and Processes metrics.</p> <p>In the Memory section, you can find the Memory Utilization, Virtual Memory Utilization, Swap Space, and Swap Activity metrics.</p> <p>The Disk section contains the I/O Activity, Global File Descriptors Usage, Disk IO Latency, and Disk IO Load metrics.</p> <p>In the Network section, you can find the Network Traffic, Network Utilization Hourly, Local Network Errors, and TCP Retransmission metrics.</p>"},{"location":"details/dashboards/dashboard-numa-details.html","title":"NUMA Details","text":"<p>For each node, this dashboard shows metrics related to Non-uniform memory access (NUMA).</p>"},{"location":"details/dashboards/dashboard-numa-details.html#memory-usage","title":"Memory Usage","text":"<p>Remotes over time the total, used, and free memory.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#free-memory-percent","title":"Free Memory Percent","text":"<p>Shows the free memory as the ratio to the total available memory.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#numa-memory-usage-types","title":"NUMA Memory Usage Types","text":"<code>Dirty</code> Memory waiting to be written back to disk <code>Bounce</code> Memory used for block device bounce buffers <code>Mapped</code> Files which have been mapped, such as libraries <code>KernelStack</code> The memory the kernel stack uses. This is not reclaimable."},{"location":"details/dashboards/dashboard-numa-details.html#numa-allocation-hits","title":"NUMA Allocation Hits","text":"<p>Memory successfully allocated on this node as intended.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#numa-allocation-missed","title":"NUMA Allocation Missed","text":"<p>Memory missed is allocated on a node despite the process preferring some different node.</p> <p>Memory foreign is intended for a node, but actually allocated on some different node.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#anonymous-memory","title":"Anonymous Memory","text":"Active Anonymous memory that has been used more recently and usually not swapped out. Inactive Anonymous memory that has not been used recently and can be swapped out."},{"location":"details/dashboards/dashboard-numa-details.html#numa-file-pagecache","title":"NUMA File (PageCache)","text":"<p>Active(file) Pagecache memory that has been used more recently and usually not reclaimed until needed.</p> <p>Inactive(file) Pagecache memory that can be reclaimed without huge performance impact.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#shared-memory","title":"Shared Memory","text":"<p>Shmem Total used shared memory (shared between several processes, thus including RAM disks, SYS-V-IPC and BSD like SHMEM).</p>"},{"location":"details/dashboards/dashboard-numa-details.html#hugepages-statistics","title":"HugePages Statistics","text":"Total Number of hugepages being allocated by the kernel (Defined with <code>vm.nr_hugepages</code>). Free The number of hugepages not being allocated by a process <code>Surp</code> The number of hugepages in the pool above the value in <code>vm.nr_hugepages</code>. The maximum number of surplus hugepages is controlled by <code>vm.nr_overcommit_hugepages</code>."},{"location":"details/dashboards/dashboard-numa-details.html#local-processes","title":"Local Processes","text":"<p>Memory allocated on a node while a process was running on it.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#remote-processes","title":"Remote Processes","text":"<p>Memory allocated on a node while a process was running on some other node.</p>"},{"location":"details/dashboards/dashboard-numa-details.html#slab-memory","title":"Slab Memory","text":"<code>Slab</code> Allocation is a memory management mechanism intended for the efficient memory allocation of kernel objects. <code>SReclaimable</code> The part of the Slab that might be reclaimed (such as caches). <code>SUnreclaim</code> The part of the Slab that can\u2019t be reclaimed under memory pressure"},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html","title":"PostgreSQL Instance Summary","text":""},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html#number-of-temp-files","title":"Number of Temp Files","text":"<p>Cumulative number of temporary files created by queries in this database since service start. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html#size-of-temp-files","title":"Size of Temp Files","text":"<p>Cumulative amount of data written to temporary files by queries in this database since service start. All temporary files are counted, regardless of why the temporary file was created, and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html#temp-files-activity","title":"Temp Files Activity","text":"<p>Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html#temp-files-utilization","title":"Temp Files Utilization","text":"<p>Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"details/dashboards/dashboard-postgresql-instance-summary.html#canceled-queries","title":"Canceled Queries","text":"<p>Based on <code>pg_stat_database_conflicts</code> view</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-compare.html","title":"PostgreSQL Instances Compare","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html","title":"PostgreSQL Instances Overview","text":""},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#connected","title":"Connected","text":"<p>Reports whether PMM Server can connect to the PostgreSQL instance.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#version","title":"Version","text":"<p>The version of the PostgreSQL instance.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#shared-buffers","title":"Shared Buffers","text":"<p>Defines the amount of memory the database server uses for shared memory buffers. Default is <code>128MB</code>. Guidance on tuning is <code>25%</code> of RAM, but generally doesn\u2019t exceed <code>40%</code>.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#disk-page-buffers","title":"Disk-Page Buffers","text":"<p>The setting <code>wal_buffers</code> defines how much memory is used for caching the write-ahead log entries. Generally this value is small (<code>3%</code> of <code>shared_buffers</code> value), but it may need to be modified for heavily loaded servers.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#memory-size-for-each-sort","title":"Memory Size for each Sort","text":"<p>The parameter <code>work_mem</code> defines the amount of memory assigned for internal sort operations and hash tables before writing to temporary disk files. The default is <code>4MB</code>.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#disk-cache-size","title":"Disk Cache Size","text":"<p>PostgreSQL\u2019s <code>effective_cache_size</code> variable tunes how much RAM you expect to be available for disk caching. Generally adding Linux free+cached will give you a good idea. This value is used by the query planner whether plans will fit in memory, and when defined too low, can lead to some plans rejecting certain indexes.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#autovacuum","title":"Autovacuum","text":"<p>Whether autovacuum process is enabled or not. Generally the solution is to vacuum more often, not less.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#postgresql-connections","title":"PostgreSQL Connections","text":"Max Connections The maximum number of client connections allowed. Change this value with care as there are some memory resources that are allocated on a per-client basis, so setting <code>max_connections</code> higher will generally increase overall PostgreSQL memory usage. Connections The number of connection attempts (successful or not) to the PostgreSQL server. Active Connections The number of open connections to the PostgreSQL server."},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#postgresql-tuples","title":"PostgreSQL Tuples","text":"Tuples The total number of rows processed by PostgreSQL server: fetched, returned, inserted, updated, and deleted. Read Tuple Activity The number of rows read from the database: as returned so fetched ones. Tuples Changed per 5 min The number of rows changed in the last 5 minutes: inserted, updated, and deleted ones."},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#postgresql-transactions","title":"PostgreSQL Transactions","text":"Transactions The total number of transactions that have been either been committed or rolled back. Duration of Transactions Maximum duration in seconds any active transaction has been running."},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#temp-files","title":"Temp Files","text":"Number of Temp Files The number of temporary files created by queries. Size of Temp files The total amount of data written to temporary files by queries in bytes. <p>All temporary files are taken into account by these two gauges, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#conflicts-and-locks","title":"Conflicts and Locks","text":"Conflicts/Deadlocks The number of queries canceled due to conflicts with recovery in the database (due to dropped tablespaces, lock timeouts, old snapshots, pinned buffers, or deadlocks). Number of Locks The number of deadlocks detected by PostgreSQL."},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#buffers-and-blocks-operations","title":"Buffers and Blocks Operations","text":"Operations with Blocks The time spent reading and writing data file blocks by back ends, in milliseconds. <p>Tip</p> <p>Capturing read and write time statistics is possible only if <code>track_io_timing</code> setting is enabled. This can be done either in configuration file or with the following query executed on the running system:</p> <pre><code>ALTER SYSTEM SET track_io_timing=ON;\nSELECT pg_reload_conf();\n</code></pre> Buffers The number of buffers allocated by PostgreSQL."},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#canceled-queries","title":"Canceled Queries","text":"<p>The number of queries that have been canceled due to dropped tablespaces, lock timeouts, old snapshots, pinned buffers, and deadlocks.</p> <p>Data shown by this gauge are based on the <code>pg_stat_database_conflicts</code> view.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#cache-hit-ratio","title":"Cache Hit Ratio","text":"<p>The number of times disk blocks were found already in the buffer cache, so that a read was not necessary.</p> <p>This only includes hits in the PostgreSQL buffer cache, not the operating system\u2019s file system cache.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#checkpoint-stats","title":"Checkpoint Stats","text":"<p>The total amount of time that has been spent in the portion of checkpoint processing where files are either written or synchronized to disk, in milliseconds.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#postgresql-settings","title":"PostgreSQL Settings","text":"<p>The list of all settings of the PostgreSQL server.</p>"},{"location":"details/dashboards/dashboard-postgresql-instances-overview.html#system-summary","title":"System Summary","text":"<p>This section contains the following system parameters of the PostgreSQL server: CPU Usage, CPU Saturation and Max Core Usage, Disk I/O Activity, and Network Traffic.</p>"},{"location":"details/dashboards/dashboard-postgresql-vacuum-monitoring-experimental.html","title":"Experimental PostgreSQL Vacuum Monitoring","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>This dashbaord provides timely insights into the autovacuum process in PostgreSQL.</p> <p>This dashboard contains the following:</p> <ul> <li> <p>Dead tuples - Identifies the number of dead rows in each table even though the rows are physically removed from the table.</p> </li> <li> <p>Last time vacuum ran - Tracks the last time a vacuum or autovacuum process successfully ran on each of your tables.</p> </li> <li> <p>Number of rows modified since last Analyze - The number of rows changed since the last time ANALYZE ran.</p> </li> <li> <p>Manual vacuum events - Tracks the number of times a manual vacuum was run on each table.</p> </li> <li> <p>Table disk usage - Tracking the disk space used by each table is crucial as it enables you to gauge expected changes in the query performance over time - but it can also help you detect potential vacuuming-related issues.</p> </li> </ul>"},{"location":"details/dashboards/dashboard-processes-details.html","title":"Processes Details","text":"<p>The Processes Details dashboard displays Linux process information - PIDs, Threads, and Processes.  The dashboard shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O). When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound. When the number of process blocked waiting for I/O is large, the load is disk bound. The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p> <p>The dashboard consists of two parts: the first section describes metrics for all hosts, and the second part provides charts for each host.</p> <p>Charts for all hosts, available in the first section, are the following ones:</p> <ul> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> <li>Runnable Processes</li> <li>Blocked Processes Waiting for I/O</li> <li>Sleeping Processes</li> <li>Running Processes</li> <li>Disk Sleep Processes</li> <li>Stopped Processes</li> <li>Zombie Processes</li> <li>Dead Processes</li> </ul> <p>The following charts are present in the second part, available for each host:</p> <ul> <li>Processes</li> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> </ul>"},{"location":"details/dashboards/dashboard-processes-details.html#number-of-pids","title":"Number of PIDs","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#percentage-of-max-pids-limit","title":"Percentage of Max PIDs Limit","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#number-of-threads","title":"Number of Threads","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#percentage-of-max-threads-limit","title":"Percentage of Max Threads Limit","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#runnable-processes","title":"Runnable Processes","text":""},{"location":"details/dashboards/dashboard-processes-details.html#processes","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p>"},{"location":"details/dashboards/dashboard-processes-details.html#blocked-processes-waiting-for-io","title":"Blocked Processes Waiting for I/O","text":""},{"location":"details/dashboards/dashboard-processes-details.html#processes_1","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p>"},{"location":"details/dashboards/dashboard-processes-details.html#sleeping-processes","title":"Sleeping Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#running-processes","title":"Running Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#disk-sleep-processes","title":"Disk Sleep Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#stopped-processes","title":"Stopped Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#zombie-processes","title":"Zombie Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-processes-details.html#dead-processes","title":"Dead Processes","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-prometheus-exporter-status.html","title":"Prometheus Exporter Status","text":"<p>The Prometheus Exporter Status dashboard reports the consumption of resources by the Prometheus exporters used by PMM. For each exporter, this dashboard reveals the following information:</p> <ul> <li>CPU usage</li> <li>Memory usage</li> <li>File descriptors used</li> <li>Exporter uptime</li> </ul>"},{"location":"details/dashboards/dashboard-prometheus-exporters-overview.html","title":"Prometheus Exporters Overview","text":""},{"location":"details/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-summary","title":"Prometheus Exporters Summary","text":"<p>This section provides a summary of how exporters are used across the selected hosts. It includes the average usage of CPU and memory as well as the number of hosts being monitored and the total number of running exporters.</p> Avg CPU Usage per Host Shows the average CPU usage in percent per host for all exporters. Avg Memory Usage per Host Shows the Exporters average Memory usage per host. Monitored Hosts Shows the number of monitored hosts that are running Exporters. Exporters Running Shows the total number of Exporters running with this PMM Server instance. <p>The CPU usage and memory usage do not include the additional CPU and memory usage required to produce metrics by the application or operating system.</p>"},{"location":"details/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-node","title":"Prometheus Exporters Resource Usage by Node","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for the selected hosts.</p> CPU Usage Plots the Exporters\u2019 CPU usage across each monitored host (by default, All hosts). Memory Usage Plots the Exporters\u2019 Memory usage across each monitored host (by default, All hosts)."},{"location":"details/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-type","title":"Prometheus Exporters Resource Usage by Type","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for host types: MySQL, MongoDB, ProxySQL, and the system.</p> CPU Cores Used Shows the Exporters\u2019 CPU Cores used for each type of Exporter. Memory Usage Shows the Exporters\u2019 memory used for each type of Exporter."},{"location":"details/dashboards/dashboard-prometheus-exporters-overview.html#list-of-hosts","title":"List of Hosts","text":"<p>At the bottom, this dashboard shows details for each running host.</p> CPU Used Show the CPU usage as a percentage for all Exporters. Mem Used Shows total Memory Used by Exporters. Exporters Running Shows the number of Exporters running. RAM Shows the total amount of RAM of the host. Virtual CPUs Shows the total number of virtual CPUs on the host. <p>You can click the value of the CPU Used, Memory Used, or Exporters Running columns to open the Prometheus Exporter Status dashboard for further analysis.</p> <p>See also</p> <p>Percona blog: Understand Your Prometheus Exporters with Percona Monitoring and Management (PMM)</p>"},{"location":"details/dashboards/dashboard-proxysql-instance-summary.html","title":"ProxySQL Instance Summary","text":""},{"location":"details/dashboards/dashboard-proxysql-instance-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-cluster-summary-experimental.html","title":"Experimental PXC/Galera Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>Availability</p> <p>This experimental dashboard is available starting with PMM 2.29.0.</p> <p>The experimental PXC/Galera Cluster Summary dashboard provides a high level information about the clusters, resource utilization and its state for MySQL databases.</p> <p></p>"},{"location":"details/dashboards/dashboard-pxc-galera-cluster-summary.html","title":"PXC/Galera Cluster Summary","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html","title":"PXC/Galera Node Summary","text":""},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-latency","title":"Galera Replication Latency","text":"<p>Shows figures for the replication latency on group communication. It measures latency from the time point when a message is sent out to the time point when a message is received. As replication is a group operation, this essentially gives you the slowest ACK and longest RTT in the cluster.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-queues","title":"Galera Replication Queues","text":"<p>Shows the length of receive and send queues.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-cluster-size","title":"Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-flow-control","title":"Galera Flow Control","text":"<p>Shows the number of <code>FC_PAUSE</code> events sent/received. They are sent by a node when its replication queue gets too full. If a node is sending out FC messages it indicates a problem.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-parallelization-efficiency","title":"Galera Parallelization Efficiency","text":"<p>Shows the average distances between highest and lowest seqno that are concurrently applied, committed and can be possibly applied in parallel (potential degree of parallelization).</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-writing-conflicts","title":"Galera Writing Conflicts","text":"<p>Shows the number of local transactions being committed on this node that failed certification (some other node had a commit that conflicted with ours) \u2013 client received deadlock error on commit and also the number of local transactions in flight on this node that were aborted because they locked something an applier thread needed \u2013 deadlock error anywhere in an open transaction. Spikes in the graph may indicate writing to the same table potentially the same rows from 2 nodes.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#available-downtime-before-sst-required","title":"Available Downtime before SST Required","text":"<p>Shows for how long the node can be taken out of the cluster before SST is required. SST is a full state transfer method.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-count","title":"Galera Writeset Count","text":"<p>Shows the count of transactions received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-size","title":"Galera Writeset Size","text":"<p>Shows the average transaction size received/replicated.</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-traffic","title":"Galera Writeset Traffic","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"details/dashboards/dashboard-pxc-galera-node-summary.html#galera-network-usage-hourly","title":"Galera Network Usage Hourly","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"details/dashboards/dashboard-pxc-galera-nodes-compare.html","title":"PXC/Galera Nodes Compare","text":""},{"location":"details/dashboards/dashboard-pxc-galera-nodes-compare.html#cluster-galera-cluster-size","title":"$cluster - Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html","title":"MongoDB ReplSet Summary","text":"<p>The MongoDB ReplSet Summary dashboard offers a comprehensive view of your MongoDB replica set\u2019s health and performance. It provides clear insights for both simple and complex, multi-environment setups.</p> <p>The dashboard displays key metrics for individual nodes and the entire replica set, allowing you to quickly spot issues and maintain optimal database performance. With focused information and effective visualizations, it helps you identify and resolve potential problems efficiently, making it easier to manage MongoDB deployments of any size.</p> <p></p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#overview","title":"Overview","text":"<p>The overview section displays essential data for individual nodes, such as their role, CPU usage, memory consumption, disk space, network traffic, uptime, and the current MongoDB version.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#state","title":"State","text":"<p>Displays the current state of a MongoDB replica set member. It shows a single value representing the node\u2019s role, such as PRIMARY, SECONDARY, or ARBITER. The state is color-coded for quick visual identification. This information is crucial for understanding the current role and health of each node in your MongoDB replica set.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#cpu-usage","title":"CPU Usage","text":"<p>Displays the current CPU usage percentage for the selected MongoDB service. It shows how much of the CPU\u2019s capacity is being used, with a range from 0% to 100%. </p> <p>The gauge is color-coded, turning red when usage exceeds 80%, helping you quickly identify high CPU load situations. This metric is crucial for monitoring the performance and resource utilization of your MongoDB instance, allowing you to spot potential bottlenecks or overloaded servers at a glance.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#memory-used","title":"Memory Used","text":"<p>Shows an estimate of how much memory can be used without causing swapping on the MongoDB server. It displays the percentage of memory currently in use, with 100% indicating that all available memory is used and swapping may occur. The gauge turns red above 80% usage, signaling that free memory is running low. This metric is crucial for predicting potential performance issues due to memory constraints, helping you proactively manage your MongoDB instance\u2019s memory resources to avoid swapping and maintain optimal performance.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#disk-io-utilization","title":"Disk I/O Utilization","text":"<p>Displays disk utilization as a percentage, showing how often there was at least one I/O request active for the MongoDB server. Ranging from 0% to 100%, it helps determine if disk load is evenly distributed or if I/O is bottlenecked. Higher values suggest more intense, potentially queued disk activity. The gauge turns red above 80%, indicating possible I/O constraints. Use this metric alongside I/O latency and queue depth to assess overall storage performance and identify potential disk-related issues affecting your MongoDB instance\u2019s responsiveness</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#disk-space-utilization","title":"Disk Space Utilization","text":"<p>Shows the percentage of used disk space for the MongoDB server\u2019s data storage. It ranges from 0% to 100%, with higher values indicating less free space. The gauge turns red above 80% usage, warning of potential disk space issues. This metric is crucial for preventing Disk full errors that could disrupt services or crash the system. When free space approaches zero, consider removing unused files or expanding storage capacity to ensure smooth MongoDB operation and prevent data-related incidents.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#disk-iops","title":"Disk IOPS","text":"<p>This stat panel displays the current rate of disk Input/Output Operations Per Second (IOPS) for the MongoDB server, showing separate values for read and write operations. It provides a real-time view of the physical I/O load on the storage system. The panel uses an area graph to visualize recent trends. High IOPS values or sudden spikes can indicate potential performance issues due to I/O subsystem overload. Monitor this metric to identify periods of intense disk activity and potential storage bottlenecks that could affect MongoDB\u2019s performance.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#network-traffic","title":"Network Traffic","text":"<p>Displays the current network traffic for the MongoDB server, showing separate values for inbound and outbound data transfer rates in bytes per second. It uses an area graph to visualize recent trends in network activity. The panel provides a real-time view of data movement across the network, helping you monitor the MongoDB server\u2019s network load.</p> <p>High values or sudden spikes can indicate increased database activity, potential performance bottlenecks, or unusual network patterns. Use this metric to assess network utilization and identify periods of intense data transfer that might affect MongoDB\u2019s performance or user experience.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#uptime","title":"Uptime","text":"<p>Displays the current uptime of the MongoDB server, showing how long it has been running without a shutdown or restart. The value is presented in seconds and uses color-coding for quick status assessment: red for very recent starts, orange for short uptimes, and green for longer periods.</p> <p>This metric is useful for tracking system stability, identifying recent restarts, and monitoring continuous operation time. Long uptimes generally indicate stable operation, while short uptimes might suggest recent maintenance or unexpected restarts that could warrant investigation.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#version","title":"Version","text":"<p>Shows the current version of MongoDB running on the selected node in the replica set.</p> <p>This information is crucial for ensuring consistency across your MongoDB deployment, tracking upgrade status, and identifying potential version-related issues or compatibility concerns. Regular checks of this panel can help maintain a uniform MongoDB version across your infrastructure and assist in planning future upgrades or troubleshooting version-specific problems.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#states","title":"States","text":""},{"location":"details/dashboards/dashboard-replsetsummary.html#node-states","title":"Node States","text":"<p>Visualizes the status changes of each node in the MongoDB replica set over the selected time range. </p> <p>The timeline format allows you to easily track state transitions, identify periods of instability, and understand the roles of different nodes throughout the monitored period. This visualization is crucial for monitoring replica set health, detecting failovers or reconfigurations, and ensuring the overall stability of your MongoDB cluster. Use this panel to quickly spot any unusual patterns or frequent state changes that might require further investigation.</p> <p>For more details on replica set states, see to the MongoDB documentation.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#details","title":"Details","text":""},{"location":"details/dashboards/dashboard-replsetsummary.html#command-operations","title":"Command Operations","text":"<p>Shows the rates of different MongoDB operations per second, including primary operations (like queries, inserts, updates, and deletes), replicated operations on secondary nodes, and automatic deletions by TTL indexes.</p> <p>It helps you visualize your database\u2019s workload, showing how different types of operations contribute to overall activity. Use this to spot unusual patterns, balance between read and write operations, and understand your MongoDB instance\u2019s performance at a glance.</p> <p>You can filter the chart to focus on specific command types by clicking on their names in the legend. This will display only the selected metric. To view multiple speci metrics, use Ctrl + click  to select multiple items.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#top-hottest-collections-by-read","title":"Top Hottest Collections by Read","text":"<p>Lists the five collections with the highest read activity. Use this panel to quickly identify which collections are under the most demand, allowing you to monitor read-heavy workloads and optimize performance accordingly.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#query-execution-times","title":"Query Execution Times","text":"<p>Displays the average latency of operations, categorized by read, write, or command. It visualizes how long each type of operation takes to execute over time, helping you identify trends or potential performance bottlenecks in your database operations. Use this panel to you to monitor and optimize the responsiveness of your MongoDB cluster.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#top-hottest-collections-by-write","title":"Top Hottest Collections by Write","text":"<p>Lists the five collections with the most write operations.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#query-efficiency","title":"Query Efficiency","text":"<p>Measures the efficiency of queries in your MongoDB cluster by showing the ratio of documents or index entries scanned versus documents returned. A ratio of 1 indicates that every document returned matched the query criteria exactly, while a higher value, such as 100, suggests that on average, 100 documents were scanned to return a single document.</p> <p>Use this panel to assess query performance, identify inefficient queries, and optimize indexing strategies. </p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#queued-operations","title":"Queued Operations","text":"<p>Displays the number of operations that are queued due to locks within your MongoDB cluster. It helps identify performance bottlenecks by showing how many operations are waiting because of locking issues. </p> <p>Use this panel to track these queued operations and monitor the impact of locking on system performance over time and take action if necessary.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#reads-writes","title":"Reads &amp; Writes","text":"<p>Tracks the number of read and write operations over time in your MongoDB environment. Reads represent data queries, while writes represent data modifications.</p> <p>Use this panel to get insights into the workload distribution and monitor the performance of database operations, ensuring that the system is handling read and write operations efficiently.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#connections","title":"Connections","text":"<p>Monitors the average number of active and available MongoDB connections over time.</p> <p>Use this panel to track connection usage and ensure the database has sufficient capacity to handle incoming requests without reaching its limit.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#collection-details","title":"Collection Details","text":""},{"location":"details/dashboards/dashboard-replsetsummary.html#size-of-collections","title":"Size of Collections","text":"<p>Displays the storage size of MongoDB collections, which are analogous to tables in relational databases, offering insights into the storage footprint of each collection across different nodes.</p> <p>Use it to effectively monitor and manage data distribution and storage consumption. The data is organized by database name, collection, and node, and can be easily filtered and sorted for detailed analysis.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#number-of-collections","title":"Number of Collections","text":"<p>Provides a count of collections across different databases and nodes, helping you understand the structure and scale of your MongoDB deployments. The data is organized by database name and node, and you can filter and sort it for detailed insights. </p> <p>Use this table to monitor the distribution of collections and manage your database schema effectively.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#replication","title":"Replication","text":""},{"location":"details/dashboards/dashboard-replsetsummary.html#replication-lag","title":"Replication Lag","text":"<p>Monitors replication lag, which occurs when a secondary node cannot replicate data as fast as it is written to the primary node. Causes of lag can include network latency, packet loss, or routing issues.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#oplog-recovery-window","title":"OpLog Recovery Window","text":"<p>Indicates the timespan (window) between the newest and oldest operations in the Oplog collection.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#performance","title":"Performance","text":""},{"location":"details/dashboards/dashboard-replsetsummary.html#flow-control","title":"Flow Control","text":"<p>Monitors and displays the performance metrics related to flow control in a MongoDB cluster. It provides insights into the frequency and duration of lagged operations, which can help you identify potential bottlenecks or performance issues.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#wiredtiger-concurrency-tickets-available","title":"WiredTiger Concurrency Tickets Available","text":"<p>Shows the number of available WiredTiger concurrency tickets, which control the number of operations that can run simultaneously in the storage engine.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#nodes-summary","title":"Nodes Summary","text":"<p>Provides a quick overview of the health and resource utilization of your nodes, making it easy to spot any potential issues or resource constraints.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#cpu-usage_1","title":"CPU Usage","text":"<p>Measures CPU time as a percentage of the CPU\u2019s total capacity, providing insights into CPU utilization.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#cpu-saturation","title":"CPU Saturation","text":"<p>Indicates when a system is running at maximum CPU capacity, leading to increased data queuing and potential performance degradation.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Tracks disk I/O operations and swap activity, which involve transferring data between the hard disk drive and RAM.</p>"},{"location":"details/dashboards/dashboard-replsetsummary.html#network-traffic_1","title":"Network Traffic","text":"<p>Monitors network traffic, showing the amount of data moving across the network at any given time.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html","title":"Sharded Cluster Summary","text":"<p>This dashboard provides a comprehensive view of your MongoDB sharded cluster\u2019s performance, health, and resource utilization. It offers insights into shard distribution, query operations, data balance, and replication status across your entire cluster.</p> <p>For MongoS (Router) specific monitoring, see the MongoDB Router Summary dashboard.</p> <p></p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#overview","title":"Overview","text":""},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#qps-of-services-in-shard","title":"QPS of Services in Shard","text":"<p>Displays the Queries Per Second (QPS) for each shard and the config server replica set in your MongoDB cluster. It shows the rate of operations (excluding commands) for each component, helping you quickly assess the query load distribution across your sharded environment.</p> <p>The chart uses the most recent non-null value and updates based on your selected time interval. This visualization allows you to easily identify which shards are handling the most queries and spot any potential load imbalances. </p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#shards","title":"Shards","text":"<p>Reports the number of shards in your MongoDB cluster. The number of shards indicates how your data is distributed across the cluster, which is crucial for understanding your database\u2019s scalability and performance.</p> <p>A shard contains a subset of sharded data for a sharded cluster. Together, the cluster\u2019s shards hold the entire data set for the cluster.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#mongos","title":"Mongos","text":"<p>Number of mongos routers registered as part of the cluster.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#draining-shards","title":"Draining Shards","text":"<p>Displays a single number representing the current count of shards that are in the process of being drained from your MongoDB cluster.</p> <p>When you run <code>removeShard</code>, MongoDB drains the shard by using the balancer to move the shard\u2019s chunks to other shards in the cluster. Once the shard is drained, MongoDB removes the shard from the cluster. The number shown here indicates how many shards are currently undergoing this draining process.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#dbs","title":"DBs","text":"<p>Shows the number of user-created databases in your MongoDB sharded cluster. It provides a quick view of how many databases your cluster is managing, updating every 5 minutes.</p> <p>This simple count helps you track database growth and understand the scale of your MongoDB deployment at a glance.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#sharded-collections","title":"Sharded Collections","text":"<p>Provides a quick view of how many collections in your MongoDB cluster are sharded. This is an important metric for understanding the scale and distribution of your data across the sharded cluster. </p> <p>A higher number indicates more collections are distributed across multiple shards, which can improve performance for large datasets. However, it also implies more complex data management.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#balancer-enabled","title":"Balancer Enabled","text":"<p>Background process that monitors the number of chunks on each shard and whether the MongoDB Balancer is currently enabled in your sharded cluster.</p> <p>The balancer is crucial for maintaining an even distribution of chunks across shards, so knowing its status is important for cluster health and performance.</p> <p>A YES indicates that the balancer is active and working to keep your data evenly distributed, while a NO might indicate a manual override or a potential issue that needs investigation.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#total-amount-of-chunks","title":"Total amount of Chunks","text":"<p>Provides a quick view of the total number of chunks in your sharded MongoDB cluster to give you an idea of how your data is distributed across the cluster.</p> <p>A high number of chunks could indicate a well-distributed dataset, while a sudden increase might suggest increased data volume or changes in your sharding strategy.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#last-election","title":"Last Election","text":"<p>Provides a quick view of how long it has been since the last election in your MongoDB replica set.</p> <p>Elections occur when a new primary node needs to be chosen, which can happen during normal operations (like planned maintenance) or due to issues (like a primary node failure).</p> <p>A very recent election might indicate a recent change or issue in your cluster that warrants investigation, while a long time since the last election suggests stability in the primary node assignment.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#chunks-distribution","title":"Chunks distribution","text":"<p>Dsplays the distribution of chunks across different shards in a MongoDB cluster as a series of horizontal bars. It updates every minute, showing the percentage of total chunks each shard holds.</p> <p>Use this to quickly identify any imbalances in data distribution among shards, which is crucial for maintaining optimal performance in a sharded MongoDB setup.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#command-operations","title":"Command Operations","text":"<p>Provides a comprehensive overview of MongoDB operation rates across your deployment. It displays the frequency of primary operations (query, insert, update, delete, and getmore), replicated operations on secondary nodes, and document deletions by Time-To-Live (TTL) indexes. </p> <p>By aggregating data from selected environments, clusters, and replica sets over customizable time intervals, the graph enables you to quickly identify workload patterns, potential replication lags, and the impact of automated data cleanup processes.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#top-hottest-collections-by-read","title":"Top Hottest Collections by Read","text":"<p>This panel displays the five MongoDB collections with the highest read rates. It shows the number of read operations per second for each collection, aggregated across your selected environment and cluster. </p> <p>The bar gauge visualization helps quickly identify which collections are experiencing the most read activity, useful for performance monitoring and resource planning. Data is updated regularly to reflect recent changes in read patterns.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#query-execution-times","title":"Query execution times","text":"<p>This graph shows the average time taken for MongoDB to execute read, write, and other operations. It displays latency in microseconds over time, helping you spot performance trends or issues across different operation types. </p> <p>Use this to quickly identify any unusual delays in database operations.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#top-hottest-collections-by-write","title":"Top Hottest Collections by Write","text":"<p>Displays the five MongoDB collections with the highest write activity. It shows the number of write operations (inserts, updates, and deletes) per second for each collection, aggregated across your selected environment and cluster. </p> <p>The bar gauge visualization helps quickly identify which collections are experiencing the most write activity, useful for performance monitoring and resource planning. Data is updated regularly to reflect recent changes in write patterns.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#operations-per-shard","title":"Operations Per Shard","text":"<p>Shows the total number of operations per second for each shard in your MongoDB cluster. </p> <p>It combines all types of operations (queries, inserts, updates, deletes, and getmore) into a single metric for each shard. The stacked area chart allows you to see both individual shard activity and total cluster activity over time. </p> <p>This visualization helps you monitor the distribution of workload across shards and identify any imbalances or unusual patterns in operation rates.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#mongodb-versions","title":"MongoDB Versions","text":"<p>Displays the current MongoDB version for each service in your cluster.</p> <p>This information helps you quickly identify which version of MongoDB is running on each service, ensuring all parts of your cluster are using consistent and up-to-date software.</p> <p>Use this to track version differences across your MongoDB deployment and plan upgrades as needed.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#node-states","title":"Node States","text":"<p>This panel shows the status of each node in your MongoDB replica set over time. It displays a timeline for each node, with colors representing different states such as Primary, Secondary, or Arbiter.</p> <p>The visualization helps you track state changes, identify any instability in the replica set, and understand the roles of different nodes throughout the selected time range. Use this to monitor the health and stability of your MongoDB replica set at a glance.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#collection-details","title":"Collection Details","text":""},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#size-of-collections-in-shards","title":"Size of Collections in Shards","text":"<p>Displays the storage size of MongoDB collections across different shards in your cluster.</p> <p>The data is organized by database and collection, with separate columns for each shard.</p> <p>This visualization helps you understand how your data is distributed across shards and identify which collections are using the most storage space. Use this information to optimize data distribution and storage usage in your MongoDB cluster.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#number-of-collections-in-shards","title":"Number of Collections in Shards","text":"<p>This table shows how many collections each database has across different shards in your MongoDB cluster. It lists database names in rows and shard names in columns, with the number of collections at each intersection.</p> <p>This overview helps you quickly see how your data is spread out, identify databases with many collections, and check if collections are evenly distributed across shards. </p> <p>Use this information to optimize your database structure and sharding strategy for better performance and resource usage.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#connections","title":"Connections","text":""},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#current-connections-per-shard","title":"Current Connections Per Shard","text":"<p>This graph shows the number of current TCP connections for each shard in your MongoDB cluster over time. It uses a stacked area chart to display incoming connections across different shards, allowing you to see both individual shard activity and total cluster connections at a glance. </p> <p>This visualization helps you monitor connection load distribution, identify any shards experiencing unusual connection patterns, and track overall cluster usage. Use this information to balance workloads, plan for capacity, and ensure your MongoDB cluster is handling connections efficiently.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#available-connections","title":"Available Connections","text":"<p>This graph displays the number of available connections for each service in your MongoDB cluster over time. It uses a stacked area chart to show how many connections are still open for new client requests across different services.</p> <p>This visualization helps you monitor connection capacity, identify services that might be reaching their connection limits, and track overall cluster availability. Use this information to ensure your MongoDB cluster has sufficient capacity to handle incoming connections, plan for scaling, and prevent potential connection-related issues before they impact performance or availability.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#chunks-in-shards","title":"Chunks in Shards","text":""},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#amount-of-chunks-in-shards","title":"Amount of Chunks in Shards","text":"<p>This table shows how data chunks are distributed across shards in your MongoDB cluster. It displays the shard names and the number of chunks each shard contains. Chunks are subsets of your sharded data, and their distribution indicates how evenly your data is spread across the cluster.</p> <p>This overview helps you quickly identify any imbalances in data distribution, which could affect query performance and storage utilization. Use this information to assess your sharding strategy and determine if rebalancing is needed to optimize your MongoDB cluster\u2019s performance and resource usage.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#dynamic-of-chunks","title":"Dynamic of Chunks","text":"<p>This graph shows how the number of data chunks changes over time for each shard in your MongoDB cluster. It displays the rate of change in chunks per second, helping you visualize the balancer\u2019s activity in redistributing data across shards.</p> <p>This dynamic view allows you to monitor how your cluster adapts to data growth and changing query patterns. Use this information to assess the effectiveness of your sharding strategy, identify periods of high balancing activity, and ensure that your data remains evenly distributed for optimal performance and scalability.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#chunks-move-events","title":"Chunks Move Events","text":"<p>This bar graph displays the frequency of chunk movement events in your MongoDB sharded cluster over time. It shows how often chunks are being migrated between shards to maintain an even data distribution. The graph helps you visualize the balancer\u2019s activity, with higher bars indicating periods of more frequent chunk migrations. </p> <p>This information is crucial for understanding your cluster\u2019s balancing behavior, identifying times of high data redistribution activity, and ensuring that your sharded data remains optimally distributed for efficient query performance and storage utilization across all shards.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#chunk-split-activity","title":"Chunk Split Activity","text":"<p>This bar graph shows how frequently chunks are being split in your MongoDB sharded cluster over time. It visualizes the rate at which chunks grow beyond their configured size limit and need to be divided, typically due to data insertions or updates.</p> <p>Higher bars indicate periods of more frequent chunk splits, which can signal rapid data growth or changes in data distribution.</p> <p>This information helps you understand your cluster\u2019s data growth patterns, assess the effectiveness of your current chunk size configuration, and anticipate when you might need to adjust your sharding strategy or add capacity to maintain optimal performance.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#replication","title":"Replication","text":""},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#replication-lag-by-shard","title":"Replication Lag by Shard","text":"<p>This graph displays the maximum replication lag for each shard in your MongoDB cluster over time. Replication lag shows how far behind secondary nodes are in applying operations from the primary node. </p> <p>The chart helps you visualize lag trends across different shards, with higher values indicating longer delays in data replication. This information is crucial for monitoring the health of your replica sets, identifying potential performance issues, and ensuring data consistency across your sharded cluster.</p> <p>Use this graph to quickly spot any shards experiencing significant replication delays, which could impact read operations directed to secondary nodes and overall cluster reliability.</p>"},{"location":"details/dashboards/dashboard-sharded-cluster-summary.html#oplog-range-by-shard","title":"Oplog Range by Shard","text":"<p>This graph shows the time span covered by the oplog (operation log) for each shard in your MongoDB cluster. It displays the duration between the oldest and newest operations stored in the oplog, measured in seconds. </p> <p>This information is crucial for understanding your cluster\u2019s replication capacity and resilience. A larger time range indicates a longer history of operations is available for replication, which can be beneficial for recovery scenarios or when secondary nodes fall behind.</p> <p>Monitor this graph to ensure your oplogs maintain sufficient history across all shards, helping you manage replication health and plan for potential adjustments to oplog size if needed.</p>"},{"location":"details/dashboards/dashboard-victoriametrics-agents-overview.html","title":"VictoriaMetrics Agents Overview","text":"<p>No description</p>"},{"location":"details/dashboards/dashboard-victoriametrics.html","title":"VictoriaMetrics","text":"<p>No description</p>"},{"location":"details/dashboards/kubernetes_cluster_summary.html","title":"Kubernetes Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>Availability</p> <p>This experimental dashboard is available starting with PMM 2.30.0.</p> <p></p> <p>Kubernetes Volumes dashboard provides a comprehensive overview of your Kubernetes cluster, including:</p> <ul> <li>Resources</li> <li>Node Status</li> <li>Pod Status</li> <li>PVC status</li> <li>CPU Overview</li> <li>Kubernetes Resource Count</li> <li>Memory Overview and more</li> </ul> <p>With this dashboard, you can view all workloads running in the cluster and optimize their performance.</p>"},{"location":"details/dashboards/kubernetes_monitor_db_clusters_managed.html","title":"DB clusters managed with Percona Kubernetes Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>This dashboard displays the primary parameters of database clusters created by Percona Operators for various databases and helps identify the performance issues.</p> <p></p>"},{"location":"details/dashboards/kubernetes_monitor_operators.html","title":"Kubernetes monitoring for Percona Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Monitoring the state of the database is crucial to timely identify and react to performance issues. Percona Monitoring and Management (PMM) solution enables you to do just that.</p> <p>However, the database state also depends on the state of the Kubernetes cluster itself. Hence it\u2019s important to have metrics that can depict the state of the Kubernetes cluster.</p> <p>For inforamtion on setting up monitoring for the Kubernetes cluster health, see documentation. </p> <p>This setup has been tested with the PMM server as the centralized data storage and the Victoria Metrics Kubernetes monitoring stack as the metrics collector. These steps may also apply if you use another Prometheus-compatible storage.</p>"},{"location":"details/dashboards/kubernetes_monitor_operators.html#kubernetes-overview","title":"Kubernetes overview","text":"<p>The Kubernetes Cluster overview dashboard gives you an overview of Kubernetes health and its objects, including Percona custom resources.</p> <p></p>"},{"location":"details/dashboards/kubernetes_pods_status.html","title":"Kubernetes Pods Status","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>Availability</p> <p>This experimental dashboard is available starting with PMM 2.37.0.</p> <p></p> <p>Kubernetes Pods Status dashboard provides detailed information about the state and performance of your pods, including CPU, Memory, and Network metrics. </p> <p>This dashboard can help you quickly pinpoint any issues affecting your pods and ensure they continue to operate smoothly.</p>"},{"location":"details/dashboards/kubernetes_volume.html","title":"Kubernetes Volumes","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This dashboard will not work for minikube cluster as there are no drivers for it.</p> <p></p> <p>Starting with PMM 2.37.0 we have introduced Kubernetes Volumes dashboard. This dashboard provides insights into your Kubernetes volumes, including capacity and usage, in real-time. </p> <p>With this dashboard, you can easily monitor the performance and usage of your volumes and take proactive measures to ensure their performance.</p>"},{"location":"details/develop-checks/index.html","title":"Developing Advisor checks","text":"<p>PMM offers sets of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>As a developer, you can create custom checks to cover additional use cases, relevant to your specific database infrastructure.</p>"},{"location":"details/develop-checks/index.html#check-components","title":"Check components","text":"<p>A check is a combination of:</p> <ul> <li>A query for extracting data from the database.</li> <li>Python script for converting extracted data into check results. This is actually a Starlark script, which is a Python dialect that adds more imperative features than Python. The script\u2019s execution environment is sandboxed, and no I/O can be done from it.</li> </ul> <p>All checks are self-contained in the first phase, as well as in most of the planned phases.</p> <p>This means that extracted data is processed on the PMM side and not sent back to Percona Platform.</p>"},{"location":"details/develop-checks/index.html#backend","title":"Backend","text":"<ol> <li>pmm-managed checks that the installation is opted-in for checks.</li> <li>pmm-managed downloads files with checks from Percona Platform.</li> <li>pmm-managed verifies file signatures using a list of hard-coded public keys. At least one signature should be correct.</li> <li>pmm-managed sends queries to pmm-agent and gathers results.</li> <li>pmm-managed executes check scripts that produce alert information.</li> <li>pmm-managed sends alerts to Alertmanager.</li> <li>Due to Alertmanager design, pmm-managed has to send and re-send alerts to it much more often than the frequency with which checks are executed. This expected behavior is not important for using checks but is important for understanding how checks work.</li> <li>Currently, Prometheus is not involved.</li> </ol>"},{"location":"details/develop-checks/index.html#frontend","title":"Frontend","text":"<p>PMM uses Alertmanager API to get information about failed checks and show them on the UI:</p> <p></p>"},{"location":"details/develop-checks/index.html#check-format-versions","title":"Check format versions","text":"<p>Starting with the 2.28 release, PMM uses Advisor checks format version 2. Format version 1 is deprecated.</p>"},{"location":"details/develop-checks/index.html#version-2-advisor-checks-for-pmm-228-and-newer","title":"Version 2 advisor checks for PMM 2.28 and newer","text":"<p>PMM 2.28 upgraded Advisor Checks to version 2, which uses a slightly different structure than version 1 checks, created in 2.7 and earlier. This is because, compared to version 1 checks, checks created in 2.28 and later offer additional support for:</p> <ul> <li>Multiple queries</li> <li>Victoria Metrics as a data source</li> <li>Database Family field</li> </ul>"},{"location":"details/develop-checks/index.html#format-for-v2-checks","title":"Format for v.2 checks","text":"<p>Advisor checks for PMM 2.28 and later use the following format:</p> Version 2 Checks Format <pre><code>---\nchecks:\n  - version: 2\n    name: exampleV2\n    summary: Check format V2\n    description: Checks something important\n    interval: standard\n    family: MYSQL\n    category: configuration ## Deprecated since PMM 2.36\n    advisor: dev            ## Required since PMM 2.36\n    queries:\n      - type: MYSQL_SHOW\n        query: VARIABLES\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n        parameters:\n          lookback: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          range: 15m\n          step: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          lookback: 5m\n          range: 15m\n          step: 5m\n\n    script: |\n      def check_context(docs, context):\n          # `docs` is a frozen (deeply immutable) list where each item represents single query results. Order of results\n          # matches order of queries in check file. Each query result is list of dicts where each item where each dict\n          # represents a single document in result set.\n          #\n          # `context` is a dict with additional functions.\n          #\n          # Global `print` and `fail` functions are available.\n          #\n          # `check_context` function is expected to return a list of dicts that are then converted to alerts;\n          # in particular, that list can be empty.\n          # Any other value (for example, string) is treated as a script execution failure\n          # (Starlark does not support Python exceptions);\n          # it is recommended to use global function `fail` for that instead.\n\n          results = []\n\n          for row in docs[0]:\n              name, value = row[\"Variable_name\"], row[\"Value\"]\n              if name == \"version\":\n                  results.append({\n                      \"summary\": \"MySQL has version {}\".format(value),\n                      \"description\": \"Current version is {}\".format(value),\n                      \"read_more_url\": \"\",\n                      \"severity\": \"warning\",\n                      \"labels\": {},\n                  })\n\n          uptimeNow = int(int(docs[1][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime {} min\".format(uptimeNow),\n              \"description\": \"Current uptime is {} min\".format(uptimeNow),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          uptimeFiveMinAgo = int(int(docs[2][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime 5 min ago was {} min\".format(uptimeFiveMinAgo),\n              \"description\": \"5 min ago uptime was {} min\".format(uptimeFiveMinAgo),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[3][0][\"values\"]:\n            dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Node has load average for last 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[4][0][\"values\"]:\n              dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Five minutes ago node had load average for 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          return results\n</code></pre>"},{"location":"details/develop-checks/index.html#checks-script","title":"Checks script","text":"<p>The check script assumes that there is a function with <code>check_context</code>, that accepts a list where each item represents the result of a single query specified in the check. Each result itself is a list of docs containing returned rows for SQL databases and documents for MongoDB. It returns zero, one, or several check results that are then converted to alerts.</p>"},{"location":"details/develop-checks/index.html#check-severity-levels","title":"Check severity levels","text":"<p>You can label your advisor checks with one of the following available severity levels: Emergency, Alert, Critical, Error, Warning, Notice, Info, Debug. PMM groups failed checks by their severity, and displays them under Advisors Checks &gt; Failed Checks.</p>"},{"location":"details/develop-checks/index.html#check-fields","title":"Check fields","text":"<p>Checks can include the following fields:</p> <ul> <li>Version (integer, required): defines what other properties are expected, what types are supported, what is expected from the script and what it can expect from the execution environment, etc.</li> <li>Name (string, required): defines machine-readable name (ID).</li> <li>Summary (string, required): defines short human-readable description.</li> <li>Description (string, required): defines long human-readable description.</li> <li>Family (string, required): specifies one of the supported database families: MYSQL, POSTGRESQL, MONGODB. This field is only available for Advisor checks v.2, created for PMM 2.28 and later.</li> <li>Advisor (string, required): specifies the advisor to which this check belongs. For local environments, specify dev.</li> <li>Interval (string/enum, optional): defines running interval. Can be one of the predefined intervals in the UI: Standard, Frequent, Rare.</li> <li>Queries (array, required): contains items that specify queries.<ul> <li>Type (string/enum, required): defines the query type. Check the list of available types in the table below.</li> <li>Query (string, can be absent if the type defines the whole query by itself): The query is executed on the PMM Client side and can contain multiple queries specific to the target DBMS.</li> <li>Parameters (key-value, can be absent if query doesn\u2019t have required parameters)</li> </ul> </li> <li>Script (string, required): contains a small Starlark script that processes query results, and returns check results. It is executed on the PMM Server side.</li> </ul>"},{"location":"details/develop-checks/index.html#query-types","title":"Query types","text":"<p>Expand the table below for the list of checks types that you can use to define your query type and the PMM Service type for which the check will run.</p> Check Types table Check type Description \u201cquery\u201d required (must be empty if \u201cNo\u201d) MYSQL_SHOW Executes \u2018SHOW \u2026\u2019 clause against MySQL database. Yes MYSQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against MySQL database. Yes POSTGRESQL_SHOW Executes \u2018SHOW ALL\u2019 command against PosgreSQL database. No POSTGRESQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against PosgreSQL database. Yes MONGODB_GETPARAMETER Executes db.adminCommand( { getParameter: \u201c*\u201d } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getParameter No MONGODB_BUILDINFO Executes db.adminCommand( { buildInfo:  1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see buildInfo No MONGODB_GETCMDLINEOPTS Executes db.adminCommand( { getCmdLineOpts: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getCmdLineOpts No MONGODB_REPLSETGETSTATUS Executes db.adminCommand( { replSetGetStatus: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see  replSetGetStatus No MONGODB_GETDIAGNOSTICDATA Executes db.adminCommand( { getDiagnosticData: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see MongoDB Performance No METRICS_INSTANT Executes instant MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about instant queries, check out the Prometheus docs. Yes METRICS_RANGE Executes range MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about range queries, check out the Prometheus docs. Yes CLICKHOUSE_SELECT Executes \u2018SELECT \u2026\u2019 statements against PMM\u2019s Query Analytics Clickhouse database. Queries can use the  {{.ServiceName}} and {{.ServiceID}}   placeholders in query string. They match the target service name and service ID respectively. Yes"},{"location":"details/develop-checks/index.html#query-parameters","title":"Query parameters","text":"<ul> <li><code>METRICS_INSTANT</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> </ul> </li> <li><code>METRICS_RANGE</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> <li>range (duration, required): specifies time window of the query. This parameter is equal to Prometheus API.</li> <li>step (duration, required): query resolution. This parameter is equal to Prometheus API.</li> </ul> </li> <li><code>POSTGRESQL_SELECT</code><ul> <li>all_dbs (boolean, optional): execute query on all available databases in PostgreSQL instance. If this parameter is not specified, then query executed on the default database (the one that was specified when service was added to PMM).</li> </ul> </li> </ul>"},{"location":"details/develop-checks/index.html#develop-checks","title":"Develop checks","text":"<p>Development / Debugging Only</p> <p>Note that check development in PMM is currently for debugging only and NOT for production use!  Future releases plan to include the option to run custom local checks in addition to hosted Percona Platform checks.</p> <p>To develop custom checks for PMM:</p> <ol> <li>Install the latest PMM Server and PMM Client builds following the installation instructions.</li> <li> <p>Run PMM Server with special environment variables:</p> <ul> <li><code>PERCONA_TEST_CHECKS_FILE=/srv/custom-checks.yml</code> to use checks from the local files instead of downloading them from Percona Platform.</li> <li><code>PERCONA_TEST_CHECKS_DISABLE_START_DELAY=true</code> to disable the default check execution start delay. This is currently set to one minute, so that checks run upon system start.</li> <li><code>PERCONA_TEST_CHECKS_RESEND_INTERVAL=2s</code> to define the frequency for sending the SA-based alerts to Alertmanager.</li> </ul> <pre><code>docker run -p 80:80 -p 443:443 --name pmm-server \\\n-e PERCONA_TEST_CHECKS_FILE=/srv/custom-checks.yml \\\n-e PERCONA_TEST_CHECKS_DISABLE_START_DELAY=true \\\n-e PERCONA_TEST_CHECKS_RESEND_INTERVAL=2s \\\nperconalab/pmm-server:dev-latest\n</code></pre> </li> <li> <p>Log in to Grafana with credentials admin/admin.</p> </li> <li> <p>Go to Configuration &gt; Settings &gt; Advanced Settings and make sure the Advisors option is enabled.</p> </li> <li> <p>Create <code>/srv/custom-checks.yml</code> inside the <code>pmm-server</code> container with the content of your check. Specify dev advisor in your check.</p> </li> <li> <p>The checks will run according to the time interval defined on the UI. You can see the result of running the check on the home dashboard:</p> <p></p> </li> <li> <p>Click on the number of failed checks to open the Failed Checks dashboard:</p> <p></p> </li> <li> <p>Check out pmm-managed logs:     <pre><code>docker exec -it pmm-server supervisorctl tail -f pmm-managed\n</code></pre></p> </li> </ol>"},{"location":"details/develop-checks/index.html#troubleshooting-and-tips","title":"Troubleshooting and tips","text":"<ul> <li>in Debug mode, PMM generates a lot of redundant information in the log files, information that is not useful for developing checks.  If debug logging is enabled, you can disable it with the following environment variable: <code>PMM_DEBUG=0</code>.</li> <li>All logs from checks subsystem has <code>component=checks</code> tag, so you can just filter <code>pmm-managed</code> logs with grep.</li> <li>Local check file should always be linked to fake dev advisor: <code>advisor: dev</code>. If PMM does not display the Development tab on the Advisors page, make sure that you specify dev advisor in the check file.</li> <li>If this still doesn\u2019t display the Development tab, probably PMM could not load your file due to formatting issues. Check pmm-managed logs for details.</li> <li>There are to ways to reload the check file:</li> <li>Click <code>Run check</code> button (but it\u2019s unavailable if you don\u2019t have any tabs on advisors page and most likely that is the case during development)</li> <li>Reload managed: <code>supervisorctl restart pmm-managed</code> (execute inside PMM server)</li> </ul>"},{"location":"details/develop-checks/index.html#submit-feedback","title":"Submit feedback","text":"<p>We welcome your feedback on the current process for developing and debugging checks. Send us your comments over Slack or post a question on the Percona Forums.</p>"},{"location":"get-started/index.html","title":"Get Started","text":"<ul> <li> <p>User Interface</p> <ul> <li>Using the web-based user interface.</li> <li>Finding dashboards.</li> <li>Rendering dashboard images.</li> <li>Viewing graph details.</li> <li>Annotating events.</li> </ul> </li> <li> <p>Percona Alerting</p> </li> <li> <p>Backup and Restore</p> </li> <li> <p>Query Analytics, a specialized dashboard for detailed query analysis.</p> </li> <li> <p>Advisors: Enabling and seeing the results of database Advisor checks.</p> </li> <li> <p>DBaaS: Configuration for DBaaS and UI for creating Database clusters.</p> </li> </ul> <p>These features are currently only available for PMM Admin users:</p> <ul> <li>Backup</li> <li>DBaaS</li> <li>Percona Alerting</li> <li>Advisors</li> </ul> <p>To use these features you must be logged in as a PMM Admin user and activate the features.</p> <p>If you are logged in as a user that has a Viewer or Editor role you\u2019ll see an \u2018insufficient access\u2019 message when trying to use these features.</p>"},{"location":"get-started/advisors-details.html","title":"Advisors details","text":""},{"location":"get-started/advisors-details.html#list-of-database-advisors","title":"List of database Advisors","text":"<p>Percona Monitoring and Management (PMM) offers four categories of database Advisors to help you improve database performance: Configuration, Performance, Query and Security Advisors.</p> <p>Each Advisor includes a set of automated checks, which investigate a specific range of possible issues and areas of improvement: security threats, non-compliance issues, performance degradation, query and index optimization strategies etc.</p> <p>This page presents the complete list of database Advisors along with the corresponding subscription tier for which they are available.</p> <p>You can also access this list through the Advisor checks for PMM section in the Percona Portal documentation, as the Advisors are hosted on the Percona Platform. PMM Server automatically downloads them from this source when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both options are enabled by default.</p>"},{"location":"get-started/advisors-details.html#configuration-advisors","title":"Configuration Advisors","text":"Advisor Name Description Available for Database Technology Version Configuration Notifies of newly released database versions to streamline database maintenance and ensure the most up-to-date performance. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Generic Configuration Provides basic recommendations for improving your database configuration. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Resources Configuration Watches your database and gives you recommendations for efficient management of resources like binaries architecture, CPU number versus DB Configuration, etc. \u2022 Percona customers\u2022 Community MySQL, MongoDB Connection Configuration Provides recommendations on configuring database connection parameters for improving database performance. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Replication Configuration Provides recommendations for scalable replication in database clusters. \u2022 Percona customers\u2022 Community MySQL, MongoDB InnoDB Configuration Advises on configuring InnoDB optimization for high performance. Percona customers MySQL Vacuum Configuration Provides recommendations on optimizing Vacuum operations. Percona customers PostgreSQL"},{"location":"get-started/advisors-details.html#performance-advisors","title":"Performance Advisors","text":"Advisor Name Description Subscription Database Technology Generic Performance Provides basic database configuration recommendations for high-performance query execution. \u2022 Percona customers\u2022 Community MongoDB, PostgreSQL Vacuum Performance Helps improve the efficiency and execution speed of database Vacuum commands. Percona customers PostgreSQL Replication Performance Checks efficient replication usage of your database. \u2022 Percona customers\u2022 Community MongoDB, PostgreSQL"},{"location":"get-started/advisors-details.html#security-advisors","title":"Security Advisors","text":"Advisor Name Description Subscription Database Technology CVE Security Informs you of any database versions affected by CVE. \u2022 Percona customers\u2022 Community MongoDB, PostgreSQL Configuration Security Checks your database configuration to ensure that security best practices are correctly implemented. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Authentication Security Ensures that all database authentication parameters are configured securely. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Replication Security Helps safeguard data replication by assessing security risks and providing recommendations for improving protection. \u2022 Percona customers\u2022 Community MySQL Connection Security Helps identify security issues on network connections and provides recommendations for enhancing security. Percona customers MySQL, MongoDB"},{"location":"get-started/advisors-details.html#query-advisors","title":"Query Advisors","text":"Advisor Name Description Subscription Database Technology Index Query Provides query and index optimization strategies for peak database performance. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL Schema Design Query Helps create efficient database schemas by analyzing queries and offering suggestions for optimization. \u2022 Percona customers\u2022 Community MySQL"},{"location":"get-started/advisors-details.html#list-of-checks","title":"List of checks","text":"<p>Every Advisor consists of one or more Advisor checks.  We have listed the checks and their details here.</p>"},{"location":"get-started/advisors-details.html#mongodb","title":"MongoDB","text":"Advisor Check Name Description Summary Connection Configuration mongodb_connection_sudden_spike Warns about any significant increase in the number of connections exceeding 50% of the recent or typical connection count. MongoDB Sudden Increase in Connection Count Connection Configuration mongodb_connections Returns the current number of connections as an informational notice when connection counts exceed 5000. MongoDB High Connections Generic Configuration mongo_cache_size Warns when Mongo wiredtiger cache size is greater than the default 50%. Mongo Storage Cache Generic Configuration mongodb_active_vs_available_connections Warns if the ratio between active and available connections is higher than 75%. MongoDB Active vs Available Connections Generic Configuration mongodb_journal Warns if the journal is disabled. MongoDB Journal Generic Configuration mongodb_loglevel Warns if MongoDB is not using the default Log level. MongoDB Non-Default Log Level Generic Configuration mongodb_read_tickets Warns if MongoDB is using more than 128 read tickets. MongoDB Read Tickets Generic Configuration mongodb_write_tickets Warns if MongoDB is using more than 128 write tickets. MongoDB Write Tickets Generic Configuration mongodb_write_tickets_runtime Warns if MongoDB is using more than 128 write tickets during runtime. MongoDB - Configuration Write Ticket Check Replication Configuration mongodb_psa_architecture_check Raises an error if the replicaSet is utilizing a PSA (Primary-Secondary-Arbiter) architecture. MongoDB PSA Architecture Replication Configuration mongodb_replicaset_topology Warns if the Replica Set has less than three data-bearing nodes. MongoDB Replica Set Topology Resources Configuration mongodb_collection_fragmented Warns if the storage size exceeds the data size of a collection, indicating potential fragmentation. This suggests the need for compaction or an initial sync to reclaim disk space. MongoDB Collections Fragmented Resources Configuration mongodb_cpucores Warns if the number of CPU cores does not meet the minimum recommended requirements according to best practices. MongoDB CPU Cores Resources Configuration mongodb_dbpath_mount Warns if dbpath does not have a dedicated mount point. MongoDB - Separate Mount Point Other Than \u201c/\u201d Partition for dbpath. Resources Configuration mongodb_fcv_check Warns if there is a mismatch between the MongoDB version and the internal FCV (Feature Compatibility Version) parameter setting. MongoDB - FCV Mismatch Resources Configuration mongodb_maxsessions Warns if MongoDB is configured with a maxSessions value other than the default value of 1000000. MongoDB maxSessions Resources Configuration mongodb_swap_allocation Warns if there is no swap memory allocated to your instance. MongoDB - Allocate Swap Memory Resources Configuration mongodb_taskexecutor Warns if the count of MongoDB TaskExecutorPoolSize exceeds the number of available CPU cores. MongoDB TaskExecutorPoolSize High Resources Configuration mongodb_xfs_ftype Warns if dbpath is not using the XFS filesystem type. MongoDB - XFS Version Configuration mongodb_EOL Raises an error or a warning if your current PSMDB or MongoDB version has reached or is nearing its End-of-Life (EOL) status. MongoDB Version EOL Version Configuration mongodb_unsupported_version Raises an error if your current PSMDB or MongoDB version is not supported. MongoDB Unsupported Version Version Configuration mongodb_version Provides information on current MongoDB or Percona Server for MongoDB versions used in your environment. It also offers details on other available minor or major versions that you may consider for upgrades. MongoDB Version Check Generic Performance mongodb_multiple_services Warns if multiple mongod services are detected running on a single node. MongoDB - Multiple mongod Services Replication Performance mongodb_chunk_imbalance Warns if the distribution of chunks across shards is imbalanced. MongoDB Sharding - Chunk Imbalance Across Shards Replication Performance mongodb_oplog_size_recommendation Warns if the oplog window is below a 24-hour period and provides a recommended oplog size based on your instance. MongoDB - Oplog Recovery Window is Low Replication Performance mongodb_replication_lag Warns if the replica set member lags behind the primary by more than 10 seconds. MongoDB Replication Lag Index Query mongodb_shard_collection_inconsistent_indexes Warns if there are inconsistent indexes across shards for sharded collections. Missing or inconsistent indexes across shards can have a negative impact on performance. MongoDB Sharding - Inconsistent Indexes Across Shards Index Query mongodb_unused_index Warns if there are unused indexes on any database collection in your instance. This requires enabling the \u201cindexStats\u201d collector. MongoDB - Unused Indexes Authentication Security mongodb_auth Warns if MongoDB authentication is disabled. MongoDB Authentication Authentication Security mongodb_localhost_auth_bypass Warns if MongoDB localhost bypass is enabled. MongoDB localhost authentication bypass enabled Configuration Security mongodb_authmech_scramsha256 Warns if MongoDB is not using the default SHA-256 hashing function as its SCRAM authentication method. MongoDB Security AuthMech Check Connection Security mongodb_bindip Warns if the MongoDB network binding is not set as Recommended. MonogDB IP Bindings CVE Security mongodb_cve_version Shows an error if MongoDB or Percona Server for MongoDB version is older than the latest version containing CVE (Common Vulnerabilities and Exposures) fixes. MongoDB CVE Version"},{"location":"get-started/advisors-details.html#mysql","title":"MySQL","text":"Advisor Check Name Description Summary Connection Configuration mysql_configuration_max_connections_usage Checks the MySQL max_connections configuration option to ensure maximum utilization is achieved. Check Max Connections Usage Generic Configuration mysql_automatic_sp_privileges_enabled Checks if the automatic_sp_privileges configuration is ON. Checks if automatic_sp_privileges configuration is ON. Generic Configuration mysql_config_binlog_retention_period Checks whether binlogs are being rotated too frequently, which is not recommended, except in very specific cases. Binlogs Retention Check Generic Configuration mysql_config_binlog_row_image Advises when to set binlog_row_image=FULL. Binlogs Raw Image is Not Set to FULL Generic Configuration mysql_config_binlogs_checksummed Advises when to set binlog_checksum=CRC32 to improve consistency and reliability. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_general_log Checks whether the general log is enabled. General Log is Enabled Generic Configuration mysql_config_log_bin Checks whether the binlog is enabled or disabled. Binary Log is disabled Generic Configuration mysql_config_sql_mode Checks whether the server has specific values configured in sql_mode to ensure maximum data integrity. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_tmp_table_size_limit Checks whether the size of temporary tables exceeds the size of heap tables. Temp Table Size is Larger Than Heap Table Size Generic Configuration mysql_configuration_log_verbosity Checks whether warnings are being printed on the log. Check Log Verbosity Generic Configuration mysql_test_database Notifies if there are database named \u2018test\u2019 or \u2018test_%\u2019. MySQL Test Database Generic Configuration mysql_timezone Verifies whether the time zone is correctly loaded. MySQL configuration check InnoDB Configuration innodb_redo_logs_not_sized_correctly Reviews the InnoDB redo log size and provides suggestions if it is configured too low. InnoDB Redo Log Size is Not Configured Correctly. InnoDB Configuration mysql_ahi_efficiency_performance_basic_check Checks the efficiency and effectiveness of InnoDB\u2019s Adaptive Hash Index (AHI). InnoDB Adaptive Hash Index (AHI) Efficiency InnoDB Configuration mysql_config_innodb_redolog_disabled Warns when the MySQL InnoDB Redo log is set to OFF, which poses a significant security risk and compromises data integrity. The MySQL InnoDB Redo log is a crucial component for maintaining the ACID (Atomicity, Consistency, Isolation, Durability) properties in MySQL databases. Redo Log is Disabled in This Instance InnoDB Configuration mysql_configuration_innodb_file_format Verifies whether InnoDB is configured with the recommended file format. MySQL InnoDB File Format InnoDB Configuration mysql_configuration_innodb_file_maxlimit Checks whether InnoDB is configured with the recommended auto-extend settings. InnoDB Tablespace Size Has a Maximum Limit. InnoDB Configuration mysql_configuration_innodb_file_per_table_not_enabled Warns when innodb_file_per_table is not enabled. innodb_file_per_table Not Enabled InnoDB Configuration mysql_configuration_innodb_flush_method Checks whether InnoDB is configured with the recommended flush method. MySQL InnoDB Flush Method InnoDB Configuration mysql_configuration_innodb_strict_mode Warns about password lifetime. InnoDB strict mode Replication Configuration mysql_config_relay_log_purge Identifies whether a replica node has relay-logs purge set. Automatic Relay Log Purging is OFF Replication Configuration mysql_config_replication_bp1 Identifies whether a replica node is in read-only mode and if checksum is enabled. Checks Basic Best Practices When Setting Replica Node. Replication Configuration mysql_config_slave_parallel_workers Identifies whether replication is single-threaded. Replication is Single-Threaded Replication Configuration mysql_config_sync_binlog Checks whether the binlog is synchronized before a transaction is committed. Sync Binlog Disabled Replication Configuration mysql_log_replica_updates Checks if a replica is safely logging replicated transactions. MySQL Configuration Check Replication Configuration replica_running_skipping_errors_or_idempotent_mode Reviews replication status to check if it is configured to skip errors or if the slave_exec_mode is set to be idempotent. Replica is skipping errors or slave_exec_mode is Idempotent. Resources Configuration mysql_32binary_on_64system Notifies if version_compile_machine equals i686. Check if Binaries are 32 Bits Version Configuration mysql_unsupported_version_check Warns against an unsupported Mysql version. Checks Mysql Version Version Configuration mysql_version Warns if MySQL, Percona Server for MySQL, or MariaDB version is not the latest available one. MySQL Version Version Configuration mysql_version_eol_57 Checks if the server version is EOL. End Of Life Server Version (5.7). Index Query mysql_performance_temp_ondisk_table_high Warns if there are too many on-disk temporary tables being created due to unoptimized query execution. Too Many on Disk Temporary Tables Index Query mysql_tables_without_pk Checks tables without primary keys. MySQL check for a table without Primary Key Schema Design Query mysql_indexes_larger Check all the tables to see if any have indexes larger than data. This indicates a sub-optimal schema and should be reviewed. Tables With Index Sizes Larger Than Data Authentication Security mysql_automatic_expired_password Warns if the MySQL parameter for automatic password expiry is not active. MySQL Automatic User Expired Password Authentication Security mysql_security_anonymous_user Verifies if anonymous users are present, as this would contradict security best practices. Anonymous User (You Must Remove Any Anonymous User) Authentication Security mysql_security_open_to_world_host Checks whether host definitions are set as \u2018%\u2019 since this is overly permissive and could pose security risks. UserS Have Host Definition \u2018%\u2019 Which is Too Open Authentication Security mysql_security_root_not_local Checks whether the root user has a host definition that is not set to 127.0.0.1 or localhost. Root User Can Connect From Non-local Location Authentication Security mysql_security_user_ssl Reports users who are not using a secure SSL protocol to connect. Users Not Using Secure SSL Authentication Security mysql_security_user_super_not_local Reports users with super privileges who are not connecting from the local host or the host is not fully restricted (e.g., 192.168.%). Users have Super privileges With Remote and Too Open Access Authentication Security mysql_security_user_without_password Reports users without passwords. Users Without Password Configuration Security mysql_config_local_infile Checks if the \u201cLOAD DATA INFILE\u201d functionality is active. Load Data in File Active Configuration Security mysql_configuration_secure_file_priv_empty Warns when  secure_file_priv is empty as this enables users with FILE privilege to create files at any location where MySQL server has Write permission. secure_file_priv is Empty Configuration Security mysql_password_expiry Checks if MySQL user passwords are expired or expiring within the next 30 days. Check MySQL User Password Expiry Configuration Security mysql_require_secure_transport Checks the status of mysql_secure_transport_only. MySQL configuration check Configuration Security mysql_security_password_lifetime Warns about password lifetime. InnoDB Password Lifetime Configuration Security mysql_security_password_policy Checks for password policy. MySQL Security Check for Password Connection Security mysql_private_networks_only Notifies about MySQL accounts that are allowed to connect from public networks. MySQL Users With Granted Public Networks Access Replication Security mysql_replication_grants Checks if replication is configured on a node without user grants. MySQL Security Check for Replication User Replication Security mysql_security_replication_grants_mixed Checks if replication privileges are mixed with more elevated privileges. Replication Privileges"},{"location":"get-started/advisors-details.html#postgresql","title":"PostgreSQL","text":"Advisor Check Name Description Connection Configuration postgresql_max_connections_1 Notifies if the max_connections configuration option is set to a high value (above 300). PostgreSQL doesn\u2019t cope well with having many connections even if they are idle. The recommended value is below 300. Generic Configuration postgresql_archiver_failing_1 Verifies if the archiver has failed. Generic Configuration postgresql_fsync_1 Returns an error if the fsync configuration option is set to OFF, as this can lead to database corruptions. Generic Configuration postgresql_log_checkpoints_1 Notifies if the log_checkpoints configuration option is not enabled. It is recommended to enable the logging of checkpoint information, as that provides a lot of useful information with almost no drawbacks. Generic Configuration postgresql_logging_recommendation_checks Verifies whether the recommended minimum logging features are enabled. Generic Configuration postgresql_wal_retention_check Checks if there are too many WAL files retained in the WAL directory. Vacuum Configuration postgresql_log_autovacuum_min_duration_1 Notifies if the log_autovacuum_min_duration configuration option is set to -1 (disabled). It is recommended to enable the logging of autovacuum run information, as it provides a lot of useful information with almost no drawbacks. Vacuum Configuration postgresql_table_autovac_settings Returns tables where autovacuum parameters are specified along with the corresponding autovacuum settings. Vacuum Configuration postgresql_txid_wraparound_approaching Verifies the age of databases and alerts if the transaction ID wraparound issue is nearing. Vacuum Configuration postgresql_vacuum_sanity_check This performs a quick check of some vacuum parameters. Version Configuration postgresql_eol_check Checks if the currently installed PostgreSQL version has reached its EOL and is no longer supported. Version Configuration postgresql_extension_check Lists outdated extensions with newer versions available. Version Configuration postgresql_unsupported_check Verifies if the currently installed version is supported by Percona. Version Configuration postgresql_version_check Checks if the currently installed version is outdated for its release level. Generic Performance postgresql_cache_hit_ratio_1 Checks the hit ratio of one or more databases and raises a complaint when they are too low. Generic Performance postgresql_config_changes_need_restart_1 Warns if there are any settings or configurations that have been changed and require a server restart or reload. Generic Performance postgresql_tmpfiles_check Reports the number of temporary files and the number of bytes written to disk since the last statistics reset. Replication Performance postgresql_stale_replication_slot_1 Warns if there is a stale replication slot. Stale replication slots will lead to WAL file accumulation and can result in a database server outage. Vacuum Performance postgresql_table_bloat_bytes Verifies the size of the table bloat in bytes across all databases and raises alerts accordingly. Vacuum Performance postgresql_table_bloat_in_percentage Verifies the size of the table bloat in the percentage of the total table size and alerts accordingly. Index Query postgresql_number_of_index_check Lists relations with more than ten indexes. Index Query postgresql_sequential_scan_check Checks for tables with excessive sequential scans. Index Query postgresql_unused_index_check Lists relations with indexes that have not been used since the statistics were last reset. Authentication Security postgresql_super_role Notifies if there are users with Superuser role. Configuration Security postgresql_expiring_passwd_check Checks for passwords that are expiring and displays the time left before they expire. CVE Security postgresql_cve_check Checks if the currently installed version has reported security vulnerabilities."},{"location":"get-started/advisors.html","title":"Working with Advisors","text":"<p>Percona Advisors provide automated insights and recommendations within Percona Monitoring and Management. These proactive insights help you uncover problems before they become larger issues: security risks, misconfigurations, poor performance, etc.</p> <p>Advisors are grouped by category: Security, Configuration, Performance and Query. Each Advisor category offers a set of automated checks, which investigate a specific range of possible issues. The list of Advisor checks available for your instance depends on whether your instance is connected to Percona Platform, and on your current subscription plan.</p>"},{"location":"get-started/advisors.html#prerequisites-for-accessing-advisor-checks","title":"Prerequisites for accessing Advisor checks","text":"<p>All checks are hosted on Percona Platform. PMM Server automatically downloads them from here when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both these options are enabled by default.</p>"},{"location":"get-started/advisors.html#highest-security-for-your-databases","title":"Highest security for your databases","text":"<p>Percona Platform communicates with PMM via secure channels, using the highest standards for privacy and security. Before downloading and running Advisor checks on your database, PMM verifies the content and integrity of all Advisor checks to confirm that every component originated from Percona Platform and that no one has altered them since the checks were digitally signed.</p>"},{"location":"get-started/advisors.html#advisor-check-tiers-and-platform-entitlements","title":"Advisor check tiers and Platform entitlements","text":"<p>Depending on the entitlements available for your Percona Account, the set of Advisor checks that PMM can download from the Percona Platform differs in terms of complexity and functionality.</p> <p>If your PMM instance is not connected to Percona Platform, PMM can only use the default Advisor checks. As soon as you connect your PMM instance to Percona Platform, has access to additional checks, available only for registered PMM instances.</p> <p>If you are a Percona customer with a Percona Customer Portal account, you also get access to Standard/Premium Advisor checks, which offer more advanced database health information.</p> <p>To see the complete list of available checks, see the Advisor Checks for PMM topic in the Percona Platform documentation.</p>"},{"location":"get-started/advisors.html#enabledisable","title":"Enable/Disable","text":"<p>To download the checks available for your Percona Account, the Advisors and Telemetry options have to be enabled under  Configuration  &gt; Settings &gt; Advanced Settings.</p> <p>These options are enabled by default so that PMM can run automatic Advisor checks in the background. However, you can disable them at any time if you do not need to check the health and performance of your connected databases.</p>"},{"location":"get-started/advisors.html#automatic-checks","title":"Automatic checks","text":"<p>Advisor checks can be executed manually or automatically. By default, PMM runs all the checks available for your PMM instances every 24 hours.</p>"},{"location":"get-started/advisors.html#change-run-interval-for-automatic-advisors","title":"Change run interval for automatic advisors","text":"<p>You can change the standard 24-hour interval to a custom frequency for each Advisor check:</p> <ul> <li>Rare interval - 78 hours</li> <li>Standard interval (default) - 24 hours</li> <li>Frequent interval - 4 hours</li> </ul> <p>To change the frequency of an automatic check:</p> <ol> <li>Click   Advisors.</li> <li>Select the Advisor tab that contains the check for which you want to change the frequency.</li> <li> <p>Expand the relevant Advisor and scroll through the list to find your check. Alternatively, use the Filter section at the top of the table to search checks by Name, Description, Status, or Interval.</p> <p>Tip</p> <p>If you need to share filtered Advisor results with your team members, send them the PMM URL. This saves your search criteria and results.</p> <ol> <li>Click the  Interval icon in the Actions column, next to the check you want to update.</li> <li>Chose an interval and click Save.</li> </ol> </li> </ol>"},{"location":"get-started/advisors.html#manual-checks","title":"Manual checks","text":"<p>In addition to the automatic checks that run every 24 hours, you can also run checks manually, for ad-hoc assessments of your database health and performance.</p> <p>To run checks manually:</p> <ol> <li>Click   Advisors on the main menu.</li> <li>Select the Advisor tab that contains the checks which you want to run manually.</li> <li>Click Run checks to run all the available checks for this Advisor group, or expand an Advisor and click Run next to each check that you want to run individually. </li> </ol>"},{"location":"get-started/advisors.html#advisor-checks-results","title":"Advisor checks results","text":"<p>The results are sent to PMM Server where you can review any failed checks on the Home dashboard. The summary count of failed checks is classified as:</p> <ul> <li>Critical, which also includes checks tagged as Alert and Emergency</li> <li>Error</li> <li>Warning</li> <li>Notice, which also includes checks tagged as Info and Debug</li> </ul> <p></p> <p>To see more details about the available checks and any checks that failed, click the   Advisors icon on the main menu.</p> <p>Check results data always remains on the PMM Server. This is not related to anonymous data sent for Telemetry purposes.</p>"},{"location":"get-started/advisors.html#create-your-own-advisors","title":"Create your own Advisors","text":"<p>PMM Advisors offer a set of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>Developers can create custom checks to cover additional use cases, relevant to specific database infrastructure. For more information, see Develop Advisor checks.</p>"},{"location":"get-started/alert-templates.html","title":"PMM alert templates","text":"<p>Alert templates provide a set of common events and expressions for alerting, serving as a foundation for creating alert rules.</p> <p>Percona Monitoring and Management (PMM) offers three categories of alert templates to enhance database performance monitoring:</p> <ol> <li>Built-in templates: templates that are available out-of-the-box with the PMM installation and are available to all PMM users.</li> <li>Percona Platform templates: additional templates dynamically delivered to PMM if the instance is connected to Percona Platform using a Percona Account.     When connected to the Platform, PMM automatically downloads these templates if the Telemetry option is enabled under Configuration &gt; Settings &gt; Advanced Settings.</li> <li>Custom templates: user-created templates for specific needs not met by built-in or Percona Platform templates. These allow you to tailor alerts to your unique environment and requirements.    For details on creating custom templates, see Percona Alerting.</li> </ol>"},{"location":"get-started/alert-templates.html#accessing-alert-templates","title":"Accessing alert templates","text":"<p>To check the alert templates for your PMM instance, go to PMM &gt; Alerting &gt; Alert Rule Templates tab.</p>"},{"location":"get-started/alert-templates.html#available-alert-template","title":"Available alert template","text":"<p>The table below lists all the alert templates available in Percona Monitoring and Management (PMM).</p> <p>This list includes both built-in templates (accessible to all PMM users), and Percona customers templates.</p> <p>To access the Percona customers templates, you must be a Percona customer and connect PMM to Percona Platform using a Percona Account.</p> Area Template name Description Available for Database technology OS Node high CPU load Monitors node CPU usage and alerts when it surpasses 80% (default threshold). Provides details about specific nodes experiencing high CPU load, indicating potential performance issues or scaling needs. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL OS Memory available less than a threshold Tracks available memory on nodes and alerts when free memory drops below 20% (default threshold). Helps prevent system instability due to memory constraints. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL OS Node high swap filling up Monitors node swap usage and alerts when it exceeds 80% (default threshold). Indicates potential memory pressure and performance degradation, allowing for timely intervention. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL PMM PMM agent down Monitors PMM Agent status and alerts when an agent becomes unreachable, indicating potential host or agent issues. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL, ProxySQL PMM Backup failed [Technical Preview] Monitors backup processes and alerts on failures, providing details about the failed backup artifact and service. Helps maintain data safety and recovery readiness. This template is currently in Technical Preview status and should be used for testing purposes only as it is subject to change. \u2022 Percona customers\u2022 Community MySQL, MongoDB, PostgreSQL, ProxySQL MongoDB MongoDB down Detects when a MongoDB instance becomes unavailable, enabling rapid response to maintain database accessibility. \u2022 Percona customers\u2022 Community MongoDB MongoDB Memory used by MongoDB connections Tracks MongoDB connection memory usage and alerts when it exceeds configurable thresholds. Helps identify and address potential performance issues caused by high memory consumption. \u2022 Percona customers\u2022 Community MongoDB MongoDB Memory used by MongoDB Monitors overall MongoDB memory usage and alerts when it exceeds 80% of total system memory. Provides details about specific MongoDB services and nodes experiencing high memory consumption, aiding in resource optimization. \u2022 Percona customers\u2022 Community MongoDB MongoDB MongoDB restarted Detects recent MongoDB restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Facilitates investigation of unexpected downtime and potential issues. \u2022 Percona customers\u2022 Community MongoDB MongoDB MongoDB DBPath disk space utilization Monitors disk space usage in MongoDB\u2019s data directory and alerts when it exceeds set thresholds. Helps prevent storage-related issues and ensures adequate space for database operations. Percona customers MongoDB MongoDB MongoDB host SSL certificate expiry Tracks SSL certificate expiration dates for MongoDB hosts and alerts when certificates are approaching expiry. Enables timely certificate renewal to maintain secure connections. Percona customers MongoDB MongoDB MongoDB oplog window Monitors the oplog window size and alerts when it falls below the recommended threshold (typically 24-48 hours). Ensures sufficient time for secondary nodes to replicate data and maintain cluster consistency. Percona customers MongoDB MongoDB MongoDB read tickets Tracks read ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Helps optimize read performance and identify potential bottlenecks. Percona customers MongoDB MongoDB MongoDB replication lag is high Monitors replication lag and alerts when it exceeds acceptable thresholds. Crucial for maintaining data consistency across replicas and identifying synchronization issues. Percona customers MongoDB MongoDB MongoDB ReplicaSet has no primary Detects when a replica set loses its primary node and alerts users. Indicates that the cluster is in read-only mode, potentially affecting write operations and overall database functionality. Percona customers MongoDB MongoDB MongoDB member is in unusual state Identifies and alerts when replica set members enter unusual states such as Recovering, Startup, or Rollback. Helps maintain cluster health and performance by enabling quick intervention. Percona customers MongoDB MongoDB MongoDB write tickets Monitors write ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Aids in optimizing write performance and identifying potential bottlenecks. Percona customers MongoDB MongoDB MongoDB too many chunk migrations Monitors amount of chunk migrations in a MongoDB sharded cluster and alerts if they are more than set thresholds. Percona customers MongoDB PBM MongoDB PBM Agent down Monitors the status of Percona Backup for MongoDB (PBM) Agents and alerts when an Agent becomes unresponsive. This indicates potential issues with the host system or with the PBM Agent itself. \u2022 Percona customers\u2022 Community MongoDB PBM MongoDB PBM backup duration Monitors the time taken to complete a backup and alerts when it exceeds set thresholds. If the backup did not complete, no alerts are sent. \u2022 Percona customers\u2022 Community MongoDB PBM MongoDB PBM backup size Monitors the amount of disk space taken by a completed backup and alerts when it exceeds set thresholds. If the backup did not complete, no alerts are sent. \u2022 Percona customers\u2022 Community MongoDB MySQL MySQL down Monitors MySQL instance availability and alerts when any MySQL service becomes unreachable. Enables quick response to maintain database services. \u2022 Percona customers\u2022 Community MySQL MySQL MySQL replication running IO Tracks MySQL replication I/O thread status and alerts if it stops running on a replica. Crucial for ensuring data is being received from the primary server. \u2022 Percona customers\u2022 Community MySQL MySQL MySQL replication running SQL Monitors MySQL replication SQL thread status and alerts if it stops running on a replica. Essential for verifying that received data is being applied correctly to maintain data consistency. \u2022 Percona customers\u2022 Community MySQL MySQL MySQL restarted Detects recent MySQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. \u2022 Percona customers\u2022 Community MySQL MySQL MySQL connections in use Tracks MySQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to connection overload. \u2022 Percona customers\u2022 Community MySQL PostgreSQL PostgreSQL down Detects when PostgreSQL instances become unavailable, enabling quick response to maintain database services. Provides details about affected services and nodes. \u2022 Percona customers\u2022 Community PostgreSQL PostgreSQL PostgreSQL restarted Identifies recent PostgreSQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. \u2022 Percona customers\u2022 Community PostgreSQL PostgreSQL PostgreSQL connections in use Monitors PostgreSQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to excessive connections. \u2022 Percona customers\u2022 Community PostgreSQL PostgreSQL PostgreSQL index bloat is high Detects excessive index bloat and alerts users. Helps identify performance degradation due to bloated indexes, enabling timely maintenance to improve query performance. Percona customers PostgreSQL PostgreSQL PostgreSQL high number of dead tuples Monitors the accumulation of dead tuples in relations and alerts when they exceed set thresholds. Indicates potential issues with vacuum settings and helps optimize storage and query performance. Percona customers PostgreSQL PostgreSQL PostgreSQL has a high number of statement timeouts Tracks and alerts on frequent query cancellations due to statement timeouts. Helps identify various issues such as high load, poorly written queries, or inadequate resource allocation. Percona customers PostgreSQL PostgreSQL PostgreSQL table bloat is high Detects excessive table bloat and alerts users. Indicates a need to adjust vacuum settings for specific relations or globally, helping to maintain optimal query performance and storage efficiency. Percona customers PostgreSQL PostgreSQL PostgreSQL high rate of transaction rollbacks Monitors the ratio of transaction rollbacks to commits and alerts on high rates. Helps identify potential application or database issues leading to frequent transaction failures. Percona customers PostgreSQL PostgreSQL PostgreSQL tables not auto analyzed Identifies tables that are not being auto-analyzed and alerts users. Crucial for maintaining accurate statistics and generating proper query execution plans. Percona customers PostgreSQL PostgreSQL PostgreSQL tables not auto vacuumed Detects tables that are not being auto-vacuumed and alerts users. Essential for managing bloat, optimizing storage, and maintaining overall database health. Percona customers PostgreSQL PostgreSQL PostgreSQL unused replication slot Identifies and alerts on unused replication slots. Helps prevent excessive WAL retention and potential disk space issues, especially when replicas are offline. Percona customers PostgreSQL ProxySQL ProxySQL server status Monitors ProxySQL server status and alerts when a server transitions to OFFLINE_SOFT (3) or OFFLINE_HARD (4) state. Includes critical details such as server endpoint, hostgroup, and associated ProxySQL service. This alert is essential for maintaining high availability and preventing database access disruptions. \u2022 Percona customers\u2022 Community ProxySQL"},{"location":"get-started/alerting.html","title":"About Percona Alerting","text":"<p>Percona Alerting is the new Alerting feature introduced in PMM 2.31. This replaces the Integrated Alerting feature available in previous versions.  </p> <p>Alerting notifies of important or unusual activity in your database environments so that you can identify and resolve problems quickly. When something needs your attention, Percona Alerting can be configured to automatically send you a notification through your specified contact points.</p> <p>PMM 2.31 introduced Percona Alerting which replaces Integrated Alerting in previous PMM versions. In addition to full feature parity, Percona Alerting includes additional benefits like Grafana-based alert rules and a unified, easy-to-use alerting command center on the Alerting page.</p> <p>Percona Alerting is enabled by default in the PMM Settings. This feature adds the Percona templated alerts option on the Alerting page.</p>"},{"location":"get-started/alerting.html#alert-types","title":"Alert types","text":"<p>Percona Alerting is powered by Grafana infrastructure. It leverages Grafana\u2019s advanced alerting capabilities and provides pre-configured Alert Rule Templates that simplify creating powerful alerting rules.</p> <p>Depending on the datasources that you want to query, and the complexity of your required evaluation criteria, Percona Alerting enables you to create the following types of alerts:</p> <ul> <li> <p>Percona templated alerts: alerts based on a set of Percona-supplied templates with common events and expressions for alerting. If you need custom expressions on which to base your alert rules, you can also create your own templates. To see the complete list of available templates, see the PMM Alert Templates topic</p> </li> <li> <p>Grafana managed alerts: alerts that handle complex conditions and can span multiple different data sources like SQL, Prometheus, InfluxDB, etc. These alerts are stored and executed by Grafana.</p> </li> </ul> <p>The Alerting page contains are split into eight tabs: Fired Alerts, Alert Rules, Alert Rule Templates, Contact Points, Notification Policies, Silences, Alert Groups and Admin.</p> <p></p>"},{"location":"get-started/alerting.html#alert-rules","title":"Alert rules","text":"<p>Alert rules describe the circumstances under which you want to be alerted. The evaluation criteria that you define determine whether an alert will fire.</p> <p>An alert rule consists of one or more queries and expressions, a condition, the frequency of evaluation, and the duration over which the condition is met. For example, you might configure an alert to fire and trigger a notification when MongoDB is down.</p> <p></p> <p>An alert rule can be in three possible states:</p> <ul> <li>Normal: Everything is working correctly and the conditions specified in the rule has not been met. This is the default state for newly created rules.</li> <li>Pending: The conditions specified in the alert rule has been met, but for a time that is less than the configured duration.</li> <li>Firing: Both the conditions and the duration specified in the alert rule have both been met.</li> </ul> <p>It takes at least one evaluation cycle for an alert rule to transition from one state to another (e.g., from <code>Normal</code> to <code>Pending</code>).</p>"},{"location":"get-started/alerting.html#alert-rules-templates","title":"Alert rules templates","text":"<p>PMM provides a set of alert rule templates with common events and expressions for alerting. These templates can be used as a basis for creating alert rules. </p> <p>Percona Monitoring and Management (PMM) offers three categories of alert templates to enhance database performance monitoring:</p> <ul> <li>Built-in templates, available out-of-the-box with PMM.</li> <li>Additional templates available after connecting PMM with Percona Platform. See Integrate PMM with Percona Platform.</li> <li>Custom templates created or uploaded on the Alerting page &gt; Alert Templates tab. You can also store your custom template files in your /srv/alerting/templates directory and PMM will load them during startup.</li> </ul>"},{"location":"get-started/alerting.html#accessing-alert-rule-templates","title":"Accessing alert rule templates","text":"<p>To see the full list of the alert templates that PMM offers, see PMM alert templates.</p> <p>You can check the alert templates available for your account under Alerting &gt; Alert rule templates tab.</p>"},{"location":"get-started/alerting.html#create-alert-rules-from-alert-rule-templates","title":"Create alert rules from alert rule templates","text":"<p>This section focuses on creating an alert rule based on PMM templates. For information on working with the other alert types, check the Grafana documentation on Grafana Labs.</p>"},{"location":"get-started/alerting.html#provision-alert-resources","title":"Provision alert resources","text":"<p>Before creating PMM alert rules, configure the required alert resources:</p> <ol> <li>Go to Configuration &gt; PMM Settings and ensure that the Alerting option is enabled. This is enabled by default starting with PMM 2.31. However, if you have disabled it, the Alerting page displays only Grafana-managed alert rules. This means that you will not be able to create alerts based on PMM templates.</li> <li>Go to Dashboards &gt; Browse and check the folders available for storing alert rules. If none of the available folders are relevant for your future alert rules, click New &gt; New Folder and create a custom one.</li> <li>Go to Alerting &gt; Alert Rule Templates and check the default PMM templates. If none of the templates include a relevant expression for the type of alerts that you want to create, click Add to create a custom template instead.</li> </ol>"},{"location":"get-started/alerting.html#configure-alert-templates","title":"Configure alert templates","text":"<p>Alerts templates are YAML files that provide the source framework for alert rules. Alert templates contain general template details and an alert expression defined in MetricsQL. This query language is backward compatible with PromQL.</p>"},{"location":"get-started/alerting.html#create-custom-templates","title":"Create custom templates","text":"<p>If none of the default PMM templates contain a relevant expression for the alert rule that you need, you can create a custom template instead.</p> <p>You can base multiple alert rules on the same template. For example, you can create a <code>pmm_node_high_cpu_load</code> template that can be used as the source for alert rules for production versus staging, warning versus critical, etc.</p>"},{"location":"get-started/alerting.html#template-format","title":"Template format","text":"<p>When creating custom templates, make sure to use the required template format below:</p> <ul> <li>name (required): uniquely identifies template. Spaces and special characters are not allowed.</li> <li>version (required): defines the template format version.</li> <li>summary (required): a template description.</li> <li>expr (required): a MetricsQL query string with parameter placeholders.</li> <li>params: contains parameter definitions required for the query. Each parameter has a name, type, and summary. It also may have a unit, available range, and default value.<ul> <li>name (required): the name of the parameter. Spaces and special characters are not allowed.</li> <li>summary (required): a short description of what this parameter represents.</li> <li>unit (optional): PMM currently supports either s (seconds) or % (percentage).</li> <li>type (required): PMM currently supports the <code>float</code> type. <code>string</code>, <code>bool</code>, and other types will be available in a future release.</li> <li>range (optional): defines the boundaries for the value of a  float parameter</li> </ul> </li> <li>value (optional): default parameter value. Value strings must not include any of these special characters: <code>&lt; &gt; ! @ # $ % ^ &amp; * ( ) _ / \\ ' + - = (space)</code></li> <li>for (required): specifies the duration of time that the expression must be met before the alert will be fired</li> <li>severity (required): specifies default alert severity level</li> <li> <p>labels (optional): are additional labels to be added to generated alerts</p> </li> <li> <p>annotations (optional): are additional annotations to be added to generated alerts.</p> </li> </ul>"},{"location":"get-started/alerting.html#template-example","title":"Template example","text":"<pre><code>---\ntemplates:\n  - name: pmm_node_high_cpu_load\n    version: 1\n    summary: Node high CPU load\n    expr: |-\n      (1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])))\n      * 100\n      &gt; bool [[ .threshold ]]\n    params:\n      - name: threshold\n        summary: A percentage from configured maximum\n        unit: \"%\"\n        type: float\n        range: [0, 100]\n        value: 80\n    for: 5m\n    severity: warning\n    annotations:\n      summary: Node high CPU load ({{ $labels.node_name }})\n      description: |-\n        {{ $labels.node_name }} CPU load is more than [[ .threshold ]]%.\n</code></pre>"},{"location":"get-started/alerting.html#test-alert-expressions","title":"Test alert expressions","text":"<p>If you want to create custom templates, you can test the MetricsQL expressions for your custom template in the Explore section of PMM. Here you can also query any PMM internal database.</p> <p>To test expressions for custom templates:</p> <ol> <li>On the side menu in PMM, choose Explore &gt; Metrics.</li> <li>Enter your expression in the Metrics field and click Run query.</li> </ol> <p>For example, to check the CPU usage, Go to Explore &gt; Metrics in your PMM dashboard and run the query expression below: <pre><code>(1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100\n</code></pre> </p> <p>Note that to paste the query above, Explore must be in <code>Code</code> mode, and not in <code>Builder</code> mode.</p>"},{"location":"get-started/alerting.html#add-an-alert-rule","title":"Add an alert rule","text":"<p>After provisioning the resources required for creating Percona templated alerts, you are now ready to create your alert rule:</p> <ol> <li>Go to Alerting &gt; Alert Rules, and click New alert rule.</li> <li>On the Create alert rule page, select the Percona templated alert option. If you want to learn about creating Grafana alerts instead, check our Grafana\u2019s documentation.</li> <li>In the Template details section, choose the template on which you want to base the new alert rule. This automatically populates the Name, Duration, and Severity fields with information from the template. You can change these values if you want to override the default specifications in the template.</li> <li> <p>In the Filters field, specify if you want the alert rule to apply only to specific services or nodes. For example: <code>service_name=ps5.7</code>. When creating alert rule filters, consider the following:</p> <ul> <li>Filters use conjunction semantics. This means that if you add more than one filter, PMM will combine their conditions to search for matches: filter 1 AND filter 2 AND filter 3.</li> <li>Label must be an exact match. You can find a complete list of labels using the  Explore menu in PMM.</li> </ul> </li> <li> <p>From the Folder drop-down menu, select the location where you want to store the rule.</p> </li> <li>Click Save and Exit to close the page and go to the Alert Rules tab where you can review, edit and silence your new alert.</li> </ol>"},{"location":"get-started/alerting.html#contact-points","title":"Contact points","text":"<p>Contact points specify where Percona Alerting should deliver notifications for alerts. PMM can be configured via a Notification policy to send a notification to specified contact points whenever an alert is fired.</p> <p>Depending on the severity of an alert, you might want to send different alert notifications to different channels. For example, you can deliver common notifications via a Slack channel, but send an email notification for potentially critical issues.  </p> <p>Percona Alerting uses email as the default contact point but you can choose from a variety of other contact points, including Slack, Webhooks, PagerDuty, and more.</p> <p>Before Percona Alerting can send out email notifications via email contact points, you will need to:</p> <ol> <li>Configure Email (SMTP) server settings.</li> <li>Configure a contact point to define the email delivery options</li> </ol> <p>Contact points with invalid settings show a No Attempts status under  Alerting &gt; Contact points.</p>"},{"location":"get-started/alerting.html#configure-email-smtp-server-settings","title":"Configure Email (SMTP) server settings","text":"<p>To use SMTP with a PMM Docker installation:</p> <ol> <li> <p>Create an <code>.env</code> file and populate it with your SMTP credentials (and other environment variables) as follows:     <pre><code>GF_SMTP_ENABLED=true  \nGF_SMTP_HOST=smtp.gmail.com:587\nGF_SMTP_USER=email@domain.com\nGF_SMTP_PASSWORD=&lt;YOUR_SMTP_PASSWORD&gt;\nGF_SMTP_SKIP_VERIFY=false\nGF_SMTP_FROM_ADDRESS=email@domain.com\nGF_SMTP_FROM_NAME=Percona Alerting\n</code></pre>     Below is a summary of each environment variable above:</p> <ul> <li><code>GF_SMTP_ENABLED</code>: When true, enables Grafana to send emails.</li> <li><code>GF_SMTP_HOST</code>: Host address of your SMTP server.</li> <li><code>GF_SMTP_USER</code>: Username for SMTP authentication.</li> <li><code>GF_SMTP_PASSWORD</code>: Password for SMTP authentication</li> <li><code>GF_SMTP_SKIP_VERIFY</code>: When true, verifies SSL for the SMTP server.</li> <li><code>GF_SMTP_FROM_ADDRESS</code>: Email address to be used when sending out emails.</li> <li><code>GF_SMTP_FROM_NAME</code>: Name to be used when sending out emails.</li> </ul> <p>NB: If you are using your Gmail\u2019s SMTP credentials as shown above, you will have to generate an app password and fill it in as the value of your $GF_SMTP_PASSWORD variable.</p> </li> <li> <p>Pass in the <code>.env</code> file to Docker run using the <code>--env-file</code> flag:     <pre><code>docker run --env-file=.env -p 443:443 -p 80:80 percona/pmm-server:2\n</code></pre>     This command starts a docker container and will keep running as long as the container is also running. Stopping the command (e.g with Ctrl+C) will stop the container hence, subsequent commands should be run in a new terminal.</p> </li> </ol>"},{"location":"get-started/alerting.html#restore-smtp-settings-following-an-upgrade","title":"Restore SMTP settings following an upgrade","text":"<p>If you configured PMM to use SMTP settings via environment variables, you do not need to do anything after an upgrade as your settings will be transferred.</p>"},{"location":"get-started/alerting.html#configure-an-email-contact-point","title":"Configure an Email contact point","text":"<p>After configuring the SMTP settings, specify email delivery options for an Email contact point:</p> <ol> <li>Go to Alerting &gt; Contact points.</li> <li>Click the edit button next to the grafana-default-email to update PMM\u2019s default Email contact point, or click New contact point to create a custom one.</li> <li>Enter a contact point name, and add the email addresses for the recipients of the email notifications.</li> <li>Expand Optional settings and fill in any other relevant settings:<ul> <li>Enable the Single email option to send a single email to the recipients containing alerts that are firing. For example, if an alert fires for three nodes, this would send only one email listing all three alerts.</li> <li>Add an optional message to include with the email notifications.</li> <li>Edit the email subject for the notifications. The default subject line uses the following format FIRING: number of alerts firing for the alert rule.</li> </ul> </li> <li>If you do not want to be notified when an alert resolves, expand Notification settings, and tick the Disable Resolved Message checkbox.</li> <li>If you want your contact point to notify via multiple channels, for example, both via Email and Teams, click New contact point type and fill out additional contact point type details.</li> <li>Click the Test button to send a test email and make sure your contact point works as expected.     </li> <li>Click the Save contact point button at the bottom of the page. The contact point is now listed under Alerting &gt; Contact points.</li> </ol>"},{"location":"get-started/alerting.html#create-additional-contact-points","title":"Create additional contact points","text":"<p>In addition to Email contact points, you can add a variety of other contact points, including Slack, email, webhooks, PagerDuty, and more.</p> <p>Follow the steps above to create additional contact points. Different contact points require different configuration information. For example, for Slack, PMM requires the recipient information, the API token and the webhook URL, which you can get from your Slack administrator.</p>"},{"location":"get-started/alerting.html#notification-policies","title":"Notification policies","text":"<p>Notification policies determine how notifications (triggered by alerts) are routed to contact points by defining where, when, and how to send notifications.</p> <p>For example, you might specify a limit for the number of times a notification is sent during a certain period. This helps ensure that you don\u2019t spam your Slack channel with too many notifications about the same issue.</p>"},{"location":"get-started/alerting.html#root-notification-policy","title":"Root notification policy","text":"<p>Percona Alerting comes pre-configured with a Notification Root Policy, which is the default notification policy. It uses the grafana-default-email contact point and is applied to all alerts that don\u2019t have a custom notification policy assigned to them.</p>"},{"location":"get-started/alerting.html#how-matching-works","title":"How matching works","text":"<p>Policies can have one or more child policies. An alert matches if the alert\u2019s labels match all the Matching Labels specified on the policy.</p> <p>Alerts that don\u2019t match any specific policies are handled by the root policy. The root policy also handles any alert rules for which the assigned custom notification policy has been deleted, to ensure notifications for existing alerts continue to be delivered.</p>"},{"location":"get-started/alerting.html#edit-the-root-notification-policy","title":"Edit the root notification policy","text":"<ol> <li>Go to  Alerting &gt; Notification policies tab.</li> <li>Click Edit on the top right of the root policy box.</li> <li>Choose whether to keep the default Email contact point, select a new available contact point or create a new one.</li> <li>In the Group by field, specify how alert rules should be processed into notifications. If multiple alerts are matched for this policy, they will be grouped based on the labels you specify, and a notification will be sent per group.</li> <li>Expand the Timing options section and specify how notification wait times should be processed. These are short pauses the system can take to efficiently process multiple sets of alerts for notifications:</li> <li>Group wait: The default is to wait 30 seconds to buffer alerts of the same group before sending a notification initially.</li> <li>Group interval: The default is to wait five minutes before sending a batch of new alerts after the first notification was sent.</li> <li>Repeat interval: The default is to wait four hours before resending an alert.</li> <li>Click Save to save your changes.</li> </ol>"},{"location":"get-started/alerting.html#create-a-new-notification-policy","title":"Create a new notification policy","text":"<p>To create a new notification policy:</p> <ol> <li> <p>Go to  Alerting &gt; Notification policies tab. </p> </li> <li> <p>Click New specific policy.</p> </li> <li>The Matching labels section defines the rules for matching alert labels. The matching label is a combination of label name, operator and label value, where the label name is any valid label in your environment. For example:  <code>node_name</code>, <code>cluster</code>, etc. A policy will match an alert if the alert\u2019s labels match all the matching labels specified on the policy. If there are no matchers, the policy will handle all the alert instances. For example, you could add a node_name=pmm-server matcher to send out notifications only for this node.</li> <li>Select an existing contact point for the policy.</li> <li>Enable Continue matching subsequent sibling nodes to continue matching subsequent siblings of the policy after an alert matched the parent policy. This can be useful, for example, when you want to send notifications to a catch-all contact point as well as to one of more specific contact points handled by subsequent policies.</li> <li>Toggle Override grouping if you do not want to use root policy grouping.</li> <li>Toggle Override general timings to specify how often you want to wait until the initial notification is sent for a new group. When this is disabled, PMM uses root policy group timings instead.</li> <li>Add a mute timing if you want to mute notifications or this policy for a specific, regular interval. For example, you can create a mute to suppress trivial notifications during weekends.  Mute timings are different from silences in the sense that they are recurring, while silences have a fixed start and end time.</li> </ol> <p>Important</p> <p>Time specified in mute timing must be in UTC and military format i.e. 14:00 not 2:00 PM.</p>"},{"location":"get-started/alerting.html#silence-alerts","title":"Silence alerts","text":"<p>Create a silence when you want to suppress/stop alerts and their associated notifications for a very specific amount of time. Silences default to today\u2019s current date and have a default duration of two hours.</p> <p>You can also schedule a silence for a future date and time. This is referred to as a <code>Pending</code> silence, which can be observed on the Silences page.</p> <p>During a silence, PMM continues to track metrics but does not trigger alerts or send notifications to any specified contact points. Once the silence expires alerts and notifications will resume.</p> <p>Silenced alerts are still recorded under Alerting &gt; Fired Alerts so that you can review them later. Silenced alerts show up as Surpressed and are disabled for as long as it\u2019s specified in the Silence Duration, or until you remove a silence.</p>"},{"location":"get-started/alerting.html#using-silences","title":"Using silences","text":"<p>You can silence an alert from the Fired alerts page or from the Alert rules page by expanding the Alert Rule and clicking the Silence button.</p> <p></p> <p>You can also create a silence from the Silences page, but here you would also need to define labels that match the alert that you want to silence.</p> <p>To create a new silence from the Silences page:</p> <ol> <li>Click the New Silence button.</li> <li>Select the start and end date to indicate when the silence should go into effect and expire.</li> <li>Optionally, update the duration to alter the time for the end of silence in the previous step to correspond to the start plus the duration.</li> <li>Enter one or more matching labels by filling out the Name and Value fields. Matchers determine which rules the silence will apply to. Note that all labels specified here must be matched by an alert for it to be silenced.</li> <li>Enter any additional comments you would like about this silence - by default, the date the silence was created is placed here.</li> <li>Review the affected alert instances that will be silenced.</li> <li>Click Submit to create the silence.</li> </ol> <p>For more information on working with silences, see About alerting silences in the Grafana documentation.</p>"},{"location":"get-started/alerting.html#alerting-compatibility","title":"Alerting compatibility","text":""},{"location":"get-started/alerting.html#template-compatibility-with-previous-pmm-versions","title":"Template compatibility with previous PMM versions","text":"<p>If you have used Integrated Alerting in previous PMM versions, your custom alert rule templates will be automatically migrated to PMM 2.31. After upgrading to this new version, you will find all your alert templates under Alerting &gt; Alert Templates.</p> <p>If you have any templates available in the  <code>/srv/ia/templates</code> folder, make sure to transfer them to <code>/srv/alerting/templates</code> as PMM 2.31 and later will look for custom templates in this location.</p> <p>If you are upgrading from PMM 2.25 and earlier, alert templates will not be automatically migrated. This is because PMM 2.26.0 introduced significant changes to the core structure of rule templates.</p> <p>In this scenario, you will need to manually recreate any custom rule templates that you want to transfer to PMM 2.26.0 or later.</p>"},{"location":"get-started/alerting.html#template-compatibility-with-other-alerting-tools","title":"Template compatibility with other alerting tools","text":"<p>If you have existing YAML alert templates that you want to leverage in Percona Alerting:</p> <ol> <li>Go to Alerting &gt; Alert Rule Templates tab and click Add at the top right-hand side of the table.</li> <li>Click Add and upload a local .yaml file that contains the definition of one or more alert templates. Alert templates added in bulk will be displayed individually on Alert rule templates page.</li> </ol>"},{"location":"get-started/alerting.html#migrate-alert-rules","title":"Migrate alert rules","text":"<p>Alert rules created with Integrated Alerting in PMM 2.30 and earlier are not automatically migrated to Percona Alerting.</p> <p>After upgrading to PMM 2.31, make sure to manually migrate any alert rules that you want to transfer to PMM 2.31 using the Integrated Alerting Migration Script.</p>"},{"location":"get-started/alerting.html#script-commands","title":"Script commands","text":"<p>The default command for migrating rules is: <pre><code>python3 ia_migration.py -u admin -p admin\n</code></pre> To see all the available options, check the scrip help using <code>ia_migration.py -h</code></p>"},{"location":"get-started/alerting.html#script-prerequisites","title":"Script prerequisites","text":"<ul> <li>Python version 3.x, which you can download from Python Downloads centre.</li> <li>Requests library, which you can install with the following command: <code>pip3 install requests</code>.</li> </ul> <p>Important</p> <p>The script sets all migrated alert rules to Active. Make sure to silence any alerts that should not be firing.</p> <p>For more information about the script and advanced migration options, check out the help information embedded in the script.</p>"},{"location":"get-started/alerting.html#disable-percona-alerting","title":"Disable Percona Alerting","text":"<p>If for some reason you want to disable PMM Alert templates and keep only Grafana-managed alerts:</p> <ol> <li>Go to Configuration &gt; PMM Settings.</li> <li>Disable the Alerting option. The Alerting page will now display only Grafana-managed alert rules.</li> </ol>"},{"location":"get-started/interface.html","title":"User Interface","text":"<p>How to log in, how the user interface is laid out, and what the controls do.</p> <p>PMM\u2019s user interface is a browser application based on Grafana.</p>"},{"location":"get-started/interface.html#logging-in","title":"Logging in","text":"<ol> <li> <p>Start a web browser and in the address bar enter the server name or IP address of the PMM server host.</p> </li> <li> <p>The page loads showing the PMM login screen.</p> </li> </ol> <p></p> <ol> <li> <p>Enter the username and password given to you by your system administrator. The defaults are:</p> </li> <li> <p>Username: <code>admin</code></p> </li> <li> <p>Password: <code>admin</code></p> </li> <li> <p>Click Log in.</p> </li> <li> <p>If this is your first time logging in, you\u2019ll be asked to set a new password. (We recommend you do.)</p> </li> <li> <p>Either enter a new password in both fields and click Submit, OR</p> </li> <li> <p>click Skip to use the default password.</p> </li> <li> <p>The PMM Home dashboard loads.</p> </li> </ol> <p></p>"},{"location":"get-started/interface.html#dashboards","title":"Dashboards","text":"<p>The interface is a collection of web pages called dashboards.</p> <p>Dashboards are grouped into folders. You can customize these, by renaming them or creating new ones.</p> <p>The area inside dashboards is populated by panels. Some are in collapsible panel groups. A panel can show a value, a graph, a chart, or a visual representation of a set.</p>"},{"location":"get-started/interface.html#controls","title":"Controls","text":"<p>These menus and controls appear on all dashboards:</p> <ol> <li> <p>Main menu (also Grafana menu, side menu).</p> </li> <li> <p>Navigation bar.</p> </li> <li> <p>View controls.</p> </li> <li> <p>View selectors (with dynamic contents).</p> </li> <li> <p>Shortcut menu (with dynamic contents).</p> </li> </ol> <p>(For details see UI Components.)</p> <p></p>"},{"location":"get-started/interface.html#navigation","title":"Navigation","text":""},{"location":"get-started/interface.html#search-for-a-dashboard-by-name","title":"Search for a dashboard by name","text":"<p>There are two ways to open the dashboard search page. (Each takes you to the same search screen.)</p> <ul> <li> <p>Click the  icon in the main menu.</p> </li> <li> <p>Click the dashboard name in the navigation bar (top row, to the right of the  icon). (To search within the current folder, click the folder name instead of the dashboard name.)</p> </li> </ul> <p></p> <ol> <li>Click Search dashboards by name and begin typing any part of the dashboard name (in this example, Instances).</li> </ol> <p></p> <ol> <li> <p>Click one of the search results to go to that dashboard. Change the search text to refine the list.</p> </li> <li> <p>To abandon the search, click the  icon at the end of the search bar.</p> </li> </ol>"},{"location":"get-started/interface.html#open-a-dashboard-with-the-menu","title":"Open a dashboard with the menu","text":"<p>In the main menu, the  PMM Dashboards icon reveals a submenu containing links to all PMM dashboards grouped by service type. (This menu will replace the shortcut menu which has links to commonly-used dashboards.)</p>"},{"location":"get-started/interface.html#panels","title":"Panels","text":"<p>Charts, graphs and set-based panels reveal extra information when the mouse is moved over them.</p> <p>Some panels have an information icon  in the top left corner. Mouse over this to reveal panel information.</p>"},{"location":"get-started/interface.html#panel-menu","title":"Panel menu","text":"<p>At the top of each panel and to the right of the panel name is the panel menu.</p> <p></p> <p>Tip</p> <p>The menu is hidden until you mouse over it. Look for the  symbol in the title bar of a panel.</p> Item Description  View Open the panel in full window mode.  Share Share the panel\u2019s link or image.  Explore Run PromQL queries.  Inspect See the panel\u2019s data or definition.  More (Only charts and graphs) Additional options."},{"location":"get-started/interface.html#view","title":"View","text":"<p>The View menu items opens panels in full-window mode. This is useful for graphs with several metrics.</p> <p>Exit a panel\u2019s full window mode by pressing Escape or clicking the left arrow  next to the dashboard name.</p> <p>See also</p> <ul> <li>How to render dashboard images</li> <li>How to annotate special events</li> </ul>"},{"location":"get-started/interface.html#timezones","title":"Timezones","text":"<p>By default, Grafana uses the timezone from your web browser. However, you can change this setting.</p>"},{"location":"get-started/interface.html#set-user-timezone","title":"Set user timezone","text":"<ol> <li>On the left menu, hover over the  Configuration, then click Preferences.</li> <li>On the Preferences tab, click on Timezone and select an option from the drop-down menu.</li> <li>Click Save.</li> </ol>"},{"location":"get-started/query-analytics.html","title":"Query Analytics","text":"<p>The Query Analytics dashboard shows how queries are executed and where they spend their time.  It helps you analyze database queries over time, optimize database performance, and find and remedy the source of problems.</p> <p></p> <p>Query Analytics supports MySQL, MongoDB and PostgreSQL. The minimum requirements for MySQL are:</p> <ul> <li>MySQL 5.1 or later (if using the slow query log).</li> <li>MySQL 5.6.9 or later (if using Performance Schema).</li> </ul> <p>Query Analytics displays metrics in both visual and numeric form. Performance-related characteristics appear as plotted graphics with summaries.</p> <p>The dashboard contains three panels:</p> <ul> <li>the Filters Panel;</li> <li>the Overview Panel;</li> <li>the Details Panel.</li> </ul> <p>Query Analytics data retrieval may experience delays due to network conditions. As a result, a small amount of data (up to 1 hour) will be buffered in the memory and reported when the connection is restored.</p>"},{"location":"get-started/query-analytics.html#filters-panel","title":"Filters Panel","text":"<ul> <li>The Filter panel on the left-hand side of the dashboard lists the filters grouped by category. It also shows the percentage of the main metrics (explained below). If you select a different metric, the percentages on the left panel will change as per this metric. When you select a metric, it reduces the overview list as per the matching filter.</li> <li>The first five of each category are shown. If there are more, the list is expanded by clicking Show all beside the category name, and collapsed again with Show top 5.</li> <li>Applying a filter may make other filters inapplicable. These become grayed out and inactive.</li> <li>Click the chart symbol  to navigate directly to an item\u2019s associated dashboard.</li> <li>Separately, the global Time range setting filters results by time, either your choice of Absolute time range, or one of the predefined Relative time ranges.</li> </ul>"},{"location":"get-started/query-analytics.html#custom-filter-groups","title":"Custom filter groups","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Starting with PMM 2.38.0, you can filter queries by custom filter groups based on key=value pairs separated from query comments. By default, this feature is disabled.</p>"},{"location":"get-started/query-analytics.html#supported-technologies-and-agents","title":"Supported technologies and agents","text":"<ul> <li>MySQL (<code>perfschema</code>, <code>slowlog</code>),</li> <li>PostgreSQL (<code>pg_stat_statements</code>, <code>pg_stat_monitor</code>)</li> </ul> <p>Example</p> <p></p> <p>In the image above we have tagged queries running databases on Windows using the following comment: </p> <p><pre><code>comment: /* OperationSystem='windows' */. \n</code></pre> Queries from the database running on Linux are tagged with:</p> <pre><code>/* OperationSystem='linux' */. \n</code></pre> <p>All types of comments and multicomments are supported <code>(/* */, --, # etc)</code>. </p> <p>So the queries are as follows:</p> <pre><code>SELECT * /* OperationSystem='windows' */ FROM city;\nSELECT city /* OperationSystem='linux' */ FROM world;\n</code></pre> <p>In the output, you can see another custom group in the <code>OperationSystem</code> filter. Use this to easily filter by any custom key or value.</p>"},{"location":"get-started/query-analytics.html#enabling-custom-filter-groups","title":"Enabling custom filter groups","text":"<ul> <li> <p>CLI: While adding a service through CLI use the flag <code>comments-parsing</code>. Possible values are <code>on/off</code>. </p> <p>Example for adding MySQL with comments parsing on:</p> <pre><code>pmm-admin add mysql --username=root --password=root-password --comments-parsing=\"on\"\n</code></pre> </li> <li> <p>UI: While adding a service through the UI you will see new checkbox to <code>enable/disable</code> comments parsing for current service.</p> <p></p> </li> </ul> <p>MySQL CLI</p> <ul> <li>If you are using official MySQL CLI to trigger queries, start mysql with <code>--comments</code> flag. Otherwise comments will not be parsed.</li> <li>In case of PGSM (<code>pg_stat_monitor</code>), set the DB variable <code>pgsm_extract_comments=yes</code></li> </ul>"},{"location":"get-started/query-analytics.html#overview-panel","title":"Overview Panel","text":"<p>The Overview panel is located above the dashboard, on the right side of the Filters panel.</p> <p></p> <p>Each row of the table represents the metrics for a chosen object type, one of:</p> <ul> <li>Query;</li> <li>Service Name;</li> <li>Database;</li> <li>Schema;</li> <li>User Name;</li> <li>Client Host.</li> </ul> <p>At the top of the second column is the dimension menu. Use this to choose the object type.</p> <p></p> <p>On the right side of the dimension column is the Dimension Search bar.</p> <p></p> <p>Enter a string and press Enter to limit the view to queries containing only the specified keywords.</p> <p>Delete the search text and press Enter to see the full list again.</p>"},{"location":"get-started/query-analytics.html#columns","title":"Columns","text":"<ul> <li>The first column is the object\u2019s identifier. For Query, it is the query\u2019s Fingerprint.</li> <li>The second column is the Main metric, containing a reduced graphical representation of the metric over time, called a sparkline, and a horizontal meter, filled to reflect a percentage of the total value.</li> <li>Additional values are revealed as mouse-over tooltips.</li> </ul>"},{"location":"get-started/query-analytics.html#tool-tips","title":"Tool-tips","text":"<ul> <li>For the Query dimension, hovering over the information icon  reveals the query ID and its example.</li> <li>Hovering on a column header reveals an informative tooltip for that column.</li> <li>Hovering on the main metric sparkline highlights the data point and a tooltip shows the data value under the cursor.</li> </ul> <ul> <li> <p>Hovering on the main metric meter reveals the percentage of the total, and other details specific to the main metric.</p> <p></p> </li> <li> <p>Hovering on column values reveals more details on the value. The contents depends on the type of value.</p> <p></p> </li> </ul>"},{"location":"get-started/query-analytics.html#adding-and-removing-columns","title":"Adding and removing columns","text":"<ul> <li> <p>Metrics columns are added with the Add column button.</p> <p></p> </li> <li> <p>When clicked, a text field and a list of available metrics are revealed. Select a metric or enter a search string to reduce the list. Selecting a metric adds it to the panel.</p> </li> <li>A metric column is removed by clicking on the column heading and selecting Remove column.</li> <li>The value plotted in the main metric column can be changed by clicking a metric column heading and selecting Swap with main metric.</li> </ul>"},{"location":"get-started/query-analytics.html#sorting","title":"Sorting","text":"<ul> <li>The entire list is sorted by one of the columns.</li> <li>Click either the up or down caret to sort the list by that column\u2019s ascending or descending values.</li> </ul>"},{"location":"get-started/query-analytics.html#pagination","title":"Pagination","text":"<ul> <li> <p>The pagination device lets you move forward or backward through pages, jump to a specific page, and choose how many items are listed per page.</p> <p></p> </li> <li> <p>Queries are grouped into pages of 25, 50 or 100 items.</p> </li> </ul>"},{"location":"get-started/query-analytics.html#details-panel","title":"Details Panel","text":"<ul> <li>Selecting an item in the Overview panel opens the Details panel with a Details Tab.</li> <li>If the dimension is Query, the panel also contains the Examples Tab, Explain Tab, and Tables Tab.</li> </ul>"},{"location":"get-started/query-analytics.html#details-tab","title":"Details Tab","text":"<p>The Details tab contains a Query time distribution bar (only for MySQL databases) and a set of Metrics in collapsible subpanels.</p> <p></p> <ul> <li> <p>The Query time distribution bar shows a query\u2019s total time made up of colored segments, each segment representing the proportion of time spent on a named activity.</p> <ul> <li><code>query_time</code>: Statement execution time.</li> <li><code>lock_time</code>: Time to acquire locks.</li> <li><code>blk_read_time</code>: Total time the statement spent reading blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>blk_write_time</code>: Total time the statement spent writing blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>innodb_io_r_wait</code>: Time for InnoDB to read the data from storage.</li> <li><code>innodb_queue_wait</code>: Time the query spent either waiting to enter the InnoDB queue, or in it pending execution.</li> <li><code>innodb_rec_lock_wait</code>: Time the query waited for row locks.</li> <li><code>other</code>: Remaining uncategorized query time.</li> </ul> </li> <li> <p>Metrics is a table with headings:</p> <ul> <li>Metric: The Metric name, with a question-mark tool-tip that reveals a description of the metric on mouse-over;</li> <li>Rate/Second: A sparkline chart of real-time values per unit time;</li> <li>Sum: A summation of the metric for the selected query, and the percentage of the total;</li> <li>Per Query Stats: The value of the metric per query.</li> </ul> </li> <li> <p>Each row in the table is a metric. The contents depend on the chosen dimension.</p> </li> <li> <p>Metadata table:</p> <p>PMM 2.39.0 now includes a metadata table for QAN to address the issue of identifying problematic queries. This feature allows you to easily identify the services, nodes, and labels associated with your identified queries.</p> <p>The Metadata table shows the following information:</p> <ul> <li>Database: The database being monitored.</li> <li>Environment: Environment being used such as Dev, Staging, Production, etc.</li> <li>Node Name: Name or identifier of a node.</li> <li>Node type: Type of the node.</li> <li>User name: Username of the database being monitored.</li> <li>Service Name: The name or identifier of the service.</li> <li>Service type: The type of service being monitored. For example, MySQL, PostgreSQL, etc.</li> </ul> <p></p> </li> </ul> <p>For PostgreSQL queries (when using <code>pg_stat_monitor</code>) the top query will also be shown in the details section if the query was called by an outer query.</p> <p></p> <p>Other useful metrics (when using pg_stat_monitor) to monitor PostgreSQL Server performance are Histograms.  Histograms provide more explicit information about number of queries for fingerprint (<code>queryid</code>). Ranges are from 0 seconds up to 100 seconds.  </p> <p>Here is a picture of histogram in graph: </p>"},{"location":"get-started/query-analytics.html#examples-tab","title":"Examples Tab","text":"<p>(For Query dimension.)</p> <p>The Examples tab shows an example of the selected query\u2019s fingerprint or table element.</p> <p></p> <p>Query example and fingerprint can be truncated to 1024 long to reduce space usage. In this case, the query explains section will not work.</p>"},{"location":"get-started/query-analytics.html#explain-tab","title":"Explain Tab","text":"<p>(For Query dimension.)</p> <p>The Explain tab shows the <code>explain</code> output for the selected query, in Classic or JSON formats.</p> <ul> <li>MySQL: Classic and JSON.</li> <li>MongoDB: JSON only.</li> <li>PostgreSQL: Supported by pg_stat_monitor (PGSM), not by pg_stat_statements (PGSS).</li> </ul> <p>Starting with PMM 2.33.0, for MySQL, the Explain tab is supported without the Examples enabled. If a query in the Explain tab contains sensitive data, placeholders will replace them. Before you can run Explain, you must specify the values for these placeholders. This image illustrates the query with placeholders.</p> <p></p> <p>Below is an illustration of the same query using values instead of placeholders.</p> <p></p> <p>The image shown above illustrates a query with two placeholders. Therefore, you must enter the correct values in both fields. After filling in these values, click Explain to get the results like in the previous PMM versions without data leaks. You will get results like in previous PMM versions. This method of <code>explain</code> prevents data leaks.</p> <p>\u2018Explain\u2019 for MongoDB</p> <p>To run the <code>EXPLAIN</code> command, you need the same permissions as for executing the original query. For example, if you want to run <code>EXPLAIN</code> on an <code>UPDATE</code> query, you need to have <code>update</code> permissions</p> <p>Example: Grant the <code>explainRole</code> with update permissions.</p> <pre><code>db.grantPrivilegesToRole( \"explainRole\", [ { resource: { db: \"\", collection: \"\" }, actions: [ \"update\" ] } ])\n</code></pre> <p></p>"},{"location":"get-started/query-analytics.html#tables-tab","title":"Tables Tab","text":"<p>(For Query dimension.)</p> <p>The Tables tab shows information on the tables and indexes involved in the selected query.</p> <p></p>"},{"location":"get-started/query-analytics.html#plan-tab","title":"Plan Tab","text":"<p>(For Query dimension.)</p> <p>The Plan tab shows the plan for PostgreSQL queries (only available when using pg_stat_monitor).</p> <p></p>"},{"location":"get-started/query-analytics.html#query-analytics-qan-for-postgresql","title":"Query Analytics (QAN) for PostgreSQL","text":"<p>QAN offers support for two types of query sources: <code>pg_stat_monitor</code> (PGSM) and <code>pg_stat_statements</code> (PGSS). While PGSS used to be the default query source, recent PMM versions have transitioned to PGSM.  If PGSM is unavailable on your system, QAN will seamlessly fall back to PGSS and you will be notified of this in pmm-admin.</p> <p>PMM has integrated support for pg_stat_monitor 2.0 (PGSM 2.0) into QAN starting with version 2.36. This robust tool enhances PostgreSQL query performance monitoring by providing access to the latest improvements and fixes included in PGSM2, including:</p> <ul> <li>Improved internal architecture that results in fewer lock acquisitions and increases performance by approximately 20%.</li> <li>Support for PostgreSQL 15 </li> <li>Enhanced consistency with <code>pg_stat_statements</code> so that the <code>pg_stat_monitor</code> view has identical column names, columns, and data types as <code>pg_stat_statements</code> for every major version of PostgreSQL from versions 11 to 15.</li> <li>A bucket status indication (done vs. current) eliminates the need for the tool to evaluate bucket status and facilitates accurate data display.</li> <li>The generation of a unique ID for a query makes it easier to monitor query planning, execution, and performance regardless of version, database, user, or schema.</li> <li>Backward compatibility with your historical data (data collected by older PMM and PGSM)</li> <li>More detailed histogram ranges</li> <li>Security improvements</li> <li>Support for all previous PGSM versions</li> </ul>"},{"location":"get-started/query-analytics.html#postresql-9x","title":"PostreSQL 9.x","text":"<p>PMM 2.43.0 upgraded the \u2018pg_query_go\u2019 package to version 5. This version helps parse PostgreSQL queries in QAN, provides improved functionality, and enables subsequent upgrades of important dependencies.</p> <p>However, this new version does not support listing PostgreSQL database tables for versions 9.4, 9.5, and 9.6 in QAN. Since all PostgreSQL 9.x versions have already reached their end-of-life status, we recommend upgrading to a supported version of PostgreSQL.</p> <p>If you\u2019re looking to upgrade, you can easily install the latest version of Percona Distribution for PostgreSQL. </p>"},{"location":"get-started/query-analytics.html#postresql-15","title":"PostreSQL 15","text":"<p>You will probably need to grant more permissions to the user in PostgreSQL 15. An error message will appear in the <code>pmm-agent</code> log if more permissions are required. This behavior pertains to PostgreSQL and not PMM.</p> <p>You can use this query:     <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD 'USERNAME';\n</code></pre>     where <code>USERNAME</code> should be replaced by the user.</p>"},{"location":"get-started/query-analytics.html#query-analytics-for-mongodb","title":"Query Analytics for MongoDB","text":"<p>MongoDB is conceptually different from relational database management systems, such as MySQL and MariaDB.</p> <p>Relational database management systems store data in tables that represent single entities. Complex objects are represented by linking tables.</p> <p>In contrast, MongoDB uses the concept of a document where all essential information for a complex object is stored in one place.</p> <p>Query Analytics can monitor MongoDB queries. Although MongoDB is not a relational database management system, you analyze its databases and collections in the same interface using the same tools.</p>"},{"location":"get-started/query-analytics.html#sharing-a-link-for-query-analytics","title":"Sharing a link for Query Analytics","text":"<p>To share a link for Query Analytics, use Copy Link. It copies the link to the clipboard with all the relevant information such as selected query, table page, selected filters, details tab, and time range. Thus, when you open the link, it will display the exact information.</p> <p>Ensure that you use Copy Link to copy the link instead of using the browser address bar or the standard Grafana functionality (to share a dashboard). Otherwise, Query Analytics might not display the exact information that existed while sharing the link.   By default, Grafana uses a relative time range and not an absolute range, so it will have a different timestamp when this link is opened.</p> <p></p>"},{"location":"get-started/query-analytics.html#qan-under-the-hood","title":"QAN under the hood","text":"<p>To understand how metrics are calculated and to learn more details about QAN, see </p> <p>QAN under the hood.</p>"},{"location":"get-started/backup/index.html","title":"Back up and restore","text":"<p>Losing your data can destroy your business. This is why backing up data is critical for all database operations. Even more important than backing up data, is the ability to restore it in the event of data loss. PMM enables you to do all this with zero downtime and minimal performance impact.</p> <p>Currently, PMM provides Backup and Restore functionality to work with:</p> <ul> <li>MongoDB (Generally Available)</li> <li>MySQL (in Technical Preview)</li> </ul> <p>Enable the Backup Management option in PMM\u2019s Advanced Settings to activate the Backup page from where you can:</p> <ul> <li>Create and restore MongoDB and MySQL backups</li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"get-started/backup/index.html#supported-setups","title":"Supported setups","text":"<p>For MySQL databases, you can create and restore on-demand and scheduled physical backups.  For MongoDB, you can create and restore physical, logical and Point-in-Time-Recovery (PITR) backups, both on-demand and scheduled.</p>"},{"location":"get-started/backup/index.html#sharded-mongodb-cluster-configurations","title":"Sharded MongoDB cluster configurations","text":"<p>PMM 2.38 added support for creating backups of sharded MongoDB clusters. However, the restoring process is not handled end-to-end, and requires you to manually restore the artifacts using the CLI in Percona Backup for MongoDB.</p> <p>For information on restoring sharded backups, check the PBM documentation</p>"},{"location":"get-started/backup/index.html#start-here","title":"Start here","text":"<p>To learn how to create and restore backups, check out subtopics below:</p> <ul> <li>Prepare a storage location</li> <li>MongoDB  backups</li> <li>MySQL backups </li> </ul>"},{"location":"get-started/backup/index.html#additional-resources","title":"Additional resources","text":"<p>Here are some external resources for learning more about databases backups:</p> <ul> <li>Amazon Web Services S3</li> <li>Percona Backup for MongoDB</li> <li>PERCONA_QPRESS</li> <li>PERCONA_XBCLOUD</li> <li>PERCONA_XBSTREAM</li> <li>PERCONA_XTRABACKUP</li> <li>oplog slices</li> <li>Percona Server for MongoDB</li> <li>MongoDB Replication</li> </ul>"},{"location":"get-started/backup/backup_mongo.html","title":"Supported setups for MongoDB backups","text":"<p>PMM supports the following actions for MongoDB backups. </p>"},{"location":"get-started/backup/backup_mongo.html#replica-set-setups","title":"Replica set setups","text":"<ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating and restoring Logical snapshot backups</li> <li>Creating and restoring Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage. Restoring logical PITR backups from S3-compatible object storage.</li> </ul>"},{"location":"get-started/backup/backup_mongo.html#sharded-clusters","title":"Sharded clusters","text":"<p>Backups of sharded clusters is supported starting with PMM 2.38. However, restoring for sharded cluster configurations is only supported from the CLI, and is handled via Percona Backup for MongoDB.</p> <ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating Logical snapshot backups</li> <li>Creating Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage</li> </ul> <p>For a detailed overview of the supported setups for MongoDB, check out the Support matrix.</p>"},{"location":"get-started/backup/backup_mysql.html","title":"Supported setups for MySQL backups","text":"<p>Important</p> <p>MySQL backup functionality is still in Technical Preview.</p> <p>PMM supports MySQL database server for:</p> <ul> <li>Creating and restoring physical backups</li> <li>Storing backups to Amazon S3-compatible object storage  </li> </ul>"},{"location":"get-started/backup/backup_mysql.html#backing-up-mysql-databases-hosted-in-docker-container","title":"Backing up MySQL databases hosted in Docker container","text":"<p>To ensure PMM can correctly backup and restore databases from a MySQL Docker container, make sure that the container is compatible with systemd.</p>"},{"location":"get-started/backup/create_PITR_mongo.html","title":"Create MongoDB PITR backups","text":"<p>Point-in-Time Recovery (PITR) restores databases up to a specific moment in time. PITR includes restoring the data from a backup snapshot and replaying all events that occurred to this data up to a specified moment from oplog slices.</p> <p>Point-in-Time Recovery helps you prevent data loss during a disaster such as crashed database, accidental data deletion or drop of tables, or unwanted update of multiple fields instead of a single one.</p>"},{"location":"get-started/backup/create_PITR_mongo.html#compatibility-with-percona-backup-for-mongodb","title":"Compatibility with Percona Backup for MongoDB","text":"<p>PMM introduced the option to create PITR Backups for MongoDB in version 2.23, as part of the larger Backup Management feature. This implementation in PMM uses Percona Backup for MongoDB (pbm) behind the scenes.</p> <p>Percona Backup for MongoDB is a distributed, low-impact solution for achieving consistent backups of MongoDB sharded clusters and replica sets. Starting with PMM 2.32, restoring PITR backups is available for backups based on pbm \u2264 2.0.1. To restore PITR backups, make sure you have pbm \u2265 2.0.1 installed.</p> <p>Percona Backup for MongoDB supports Percona Server for MongoDB and MongoDB Community \u2264 3.6, with MongoDB Replication enabled. For more information, see the Percona Backup for MongoDB documentation.</p>"},{"location":"get-started/backup/create_PITR_mongo.html#how-does-it-work","title":"How does it work?","text":"<p>When point-in-time recovery (PITR) is enabled, pbm-agent periodically saves consecutive slices of the oplog.</p> <p>To start saving oplog, PBM requires a backup snapshot. Such snapshots are created when you activate a PITR-scheduled task in PMM.</p> <p>Since PBM saves oplog slices and streams them into your storage between scheduled task runs, scheduling frequent PITR backups is not necessary. You can use the available oplog slices in your storage to restore a backup to any moment between snapshots.</p> <p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Select the Schedule Backup option in the Create Scheduled backup window.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select Logical as this is the only data model that currently supports PITR backups.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage.     However, restoring from local storage is not supported yet.     If no options are available here, see the Create a storage location topic.</li> <li>Specify the backup type and the schedule for your backup:<ul> <li>Backup Type: select the  PITR option.</li> <li>Schedule: configure the frequency and the start time for this backup.  </li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is not available for PITR backups. Currently, retention policies can only be specified for Snapshot backups stored on Amazon S3-compatible storage.</li> </ul> </li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual).      Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li> <p>In the Folder field, check the target directory available for the specified service and location. By default, this field comes prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre></p> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> </li> <li> <p>Click Schedule to start creating the backup artifact.</p> </li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol> <p></p>"},{"location":"get-started/backup/create_PITR_mongo.html#failed-backup-alerts","title":"Failed backup alerts","text":"<p>If you want to be notified of any MongoDB backups that fail, you can create an alert based on the Backup Failed alert template. For information on working with alert templates, see the Percona Alerting topic.</p>"},{"location":"get-started/backup/create_PITR_mongo.html#pitr-artifacts","title":"PITR artifacts","text":"<p>The PITR oplog is available a few minutes (10 by default) after your PITR job has run for the first time. To see the corresponding PITR artifact, check out the list under Backup &gt; All Backups.</p> <p></p>"},{"location":"get-started/backup/create_PITR_mongo.html#pitr-and-other-scheduled-backups","title":"PITR and other scheduled backups","text":"<p>Make sure to disable any other scheduled backup jobs before creating a PITR backup. PMM displays an error message if you try to enable PITR while other scheduled backup jobs are active:</p> <p></p> <p>This constraint applies at the service level. You can still have PITR enabled for one service while having regular scheduled backup jobs for other services.</p>"},{"location":"get-started/backup/create_mongo_on_demand.html","title":"Create MongoDB on-demand and scheduled backups","text":"<p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <p>To schedule or create an on-demand backup, check the instructions below. If you want to create a Point-in-time-recovery (PITR) backup instead, see Create MongoDB PITR backups.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>In the Create Scheduled backup window, select whether you want to create an On Demand or a Schedule Backup.</li> <li>Enter a unique name for the backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select whether you want to create a Physical or Logical backup of your data, depending on your use case and requirements.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage. If no options are available here, see the Create a storage location topic.</li> <li> <p>Specify the backup type, the schedule, and a retention policy for your backup:</p> <ul> <li>Backup Type: select Full. If you want to create a PITR backup instead, see the Create MongoDB PITR backups topic</li> <li>Schedule: if you\u2019re creating a scheduled backup, configure its frequency and start time.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for snapshot backups stored on S3-compatible storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries. </li> <li>In the Folder field, check the target directory available for the specified service and location. By default, this field is prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre></li> </ul> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> <ol> <li>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol> </li> </ol>"},{"location":"get-started/backup/create_mysql_backup.html","title":"Create a MySQL backup","text":"<p>To create a backup:</p> <ol> <li>Go to   Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Specify the type of backup that you want to create: On Demand or Schedule Backup.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field and selects the Physical data model, as this is the only model available for MySQL backups.</li> <li>Choose a storage location for the backup. MySQL currently only supports storing backups to Amazon S3. If no options are available here, see the Create a storage location topic section above.</li> <li>If you\u2019re creating scheduled backups, also specify the backup type, the schedule, and a retention policy for your backup:<ul> <li>Backup Type: currently, PMM only supports Full backup types for MySQL.</li> <li>Schedule: configure the frequency and the start time for this backup.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for Snapshot backups stored on S3-compatible object storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> </ul> </li> <li>Leave the Folder field as is. This field is relevant for MongoDB backups to ensure compatibility with PBM wokflows and comes prefilled with the cluster label.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol>"},{"location":"get-started/backup/delete_a_backup.html","title":"Delete a backup","text":"<p>You can only delete backup artifacts stored on Amazon S3-compatible. Local backups must be removed manually.</p> <p>To delete a backup:</p> <ol> <li>Go to   Backup &gt; All Backups and find the row with the backup you want to delete.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  Delete backup.</li> <li>In the Delete backup artifact dialog box, enable Delete from storage if you also want to delete the actual backup content besides just the backup register.</li> <li>Click Delete.</li> </ol>"},{"location":"get-started/backup/edit_scheduled.html","title":"Edit a scheduled backup","text":"<ol> <li>Go to Backup &gt; Scheduled Backup Jobs.</li> <li>In the Actions column:<ul> <li>Click the switch  to enable or disable the backup.</li> <li>Click  to edit, delete or create a copy (disabled by default) of the backup schedule.</li> </ul> </li> </ol>"},{"location":"get-started/backup/mongo-prerequisites.html","title":"MongoDB backup prerequisites","text":"<p>Before creating MongoDB backups, make sure to:</p> <ol> <li>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Management has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management then click Apply changes.</li> <li>Prepare and create a storage location for your backups.</li> <li>Check that PMM Client is installed and running on all MongoDB nodes in the cluster.</li> <li>Check that Percona Backup for MongoDB (PBM) is installed and <code>pbm-agent</code> is running on all MongoDB nodes in the replica set. Make sure to configure the MongoDB connection URI for pbm-agent on all nodes.</li> <li>Check that installed mongod binary is added to PATH variable of the user under which PMM client is running, and that mongod is controlled as a service by systemctl. PMM only works with a single mongod installed on a node.</li> <li> <p>Check that your MongoDB Services are managed as clusters in PMM. Go to PMM Inventory &gt; Services page, expand the Details section  on the Options column, and make sure that all the services in the table specify a cluster name. Services that do not specify a cluster name should be removed and re-added using commands like the following:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre> </p> </li> <li> <p>Check that MongoDB nodes are members of replica set.</p> </li> <li>Check that you set the required permissions for creating and restoring MongoDB backups.</li> <li>Verify the MongoDB supported configurations and limitations.</li> </ol> <p>Important</p> <p>Use <code>pbm</code> in manual mode only for restoring sharded cluster backups or other operations that can only be completed via the PBM CLI! Since PMM takes care of the PBM configuration, any unnecessary manual intervention can break the state.</p> <p>PMM 2.32 and later require PBM 2.0.1 or newer.</p>"},{"location":"get-started/backup/mongodb_limitations.html","title":"MongoDB Backup and Restore support matrix","text":"<p>Creating and restoring MongoDB backups in PMM currently has the following limitations and requirements:</p> <ul> <li>Physical backups and restores are supported only for Percona Server for MongoDB.</li> <li>Physical restores are not supported for deployments with arbiter nodes. For more information, see the Percona Backup for MongoDB documentation.</li> <li>Creating backups for sharded clusters was included in PMM 2.38 and is available straight from the UI. However, restoring these backup artifacts is only possible via the CLI, using Percona Backup for MongoDB. For information on restoring sharded backups, check the PBM documentation.</li> <li>Retention policy is supported only for snapshot types of scheduled backups and for the S3-compatible storage type.</li> <li>Before restoring, make sure to prevent clients from accessing the database.</li> </ul>"},{"location":"get-started/backup/mongodb_limitations.html#support-matrix","title":"Support matrix","text":""},{"location":"get-started/backup/mongodb_limitations.html#backup-logical","title":"Backup: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local Full Full S3 Full Full Local Full"},{"location":"get-started/backup/mongodb_limitations.html#backup-physical","title":"Backup: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Full Full Local Full"},{"location":"get-started/backup/mongodb_limitations.html#restore-logical","title":"Restore: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local No Full S3 Full Full Local Full"},{"location":"get-started/backup/mongodb_limitations.html#restore-physical","title":"Restore: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Partial* Full Local Partial* <p>* Partial support for non-containerized deployments and NO support for containerized deployments.</p>"},{"location":"get-started/backup/mysql_prerequisites.html","title":"MySQL backup prerequisites","text":"<p>Before creating MySQL backups, make sure to:</p> <ol> <li> <p>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Managemt has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management then click Apply changes.    !!! caution alert alert-warning \u201cImportant\u201d     If PMM Server runs as a Docker container, enable backup features at container creation time by adding <code>-e ENABLE_BACKUP_MANAGEMENT=1</code> to your <code>docker run</code> command.</p> </li> <li> <p>Check that the PMM Client is installed and running on the node where the backup will be performed.</p> </li> <li> <p>To enable Xtrabackup for MySQL 8.0+, check that pmm-agent connects to MySQL with a user that has BACKUP_ADMIN privilege.</p> </li> <li> <p>Check that there is only one MySQL instance running on the node.</p> </li> <li> <p>Verify that MySQL is running:</p> <ul> <li> <p>as a service via <code>systemd</code>;</p> </li> <li> <p>with the name <code>mysql</code> or <code>mysqld</code> (to confirm, use <code>systemctl status mysql</code> or <code>systemctl status mysqld</code> respectively);</p> </li> <li> <p>from a <code>mysql</code> system user account.</p> </li> </ul> </li> <li> <p>Make sure that there is a <code>mysql</code> system group.</p> </li> <li> <p>Check that MySQL is using the <code>/var/lib/mysql</code> directory for database storage.</p> </li> <li> <p>Make sure that <code>pmm-agent</code> has read/write permissions to the <code>/var/lib/mysql</code> directory.</p> </li> <li> <p>Check that the latest versions of the following packages are installed and included in the <code>$PATH</code> environment variable:</p> <ul> <li> <p><code>xtrabackup</code>, which includes:</p> <ul> <li> <p><code>xbcloud</code></p> </li> <li> <p><code>xbstream</code></p> </li> </ul> </li> <li> <p>[<code>qpress</code>][PERCONA_QPRESS].</p> </li> </ul> </li> </ol> <p>Important</p> <p>Make sure that the versions of xtrabackup, xbcloud, xbstream, and qpress are fully compatible with the currently installed version of MySQL on the system. </p>"},{"location":"get-started/backup/prepare_storage_location.html","title":"Prepare a storage location","text":"<p>Prepare a storage location as a backup destination for creating and storing your backup artifacts.</p> <p>PMM supports the following types of storage:</p> <ul> <li>Amazon S3-compatible: enables you to use not only AWS S3, but also other storage solutions that support S3 API, like min.io.</li> <li>Local storage: currently only available for MongoDB backups.</li> </ul>"},{"location":"get-started/backup/prepare_storage_location.html#prepare-a-location-for-local-backups","title":"Prepare a location for local backups","text":"<p>If you prefer storing your MongoDB backup artifacts on a remote filesystem, make sure that you\u2019ve mounted the remote folder to all the mongoDB nodes on the same path, and that PBM tool has Write permissions on the path you define.</p> <p>For more information, see the Percona Backup for MongoDB (PBM) documentation.</p>"},{"location":"get-started/backup/prepare_storage_location.html#prepare-a-location-for-s3-compatible-storage","title":"Prepare a location for S3-compatible storage","text":"<p>If you want to store backup artifacts in S3-compatible storage, you can use Amazon S3, Min.io or any other storage solution with S3-compatible API.</p> <p>Before creating a cloud storage location for our future backups, make sure you have your S3-compatible storage ready. In addition to bucket location details, you will also need to ensure proper S3 permissions.</p> <p>The general minimum permissions are LIST/PUT/GET/DELETE. A sample IAM policy is:</p> <pre><code>    ```json\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:ListBucket\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing\"\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:PutObject\",\n                    \"s3:PutObjectAcl\",\n                    \"s3:GetObject\",\n                    \"s3:GetObjectAcl\",\n                    \"s3:DeleteObject\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing/*\"\n            }\n        ]\n    }\n    ```\n</code></pre>"},{"location":"get-started/backup/prepare_storage_location.html#create-the-storage-location","title":"Create the storage location","text":"<ol> <li> <p>Go to Backup &gt; Storage Locations:     </p> </li> <li> <p>Click Add storage location and fill in a name and description for this new location.</p> </li> <li>Choose the type of storage location you are creating:<ul> <li>S3: Specify the S3-compatible backup location endpoint (URL), bucket name, and connection details.</li> <li>Local Client: specify the path on your local client for files to be backed up to.</li> </ul> </li> </ol> <p>Important</p> <p>If your S3 endpoint is using a custom x509 certificate, PMM Server and all PMM Clients must be able to verify it. For this, append the CA certificate to the file containing the list of root CA certificates. These are stored on /etc/ssl/cert.pem file inside the pmm-server container. On the Client side, it is usually /etc/ssl/certs/ca-bundle.crt</p> <ol> <li> <p>Optionally, for S3-compatible storages, you can click Test to check the connection.</p> </li> <li> <p>Click Add to create the location.</p> </li> </ol>"},{"location":"get-started/backup/prepare_storage_location.html#specific-target-directories-for-backups","title":"Specific target directories for backups","text":"<p>During backup creation, PMM enables you to set a specific folder within the local or S3-compatible location that you prepared following the instructions above. Organizing backups in folders not only makes it easier to group backups for an entire cluster, but also improves PMM-PBM (Percona Backup for MongoDB) integration workflows. </p> <p>The Folder field on the Create Backup pages is automatically populated with the value of the cluster label. You can change this default folder from PMM\u2019s Advanced Settings, but make sure you understand how your custom folder will impact PBM integration workflows.</p>"},{"location":"get-started/backup/restore_MongoDB_backups.html","title":"Restore a MongoDB backup","text":"<p>MongoDB backups can only be restored to the same service they were created from.</p> <p>To restore a backup:</p> <ol> <li>Go to  Backup \u2192 All backups and find the backup that you want to restore.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  Restore from backup. This opens the Restore from backup dialog, with the Same service option automatically preselected. This is because, currently, MongoDB backups can only be restored to a service with identical properties.</li> <li>If you are restoring a PITR backup, select the point for the date and time that you want to restore the database to.</li> <li>Click Restore then go to the Restores tab to check the status of the restored backup.</li> </ol> <p>Important</p> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p>"},{"location":"get-started/backup/restore_MongoDB_backups.html#restore-to-a-new-cluster-manually","title":"Restore to a new cluster manually","text":"<ol> <li>Install MongoDB and Percona Backup for MongoDB. Pay attention to the versions. To minimize potential incompatibility, use the same versions that were used for taking backups.    For instructions, see the PBM install documentation.</li> <li> <p>Configure your environment:</p> <ul> <li>to restore to a new environment with the same replica set name, make sure that the replica set name in your new destination cluster use the same name as that in the cluster that was backed up.   For more information, see Restoring a backup into a new-environment in the PBM documentation.  </li> <li> <p>to restore logical backups to a new environment that has a different replica set name, configure the name mapping between the source and target environments.    For the new environment, you can either set the PBM_REPLSET_REMAPPING environment variable for pbm CLI, or use the <code>--replset-remapping</code> flag for PBM commands.</p> <p>The mapping format is <code>&lt;rsTarget&gt;=&lt;rsSource&gt;</code>.</p> <p>For example:</p> <p><code>$ export PBM_REPLSET_REMAPPING=\"targetRS=sourceRS\"</code></p> <p>OR </p> <p><code>$ pbm restore &lt;timestamp&gt; --replset-remapping=\"targetRS=sourceRS\"</code></p> <p>For more information, see Restoring into a replica set with a different name in the PBM documentation.</p> </li> </ul> </li> <li> <p>Make sure that Percona Backup for MongoDB configuration in the new environment points to the remote storage defined for the original environment, including the authentication credentials for object stores.</p> <p>The easiest way to configure it is to create a config file, called, for example, <code>pbm_config.yaml</code>.</p> <p>For this, you can either copy the config from the source host or create a new one.</p> <p>To redirect the config output from the existing environment, use: <pre><code>  pbm config &gt;&gt; pbm_config.yaml\n</code></pre> then copy the resulting file to the new environment.</p> <p>Here\u2019s an example of config file content for AWS S3-compatible storage:</p> <p><pre><code>storage:\n  type: s3\n  s3:\n    region: us-west-2\n    bucket: pbm-test-bucket\n    prefix: backup_name_from_pmm\n    credentials:\n      access-key-id: &lt;your-access-key-id-here&gt;\n      secret-access-key: &lt;your-secret-key-here&gt; \n</code></pre> The prefix name is the artifact name that appears in the Backup name column, under  Backup &gt; All Backups page:</p> <p> </p> <p>To implement the config, use the following command:     <pre><code>pbm config --file pbm_config.yaml\n</code></pre></p> <p>For more information, see Restoring a backup into a new-environment in the PBM documentation.  </p> </li> <li> <p>Run <code>pbm list</code> to check if pbm is ready to perform the restore procedure.</p> </li> <li> <p>Once all the backups made from the original environment are available, run the restore command:</p> <ul> <li> <p>For snapshot backups:</p> <p>a) run the following command:</p> <p><pre><code>pbm list\n  Backup snapshots: 2022-11-23T19:40:06Z [restore_to_time: 2021-01-13T15:53:40Z]\n</code></pre> b) provide the timestamp of the backup to the <code>pbm</code> command:</p> <p><code>pbm restore 2022-11-23T19:40:06Z</code></p> <p>For more information, see Restore a backup topic in the PBM documentation.</p> </li> <li> <p>For PITR backups:</p> <p>a) run the following command:</p> <p><pre><code>  pbm list\n  Backup snapshots:\n    2022-11-23T19:40:06Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:40:25Z]\n    2022-11-23T19:45:07Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:45:22Z]\n  PITR &lt;on&gt;:\n    2022-11-23T19:40:26Z - 2022-11-23T19:45:22Z\n</code></pre>     b) provide the timestamp from one of the PITR ranges to the <code>pbm</code> command:</p> <p><code>pbm restore --time=\"2022-11-23T19:40:26</code></p> </li> </ul> <p>For more information, see the Point-in-time Recovery topic in the PBM documentation.</p> </li> <li> <p>Check the progress of the restore operation, using one of the commands below:</p> <ul> <li> <p>For logical restores: <code>pbm describe-restore &lt;restore_name&gt;</code></p> </li> <li> <p>For physical restores: <code>pbm describe-restore --config=/path/to/pbm_config.yaml &lt;restore_name&gt;</code></p> </li> </ul> <p>Required arguments:</p> <ul> <li>PBM generates the <code>&lt;restore_name&gt;</code> information after you start the restoring.</li> <li>The pbm_config.yaml file required for physical restores is the PBM config file that you provided for step 3.</li> </ul> </li> </ol> <p>Important</p> <p>Make sure not to run pbm backup from the new environment while the Percona Backup for MongoDB config is pointing to the remote storage location of the original environment.</p>"},{"location":"get-started/backup/restore_MongoDB_backups.html#restoring-from-a-sharded-cluster","title":"Restoring from a sharded cluster","text":"<p>Sharded cluster backups are supported starting with PMM 2.38 and PMM handles the backup process end-to-end. However, restoring such artifacts is currently possible only via the CLI, using Percona Backup for MongoDB.</p> <p>For information on restoring sharded backups, check the PBM documentation</p>"},{"location":"get-started/backup/restore_mysql_backup.html","title":"Restore a MySQL backup","text":""},{"location":"get-started/backup/restore_mysql_backup.html#restore-compatibility","title":"Restore compatibility","text":"<p>MySQL backups can be restored to the same service it was created from, or to a compatible one. </p> <p>To restore a backup:</p> <ol> <li>Go to  Backup &gt; All backups and find the backup that you want to restore.</li> <li>Click the three dots  in the Actions column to check all the information for the backup, then click  Restore from backup.</li> <li>In the Restore from backup dialog, select Same service to restore to a service with identical properties or Compatible services to restore to a compatible service.</li> <li>Select one of the available service names from the drop-down menu.</li> <li>Check the values, then click Restore.</li> <li>Go to the Restores tab to check the status of the restored backup.</li> </ol> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p>"},{"location":"get-started/roles-and-permissions/index.html","title":"Roles and permissions","text":"<p>Roles are the sets of permissions and configurations that determine which metrics a user can access.</p> <p>Each PMM user is associated with a role that includes permissions. Permissions determine the privileges that a user has in PMM.</p> <p>By creating roles, you can specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related to test environments.</p>"},{"location":"get-started/roles-and-permissions/index.html#about-access-control","title":"About Access Control","text":"<p>Caution</p> <p>PMM Access Control is currently in technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Access control in PMM allows you to manage who has access to individual Prometheus (Victoria Metrics)  metrics based on labels. Thus, access management provides a standardized way of granting, changing, and revoking access to metrics based on the role assigned to the users.</p> <p>The following topics are covered as part of access control:</p> <ul> <li>Configure access control</li> <li>Labels for access control</li> <li>Create access roles</li> <li>Use case</li> </ul>"},{"location":"get-started/roles-and-permissions/access_roles.html","title":"Create access roles","text":"<p>Roles are a vital part of Access control. Roles provide users with access to specific, role-based metrics.</p> <p>To create access roles in PMM, do the following:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Access Roles. Access Roles tab  opens.</p> <p></p> </li> <li> <p>Click Create. Create role page opens.</p> </li> <li> <p>Enter the Role name and Role description.</p> <p></p> </li> <li> <p>Select the following from the drop-downs for metrics access:</p> <ul> <li>Label</li> <li>Operator</li> <li>Value of the label.</li> </ul> <p>If you want to add more than one label for a role, click + and select the values from the drop-down.</p> <p>For information on how the Prometheus selectors work, see Prometheus selectors.</p> </li> <li> <p>Click Create role.</p> </li> </ol> <p>Note</p> <p>To create roles, you must have admin privileges. For more information, see Manage users.</p>"},{"location":"get-started/roles-and-permissions/assign_roles.html","title":"Assign roles to users","text":"<p>To assign access roles to users, do the following:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Users. Users tab opens.</p> <p></p> </li> <li> <p>Select the Access Role you want to assign to a user from the dropdown. You can assign several roles to a user.</p> <p></p> </li> </ol>"},{"location":"get-started/roles-and-permissions/configure_access_roles.html","title":"Configure access control","text":"<p>You can configure access control in PMM as follows:</p> <ul> <li>Docker</li> <li>User Interface</li> </ul>"},{"location":"get-started/roles-and-permissions/configure_access_roles.html#configure-access-control-using-docker","title":"Configure access control using Docker","text":"<p>To configure access roles in a <code>pmm-server</code> docker container, pass an additional environment variable <code>ENABLE_RBAC=1</code> when starting the container.</p> <pre><code>docker run \u2026 -e ENABLE_RBAC=1\n</code></pre> <p>For compose add an additional variable:</p> <pre><code>services:\n  pmm-server:\n    \u2026\n    environment:\n      \u2026\n      ENABLE_RBAC=1\n</code></pre>"},{"location":"get-started/roles-and-permissions/configure_access_roles.html#configure-access-control-from-the-ui","title":"Configure access control from the UI","text":"<p>To configure access control from the UI, do the following:</p> <p>From the main menu, navigate to  Configuration \u2192  Settings \u2192 Advanced Settings \u2192 Access Control and click  toggle.</p>"},{"location":"get-started/roles-and-permissions/lbac.html","title":"Labels for access control","text":"<p>Label-based access control in PMM allows you to manage who has access to metrics based on labels. By creating roles, you can specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related to test environments. </p> <p>With Label-based access control, you can associate multiple labels with a role, ensuring only data from series that match your defined labels is returned. </p>"},{"location":"get-started/roles-and-permissions/lbac.html#standard-vs-custom-labels","title":"Standard vs custom labels","text":"<p>PMM supports standard as well as custom labels. PMM automatically assigns standard labels. You can also set standard labels when an object (Node, Service, or Agent) is created. Custom labels are assigned and updated only by a user.</p> <p>Examples</p> Label Type Object **Label name ** Example Standard Node node_id /node_id/123 Service service_type - mysql, mongodb, postgresql etc. Custom Node, Service, Agent Any string matching regular expression:  [a-zA-Z_][a-zA-Z0-9_]*.  Also, it cannot start with two underscores. owner=\u201djoe\u201d _rack=\u201d12345\u201d"},{"location":"get-started/roles-and-permissions/lbac.html#adding-labels","title":"Adding labels","text":"<p>In PMM, labels enable you to identify, categorize, and organize your monitored services and resources. Labels also simplify filtering, grouping, and analyzing data. </p> <p>While adding a service for monitoring in PMM, you can add custom or standard labels.</p> <p>Using PMM UI</p> <p>You can set the labels using the User interface as follows:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Add Service.</p> </li> <li> <p>Select the service you want to add to PMM for monitoring. The page to add the service opens.</p> <p></p> </li> <li> <p>Enter the details such as Hostname, Service name, Port, Username, Password, Max query length.</p> <p></p> </li> <li> <p>(Optional) Enter the Labels for the service being monitored.</p> <p></p> </li> <li> <p>(Optional) Check the Additional Options that you want to include, such as:</p> <ul> <li> <p>Skip connection check: Do not check the connection to the database.</p> </li> <li> <p>Use TLS for database connections: Enabling TLS (Transport Layer Security) for database connections is an important security measure to protect the confidentiality and integrity of data transmitted between the PMM Server and the monitored database instances.</p> </li> <li> <p>Skip TLS certificate and hostname validation: For certain purposes, like debugging and testing, it may be necessary to bypass TLS certificate and hostname validation.</p> </li> <li> <p>Table statistics limit: Do not collect table statistics if the number of tables in a database exceeds this limit (defaults to 1000).</p> </li> <li> <p>Disable comments parsing: Filter out comments in log files or data streams to isolate valid data.</p> </li> <li> <p>Use performance schema: Use Performance Schema instead of Slow Query Log (default) for monitoring and diagnosing performance issues in your database.</p> </li> </ul> </li> </ol> <p>You can also edit the labels for a service with the PMM user interface. For details on editing labels for a service, see Editing labels for a service</p> <p>Using pmm-admin</p> <p>You can also assign labels using pmm-admin.</p>"},{"location":"get-started/roles-and-permissions/manage_roles.html","title":"Manage access roles","text":"<p>You can manage roles in PMM by editing or deleting a role.</p>"},{"location":"get-started/roles-and-permissions/manage_roles.html#edit-roles","title":"Edit roles","text":"<p>To edit access roles, do the following:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Access Roles. The Access Roles tab opens.</p> </li> <li> <p>On the role you want to edit, click the ellipsis (three vertical dots) &gt; edit role in the Options column. The Edit role page opens.</p> <p></p> </li> <li> <p>Make the required changes to the role.</p> <p></p> </li> <li> <p>Click Save Changes.</p> </li> </ol>"},{"location":"get-started/roles-and-permissions/manage_roles.html#set-a-role-as-default","title":"Set a role as default","text":"<p>When a user signs in to PMM for the first time and the user has no role assigned, the user is automatically assigned the Default role. For administrators, the default role provides a convenient way to configure default permissions for new users.</p> <p>To set a role as default, do the following:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Access Roles. The Access Roles tab opens.</p> </li> <li> <p>On the role you want to set as default, click the ellipsis (three vertical dots) \u2192 set as default in the Options column.</p> </li> </ol> <p></p>"},{"location":"get-started/roles-and-permissions/manage_roles.html#remove-roles","title":"Remove roles","text":"<p>To remove access roles, do the following:</p> <ol> <li> <p>From the Main menu, navigate to  Configuration \u2192 Access Roles. The Access Roles tab opens.</p> </li> <li> <p>On the role you want to remove, click the ellipsis (three vertical dots) \u2192  Delete in the Options column. Delete role pop-up opens.</p> <p></p> </li> <li> <p>Starting with PMM 2.36.0, if the role that you want to delete is already assigned to a user, you will see a drop-down with replacement roles. Select the replacement role and the selected role will be assigned to the user.</p> <p></p> </li> <li> <p>Click Confirm and delete the role.</p> </li> </ol>"},{"location":"get-started/roles-and-permissions/use_case.html","title":"Use Case","text":""},{"location":"get-started/roles-and-permissions/use_case.html#use-case-1","title":"Use case 1","text":"<p>This use case demonstrates the following scenario:</p> <p>Labels</p> <ul> <li> <p>Environments: prod and qa</p> </li> <li> <p>Projects: shop and bank</p> </li> </ul> <p>Roles</p> <ul> <li>Roles: Admin, Dev and QA</li> </ul> <p>An overview of the infrastructure can be seen in the diagram below. PMM monitors several services. The metrics that are stored in VictoriaMetrics have the appropriate labels.</p> <p></p> <p>This diagram shows several roles within a company structure that have access to PMM, as well as the permissions they should be granted:</p> <ul> <li>Admin role - has access to all the metrics</li> <li>DBA role - has access to all metrics within env=prod only</li> <li> <p>QA role - has access to all metrics within env=qa only</p> <p></p> </li> </ul>"},{"location":"get-started/roles-and-permissions/use_case.html#use-case-2","title":"Use case 2","text":"<p>The use case demonstrates the following scenario:</p> <p>Labels</p> <ul> <li> <p>Environments: prod and dev</p> </li> <li> <p>Services: postgresql and mysql</p> </li> </ul> <p>Roles</p> <ul> <li>role_postresql</li> <li>role_mysql</li> </ul> Role assigned Labels applied to the role Accessible Metrics User 1 role_postresql dev, service_name=postgresql The metrics for service postgresql will be accessible. User 2 role_mysql prod, service_name=mysql The metrics for service mysql will be accessible. User 3 role_postgresql and role_mysql dev, service_name=postgresql and  prod, service_name=mysql The metrics for both the services mysql and postresql will be accessible."},{"location":"how-to/index.html","title":"How to","text":"<ul> <li>Configure via the PMM Settings page.</li> <li>Manage users via the PMM Users page.</li> <li>Upgrade PMM Server via the user interface.</li> <li>Secure your PMM installation.</li> <li>Optimize the performance of your PMM installation.</li> <li>Set up PMM in HA mode.</li> <li>Annotate charts to mark significant events.</li> <li>Share dashboards and panels to save or share.</li> <li>Extend Metrics with textfile collector.</li> <li>Troubleshoot</li> </ul>"},{"location":"how-to/HA.html","title":"Set up PMM in High Availability (HA) mode","text":"<p>High Availability (HA) is a critical aspect of any monitoring system, as it ensures that your monitoring infrastructure remains resilient and continues to function seamlessly, even if one or more instances encounter issues. HA implements redundant systems that are ready to take over to minimize downtime and maintain continuous visibility into the performance and health of PMM.</p>"},{"location":"how-to/HA.html#ha-options-pmm","title":"HA options PMM","text":"<p>Since HA can add complexity, before considering HA for PMM, keep in mind that:</p> <ul> <li> <p>Critical systems requiring immediate response benefit from sub-second failover HA, while less critical applications with some tolerance for downtime (seconds or minutes) have more flexibility.</p> </li> <li> <p>PMM itself has a one-minute minimum alerting interval, so even with perfect HA, the fastest you\u2019ll know about an issue is one minute after it occurs.</p> </li> <li> <p>Consider your specific uptime needs, performance requirements, and potential data loss you can tolerate, while also keeping in mind PMM\u2019s limitations.</p> </li> </ul>"},{"location":"how-to/HA.html#1-simple-docker-restart-with-data-caching","title":"1. Simple Docker restart with data caching","text":"<p>The most straightforward approach to increase availability in PMM is to launch the PMM Server within Docker using the <code>--restart=always</code> flag. See Setting up PMM Server with Docker for more information.</p> <p>This ensures that the PMM Server automatically restarts if a minor issue occurs. Additionally, PMM\u2019s data caching feature stores data locally on the PMM Client when the connection to the PMM Server is interrupted.</p> <p>Once the connection is restored, the cached data is transferred to the PMM Server, ensuring no data loss during the restart process.</p> <p>This option is suitable for scenarios where the primary concern is the ability to investigate potential issues later. However, it\u2019s important to note that this approach is limited by the underlying physical infrastructure. If the failure stems from a hardware issue, automatic recovery might be challenging.</p>"},{"location":"how-to/HA.html#2-leverage-kubernetes-for-enhanced-isolation","title":"2. Leverage Kubernetes for enhanced isolation","text":"<p>If you are running PMM in a Kubernetes (K8s) environment, PMM offers a Helm chart that facilitates running PMM with enhanced isolation. See Setting up PMM Server with Helm.</p> <p>In this setup, even if the physical infrastructure encounters a problem, K8s automatically handles failover, migrating the PMM instance to a healthy node. </p> <p>While restarts within K8s can take up to several minutes (depending on your infrastructure configuration), PMM\u2019s data caching ensures that information is preserved during this transition. Alerts will still be triggered to keep you informed about any issues that started during PMM\u2019s restart and continue after PMM is back.</p>"},{"location":"how-to/HA.html#3-fully-clustered-pmm-in-kubernetes-in-development","title":"3. Fully-clustered PMM in Kubernetes (in development)","text":"<p>If you have a large deployment with numerous instances and distributed locations, you might find that a fully clustered PMM setup in Kubernetes is better suited to your needs. We are actively developing this solution to cater specifically to users managing extensive and complex monitoring environments.</p> <p>This option will provide a comprehensive HA solution, including clustered database setups (ClickHouse, VictoriaMetrics, and PostgreSQL). In this setup, multiple PMM instances will be configured, with one being the leader and the others as followers.</p> <p>Leader election will be managed using the Raft consensus algorithm, ensuring a smooth transition of the leader role if the current leader fails. The architecture will consist of:</p> <ul> <li>Multiple PMM instances for redundancy</li> <li>Clustered PostgreSQL for storing metadata and configuration data</li> <li>Clustered ClickHouse for storing query performance metrics (Query Analytics)</li> <li>Clustered VictoriaMetrics for storing operational metrics from monitored databases and hosts</li> <li>HAProxy for managing and directing network traffic to the current leader PMM instance</li> </ul>"},{"location":"how-to/HA.html#4-manual-setup-for-ha","title":"4. Manual setup for HA","text":"<p>Important</p> <p>Manual setup for HA is feature is currently in Technical Preview. Early adopters are advised to use this feature for testing purposes only as it is subject to change.</p> <p>If none of the above options work for your specific use case, consider setting up PMM in HA mode manually by following the steps below.</p> <p>To enable communication and coordination among the PMM Server instances, two key protocols are used:</p> <ul> <li>Gossip protocol: Enables PMM servers to discover and share information about their states. It is used for managing the PMM server list and failure detection, ensuring that all instances are aware of the current state of the cluster.</li> <li>Raft protocol: Ensures that PMM servers agree on a leader and that logs are replicated among all machines to maintain data consistency.</li> </ul> <p>These protocols work in tandem to ensure that the PMM Server instances can effectively store and manage the data collected from your monitored databases and systems. </p> <p>In an HA configuration, three PMM Server instances are configured: one as the leader and the others as followers. The leader server handles all client requests. If the leader fails, the followers take over, minimizing downtime.</p> <p>To eliminate single points of failure and provide better service level agreements (SLAs), the critical services typically bundled with PMM Server are extracted and set up as separate, clustered instances:</p> <ul> <li>ClickHouse: A clustered setup of ClickHouse is used to store Query Analytics (QAN) metrics. This ensures that QAN data remains highly available and can be accessed even if one of the ClickHouse nodes fails.</li> <li>VictoriaMetrics: A clustered setup of VictoriaMetrics is used to store Prometheus metrics. This provides a highly available and scalable solution for storing and querying metrics data.</li> <li>PostgreSQL: A clustered setup of PostgreSQL is used to store PMM data, such as inventory and settings. This ensures that PMM\u2019s configuration and metadata remain highly available and can be accessed by all PMM Server instances.</li> </ul>"},{"location":"how-to/HA.html#prerequisites","title":"Prerequisites","text":"<p>You will need the following before you can begin the deployment:</p> <ul> <li>Docker installed and configured on your system. If you haven\u2019t installed Docker, you can follow this guide.</li> </ul> <p>Note</p> <ul> <li>The sections below provide instructions for setting up the services on both the same and separate instances. However, it is not recommended to run the services on a single machine for production purposes. This approach is only recommended for the development environment.</li> <li>It is recommended to use clustered versions of PosgreSQL, Victoriametrics, Clickhouse, etc., instead of standalone versions when setting up the services.</li> </ul> <p>To set up PMM in HA mode manually:</p>"},{"location":"how-to/HA.html#step-1-define-environment-variables","title":"Step 1: Define environment variables","text":"<p>Before you start with the setup, define the necessary environment variables on each instance where the services will be running. These variables will be used in subsequent commands. </p> <p>For all IP addresses, use the format <code>17.10.1.x</code>, and for all usernames and passwords, use a string format like <code>example</code>.</p> Variable Description <code>CH_HOST_IP</code> The IP address of the instance where the ClickHouse service is running or the desired IP address for the ClickHouse container within the Docker network, depending on your setup.Example: <code>17.10.1.2</code> <code>VM_HOST_IP</code> The IP address of the instance where the VictoriaMetrics service is running or the desired IP address for the VictoriaMetrics container within the Docker network, depending on your setup.Example: <code>17.10.1.3</code> <code>PG_HOST_IP</code> The IP address of the instance where the PostgreSQL service is running or the desired IP address for the PostgreSQL container within the Docker network, depending on your setup. Example: <code>17.10.1.4</code> <code>PG_USERNAME</code> The username for your PostgreSQL server. Example: <code>pmmuser</code> <code>PG_PASSWORD</code> The password for your PostgreSQL server. Example: <code>pgpassword</code> <code>GF_USERNAME</code> The username for your Grafana database user.Example: <code>gfuser</code> <code>GF_PASSWORD</code> The password for your Grafana database user.Example: <code>gfpassword</code> <code>PMM_ACTIVE_IP</code> The IP address of the instance where the active PMM server is running or the desired IP address for your active PMM server container within the Docker network, depending on your setup.Example: <code>17.10.1.5</code> <code>PMM_ACTIVE_NODE_ID</code> The unique ID for your active PMM server node.Example: <code>pmm-server-active</code> <code>PMM_PASSIVE_IP</code> The IP address of the instance where the first passive PMM server is running or the desired IP address for your first passive PMM server container within the Docker network, depending on your setup. Example: <code>17.10.1.6</code> <code>PMM_PASSIVE_NODE_ID</code> The unique ID for your first passive PMM server node.Example: <code>pmm-server-passive</code> <code>PMM_PASSIVE2_IP</code> The IP address of the instance where the second passive PMM server is running or the desired IP address for your second passive PMM server container within the Docker network, depending on your setup.Example: <code>17.10.1.7</code> <code>PMM_PASSIVE2_NODE_ID</code> The unique ID for your second passive PMM server node.Example: <code>pmm-server-passive2</code> <code>PMM_DOCKER_IMAGE</code> The specific PMM Server Docker image for this guide.Example: <code>percona/pmm-server:2</code> Expected output <pre><code>export CH_HOST_IP=17.10.1.2\nexport VM_HOST_IP=17.10.1.3\nexport PG_HOST_IP=17.10.1.4\nexport PG_USERNAME=pmmuser\nexport PG_PASSWORD=pgpassword\nexport GF_USERNAME=gfuser\nexport GF_PASSWORD=gfpassword\nexport PMM_ACTIVE_IP=17.10.1.5\nexport PMM_ACTIVE_NODE_ID=pmm-server-active\nexport PMM_PASSIVE_IP=17.10.1.6\nexport PMM_PASSIVE_NODE_ID=pmm-server-passive\nexport PMM_PASSIVE2_IP=17.10.1.7\nexport PMM_PASSIVE2_NODE_ID=pmm-server-passive2\nexport PMM_DOCKER_IMAGE=percona/pmm-server:2\n</code></pre> <p>Note</p> <p>Ensure that you have all the environment variables from Step 1 set in each instance where you run these commands.</p>"},{"location":"how-to/HA.html#step-2-create-docker-network-optional","title":"Step 2: Create Docker network (Optional)","text":"<ol> <li> <p>Set up a Docker network for PMM services if you plan to run all the services on the same instance. As a result of this Docker network, your containers will be able to communicate with each other, which is essential for the High Availability (HA) mode to function properly in PMM. This step may be optional if you run your services on separate instances.</p> </li> <li> <p>Run the following command to create a Docker network:</p> <pre><code>docker network create pmm-network --subnet=17.10.1.0/16\n</code></pre> </li> </ol>"},{"location":"how-to/HA.html#step-3-set-up-clickhouse","title":"Step 3: Set up ClickHouse","text":"<p>ClickHouse is an open-source column-oriented database management system. In PMM, ClickHouse stores Query Analytics (QAN) metrics, which provide detailed information about your queries.</p> <p>To set up ClickHouse:</p> <ol> <li> <p>Pull the ClickHouse Docker image.</p> <pre><code>docker pull clickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> </li> <li> <p>Create a Docker volume for ClickHouse data.</p> <pre><code>docker volume create ch_data\n</code></pre> </li> <li> <p>Run the ClickHouse container.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ch \\\n--network pmm-network \\\n--ip ${CH_HOST_IP} \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <pre><code>docker run -d \\\n--name ch \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <p>Note</p> <ul> <li>If you run the services on the same instance, the <code>--network</code> and <code>--ip</code> flags assign a specific IP address to the container within the Docker network created in the previous step. This IP address is referenced in subsequent steps as the ClickHouse service address. </li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances since ClickHouse will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"how-to/HA.html#step-4-set-up-victoriametrics","title":"Step 4: Set up VictoriaMetrics","text":"<p>VictoriaMetrics provides a long-term storage solution for your time-series data. In PMM, it is used to store Prometheus metrics.</p> <p>To set up VictoriaMetrics:</p> <ol> <li> <p>Pull the VictoriaMetrics Docker image.</p> <pre><code>docker pull victoriametrics/victoria-metrics:v1.93.4\n</code></pre> </li> <li> <p>Create a Docker volume for VictoriaMetrics data.</p> <pre><code>docker volume create vm_data\n</code></pre> </li> <li> <p>Run the VictoriaMetrics container.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name vm \\\n--network pmm-network \\\n--ip ${VM_HOST_IP} \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <pre><code>docker run -d \\\n--name vm \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <p>Note</p> <ul> <li>If you run the services on the same instance,  the <code>--network</code> and <code>--ip</code> flags are used to assign a specific IP address to the container within the Docker network created in Step 2. This IP address is referenced in subsequent steps as the VictoriaMetrics service address. </li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances, as VictoriaMetrics will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"how-to/HA.html#step-5-set-up-postgresql","title":"Step 5: Set up PostgreSQL","text":"<p>PostgreSQL is a powerful, open-source object-relational database system. In PMM, it\u2019s used to store data related to inventory, settings, and other features.</p> <p>To set up PostgreSQL:</p> <ol> <li> <p>Pull the Postgres Docker image.</p> <pre><code>docker pull postgres:14\n</code></pre> </li> <li> <p>Create a Docker volume for Postgres data:</p> <pre><code>docker volume create pg_data\n</code></pre> </li> <li> <p>Create a directory to store init SQL queries:</p> <pre><code>mkdir -p /path/to/queries\n</code></pre> <p>Replace <code>/path/to/queries</code> with the path where you want to store your <code>init</code> SQL queries.</p> </li> <li> <p>Create an <code>init.sql.template</code> file in newly created directory with the following content:</p> <pre><code>CREATE DATABASE \"pmm-managed\";\nCREATE USER &lt;YOUR_PG_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_PG_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE \"pmm-managed\" TO &lt;YOUR_PG_USERNAME&gt;;\nCREATE DATABASE grafana;\nCREATE USER &lt;YOUR_GF_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_GF_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE grafana TO &lt;YOUR_GF_USERNAME&gt;;\n\n\\c pmm-managed\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n</code></pre> </li> <li> <p>Use <code>sed</code> to replace the placeholders with the environment variables and write the output to <code>init.sql</code>.</p> <pre><code>sed -e 's/&lt;YOUR_PG_USERNAME&gt;/'\"$PG_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_PG_PASSWORD&gt;/'\"$PG_PASSWORD\"'/g' \\\n    -e 's/&lt;YOUR_GF_USERNAME&gt;/'\"$GF_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_GF_PASSWORD&gt;/'\"$GF_PASSWORD\"'/g' \\\n    init.sql.template &gt; init.sql\n</code></pre> </li> <li> <p>Run the PostgreSQL container.</p> <p>You can either run all the services on the same instance or on a seperate instance.</p> <p>Note</p> <p>It is recommended to use absolute paths instead of relative paths for volume mounts.</p> Run services on same instanceRun services on a seperate instance <pre><code>  docker run -d \\\n    --name pg \\\n    --network pmm-network \\\n    --ip ${PG_HOST_IP} \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d/ \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <pre><code>   docker run -d \\\n    --name pg \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <p>Replace <code>/path/to/queries</code> with the path to your <code>init.sql</code> file. This command mounts the <code>init.sql</code> file to the <code>docker-entrypoint-initdb.d</code> directory, which is automatically executed upon container startup.</p> <p>Note</p> <ul> <li>If you run the services on the same instance, the <code>--network</code> and <code>--ip</code> flags are used to assign a specific IP address to the container within the Docker network created in Step 2. This IP address is referenced in subsequent steps as the PostgreSQL service address.</li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances, as PostgreSQL will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"how-to/HA.html#step-6-running-pmm-services","title":"Step 6: Running PMM Services","text":"<p>The PMM server orchestrates the collection, storage, and visualization of metrics. In our high-availability setup, we\u2019ll have one active PMM server and two passive PMM servers.</p> <ol> <li> <p>Pull the PMM Server Docker image:</p> <pre><code>docker pull ${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Create a Docker volume for PMM-Server data:</p> <pre><code>docker volume create pmm-server-active_data\ndocker volume create pmm-server-passive_data\ndocker volume create pmm-server-passive-2_data\n</code></pre> </li> <li> <p>Run the active PMM managed server. This server will serve as the primary monitoring server.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n--hostname ${PMM_ACTIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_ACTIVE_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Run the first passive PMM managed server. This server will act as a standby server, ready to take over if the active server fails.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n--hostname ${PMM_PASSIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Run the second passive PMM managed server. Like the first passive server, this server will also act as a standby server.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n--hostname ${PMM_PASSIVE2_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE2_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive-2_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v /srv/pmm-data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>Note</p> <ul> <li>Ensure to set the environment variables from Step 1  in each instance where you run these commands.</li> <li>If you run the service on the same instance, remove the <code>-p</code> flags.</li> <li>If you run the service on a separate instance, remove the <code>--network</code> and <code>--ip</code> flags.</li> </ul> </li> </ol>"},{"location":"how-to/HA.html#step-7-running-haproxy","title":"Step 7: Running HAProxy","text":"<p>HAProxy provides high availability for your PMM setup by directing traffic to the current leader server via the <code>/v1/leaderHealthCheck</code> endpoint.</p> <ol> <li> <p>Pull the HAProxy Docker image.</p> <pre><code>docker pull haproxy:2.4.2-alpine\n</code></pre> </li> <li> <p>Create a directory to store the SSL certificate.</p> <pre><code>mkdir -p /path/to/certs\n</code></pre> <p>Replace <code>/path/to/certs</code> with the path where you want to store your SSL certificates.</p> </li> <li> <p>Navigate to this directory and generate a new private key.</p> <pre><code>openssl genrsa -out pmm.key 2048\n</code></pre> <p>This command generates a 2048-bit RSA private key and saves it to a file named <code>pmm.key</code>.</p> </li> <li> <p>Using the private key, generate a self-signed certificate.</p> <pre><code>openssl req -new -x509 -key pmm.key -out pmm.crt -days 365\n</code></pre> <p>Enter country, state, organization name, etc. when asked. Use <code>-days 365</code> option for 365-day certificate validity.    </p> </li> <li> <p>Copy your SSL certificate and private key to the directory you created in step 2. Ensure that the certificate file is named <code>pmm.crt</code> and the private key file is named <code>pmm.key</code>. </p> <p>Concatenate these two files to create a PEM file:</p> <pre><code>cat pmm.crt pmm.key &gt; pmm.pem\n</code></pre> </li> <li> <p>Create a directory to store HA Proxy configuration.</p> <pre><code>mkdir -p /path/to/haproxy-config\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path where you want to store your HAProxy configuration.</p> </li> <li> <p>Create an HAProxy configuration file named <code>haproxy.cfg.template</code> in that directory. This configuration tells HAProxy to use the <code>/v1/leaderHealthCheck</code> endpoint of each PMM server to identify the leader.</p> <pre><code>global\n    log stdout    local0 debug\n    log stdout    local1 info\n    log stdout    local2 info\n    daemon\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend http_front\n    bind *:80\n    default_backend http_back\n\nfrontend https_front\n    bind *:443 ssl crt /etc/haproxy/certs/pmm.pem\n    default_backend https_back\n\nbackend http_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-http PMM_ACTIVE_IP:80 check\n    server pmm-server-passive-http PMM_PASSIVE_IP:80 check backup\n    server pmm-server-passive-2-http PMM_PASSIVE2_IP:80 check backup\n\nbackend https_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-https PMM_ACTIVE_IP:443 check ssl verify none\n    server pmm-server-passive-https PMM_PASSIVE_IP:443 check ssl verify none\n    server pmm-server-passive-2-https PMM_PASSIVE2_IP:443 check ssl verify none\n</code></pre> </li> <li> <p>Before starting the HAProxy container, use <code>sed</code> to replace the placeholders in <code>haproxy.cfg.template</code> with the environment variables, and write the output to <code>haproxy.cfg</code>.</p> <pre><code>sed -e \"s/PMM_ACTIVE_IP/$PMM_ACTIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE_IP/$PMM_PASSIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE2_IP/$PMM_PASSIVE2_IP/g\" \\\n    /path/to/haproxy.cfg.template &gt; /path/to/haproxy.cfg    \n</code></pre> </li> <li> <p>Run the HAProxy container.</p> <pre><code>docker run -d \\\n  --name haproxy \\\n  --network pmm-network \\\n  -p 80:80 \\\n  -p 443:443 \\\n  -v /path/to/haproxy-config:/usr/local/etc/haproxy \\\n  -v /path/to/certs:/etc/haproxy/certs \\\n  haproxy:2.4.2-alpine\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path to the <code>haproxy.cfg</code> file you created in step 6, and <code>/path/to/certs</code> with the path to the directory containing the SSL certificate and private key. </p> </li> </ol> <p>Note</p> <ul> <li>It is recommended to use absolute paths instead of relative paths for volume mounts.</li> <li>If you\u2019re running services on separate instances, you can remove the <code>--network</code> flag.</li> </ul> <p>HAProxy is now configured to redirect traffic to the leader PMM managed server. This ensures highly reliable service by redirecting requests to the remainder of the servers in the event that the leader server goes down.</p>"},{"location":"how-to/HA.html#step-8-access-pmm","title":"Step 8: Access PMM","text":"<p>You can access the PMM web interface via HAProxy once all the components are set up and configured:</p> <ol> <li>Access the PMM services by navigating to <code>https://&lt;HAProxy_IP&gt;</code> in your web browser. Replace <code>&lt;HAProxy_IP&gt;</code> with the IP address or hostname of the machine running the HAProxy container.</li> <li>You should now see the PMM login screen. Log in using the default credentials, unless you changed them during setup.</li> <li>You can use the PMM web interface to monitor your database infrastructure, analyze metrics, and perform various database management tasks.</li> </ol> <p>When you register PMM Clients, you must use the HAProxy IP address (or hostname) rather than the PMM Server address once your PMM environment has been set up in high-availability (HA) mode. Even if one PMM server becomes unavailable, clients will still be able to communicate with the servers.</p> <p>You have now successfully set up PMM in HA mode using Docker containers. Your PMM environment is more resilient to failures and can continue providing monitoring services if any of the instances fail.</p> <p>Note</p> <p>Ensure that all containers are running and accessible. You can use <code>docker ps</code> to check the status of your Docker containers. If a container is not running, you can view its logs using the command <code>docker logs &lt;container_name&gt;</code> to investigate the issue.</p>"},{"location":"how-to/PMM_dump.html","title":"Export PMM data with PMM Dump","text":"<p>PMM data dumps are compressed tarball files containing a comprehensive export of your PMM metrics and QAN data collected by PMM Server.</p> <p>You can download these dataset files locally, or share them with Percona Support via an SFTP server. This enables you to share PMM data securely, which is especially useful when you need you troubleshoot PMM issues without without providing access to your PMM instance.</p> <p>Starting with 2.41, PMM enables you to generate PMM Datasets straight from PMM. If you are using an older PMM version, you can use the standalone PMM Dump utility instead.</p>"},{"location":"how-to/PMM_dump.html#dump-contents","title":"Dump contents","text":"<p>The dump.tar.gz dump file is a .TAR archive compressed via Gzip. Here\u2019s what\u2019s inside the folders it contains:</p> <ul> <li>meta.json: metadata about the data dump</li> <li>vm: Victoria Metrics data chunks in native VM format, organized by timeframe</li> <li>ch: Query Analytics (QAN) data stored in ClickHouse, organized by rows count</li> <li>log.json: logs detailing the export and archive creation process</li> </ul>"},{"location":"how-to/PMM_dump.html#create-a-data-dump","title":"Create a data dump","text":"<p>To create a dump of your dataset:</p> <ol> <li>From the main menu on the left, go to  Help &gt; PMM Dump.</li> <li>Click Create dataset to go to the Export new dataset page.</li> <li>Choose the service for which you want to create the dataset or leave it empty to export all data.</li> <li>Define the time range for the dataset.</li> <li>Enable Export QAN to include Query Analytics (QAN) metrics alongside the core metrics.</li> <li>Enable Ignore load to export the dump bypassing the default resource limit restrictions.</li> <li>Click Create dataset. This will generate a data dump file and automatically record an entry in the PMM Dump table. From there, you can use the options available in the Options menu to send the dump file to Percona Support or download it locally for internal usage.</li> </ol>"},{"location":"how-to/PMM_dump.html#send-a-data-dump-to-percona-support","title":"Send a data dump to Percona Support","text":"<p>If you are a Percona Customer, you can securely share PMM data dumps with Percona Support via SFTP.</p> <ol> <li>From the main menu on the left, go to  Help &gt; PMM Dump.</li> <li>Select the PMM dump entry which you want to send to Support.</li> <li>In the Options column, expand the table row to check the PMM Service associated with the dataset, click the ellipsis (three vertical dots) and select Send to Support.</li> <li>Fill in the details of the SFTP server, then click Send.</li> <li>Update your Support ticket to let Percona know that you\u2019ve uploaded the dataset on the SFTP server.</li> </ol>"},{"location":"how-to/account-info.html","title":"Check Percona Portal account information","text":"<p>When you connect your PMM instances to Percona Platform, PMM gets access to:</p> <ul> <li>More alert templates</li> <li>Basic Advisor Checks for additional database checks</li> <li>Standard/Premium Advisor Checks for more advanced database health checks.</li> </ul> <p>Standard/Premium checks are available when you connect to Percona Platform with a customer account.</p> <p>You can check the list of available Standard/Premium Advisor checks in the Advisors details page.</p> <p>When you connect with a customer account, PMM  reveals two new tabs on the main menu, where you can check all the information available for your customer accounts:  Entitlements and Support tickets:</p> <p></p> <p></p>"},{"location":"how-to/annotate.html","title":"Annotate","text":"<p>Annotations mark a moment in time. They are useful for marking system changes or other significant application events. They can be set globally or for specific nodes or services.</p> <p>You create them on the command line with the <code>pmm-admin annotate</code> command.</p> <p>Annotations show as a vertical dashed line on a dashboard graph. Reveal the annotation text by mousing over the caret indicator below the line.</p> <p></p> <p>You turn annotations on or off with the PMM Annotations switch in the second row menu bar.</p> <p></p>"},{"location":"how-to/configure.html","title":"Configure","text":"<p>The Settings page is where you configure PMM.</p> <p>Open the Settings page from the main menu with  Configuration \u2192  Settings. The page opens with the Metrics Resolution settings tab selected.</p> <p></p> <p>On the left are the selector tabs:</p> <ul> <li>Configure</li> <li>Metrics resolution<ul> <li>Configure metrics resolution per-service</li> <li>Example</li> </ul> </li> <li>Advanced settings<ul> <li>Data retention</li> <li>Telemetry</li> <li>Check for updates</li> <li>Advisors</li> <li>Percona Alerting</li> <li>Backup Management</li> <li>Public address</li> <li>Database as a Service (DBaaS)</li> <li>Microsoft Azure monitoring</li> </ul> </li> <li>SSH Key</li> <li>Alertmanager integration</li> <li>Percona Platform</li> </ul> <p>Tip</p> <p>Click Apply changes to save any changes made here.</p>"},{"location":"how-to/configure.html#metrics-resolution","title":"Metrics resolution","text":"<p>Metrics are collected at three intervals representing low, medium and high resolutions.</p> <p>The Metrics Resolution settings tab contains a radio button with three fixed presets (Rare, Standard and Frequent) and one editable custom preset (Custom).</p> <p></p> <p>Each preset is a group of low, medium and high resolutions. The values are in seconds.</p> <p>Time intervals and resolutions</p> <p>Short time intervals are high resolution metrics. Longer time intervals are low resolution. So:</p> <ul> <li>A low-resolution interval increases the time between collection, resulting in low-resolution metrics and lower disk usage.</li> <li>A high-resolution interval decreases the time between collection, resulting in high-resolution metrics and higher disk usage.</li> </ul> <p>The default values (in seconds) for the fixed presets and their resolution names are:</p> Editable? Preset Low Medium High No Rare 300 180 60 No Standard 60 10 5 No Frequent 30 5 1 Yes Custom (defaults) 60 10 5 <p>Values for the Custom preset can be entered as values, or changed with the arrows.</p> <p>If there is poor network connectivity between PMM Server and PMM Client, or between PMM Client and the database server being monitored, scraping every second may not be possible when the network latency is greater than 1 second.</p>"},{"location":"how-to/configure.html#configure-metrics-resolution-per-service","title":"Configure metrics resolution per-service","text":"<p>You can configure metrics resolutions both globally and on a per-service basis. While the global setting in the Settings tab applies to all services, PMM 2.42 and later also enables you to customize resolution for individual services. You can do this by adjusting the <code>metrics_resolutions</code> setting for each exporter using the API (see below for an example).</p> <p>Customizing resolution settings for individual services allows you to fine-tune your PMM setup, balancing data granularity with resource consumption. This feature enables you to:</p> <ul> <li>Allocate resources efficiently by focusing on high-resolution data for key services</li> <li>Reduce storage requirements by lowering resolution for less important components</li> <li>Align your monitoring setup with the specific needs of your environment</li> </ul> <p>To change resolution settings:</p> <ol> <li> <p>Identify the appropriate API endpoint:</p> <ul> <li>for PostgreSQL: <code>ChangePostgresExporter</code></li> <li>for MySQL: <code>ChangeMySQLdExporter</code></li> <li>for MongoDB: <code>ChangeMongoDBExporter</code></li> </ul> </li> <li> <p>Locate the <code>agent_id</code> of the exporter you want to modify. You can find this in the Inventory dashboard under the Monitoring column for the target service.</p> </li> <li> <p>Set the desired resolution using <code>hr</code> (high), <code>mr</code> (medium), or <code>lr</code> (low) in the <code>metrics_resolutions</code> field, running a command similar to</p> </li> </ol> <pre><code>curl --request POST \\\n        --url https://&lt;your-pmm-user&gt;:&lt;your-pmm-pwd&gt;@&lt;your-pmm-address&gt;/v1/inventory/Agents/&lt;change-endpoint&gt; \\\n        --header 'accept: application/json' \\\n        --header 'content-type: application/json' \\\n        --data '\n    {\n    \"common\": {\n        \"metrics_resolutions\": {\n           \"hr\": \"&lt;your-hr&gt;\",\n           \"mr\": \"&lt;your-mr&gt;\",\n           \"lr\": \"&lt;your-lr&gt;\"\n        }\n    },\n    \"agent_id\": \"/agent_id/&lt;your-agent-id&gt;\"  \n    }  '\n</code></pre> <p>Note</p> <ul> <li><code>metrics_resolutions</code>: can include \u2018hr, \u2018mr\u2019, \u2018lr\u2019 in any combination.</li> <li>Use curl\u2019s <code>--insecure</code> option in case you have self-signed certificates.</li> </ul>"},{"location":"how-to/configure.html#example","title":"Example","text":"<p>Setting 60s high, 300s medium, and 3600s low resolution for a MongoDB server with a MongoDB exporter\u2019s <code>agent_id</code> equal to <code>/agent_id/0ad0eebf-65a2-488f-a473-3a98b335b6d8</code>:</p> <pre><code>curl --insecure --request POST \\\n        --url https://admin:adminPwd@127.0.0.1/v1/inventory/Agents/ChangeMongoDBExporter \\\n        --header 'accept: application/json' \\\n        --header 'content-type: application/json' \\\n        --data '\n    {\n    \"common\": {\n        \"metrics_resolutions\": {\n           \"hr\": \"60s\",\n           \"mr\": \"300s\",\n           \"lr\": \"3600s\"\n        }\n    },\n    \"agent_id\": \"/agent_id/0ad0eebf-65a2-488f-a473-3a98b335b6d8\"  \n    }  '\n</code></pre> <p>If successful, the command above will print an output similar to the following, from which you can verify that the changes took effect:</p> <pre><code> {\n   \"mongodb_exporter\":  {\n     \"agent_id\":  \"/agent_id/0ad0eebf-65a2-488f-a473-3a98b335b6d8\",\n     \"pmm_agent_id\":  \"/agent_id/893dc1b9-f5d6-449f-b6f1-4433fbc38fce\",\n     \"service_id\":  \"/service_id/311930d0-babb-4a64-b936-440ad745c71d\",\n     \"username\":  \"mongodb_exporter\",\n     \"tls_skip_verify\":  true,\n     \"push_metrics_enabled\":  true,\n     \"status\":  \"RUNNING\",\n     \"listen_port\":  42002,\n     \"collections_limit\":  -1,\n     \"enable_all_collectors\":  true,\n     \"process_exec_path\":  \"/usr/local/percona/pmm2/exporters/mongodb_exporter\",\n     \"log_level\":  \"warn\",\n     \"metrics_resolutions\":  {\n       \"hr\":  \"60s\",\n       \"mr\":  \"300s\",\n       \"lr\":  \"3600s\"\n     }\n   }\n</code></pre> <p>You can also find the new configured metrics resolutions in the <code>vmagentscrapecfg</code> file. To locate this file, check the <code>-promscrape.config</code> variable passed to the <code>vmagent</code> command (you can use <code>ps aux | grep vmagent</code> for this scope).</p> <p>To reset a custom resolution, make an API call with \u201cmr\u201d: \u201c0s\u201d (or \u201chr\u201d: \u201c0s\u201d, \u201clr\u201d: \u201c0s\u201d as appropriate). This will revert the exporter to using the global PMM settings.</p> <p>For more information on configuring per-service metrics resolution, see the following sections in the API documentation:</p> <ul> <li>Change Postgres Exporter</li> <li>Change mysqld Exporter</li> <li>Change MongoDB Exporter</li> </ul>"},{"location":"how-to/configure.html#advanced-settings","title":"Advanced settings","text":""},{"location":"how-to/configure.html#data-retention","title":"Data retention","text":"<p>Data retention specifies how long data is stored by PMM Server. By default, time-series data is stored for 30 days. You can adjust the data retention time to balance your system\u2019s available disk space with your metrics history requirements.</p>"},{"location":"how-to/configure.html#telemetry","title":"Telemetry","text":"<p>The Telemetry switch enables gathering and sending basic anonymous data to Percona, which helps us to determine where to focus the development and what is the uptake for each release of PMM. Specifically, gathering this information helps determine if we need to release patches to legacy versions beyond support, determine when supporting a particular version is no longer necessary, and understand the best frequency of releases.</p> <p>PMM Telemetry is based on data collected by various PMM components and stored inside PMM server</p> <p>When PMM is installed, telemetry is not sent immediately. Before the first telemetry report is generated, PMM provides users with a 24-hour grace period to disable telemetry.</p> <p>To see the metrics being collected by telemetry, from the main menu navigate to  Configuration \u2192 Settings \u2192 Advanced Settings \u2192 Telemetry and hover over the exclamation mark.</p> <p></p> <p>We do not gather anything that can identify your system, but consider the following:</p> <ol> <li> <p>The Country Code is evaluated from the submitting IP address before being discarded.</p> </li> <li> <p>We do create an \u201cinstance ID\u201d - a random string generated using UUID v4.  This instance ID is generated to distinguish new instances from existing ones, for figuring out instance upgrades.</p> </li> </ol> <p>The first telemetry reporting of a new PMM Server instance is delayed by 24 hours to allow enough time to disable the service for those that do not wish to share any information.</p> <p>The landing page for this service, check.percona.com, explains what this service is.</p> <p>Grafana\u2019s anonymous usage statistics is not managed by PMM. To activate it, you must change the PMM Server container configuration after each update.</p> <p>As well as via the PMM Settings page, you can also disable telemetry with the <code>-e DISABLE_TELEMETRY=1</code> option in your docker run statement for the PMM Server.</p> <p>For information on the various config parameters for telemetry, see the config file.</p>"},{"location":"how-to/configure.html#check-for-updates","title":"Check for updates","text":"<p>When active, PMM will automatically check for updates and put a notification in the home page Updates dashboard if any are available.</p>"},{"location":"how-to/configure.html#advisors","title":"Advisors","text":"<p>Advisors are sets of checks grouped by functionality that run a range of database health checks on a registered PMM instance.</p> <p>The findings are reported on the Advisors &gt; Advisor Insights page, and an overview is displayed on the Home dashboard.</p> <p>The Advisors option is enabled by default.  Checks are re-fetched and rerun at intervals.</p> <p>See Working with Advisor checks.</p>"},{"location":"how-to/configure.html#percona-alerting","title":"Percona Alerting","text":"<p>Enables Percona Alerting and reveals the Percona templated alerts option on the Alerting page.</p>"},{"location":"how-to/configure.html#backup-management","title":"Backup Management","text":"<p>Enables Backup Management option and reveals the Backup page from where you can:</p> <ul> <li>Create and restore MongoDB and MySQL backups</li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"how-to/configure.html#public-address","title":"Public address","text":"<p>The address or hostname PMM Server will be accessible at. Click Get from browser to have your browser detect and populate this field automatically.</p>"},{"location":"how-to/configure.html#database-as-a-service-dbaas","title":"Database as a Service (DBaaS)","text":"<p>Caution</p> <p>DBaaS functionality is a technical preview that must be turned on with a server feature flag. See DBaaS.</p> <p>Enables/disables DBaaS features on this server.</p> <p>Important</p> <p>Deactivating DBaaS does not suspend or remove running DB clusters.</p>"},{"location":"how-to/configure.html#microsoft-azure-monitoring","title":"Microsoft Azure monitoring","text":"<p>Caution</p> <p>This is a technical preview feature.</p> <p>Activates Microsoft Azure monitoring.</p>"},{"location":"how-to/configure.html#ssh-key","title":"SSH Key","text":"<p>This section lets you upload your public SSH key to access the PMM Server via SSH (for example, when accessing PMM Server as a virtual appliance).</p> <p></p> <p>Enter your public key in the SSH Key field and click Apply SSH Key.</p>"},{"location":"how-to/configure.html#alertmanager-integration","title":"Alertmanager integration","text":"<p>Alertmanager manages alerts, de-duplicating, grouping, and routing them to the appropriate receiver or display component.</p> <p>This section lets you configure how VictoriaMetrics integrates with an external Alertmanager.</p> <p>Tip</p> <p>If possible, use Integrated Alerting instead of Alertmanager.</p> <ul> <li>The Alertmanager URL field should contain the URL of the Alertmanager which would serve your PMM alerts.</li> <li>The Prometheus Alerting rules field is used to specify alerting rules in the YAML configuration format.</li> </ul> <p>Fill in both fields and click the Apply Alertmanager settings button to proceed.</p>"},{"location":"how-to/configure.html#percona-platform","title":"Percona Platform","text":"<p>This is where you connect your PMM server to your Percona Platform Account.</p> <p>To learn how to connect your PMM servers to Percona Platform and leverage Platform services that boost the monitoring capabilities of your PMM installations, see Integrate PMM with Percona Platform.</p> <p>Your Percona Platform Account is separate from your PMM User account.</p>"},{"location":"how-to/extend-metrics.html","title":"Extend Metrics","text":"<p>When you need a metric that\u2019s not present in the default list of <code>node_exporter</code> metrics you may be able to use the <code>textfile</code> collector. The textfile collector allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has.</p>"},{"location":"how-to/extend-metrics.html#enable-the-textfile-collector","title":"Enable the textfile collector","text":"<p>The collector is enabled by default. The following folders are used for different resolutions:</p> Resolution Folder High <code>/usr/local/percona/pmm2/collectors/textfile-collector/high-resolution</code> Medium <code>/usr/local/percona/pmm2/collectors/textfile-collector/medium-resolution</code> Low <code>/usr/local/percona/pmm2/collectors/textfile-collector/low-resolution</code> <p></p> <p>The exporter parses all files in these directories that match the filename wildcard expression <code>*.prom</code> using a simple text-based exposition format. Metrics are stored on the PMM Server-side with additional labels related to this Node.</p>"},{"location":"how-to/extend-metrics.html#examples-of-shell-commands-for-custom-metrics","title":"Examples of shell commands for custom metrics","text":"<p>To statically set roles for a machine using labels:</p> <pre><code>echo 'node_role{role=\"my_monitored_server_1\"} 1' &gt; /usr/local/percona/pmm2/collectors/textfile-collector/low-resolution/node_role.prom\n</code></pre> <p>Here\u2019s an example of a <code>cron</code> job that automatically pushes logged-in users:</p> <pre><code>$ cat /etc/cron.d/loggedin_users\n*/1 * * * *     root    /usr/bin/who | /usr/bin/wc -l | sed -ne 's/^/node_loggedin_users /p' &gt; /usr/local/percona/pmm2/collectors/textfile-collector/high-resolution/node_users.prom\n</code></pre> <p></p>"},{"location":"how-to/integrate-platform.html","title":"Integrate PMM with Percona Platform","text":"<p>Percona Platform brings together database distributions, support expertise, services, management, and automated insights.</p> <p>Connect your PMM servers to Percona Platform to boost the monitoring capabilities of your PMM installations and manage database deployments easier. In addition, you get access to PMM updates, automated insights, advanced advisor checks and more alert rule templates.</p>"},{"location":"how-to/integrate-platform.html#connect-pmm-to-percona-platform","title":"Connect PMM to Percona Platform","text":"<p>You can connect to Percona Platform with a Percona Account or via Google or GitHub authentication. If Percona Support has enabled a custom identity provider for your account, you can also log in using your company\u2019s credentials.</p> <p>We recommend that you connect with a Percona Account, as this gives you access to other Percona services, including Percona Platform, Percona Customer Portal, and Community Forum. If you don\u2019t have a Percona Account, you can create one on the Percona Platform homepage using the Don\u2019t have an account? Create one? link.</p>"},{"location":"how-to/integrate-platform.html#prerequisites","title":"Prerequisites","text":"<p>To ensure that PMM can establish a connection to Percona Platform:</p>"},{"location":"how-to/integrate-platform.html#upgrade-to-pmm-2270-or-later","title":"Upgrade to PMM 2.27.0 or later","text":"<p>Before connecting your PMM server to Percona Platform, make sure you are using PMM version 2.27 or newer. Otherwise, upgrade your PMM installation beforehand.</p> <p>This is required because, starting with PMM 2.27, Percona Platform has replaced username/password authentication with access token authentication. Access-token authentication increases security and enables federated identity.</p> <p>This change did not affect existing connections to PMM Platform, which were not automatically terminated.</p> <p>For more information, see Install and set up PMM.</p>"},{"location":"how-to/integrate-platform.html#check-that-you-are-a-member-of-an-existing-platform-organization","title":"Check that you are a member of an existing Platform organization","text":"<ol> <li> <p>Log in to Percona Platform using your Percona Account. If you are connecting via GitHub, make sure you set your email address as public in your GitHub account. If your email address is private instead, Percona Platform cannot access it to authenticate you.</p> </li> <li> <p>On the Getting Started page, check that the Create organization step shows an option to view your organization.</p> </li> </ol> <p>Contact your account administrator or create a new organization for your Percona Account if this is the case.</p>"},{"location":"how-to/integrate-platform.html#set-the-public-address-of-your-pmm-server","title":"Set the public address of your PMM server","text":"<p>PMM automatically detects and populates the public address of the PMM server when this is not set up.  If you need to set it differently, go to Settings &gt; Advanced Settings and edit the  Public Address field.</p>"},{"location":"how-to/integrate-platform.html#connect-pmm-to-percona-platform_1","title":"Connect PMM to Percona Platform","text":"<p>To connect your PMM server to Percona Platform, copy your personal access token from Platform Portal and paste it into PMM. You will find your access token in Platform Portal as part of your user profile page.</p>"},{"location":"how-to/integrate-platform.html#token-validity","title":"Token validity","text":"<p>For security reasons, access tokens expire after 30 minutes. Make sure to paste the code before that, or generate a new one if it expires.</p> <p>To connect your PMM server to Percona Platform:</p> <ol> <li> <p>In PMM, go to Settings &gt; Percona Platform tab to fill in the Connect PMM to Percona Portal form: </p> </li> <li> <p>The PMM server ID field is automatically populated with the ID identified for your PMM instance. Enter the name of your PMM instance and click Get token to go to Percona Platform Portal and generate your access token.</p> </li> <li>Log into Percona Platform using your Percona Account (if you don\u2019t have an active current session).</li> <li>On the Profile Settings page, copy the code from the Percona Platform Access Token field.</li> <li>Back into PMM, paste the Access Token into the Percona Platform Access Token field, and click  Connect.</li> </ol> <p>To confirm that you have successfully connected the server and check the list of all servers currently connected to an organization, go to Percona Platform &gt; Dashboard tab and click View Instances next to the Connect your PMM step.</p>"},{"location":"how-to/integrate-platform.html#check-percona-portal-entitlements","title":"Check Percona Portal entitlements","text":"<p>After connecting to the Percona Platform, PMM has access to additional alert templates, Advisor checks, and account information. See Check Percona Portal account information.</p>"},{"location":"how-to/integrate-platform.html#disconnect-a-pmm-instance","title":"Disconnect a PMM instance","text":"<p>Disconnect a PMM instance when you want to unlink it from your Percona Platform organization or stop monitoring it there.</p> <p>To disconnect a PMM server, go to  Configuration &gt; Settings &gt; Percona Platform and click Disconnect.</p>"},{"location":"how-to/integrate-platform.html#disconnecting-instances-as-an-admin","title":"Disconnecting instances as an Admin","text":"<p>In situations where you are not able to disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>Availability</p> <p>This feature is available starting with PMM 2.29.0.</p> <p>If you cannot disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you are a PMM Admin, you can terminate any connections to Percona Platform, even if you are not logged into PMM with a Percona Account. However, we recommend logging in with a Percona Account before disconnecting servers, as this will automatically remove the disconnected servers from Percona Platform as well. </p> <p>If you do disconnect servers without being connected with a Percona Account, you\u2019ll have to manually remove the unavailable servers from Percona Platform. This ensures that your list of connected PMM instances stays up-to-date in Percona Platform. </p> <p>To do this, go to PMM instances, and remove any servers that you have already disconnected from PMM.</p>"},{"location":"how-to/integrate-platform.html#sign-into-pmm-with-your-percona-account","title":"Sign into PMM with your Percona Account","text":"<p>Once you\u2019ve successfully connected your PMM instance to the Percona Platform, you can also sign into PMM using your Percona Account:</p> <ol> <li>Log out of your existing PMM session.</li> <li>On the PMM login screen, click Sign in with Percona Account.  If you have an active Percona Account session on the same browser, PMM will log you in automatically. Otherwise, enter your Percona Account credentials to start a new session.</li> </ol>"},{"location":"how-to/manage-users.html","title":"Manage users","text":"<p>This topic explains user management in PMM.</p> <p>You can manage users from the main menu by navigating to Server Admin \u2192 Users page.</p> <p></p>"},{"location":"how-to/manage-users.html#add-users","title":"Add users","text":"<p>You can add a user in PMM from User \u2192 New user tab.</p> <p></p> <p>To add a new user in PMM:</p> <ol> <li>On the Users tab, click New user.</li> <li> <p>On the Add new user dialog box, enter the following:</p> <ul> <li>Name</li> <li>email address or username (if this is an existing grafana user)</li> <li>Username</li> <li>Password</li> </ul> </li> <li> <p>Click create user.</p> </li> </ol>"},{"location":"how-to/manage-users.html#edit-users","title":"Edit users","text":"<p>You can edit users by changing the information or settings for an individual user account.</p> <p>Important</p> <p>After changing the default admin password for the PMM server, register the pmm-agent using the same credentials and add the services again. Otherwise, PMM will cease to monitor the service/nodes.</p>"},{"location":"how-to/manage-users.html#grant-or-revoke-admin-privileges","title":"Grant or Revoke admin privileges","text":"<p>You can grant or revoke admin access to a user as follows:</p> <ol> <li> <p>On the Users tab, click the user account you want to edit.</p> </li> <li> <p>To grant or revoke the privileges, click the user. User information dialog box opens.</p> </li> <li> <p>In the Permissions section, click Change and then select Yes/No, depending on whether you want to provide admin access or not.</p> </li> <li> <p>Click Change.</p> </li> </ol> <p>Important</p> <p>After connecting your PMM instance to the Percona Platform, when you log in using your Percona account, you will be granted the Viewer access. For Admin access, log in to PMM as an admin, and change the permissions for this user.</p>"},{"location":"how-to/manage-users.html#change-organization-role","title":"Change organization role","text":"<p>You can change the organization role assigned to your user account.</p> <p></p> <p>To change the role:</p> <ol> <li> <p>On the Users tab, click the user for whom you want to change the role.</p> </li> <li> <p>In the Organisations section, click Change role.</p> </li> <li> <p>Select the role from the drop-down and click save.</p> </li> </ol> <p>The following are the privileges for the various roles:</p> <ul> <li> <p>Admin - Managing data sources, teams, and users within an organization.</p> </li> <li> <p>Editor - Creating and editing dashboards.</p> </li> <li> <p>Viewer - Viewing dashboards.</p> </li> </ul> <p>For detailed information on the privileges for these roles and the different tasks that they can perform, refer to: Grafana organization roles.</p>"},{"location":"how-to/manage-users.html#delete-users","title":"Delete Users","text":"<p>You can delete a user in PMM as follows:</p> <ol> <li> <p>On the User tab, click the user you want to delete.</p> </li> <li> <p>Click Delete user.</p> </li> </ol>"},{"location":"how-to/optimize.html","title":"Optimize","text":""},{"location":"how-to/optimize.html#improving-pmm-performance-with-table-statistics-options","title":"Improving PMM Performance with Table Statistics Options","text":"<p>If a MySQL instance has a lot of schemas or tables, there are two options to help improve the performance of PMM when adding instances with <code>pmm-admin add</code>:</p> <ul> <li><code>--disable-tablestats</code>, or,</li> <li><code>--disable-tablestats-limit</code>.</li> </ul> <p>Important</p> <ul> <li>These settings are only for adding an instance. To change them, you must remove and re-add the instances.</li> <li>Only one of these options can be used when adding an instance.</li> </ul>"},{"location":"how-to/optimize.html#disable-per-table-statistics-for-an-instance","title":"Disable per-table statistics for an instance","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats</code> option disables table statistics collection when there are more than the default number (1000) of tables in the instance.</p>"},{"location":"how-to/optimize.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats\n</code></pre>"},{"location":"how-to/optimize.html#change-the-number-of-tables-beyond-which-per-table-statistics-is-disabled","title":"Change the number of tables beyond which per-table statistics is disabled","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats-limit</code> option changes the number of tables (from the default of 1000) beyond which per-table statistics collection is disabled.</p>"},{"location":"how-to/optimize.html#usage_1","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats-limit=&lt;LIMIT&gt;\n</code></pre>"},{"location":"how-to/optimize.html#example","title":"EXAMPLE","text":"<p>Add a MySQL instance, disabling per-table statistics collection when the number of tables in the instance reaches 2000.</p> <pre><code>pmm-admin add mysql --disable-tablestats-limit=2000\n</code></pre>"},{"location":"how-to/secure.html","title":"Secure","text":"<p>By Default, PMM ships with a self-signed certificate to enable usage out of the box.  While this does enable users to have encrypted connections between clients (database clients and web/API clients) and the PMM server, it shouldn\u2019t be considered a properly secured connection.  Taking the following precautions will ensure that you are truly secure:</p> <ul> <li> <p>SSL encryption with trusted certificates to secure traffic between clients and server;</p> </li> <li> <p>Grafana HTTPS secure cookies</p> </li> </ul>"},{"location":"how-to/secure.html#ssl-encryption","title":"SSL encryption","text":"<p>Valid and trusted SSL certificates are needed to encrypt traffic between the client and server.  Certificates can be purchased online from various sources, or some organizations generate their own trusted certificates.  Regardless of which path you choose for enabling maximum security, the process to secure PMM consists of the following components:</p> <ol> <li> <p>Staging the files in the proper locations:</p> <ul> <li>You can directly mount to a local directory containing the required certificates or</li> <li>You can copy the files to the appropriate directory in your Container|AMI|OVF</li> </ul> </li> <li> <p>Restarting PMM</p> </li> <li>Ensuring the client(s) trust the certificate issuer (Ubuntu | RedHat can get you started but this is somewhat OS specific)</li> </ol> <p>With our Docker, OVF and AMI images, certificates are stored in <code>/srv/nginx</code> and our self-signed certificates are staged there by default.</p>"},{"location":"how-to/secure.html#mounting-certificates","title":"Mounting certificates","text":"<p>For container-based installation, if your certificates are in a directory called <code>/etc/pmm-certs</code> on the container host, run the following to mount that directory in the proper location so that PMM can find it when the container starts:</p> <pre><code>docker run -d -p 443:443 --volumes-from pmm-data \\\n  --name pmm-server -v /etc/pmm-certs:/srv/nginx \\\n  --restart always percona/pmm-server:2\n</code></pre> <ul> <li>All certificates must be owned by root. You can do this with: <code>chown 0:0 /etc/pmm-certs/*</code></li> <li>The mounted certificate directory (<code>/etc/pmm-certs</code> in this example) must contain the files named <code>certificate.crt</code>, <code>certificate.key</code>, <code>ca-certs.pem</code>, and <code>dhparam.pem</code>.</li> <li>For SSL encryption, the container should publish on port 443 instead of 80.</li> </ul>"},{"location":"how-to/secure.html#copying-certificates","title":"Copying certificates","text":"<p>If PMM Server is running as a Docker image, use <code>docker cp</code> to copy certificates. This example copies certificate files from the current working directory to a running PMM Server docker container.</p> <pre><code>docker cp certificate.crt pmm-server:/srv/nginx/certificate.crt\ndocker cp certificate.key pmm-server:/srv/nginx/certificate.key\ndocker cp ca-certs.pem pmm-server:/srv/nginx/ca-certs.pem\ndocker cp dhparam.pem pmm-server:/srv/nginx/dhparam.pem\ndocker exec -it pmm-server chown root.root /srv/nginx/*\n</code></pre>"},{"location":"how-to/secure.html#use-trusted-ssl-when-connecting-pmm-client-to-pmm-server","title":"Use trusted SSL when connecting PMM Client to PMM Server","text":"<p>For the new trusted certificates to take effect, you\u2019ll just need to restart the PMM server (or advanced users can restart just nginx from a shell: supervisorctl restart nginx). </p> <p>You can now register clients to the PMM Server using the following: <pre><code>pmm-admin config --server-url=https://&lt;user&gt;:&lt;password&gt;@&lt;server IP&gt;\n</code></pre></p> <p>Remember</p> <p>Your client machine(s) must trust the issuer of the certificate, or you will still see \u201cuntrusted connections\u201d messages when accessing the web interface. Thus, your client will need the <code>--server-insecure-tls</code> parameter when running the <code>pmm-admin config</code> command. Follow the instructions on your operating system to install the issuer certificate (ca-certs.pem). </p> <p>In case of pmm-client running in the container, mount certificates to <code>/etc/pki/tls/certs</code>:</p> <pre><code>PMM_SERVER=X.X.X.X:443\ndocker run \\\n--rm \\\n--name pmm-client \\\n-e PMM_AGENT_SERVER_ADDRESS=${PMM_SERVER} \\\n-e PMM_AGENT_SERVER_USERNAME=admin \\\n-e PMM_AGENT_SERVER_PASSWORD=admin \\\n-e PMM_AGENT_SETUP=1 \\\n-e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n-v /your_directory_with/certs:/etc/pki/tls/certs \\\n--volumes-from pmm-client-data \\\npercona/pmm-client:2\n</code></pre>"},{"location":"how-to/secure.html#grafana-https-secure-cookies","title":"Grafana HTTPS secure cookies","text":"<p>To enable:</p> <ol> <li> <p>Start a shell within the Docker container.</p> <pre><code>docker exec -it pmm-server bash\n</code></pre> </li> <li> <p>Edit <code>/etc/grafana/grafana.ini</code>.</p> </li> <li> <p>Enable <code>cookie_secure</code> and set the value to <code>true</code>.</p> </li> <li> <p>Restart Grafana.</p> <pre><code>supervisorctl restart grafana\n</code></pre> </li> </ol>"},{"location":"how-to/share-dashboard.html","title":"Share dashboards and panels","text":"<p>When you need to share a dashboard with your team members, you can either send them a direct link to the dashboard, or render and send each panel as a .PNG image.</p>"},{"location":"how-to/share-dashboard.html#share-panel-as-direct-link","title":"Share panel as direct link","text":"<ol> <li>Go to the dashboard with the panel that you want to share.</li> <li> <p>Click at the top of the panel to display the panel menu:     </p> </li> <li> <p>Select Share to reveal the Share Panel window and either:</p> <ul> <li>copy and send the full URL for the dashboard, OR</li> <li>toggle the Shorten URL option to generate a simple link with a unique identifier</li> </ul> </li> </ol> <p>Tip</p> <p>If your current domain is different than the one specified in the Grafana .INI configuration file, PMM will ask you to correct this mismatch before you can generate a short URL.</p>"},{"location":"how-to/share-dashboard.html#share-a-panel-as-a-png-file","title":"Share a panel as a PNG file","text":"<p>To enable image rendering:</p> <ol> <li> <p>Deploy the Grafana Image Renderer container alongside PMM Server:</p> <pre><code>docker run -d \\\n--name renderer \\\n-e IGNORE_HTTPS_ERRORS=true \\\ngrafana/grafana-image-renderer:latest\n</code></pre> </li> <li> <p>Stop your existing PMM Server container:</p> <pre><code>docker stop pmm-server\ndocker rm pmm-server\n</code></pre> </li> <li> <p>Start a new PMM Server container with the <code>GF_RENDERING_SERVER_URL</code> and <code>GF_RENDERING_CALLBACK_URL</code> environment variables. For example:</p> <pre><code>docker run -d \\\n--name pmm-server \\\n-p 443:443 \\\n--volumes-from pmm-data \\   \n-e GF_RENDERING_SERVER_URL=http://renderer:8081/render \\\n-e GF_RENDERING_CALLBACK_URL=https://pmm-server:443/graph/ \\\npercona/pmm-server:2\n</code></pre> </li> </ol>"},{"location":"how-to/share-dashboard.html#render-panel-image","title":"Render panel image","text":"<p>To Render a panel image:</p> <ol> <li>Go to the dashboard with the panel that you want to share.</li> <li>Click at the top of the panel to display the panel menu.</li> <li>Select Share to reveal the Share Panel window.</li> <li>In the Link tab, click Direct link rendered image. This opens a new browser tab.</li> <li>Wait for the image to be rendered, then use your browser\u2019s Image Save function to download the image. </li> </ol>"},{"location":"how-to/troubleshoot.html","title":"Resolve issues","text":"<p>This section describes solutions to common problems and scenarios you might encounter while using PMM.</p>"},{"location":"how-to/troubleshoot.html#troubleshooting-checklist","title":"Troubleshooting checklist","text":"<p>The following questions might help you identify the origin of the problem while using Percona Monitoring and Management:</p> <ol> <li>Are you using the latest PMM version?</li> <li>Did you check the known issues section in the Release Notes for that particular PMM release?</li> <li>Are you receiving any error messages?</li> <li>Do the logs contain any messages about the problem? See Message logs and Trace logs for more information.</li> <li>Does the problem occur while configuring PMM, such as:<ul> <li>Does the problem occur while you configure a specific function?</li> <li>Does the problem occur when you perform a particular task?</li> </ul> </li> <li>Are you using the recommended authentication method?</li> <li>Does your system\u2019s firewall allow TCP traffic on the ports used by PMM?</li> <li>Have you allocated enough disk space for installing PMM? If not, check the disk allocation space.</li> <li>Are you using a Technical Preview feature? Technical Preview features are not production-ready and should only be used in testing environments. For more information, see the relevant Release Notes.</li> <li>For installing the PMM client, are you using a package other than a binary package without root permissions?</li> <li>Is your PMM Server installed and running with a known IP address accessible from the client node?</li> <li>Is the PMM Client installed, and is the node registered with PMM Server?</li> <li>Is PMM-client configured correctly and has access to the config file?</li> <li>For monitoring MongoDB, do you have adminUserAnyDatabase or superuser role privilege to any database servers you want to monitor?</li> <li>For monitoring Amazon RDS using PMM, is there too much latency between PMM Server and the Amazon RDS instance?</li> <li>Have you upgraded the PMM Server before you upgraded the PMM Client? If yes, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> <li>Is the PMM Server version higher than or equal to the PMM Client version? Otherwise, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> </ol>"},{"location":"how-to/troubleshoot.html#troubleshooting-areas","title":"Troubleshooting areas","text":""},{"location":"how-to/troubleshoot.html#upgrade-issues","title":"Upgrade issues","text":""},{"location":"how-to/troubleshoot.html#pmm-server-not-updating-correctly","title":"PMM server not updating correctly","text":"<p>If the PMM server wasn\u2019t updated correctly, or if you have concerns about the release, you can force the update process in 2 ways:</p> <ol> <li> <p>From the UI - Home panel: click the Alt key on the reload icon in the Update panel to make the Update Button visible even if you are on the same version as available for update. Pressing this button will force the system to rerun the update so that any broken or not installed components can be installed. In this case, you\u2019ll go through the usual update process with update logs and successful messages at the end.</p> </li> <li> <p>By API call (if UI not available): You can call the Update API directly with:</p> <pre><code>curl --user admin:admin --request POST 'http://PMM_SERVER/v1/Updates/Start'\n</code></pre> <p>Replace <code>admin:admin</code> with your username/password, and replace <code>PMM_SERVER</code> with your server address.</p> <p>You will not see the logs using this method.</p> <p>Refresh The Home page in 2-5 minutes, and you should see that PMM was updated.</p> </li> <li> <p>Upgrade PMM server using Docker.</p> </li> </ol>"},{"location":"how-to/troubleshoot.html#pmm-server-not-showing-latest-versions-available-with-the-instances-created-from-aws","title":"PMM server not showing latest versions available with the instances created from AWS","text":"<p>For PMM versions prior to 2.33.0, in specific environments, including AWS, some EPEL repository mirrors did not respond within the time limit defined by <code>pmm-update</code> (currently set to 30 seconds). It was causing supervisord to kill pmm-update-checker, which determines if a newer PMM Server is available for upgrade.</p> <p>Solution</p> <p>Log in to the PMM Server and run the following command as a root user:</p> <pre><code>   $ yum-config-manager --setopt=epel.timeout=1 --save\n</code></pre>"},{"location":"how-to/troubleshoot.html#pmm-server-fails-while-upgrading","title":"PMM server fails while upgrading","text":"<p>A bug in PMM Server ansible scripts caused PMM to upgrade Nginx\u2019s dependencies without updating Nginx itself. Due to this, PMM throws an error while upgrading and cannot upgrade to a newer version. </p> <p>Important</p> <p>This issue has been resolved for PMM version 2.33.0. However, the issue persists on all the versions prior to 2.33.0.</p> <p>Solution</p> <p>While PMM is being upgraded, log in to the PMM server and run the following command:</p> <pre><code>   sed -i 's/- nginx/- nginx*/' /usr/share/pmm-update/ansible/playbook/tasks/update.yml\n</code></pre>"},{"location":"how-to/troubleshoot.html#pmm-cannot-acess-admin-user-after-upgrading","title":"PMM cannot acess admin user after upgrading","text":"<p>After upgrading PMM from version 2.39.0 to 2.40.0 (not el7) using Docker, the <code>admin</code> user cannot access the PMM UI.</p> <p>Solution: To fix the problem and gain back admin access to the PMM interface execute the following:</p> <pre><code># psql -U grafana\ngrafana=&gt; update \"user\" set id='1' where login='admin';\nUPDATE 1\ngrafana=&gt; \\q\n\n# grafana cli --homepath=/usr/share/grafana --config=/etc/grafana/grafana.ini admin reset-admin-password &lt;PASS&gt;\n</code></pre>"},{"location":"how-to/troubleshoot.html#configuration-issues","title":"Configuration issues","text":"<p>This section focuses on configuration issues, such as PMM-agent connection, adding and removing services for monitoring, and so on.</p>"},{"location":"how-to/troubleshoot.html#client-server-connections","title":"Client-server connections","text":"<p>There are many causes of broken network connectivity.</p> <p>The container is constrained by the host-level routing and firewall rules when using using Docker. For example, your hosting provider might have default <code>iptables</code> rules on their hosts that block communication between PMM Server and PMM Client, resulting in DOWN targets in VictoriaMetrics. If this happens, check the firewall and routing settings on the Docker host.</p> <p>PMM can also generate diagnostics data that can be examined and/or shared with our support team to help solve an issue. You can get collected logs from PMM Client using the pmm-admin summary command.</p> <p>Logs obtained in this way include PMM Client logs and logs received from the PMM Server, and stored separately in the <code>client</code> and <code>server</code> folders. The <code>server</code> folder also contains its <code>client</code> subfolder with the self-monitoring client information collected on the PMM Server.</p> <p>Beginning with PMM 2.4.0, there is a flag that enables the fetching of <code>pprof</code> debug profiles and adds them to the diagnostics data. To enable, run <code>pmm-admin summary --pprof</code>.</p>"},{"location":"how-to/troubleshoot.html#accessing-logs-and-pmm-server-data","title":"Accessing logs and PMM Server data","text":"<p>Download logs and components configuration to troubleshoot any issues with the PMM Server:</p> <ol> <li>Through direct URL, by visiting <code>https://&lt;address-of-your-pmm-server&gt;/logs.zip</code>.</li> <li> <p>By calling the Logs endpoint, which enables you to customize the log content using the <code>line-count</code> parameter: For example:</p> </li> <li> <p>Default 50,000 lines: <code>https://&lt;pmm-server&gt;/logs.zip</code></p> </li> <li>Custom number of lines: <code>https://&lt;pmm-server&gt;/logs.zip?line-count=10000</code></li> <li>Unlimited, full log: <code>https://&lt;pmm-server&gt;/logs.zip?line-count=-1</code></li> <li> <p>Through the UI, by selecting the Help &gt; PMM Logs option from the main menu.</p> <p>If you need to share logs with Percona Support via an SFTP server, you can also use the PMM Dump option from the Help menu to generate a compressed tarball file containing a comprehensive export of your PMM metrics and QAN data. For more information, see Export PMM data with PMM Dump topic in the product documentation.</p> </li> </ol>"},{"location":"how-to/troubleshoot.html#connection-difficulties","title":"Connection difficulties","text":"<p>Passwords</p> <p>When adding a service, the host might not be detected if the password contains special symbols (e.g., <code>@</code>, <code>%</code>, etc.).</p> <p>In such cases, you should convert any password, replacing special characters with their escape sequence equivalents.</p> <p>One way to do this is to use the <code>encodeURIComponent</code> JavaScript function in your browser\u2019s web console (commonly found under a Development Tools menu). Run the function with your password as the parameter. For example:</p> <pre><code>&gt; encodeURIComponent(\"s3cR#tpa$$worD\")\n</code></pre> <p>will give:</p> <pre><code>\"s3cR%23tpa%24%24worD\"\n</code></pre> <p>Password change</p> <p>When adding clients to the PMM server, you use the <code>admin</code> user. However, if you change the password for the admin user from the PMM UI, then the clients will not be able to access PMM due to authentication issues. Also, Grafana will lock out the admin user due to multiple unsuccessful login attempts.</p> <p>In such a scenario, use API key for authentication. You can use API keys as a replacement for basic authentication.</p>"},{"location":"how-to/troubleshoot.html#percona-alerting","title":"Percona Alerting","text":""},{"location":"how-to/troubleshoot.html#no-alert-rule-templates-tab-on-the-alerting-page","title":"No Alert rule templates tab on the Alerting page","text":"<p>Percona Alerting option isn\u2019t active.</p> <ol> <li>Go to  Configuration \u2192  Settings \u2192 Advanced Settings.</li> <li>Enable Alerting.</li> </ol>"},{"location":"how-to/troubleshoot.html#custom-alert-rule-templates-not-migrated-to-percona-alerting","title":"Custom alert rule templates not migrated to Percona Alerting","text":"<p>If you have used Integrated Alerting in previous PMM versions, and had custom templates under <code>/srv/ia/templates</code>, make sure to transfer them to <code>/srv/alerting/templates</code>.  PMM is no longer sourcing templates from the <code>ia</code> folder, since we have deprecated Integrated Alerting with the 2.31 release. </p>"},{"location":"how-to/troubleshoot.html#unreachable-external-ip-addresses","title":"Unreachable external IP addresses","text":"<p>If you get an email or page from your system that the IP is not reachable from outside my organization, do the following:</p> <p>To configure your PMM Server\u2019s Public Address, select  Configuration \u2192  Settings \u2192 Advanced Settings, and supply an address to use in your alert notifications.</p>"},{"location":"how-to/troubleshoot.html#alert-rule-templates-are-disabled","title":"Alert Rule Templates are disabled","text":"<p>Built-In alerts are not editable, but you can copy them and edit the copies. (In PMM 2.14.0 and above).</p> <p>If you create a custom alert rule template, you will have access to edit.</p>"},{"location":"how-to/troubleshoot.html#qan-issues","title":"QAN issues","text":"<p>This section focuses on problems with QAN, such as queries not being retrieved so on.</p>"},{"location":"how-to/troubleshoot.html#missing-data","title":"Missing data","text":"<p>Why don\u2019t I see any query-related information?</p> <p>There might be multiple places where the problem might come from:</p> <ul> <li>Connection problem between pmm-agent and pmm-managed</li> <li>PMM-agent cannot connect to the database.</li> <li>Data source is not properly configured.</li> </ul> <p>Why don\u2019t I see the whole query?</p> <p>Long query examples and fingerprints can be truncated to 1024 symbols to reduce space usage. In this case, the query explains section will not work.</p>"},{"location":"how-to/troubleshoot.html#plugins-issues","title":"Plugins issues","text":"<p>PMM does not allow to install, upgrade or remove plugins</p> <p>Users have encountered issues with installing, updating and removing plugins from PMM. The cause of this issue is the incorrect permissions assigned to the <code>/srv/grafana/plugins</code> directory. These permissions are preventing the grafana component from writing to the directory.</p> <p>Solution</p> <p>Set the ownership on the directory<code>/srv/grafana/plugins</code> to <code>grafana:grafana</code>.</p>"},{"location":"how-to/upgrade.html","title":"Upgrade","text":""},{"location":"how-to/upgrade.html#plan-the-upgrade-order","title":"Plan the upgrade order","text":""},{"location":"how-to/upgrade.html#upgrade-pmm-server-first","title":"Upgrade PMM Server first","text":"<p>Make sure to upgrade the PMM Server before you upgrade the PMM Client.</p> <p>Ensure that the PMM Server version is higher than or equal to the PMM Client version. Otherwise, there might be configuration issues, thus leading to failure in the client-server communication as PMM Server might not be able to identify all the parameters in the configuration.</p> <p>For example, for a PMM Server version 2.25.0, the PMM Client version should be 2.25.0 or 2.24.0. If the PMM Client version is 2.26.0, PMM might not work as expected.</p>"},{"location":"how-to/upgrade.html#staged-upgrade-approach","title":"Staged upgrade approach","text":"<p>When upgrading PMM from older versions (2.30.0 and below), we recommend following a staged approach: first, upgrade to version 2.33.0, and then proceed to the latest version. </p> <p>This sequential upgrading process ensures that PMM\u2019s internal components are migrated and updated correctly.</p>"},{"location":"how-to/upgrade.html#update-the-server","title":"Update the Server","text":"<p>Known issues for older versions</p> <ul> <li> <p>Upgrading to PMM 2.32.0 from older versions fails. We recommend upgrading directly to 2.33 or the latest version. For more information, see the troubleshooting topic.</p> </li> <li> <p>PMM versions prior to 2.33.0 may not show the latest versions available with instances created from the AWS marketplace in specific environments, including AWS. For a solution, see the troubleshooting section.</p> </li> </ul> <p>Client and server components are installed and updated separately.</p> <p>PMM Server can run natively, as a Docker image, a virtual appliance, or an AWS cloud instance. Each has its own installation and update steps.</p> <p>The preferred and simplest way to update PMM Server is with the PMM Upgrade panel on the Home page.</p> <p></p> <p>The panel shows:</p> <ul> <li>the current server version and release date;</li> <li>whether the server is up to date;</li> <li>the last time a check was made for updates.</li> </ul> <p>Click the refresh button to manually check for updates. If an update is available, click the Update button to install the indicated version.</p> <p>See also</p> <p>PMM Server Docker upgrade</p>"},{"location":"how-to/upgrade.html#updating-a-pmm-agent","title":"Updating a PMM-Agent","text":"<p>There are two primary methods to update the PMM Agent, depending on your initial installation method:</p> <ol> <li>Using your operating system\u2019s package manager.</li> <li>Updating from a tarball.</li> </ol>"},{"location":"how-to/upgrade.html#package-manager-method","title":"Package Manager method","text":"<p>The package manager method is generally more convenient and efficient. Percona provides the percona-release package, which helps you install Percona software, including the PMM Agent. The PMM Agent is available from the <code>pmm-client</code> repository.</p> <p>To deploy a new version of the Agent via package manager, simply replace the currently installed package with the latest version of the PMM Agent or with a specific version.</p>"},{"location":"how-to/upgrade.html#install-the-latest-pmm-agent-version","title":"Install the latest PMM Agent version","text":"<p>Run the commands below to install the latest PMM Agent version via package manager and keep your existing Agent configuration during the update process.</p> Debian-basedRed Hat-based <pre><code>percona-release enable pmm2-client\napt update\napt install pmm2-client\n</code></pre> <pre><code>percona-release enable pmm2-client\nyum update pmm2-client\n</code></pre>"},{"location":"how-to/upgrade.html#deploy-a-specific-version","title":"Deploy a specific version","text":"<p>To deploy a specific version of the PMM Agent via package manager, check the available versions and then provide the full name of the package. For example:</p> Red Hat-basedDebian-based <pre><code> yum --showduplicates search pmm2-client\n pmm2-client-2.41.1-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\n pmm2-client-2.41.2-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\n pmm2-client-2.42.0-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\n\n yum update pmm2-client-2.41.2-6.el9.x86_64\n</code></pre> <pre><code>apt-cache madison pmm2-client\npmm2-client | 2.42.0-6.focal | http://repo.percona.com/pmm2-client/apt focal/main amd64 Packages\npmm2-client | 2.41.2-6.focal | http://repo.percona.com/pmm2-client/apt focal/main amd64 Packages\npmm2-client | 2.41.1-6.focal | http://repo.percona.com/pmm2-client/apt focal/main amd64 Packages\n\napt install pmm2-client=2.42.0-6.focal\n</code></pre>"},{"location":"how-to/upgrade.html#tarball-method","title":"Tarball method","text":"<p>If you initially installed the PMM Agent from a tarball, you can update it by replacing the currently installed package with the latest version:</p> <ol> <li>Download <code>tar.gz</code> with <code>pmm2-client</code>.</li> <li>Extract the tarball.</li> <li>Run <code>./install_tarball</code> script with the <code>-u</code> flag.</li> </ol> <p>Important</p> <p>The configuration file will be overwritten if you do not provide the <code>-u</code> flag while the <code>pmm-agent</code> is updated.</p>"},{"location":"how-to/upgrade.html#upgrade-from-pmm-1","title":"Upgrade from PMM 1","text":"<p>Because of the significant architectural changes between PMM1 and PMM2, there is no direct upgrade path. The approach to making the switch from PMM version 1 to 2 is a gradual transition, outlined in this blog post.</p> <p>In short, it involves first standing up a new PMM2 server on a new host and connecting clients to it. As new data is reported to the PMM2 server, old metrics will age with the retention period (30 days, by default), at which point you\u2019ll be able to shut down your existing PMM1 server.</p> <p>Any alerts configured through the Grafana UI will have to be recreated due to the target dashboard id\u2019s not matching between PMM1 and PMM2.  In this instance we recommend moving to Alertmanager recipes in PMM2 for alerting which, for the time being, requires a separate Alertmanager instance. We are working on integrating this natively into PMM2 Server and expect to support your existing Alertmanager rules.</p>"},{"location":"quickstart/index.html","title":"Get started with PMM","text":"<p>To get up and running with Percona Monitoring and Management (PMM) in no time, install PMM on Bare Metal/Virtual using the Easy-install script for Docker.</p> <p>This is the simplest and most efficient way to install PMM.</p> Alternative installation options <p>For alternative setups, explore the additional installation options detailed in the Setting up chapter:</p> <ul> <li>Deploy on Podman</li> <li>Deploy based on a Docker image</li> <li>Deploy on Virtual Appliance</li> <li>Deploy on Kubernetes via Helm</li> <li>Run a PMM instance hosted at AWS Marketplace</li> </ul>"},{"location":"quickstart/index.html#prerequisites","title":"Prerequisites","text":"<p>Before you start installing PMM, verify that your system meets the compatibility requirements.</p> Verify system compatibility <ul> <li>Disk: Approximately 1 GB of storage per monitored database node with data retention set to one week. By default, retention is 30 days.</li> <li>Memory: A minimum of 2 GB per monitored database node. The increase in memory usage is not proportional to the number of nodes. For example, the data from 20 nodes should be easily handled with 16 GB.</li> <li>Ports: Your system\u2019s firewall should allow TCP traffic on port 443.</li> </ul>"},{"location":"quickstart/index.html#install-pmm","title":"Install PMM","text":"<p>The Easy-install script only runs on Linux-compatible systems. To use it, run the command with <code>sudo</code> privileges or as <code>root</code>:</p> <ol> <li> <p>Download and install PMM using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>curl -fsSL https://www.percona.com/get/pmm2 | /bin/bash\n</code></pre> <pre><code>wget -qO - https://www.percona.com/get/pmm2 | /bin/bash    \n</code></pre> </li> <li> <p>After the installation is complete, log into PMM with the default <code>admin:admin</code> credentials.</p> </li> </ol> What\u2019s happening under the hood? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not installed on your system.</li> <li>Stops and renames any currently running PMM Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old <code>pmm-server</code> container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Docker image.</li> </ul>"},{"location":"quickstart/index.html#connect-database","title":"Connect database","text":"<p>Once PMM is set up, choose the database or the application that you want it to monitor:</p>  MySQL PostgreSQL MongoDB ProxySQL HAProxy <p>To connect a self-hosted MySQL database:</p> <ol> <li> <p>Create database account for PMM using the following command example. This creates a database user with name <code>pmm</code>, password <code>&lt;your_password&gt;</code>, and the necessary permissions:</p> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY '&lt;your_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:    </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install the Percona Release Tool.  If this is already, make sure to update it to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm2-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version.</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm2-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MySQL database using Performance Schema:  </p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> Alternative database connection workflows <p>While the default instructions above focus on connecting a self-hosted MySQL database, PMM offers the flexibility to connect to various MySQL databases, including AWS RDS, Azure MySQL or Google Cloud MySQL. </p> <p>The PMM Client installation also comes with options: in addition to the installation via Package Manager described above, you can also install it as a Docker container or as a binary package. Explore alternative PMM Client installation options for more information.</p> <p>Additionally, if direct access to the database node isn\u2019t available, opt to Add remote instance via User Interface instead. </p> <p>To connect a PostgreSQL database: </p> <ol> <li> <p>Create a PMM-specific user for monitoring:</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '&lt;your_password&gt;';\n</code></pre> </li> <li> <p>Ensure that PMM can log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If  not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> </li> <li> <p>Set up the <code>pg_stat_monitor</code> database extension and configure your database server accordingly. </p> <p>If you need to use the <code>pg_stat_statements</code> extension instead, see Adding a PostgreSQL database and the <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Set or change the value for <code>shared_preload_library</code> in your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> </li> <li> <p>Set up configuration values in your <code>postgresql.conf</code> file:</p> <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre> </li> <li> <p>In a <code>psql</code> session, run the following command to create the view where you can access the collected statistics. We recommend that you create the extension for the <code>postgres</code> database so that you can receive access to statistics from each database.</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:  </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm2-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm2-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the PostgreSQL database:</p> <pre><code>pmm-admin add postgresql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions and advanced installation options, see Adding a PostgreSQL database.</p> <p>To connect a MongoDB database:</p> <ol> <li> <p>Run the following command in <code>mongo</code> shell to create a role with the monitoring permissions: </p> <pre><code>db.createRole({\n    \"role\":\"explainRole\",\n    \"privileges\":[\n        {\n            \"resource\":{\n                \"db\":\"\",\n                \"collection\":\"\"\n            },\n            \"actions\":[\n                \"collStats\",\n                \"dbHash\",\n                \"dbStats\",\n                \"find\",\n                \"listIndexes\",\n                \"listCollections\"\n            ]\n        }\n    ],\n    \"roles\":[]\n})\n</code></pre> </li> <li> <p>Create a user and grant it the role created above:</p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\":\"pmm\",\n    \"pwd\":\"&lt;your_password&gt;\",\n    \"roles\":[\n        {\n            \"role\":\"explainRole\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"clusterMonitor\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"read\",\n            \"db\":\"local\"\n        }\n    ]\n})\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm2-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm2-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MongoDB database:</p> <pre><code>pmm-admin add mongodb --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Adding a MongoDB database for monitoring.</p> <p>To connect a ProxySQL service:</p> <ol> <li> <p>Configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL.</p> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm2-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm2-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the ProxySQL service:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Enable ProxySQL performance metrics monitoring.</p> <p>To connect an HAProxy service:</p> <ol> <li>Set up an HAproxy instance. </li> <li>Add the instance to PMM (default address is http://localhost:8404/metrics), and use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node: </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm2-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm2-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Run the command below, specifying the `listen-port`` as the port number where HAProxy is running. (This flag is mandatory.)</p> <pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> </li> </ol> <p>For detailed instructions and more information on the command arguments, see the HAProxy topic.</p>"},{"location":"quickstart/index.html#check-database-monitoring-results","title":"Check database monitoring results","text":"<p>After installing PMM and connecting the database, go to the database\u2019s Instance Summary dashboard. This shows essential information about your database performance and an overview of your environment.</p> <p>For more information, see PMM Dashboards.</p>"},{"location":"quickstart/index.html#next-steps","title":"Next steps","text":"<ul> <li>Configure PMM via the interface</li> <li>Manage users in PMM</li> <li>Set up roles and permissions</li> <li>Back up and restore data in PMM</li> </ul>"},{"location":"release-notes/index.html","title":"Release Notes","text":"<ul> <li>Percona Monitoring and Management 2.44.0</li> <li>Percona Monitoring and Management 2.43.2</li> <li>Percona Monitoring and Management 2.43.1</li> <li>Percona Monitoring and Management 2.43.0</li> <li>Percona Monitoring and Management 2.42.0</li> <li>Percona Monitoring and Management 2.41.2</li> <li>Percona Monitoring and Management 2.41.1</li> <li>Percona Monitoring and Management 2.41.0</li> <li>Percona Monitoring and Management 2.40.1</li> <li>Percona Monitoring and Management 2.40.0</li> <li>Percona Monitoring and Management 2.39.0</li> <li>Percona Monitoring and Management 2.38.1</li> <li>Percona Monitoring and Management 2.38.0</li> <li>Percona Monitoring and Management 2.37.1</li> <li>Percona Monitoring and Management 2.37.0</li> <li>Percona Monitoring and Management 2.36.0</li> <li>Percona Monitoring and Management 2.35.0</li> <li>Percona Monitoring and Management 2.34.0</li> <li>Percona Monitoring and Management 2.33.0</li> <li>Percona Monitoring and Management 2.32.0</li> <li>Percona Monitoring and Management 2.31.0</li> <li>Percona Monitoring and Management 2.30.0</li> <li>Percona Monitoring and Management 2.29.1</li> <li>Percona Monitoring and Management 2.29.0</li> <li>Percona Monitoring and Management 2.28.0</li> <li>Percona Monitoring and Management 2.27.0</li> <li>Percona Monitoring and Management 2.26.0</li> <li>Percona Monitoring and Management 2.25.0</li> <li>Percona Monitoring and Management 2.24.0</li> <li>Percona Monitoring and Management 2.23.0</li> <li>Percona Monitoring and Management 2.22.0</li> <li>Percona Monitoring and Management 2.21.0</li> <li>Percona Monitoring and Management 2.20.0</li> <li>Percona Monitoring and Management 2.19.0</li> <li>Percona Monitoring and Management 2.18.0</li> <li>Percona Monitoring and Management 2.17.0</li> <li>Percona Monitoring and Management 2.16.0</li> <li>Percona Monitoring and Management 2.15.1</li> <li>Percona Monitoring and Management 2.15.0</li> <li>Percona Monitoring and Management 2.14.0</li> <li>Percona Monitoring and Management 2.13.0</li> <li>Percona Monitoring and Management 2.12.0</li> <li>Percona Monitoring and Management 2.11.1</li> <li>Percona Monitoring and Management 2.11.0</li> <li>Percona Monitoring and Management 2.10.1</li> <li>Percona Monitoring and Management 2.10.0</li> <li>Percona Monitoring and Management 2.9.1</li> <li>Percona Monitoring and Management 2.9.0</li> <li>Percona Monitoring and Management 2.8.0</li> <li>Percona Monitoring and Management 2.7.0</li> <li>Percona Monitoring and Management 2.6.1</li> <li>Percona Monitoring and Management 2.6.0</li> <li>Percona Monitoring and Management 2.5.0</li> <li>Percona Monitoring and Management 2.4.0</li> <li>Percona Monitoring and Management 2.3.0</li> <li>Percona Monitoring and Management 2.2.2</li> <li>Percona Monitoring and Management 2.2.1</li> <li>Percona Monitoring and Management 2.2.0</li> <li>Percona Monitoring and Management 2.1.0</li> <li>Percona Monitoring and Management 2.0.1</li> <li>Percona Monitoring and Management 2.0.0</li> </ul>"},{"location":"release-notes/2.0.0.html","title":"Percona Monitoring and Management 2.0.0","text":"Date: September 19, 2019 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. You can run PMM in your own environment for the best security and reliability. It provides thorough time-based analysis for MySQL, MongoDB, and PostgreSQL servers to ensure that your data works as efficiently as possible.</p> <p>For installation instructions, see Installing Percona Monitoring and Management.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p> <p>The new PMM2 introduces a number of enhancements and additional feature improvements, including:</p> <ul> <li>Detailed query analytics and filtering technologies enable you to identify issues faster than ever before.</li> <li>A better user experience: Service-level dashboards give you immediate access to the data you need.</li> <li>The new addition of PostgreSQL query tuning.</li> <li>Enhanced security protocols to ensure your data is safe.</li> <li>Our new API allows you to extend and interact with third-party tools.</li> </ul> <p>More details about new and improved features available within the release can be found in the corresponding blog post.</p> <p>Help us improve our software quality by reporting any Percona Monitoring and Management bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.0.1.html","title":"Percona Monitoring and Management 2.0.1","text":"Date: October 9, 2019 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. You can run PMM in your own environment for maximum security and reliability. It provides thorough time-based analysis for MySQL, MongoDB, and PostgreSQL servers to ensure that your data works as efficiently as possible.</p> <p>For install instructions, see Installing Percona Monitoring and Management.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p>"},{"location":"release-notes/2.0.1.html#improvements","title":"Improvements","text":"<ul> <li>PMM-4779: Securely share dashboards with Percona</li> <li>PMM-4735: Keep one old slowlog file after rotation</li> <li>PMM-4724: Alt+click on check updates button enables force-update</li> <li>PMM-4444: Return \u201cwhat\u2019s new\u201d URL with the information extracted from the pmm-update package change   log</li> </ul>"},{"location":"release-notes/2.0.1.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-4758: Remove Inventory rows from dashboards</li> <li>PMM-4757: <code>qan_mysql_perfschema_agent</code> failed querying <code>events_statements_summary_by_digest</code> due to data types conversion</li> <li>PMM-4755: Fixed a typo in the InnoDB AHI Miss Ratio formula</li> <li>PMM-4749: Navigation from Dashboards to QAN when some Node or Service was selected now applies filtering by them in QAN</li> <li>PMM-4742: General information links were updated to go to PMM 2 related pages</li> <li>PMM-4739: Remove request instances list</li> <li>PMM-4734: A fix was made for the collecting <code>node_name</code> formula at MySQL Replication Summary dashboard</li> <li>PMM-4729: Fixes were made for formulas on MySQL Instances Overview</li> <li>PMM-4726: Links to services in MongoDB singlestats didn\u2019t show Node name</li> <li>PMM-4720: <code>machine_id</code> could contain trailing <code>\\\\n</code></li> <li>PMM-4640: It was not possible to add MongoDB remotely if password contained a <code>#</code> symbol</li> </ul> <p>Help us improve our software quality by reporting any Percona Monitoring and Management bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.1.0.html","title":"Percona Monitoring and Management 2.1.0","text":"Date: November 11, 2019 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. You can run PMM in your own environment for maximum security and reliability. It provides thorough time-based analysis for MySQL, MongoDB, and PostgreSQL servers to ensure that your data works as efficiently as possible.</p> <p>For install instructions, see Installing Percona Monitoring and Management.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p>"},{"location":"release-notes/2.1.0.html#improvements-and-new-features","title":"Improvements and new features","text":"<ul> <li>PMM-4063: Update QAN filter panel to show only labels available for selection under currently applied filters</li> <li>PMM-815: Latency Detail graph added to the MongoDB Instance Summary dashboard</li> <li>PMM-4768: Disable heavy-load collectors automatically when there are too many tables</li> <li>PMM-4821: Use color gradient in filled graphs on all dashboards</li> <li>PMM-4733: Add more log and configuration files to the downloadable <code>logs.zip</code> archive</li> <li>PMM-4672: Use integer percentage values in QAN filter panel</li> <li>PMM-4857: Update tooltips for all MongoDB dashboards</li> <li>PMM-4616: Rename column in the Query Details section in QAN from Total to Sum</li> <li>PMM-4770: Use Go 1.12.10</li> <li>PMM-4780: Update Grafana to version 6.4.1</li> <li>PMM-4918: Update Grafana plugins to newer versions, including the <code>clickhouse-datasource</code> plugin</li> </ul>"},{"location":"release-notes/2.1.0.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-4935: Wrong instance name displayed on the MySQL Instance Summary dashboard due to the incorrect string crop</li> <li>PMM-4916: Wrong values are shown when changing the time range for the Node Summary Dashboard in case of remote instances</li> <li>PMM-4895 and PMM-4814: The update process reports completion before it is actually done and therefore some dashboards, etc. may not be updated</li> <li>PMM-4876: PMM Server access credentials are shown by the <code>pmm-admin status</code> command instead of hiding them for security reasons</li> <li>PMM-4875: PostgreSQL error log gets flooded with warnings when <code>pg_stat_statements</code> extension is not installed in the database used by PMM Server or when PostgreSQL user is unable to connect to it</li> <li>PMM-4852: Node name has an incorrect value if the Home dashboard opened after QAN</li> <li>PMM-4847: Drill-downs from the Environment Overview dashboard doesn\u2019t show data for the preselected host</li> <li>PMM-4841 and PMM-4845: <code>pg_stat_statement</code> QAN Agent leaks database connections</li> <li>PMM-4831: Clean-up representation of selectors names on MySQL-related dashboards for a better consistency</li> <li>PMM-4824: Incorrectly calculated singlestat values on MySQL Instances Overview dashboard</li> <li>PMM-4819: In case of the only one monitored host, its uptime is shown as a smaller value than the all hosts uptime due to the inaccurate rounding</li> <li>PMM-4816: Set equal thresholds to avoid confusing singlestat color differences on a Home dashboard</li> <li>PMM-4718: Labels are not fully displayed in the filter panel of the Query Details section in QAN</li> <li>PMM-4545: Long queries are not fully visible in the Query Examples section in QAN</li> </ul> <p>Help us improve our software quality by reporting any Percona Monitoring and Management bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.10.0.html","title":"Percona Monitoring and Management 2.10.0","text":"Date: September 15, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.10.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-2045: New dashboard: MySQL Group Replication Summary</li> <li>PMM-5738: Enhanced exporter: replaced original <code>mongodb-exporter</code> with a completely rewritten one with improved functionality</li> <li>PMM-5126: Query Analytics Dashboard: Search by query substring or dimension (Thanks to user <code>debug</code> for reporting this issue)</li> <li>PMM-6360: Grafana Upgrade to 7.1.3</li> <li>PMM-6355: Upgrade Prometheus to 2.19.3</li> <li>PMM-6597: Documentation: Updated Image rendering instructions for PMM</li> <li>PMM-6568: Reusable user interface component: Pop-up dialog.  Allows for more consistent interfaces across PMM</li> <li>PMM-6375, PMM-6373, PMM-6372: Sign in, Sign up and Sign out UI for Percona Account inside PMM Server</li> <li>PMM-6328: Query Analytics Dashboard: Mouse-over crosshair shows value on sparklines</li> <li>PMM-3831: Node Summary Dashboard: Add <code>pt-summary</code> output to dashboard to provide details on system status and configuration</li> </ul>"},{"location":"release-notes/2.10.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6647: MongoDB dashboards: RocksDB Details removed, MMAPv1 &amp; Cluster Summary changed</li> <li>PMM-6536: Query Analytics Dashboard: Improved filter/time search message when no results</li> <li>PMM-6467: PMM Settings: User-friendly error message</li> <li>PMM-5947: Bind services to internal address for containers</li> </ul>"},{"location":"release-notes/2.10.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6336: Suppress sensitive data: honor <code>pmm-admin</code> flag <code>--disable-queryexamples</code> when used in conjunction with <code>--query-source=perfschema</code></li> <li>PMM-6244: MySQL InnoDB Details Dashboard: Inverted color scheme on \u201cBP Write Buffering\u201d panel</li> <li>PMM-6294: Query Analytics Dashboard doesn\u2019t resize well for some screen resolutions (Thanks to user <code>debug</code> for reporting this issue)</li> <li>PMM-5701: Home Dashboard: Incorrect metric for <code>DB uptime</code> (Thanks to user <code>hubi_oediv</code> for reporting this issue)</li> <li>PMM-6427: Query Analytics dashboard: Examples broken when switching from MongoDB to MySQL query</li> <li>PMM-5684: Use actual data from <code>INFORMATION_SCHEMA</code> vs relying on cached data (which can be 24 hrs old by default)</li> <li>PMM-6500: PMM Database Checks: Unwanted high-contrast styling</li> <li>PMM-6440: MongoDB ReplSet Summary Dashboard: Primary shows more lag than replicas</li> <li>PMM-6436: Query Analytics Dashboard: Styles updated to conform with upgrade to Grafana 7.x</li> <li>PMM-6415: Node Summary Dashboard: Redirection to database\u2019s Instance Summary dashboard omits Service Name</li> <li>PMM-6324: Query Analytics Dashboard: Showing stale data while fetching updated data for query details section</li> <li>PMM-6316: Query Analytics Dashboard: Inconsistent scrollbar styles</li> <li>PMM-6276: PMM Inventory: Long lists unclear; poor contrast &amp; column headings scroll out of view</li> <li>PMM-6529: Query Analytics filter input margin disappears after scrolling</li> </ul>"},{"location":"release-notes/2.10.0.html#known-issues","title":"Known Issues","text":"<ul> <li>PMM-6643: High CPU usage for new MongoDB exporter  (fixed in Percona Monitoring and Management 2.10.1)</li> </ul>"},{"location":"release-notes/2.10.1.html","title":"Percona Monitoring and Management 2.10.1","text":"Date: September 22, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.10.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6643: New MongoDB exporter has higher CPU usage compared with old</li> </ul>"},{"location":"release-notes/2.11.0.html","title":"Percona Monitoring and Management 2.11.0","text":"Date: October 14, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.11.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-6567: Technical preview of new PostgreSQL extension <code>pg_stat_monitor</code></li> <li>PMM-6515: Link added directly to Node/Service page from Query Analytics filters, opens in new window</li> </ul>"},{"location":"release-notes/2.11.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6727: Grafana plugin updates: <code>grafana-polystat-panel=1.2.2</code>, <code>grafana-piechart-panel=1.6.1</code></li> <li>PMM-6625: Default sort to \u201cAverage - descending\u201d on all dashboards</li> <li>PMM-6609: MySQL Instances Compare &amp; Summary dashboards: Changed metric in \u2018MySQL Internal Memory Overview\u2019</li> <li>PMM-6598: Dashboard image sharing (Share Panel): Improved wording with link to configuration instructions</li> <li>PMM-6557: Update Prometheus to 2.21.0</li> <li>PMM-6554: MySQL InnoDB Details dashboard: Add \u201csync flushing\u201d to \u201cInnoDB Flushing by Type\u201d</li> </ul>"},{"location":"release-notes/2.11.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-4547: MongoDB dashboard replication lag count incorrect (Thanks to user <code>vvol</code> for reporting this issue)</li> <li>PMM-6639: Integrated update does not detect all container types</li> <li>PMM-6765: Tables information tab reports \u2018table not found\u2019 with new PostgreSQL extension <code>pg_stat_monitor</code></li> <li>PMM-6764: Query Analytics: cannot filter items that are hidden - must use \u201cShow all\u201d</li> <li>PMM-6742: Upgrade via PMM UI stalls (on <code>yum update pmm-update</code>)</li> <li>PMM-6689: No PostgreSQL queries or metrics in Query Analytics with PostgreSQL 13 (<code>postgresql_pgstatements_agent</code> in Waiting status)</li> <li>PMM-6738: PostgreSQL examples shown despite <code>--disable-queryexamples</code> option</li> <li>PMM-6535: Unable to open \u2018Explore\u2019 in new window from Grafana menu</li> <li>PMM-6532: Click-through URLs lose time ranges when redirecting to other dashboards</li> <li>PMM-6531: Counter-intuitive coloring of element \u201cUpdate Stats when Metadata Queried\u201d</li> <li>PMM-6645: Clean up unnecessary errors in logs (<code>vertamedia-clickhouse-datasource</code> plugin)</li> <li>PMM-6547: Hexagonal graph tooltip text overflows bounding box</li> </ul>"},{"location":"release-notes/2.11.1.html","title":"Percona Monitoring and Management 2.11.1","text":"Date: October 19, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.11.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6782: High CPU usage after update to 2.11.0</li> </ul>"},{"location":"release-notes/2.12.0.html","title":"Percona Monitoring and Management 2.12.0","text":"Date: December 1, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.12.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li>VictoriaMetrics replaces Prometheus and is now the default data source. VictoriaMetrics supports both PUSH (client to server) and PULL metrics collection modes. (Read more.)</li> <li>PMM Client can be run as a Docker image.</li> <li>The \u2018Add Instance\u2019 page and forms have been redesigned and look much better.</li> </ul>"},{"location":"release-notes/2.12.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-5799: PMM Client now available as docker image in addition to RPM, DEB and <code>.tgz</code></li> <li>PMM-6968: Integrated Alerting: Basic notification channels actions API Create, Read, Update, Delete</li> <li>PMM-6842: VictoriaMetrics: Grafana dashboards to monitor <code>VictoriaMetricsDB</code> as replacement for dashboards that used to monitor Prometheus DB</li> <li>PMM-6395: Replace Prometheus with VictoriaMetrics in PMM for better performance and additional functionality</li> </ul>"},{"location":"release-notes/2.12.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6744: Prevent timeout of low resolution metrics in MySQL instances with many tables (~1000\u2019s)</li> <li>PMM-6504: MySQL Replication Summary: MySQL Replication Delay graph not factoring in value of intentionally set <code>SQL_Delay</code> thus inflating time displayed</li> <li>PMM-6820: <code>pmm-admin status --wait</code> option added to allow for configurable delay in checking status of <code>pmm-agent</code></li> <li>PMM-6710: <code>pmm-admin</code>: Allow user-specified custom \u2018group\u2019 name when adding external services</li> <li>PMM-6825: Allow user to specify \u2018listen address\u2019 to <code>pmm-agent</code> otherwise default to 127.0.0.1</li> <li>PMM-6793: Improve user experience of \u2018add remote instance\u2019 workflow</li> <li>PMM-6759: Enable Kubernetes startup probes to get status of <code>pmm-agent</code> using \u2018GET HTTP\u2019 verb</li> <li>PMM-6736: MongoDB Instance Summary dashboard: Ensure colors for ReplSet status matches those in MongoDB ReplSet Summary dashboard for better consistency</li> <li>PMM-6730: Node Overview/Summary Cleanup: Remove duplicate service type \u2018DB Service Connections\u2019</li> <li>PMM-6542: PMM Add Instance: Redesign page for more intuitive experience when adding various instance types to monitoring</li> <li>PMM-6518: Update default data source name from \u2018Prometheus\u2019 to \u2018Metrics\u2019 to ensure graphs are populated correctly after upgrade to VictoriaMetrics</li> <li>PMM-6428: Query Analytics dashboard - Ensure user-selected filter selections are always visible even if they don\u2019t appear in top 5 results</li> <li>PMM-5020: PMM Add Remote Instance: User can specify \u2018Table Statistics Limit\u2019 for MySQL and AWS RDS MySQL to disable table stat metrics which can have an adverse impact on performance with too many tables</li> </ul>"},{"location":"release-notes/2.12.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6811: MongoDB Cluster Summary: when secondary optime is newer than primary optime, lag incorrectly shows 136 years</li> <li>PMM-6650: Custom queries for MySQL 8 fail on 5.x (on update to <code>pmm-agent</code> 2.10) (Thanks to user debug for reporting this issue)</li> <li>PMM-6751: PXC/Galera dashboards: Empty service name with MySQL version &lt; 5.6.40</li> <li>PMM-5823: PMM Server: Timeout when simultaneously generating and accessing logs via download or API</li> <li>PMM-4547: MongoDB dashboard replication lag count incorrect (Thanks to user <code>vvol</code> for reporting this issue)</li> <li>PMM-7057: MySQL Instances Overview: Many monitored instances (~250+) gives \u2018too long query\u2019 error</li> <li>PMM-6883: Query Analytics: \u2018Reset All\u2019 and \u2018Show Selected\u2019 filters behaving incorrectly</li> <li>PMM-6686: Query Analytics: Filters panel blank on Microsoft Edge 44.18362.449.0</li> <li>PMM-6007: PMM Server virtual appliance\u2019s IP address not shown in OVF console</li> <li>PMM-6754: Query Analytics: Bad alignment of percentage values in Filters panel</li> <li>PMM-6752: Query Analytics: Time interval not preserved when using filter panel dashboard shortcuts</li> <li>PMM-6664: Query Analytics: No horizontal scroll bar on Explain tab</li> <li>PMM-6632: Node Summary - Virtual Memory Utilization chart: incorrect formulas</li> <li>PMM-6537: MySQL InnoDB Details - Logging - Group Commit Batch Size: giving incorrect description</li> <li>PMM-6055: PMM Inventory - Services: \u2018Service Type\u2019 column empty when it should be \u2018External\u2019 for external services</li> </ul>"},{"location":"release-notes/2.12.0.html#known-issues","title":"Known Issues","text":"<ul> <li> <p>PMM-7092: Update docker <code>pmm-server</code> 2.11.1 to 2.12.0 results in an unhealthy container.</p> <p>Workaround: A folder is not created on container upgrade and will need to be created manually for one of the components. Before starting the new pmm-server 2.12.0, execute:\u00a0\u00a0</p> <pre><code>docker exec -ti pmm-server mkdir -p /srv/victoriametrics/data\ndocker exec -ti pmm-server chown -R pmm:pmm /srv/victoriametrics/\ndocker restart pmm-server\n</code></pre> </li> </ul>"},{"location":"release-notes/2.13.0.html","title":"Percona Monitoring and Management 2.13.0","text":"Date: December 29, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.13.0.html#release-highlights","title":"Release Highlights","text":"<ol> <li> <p>Ability to monitor SSL-enabled MongoDB</p> <p>Allows PMM administrators to set up configured SSL certificate \u201ckeys\u201d to authenticate the connection to PMM, specifically for setting up MongoDB. This is a critical security requirement especially in large enterprise infrastructure environments.</p> </li> <li> <p>Technical Previews</p> <p>Caution</p> <p>We do not recommend the use of technical preview features in enterprise or production environments until the functionality is released as general availability (GA). While in Technical Preview status, these features are not supported by Percona Support SLA, except by Product/Engineering on a best-efforts basis.</p> <ol> <li> <p>Integrated Alerting MVP</p> <p>A new feature in PMM to set up parameters and revive alerts about the Services and Nodes monitored by PMM.</p> <p>Read more on our blog and in our documentation.</p> </li> <li> <p>Node Summary/Nodes Overview dashboards: Show External services on dashboards</p> <p>Improves the user experience for adding and viewing external services on the Node Summary dashboard of PMM. External services means any data that can be monitored by a Prometheus exporter, for example, non-Percona supported databases like Redis, ElasticSearch, Cassandra, etc. or an organization\u2019s external application.</p> </li> <li> <p>DBaaS Preview phase 1.0</p> <p>We are also releasing the first preview of DBaaS functionality; when combined with a compatible Kubernetes environment and Percona Operators, you can create Percona XtraDB or MongoDB clusters with just a few clicks. (Read more about configuration and usage.)</p> </li> </ol> </li> </ol>"},{"location":"release-notes/2.13.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-5364: Ability to monitor SSL-enabled MongoDB by passing certificate parameters in <code>pmm-admin add</code> command (Thanks to Hubertus Krogmann for reporting this issue)</li> <li>PMM-7086: Re-mapped <code>/prometheus/&lt;end-point&gt;</code> to <code>/victoriametrics/&lt;end-point&gt;</code> but created aliases for users that still rely on the <code>/prometheus/&lt;end-point&gt;</code> in bookmarks and scripts (Thanks to Daniel Guzman Burgos for reporting this issue)</li> <li>PMM-6713: Node Summary/Nodes Overview dashboards: External exporters can now be added to dashboard and shown as part of grouping of a broader service</li> <li>PMM-7173: VictoriaMetrics updated to 1.50.2: Includes HTML pages vs JSON output and new functions available for alerting rules (see all tags)</li> </ul>"},{"location":"release-notes/2.13.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7054: ProxySQL Instance Summary dashboard: no Node Metrics</li> <li>PMM-7092: PMM Server Docker update from 2.11.1 to 2.12.0 leaves container in unhealthy state (Thanks to Hubertus Krogmann for reporting this issue)</li> <li>PMM-7208: Confusing \u201cAccess denied\u201d message for \u2018Viewer\u2019 users on many dashboards</li> <li>PMM-6987: No IP address shown in log file of OVF appliance running in headless mode</li> <li>PMM-7146: MongoDB Instance Summary dashboard: <code>ReplSet</code> element showing metric name instead of replication set</li> <li>PMM-6992: Administrators can\u2019t see user\u2019s actual IP address in Grafana profile-Preferences-Sessions</li> <li>PMM-6865: Rendered dashboard images partly obscured by error message</li> </ul>"},{"location":"release-notes/2.14.0.html","title":"Percona Monitoring and Management 2.14.0","text":"Date: January 28, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.14.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Switch to push metrics by default</p> <p>In PMM 2.12.0, Percona replaced its metrics collection engine (formerly Prometheus) with VictoriaMetrics. Historically, PMM used a pull method with Prometheus while VictoriaMetrics can operate in either a pull or push method. When PMM 2.12.0 was released, Percona kept the default method as pull. Now with PMM 2.14.0, Percona is shifting the default to push for all newly-added instances. This blog post describes the two methods and why push benefits users. Also, here is a post by Peter Zaitzev of FAQs relating to the move to VictoriaMetrics and the push model. Documentation on the push method is here.</p> <p>Note: Installing the 2.14.0 or newer PMM server will change the default behavior on 2.12.0 and 2.13.0 clients from \u201cpull\u201d method to \u201cpush\u201d for any newly added services. Existing services will remain in whatever mode they were prior to upgrade.</p> </li> <li> <p>DBaaS Preview phase 1.0 (Technical  Preview)</p> <p>In 2.13.0 we introduced Percona\u2019s Database as a Service (DBaaS) which enables non-DBAs (software architects, developers, site reliability engineers, etc.) to perform typical DBA tasks to manage an organization\u2019s database environment via user interfaces and automation orchestration.  This release contains several enhancements and fixes, many directly from user feedback.</p> <p>Note: This capability is feature-flagged and turned off by default. Users require a variable to be passed to PMM to expose this functionality.</p> </li> <li> <p>External services presentation on node summary dashboard</p> <p>Improvements to the user experience for adding and viewing external services (any data that can be monitored by a Prometheus exporter such as: non-Percona supported databases like Redis, ElasticSearch, Cassandra, etc. or an organization\u2019s external application) on the Node Summary dashboard of PMM.</p> </li> </ul>"},{"location":"release-notes/2.14.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-5765: Ability to monitor External Services for situations where PMM Client can\u2019t be installed \u2013 Uses a new command <code>pmm-admin add external-serverless</code>. (See pmm-admin.) (This is a Technical Preview feature)</li> <li>PMM-7015: DBaaS Preview: Create DB cluster with randomly-generated password</li> <li>PMM-7007: Integrated Alerting: Ability to copy (duplicate) alert rules</li> <li>PMM-7006: Integrated Alerting: Ability to delete alert rules</li> <li>PMM-6941: Integrated Alerting: Ability to delete alert rule templates</li> </ul>"},{"location":"release-notes/2.14.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6985: DBaaS: Ability to force unregister Kubernetes cluster</li> <li>PMM-7145: \u2018Push\u2019 metrics mode is default when adding services and nodes (All agents collecting data from Services and Nodes will now use PUSH model if not specified explicitly. You will still be able to use <code>--metrics-mode</code> flag to use Pull metrics if needed. All previously set up agents will keep their existing mode. To change these you need to remove and re-add them.)</li> <li>PMM-7282: Integrated Alerting: Ability to create rule without channels and filters</li> <li>PMM-7226: Integrated Alerting: Validate parameters during rule creation/update</li> <li>PMM-7082: Integrated Alerting: Severity levels are color-coded</li> <li>PMM-7065: Integrated Alerting: Show rule details for items in Alert Rules list</li> <li>PMM-7048: DBaaS: Simplify Cluster creation by moving Create Cluster button to earlier steps</li> <li>PMM-6993: Protect against possible problems with EXPLAIN of stored functions in MySQL \u2013 We are fixing possible problems caused by an attempt to analyze queries covered in https://bugs.mysql.com/bug.php?id=67632.</li> </ul>"},{"location":"release-notes/2.14.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7312: Error when accessing Metrics data on Dashboards for large installations</li> <li>PMM-7310: VictoriaMetrics consuming 100\u2019s Gb\u2019s of disk in <code>/tmp/searchResults</code> in PMM 2.13.0</li> <li>PMM-5137: Swagger page redirect isn\u2019t working</li> <li>PMM-7144: DBaaS: Creating DB cluster with same name (Thanks to Beata Handzelova for reporting this issue)</li> <li>PMM-7323: DBaaS: \u2018Remove DB Cluster from Kubernetes Cluster\u2019 removes wrong one</li> <li>PMM-7251: Integrated Alerting: Error <code>Rule with ID \"mysql_version\" not found</code> if both Security Threat Tool and Integrated Alerting enabled</li> <li>PMM-7247: DBaaS: Disk size is always 0 for Percona XtraDB cluster</li> <li>PMM-7178: <code>pg_stat_monitor</code> integration is broken with version 0.6.0 of the plugin</li> <li>PMM-7169: Old data (from Prometheus) not deleted when Retention period expires</li> <li>PMM-7105: Query Analytics: no \u2018Example\u2019 or \u2018Explain\u2019 data for MariaDB</li> <li>PMM-7239: Integrated Alerting: Validate Slack channel names in Notification Channels</li> <li>PMM-7213: MySQL InnoDB Details dashboard: remove color-coding on \u2018Data Buffer Pool Fit\u2019 element</li> <li>PMM-7167: Some panels not visible when using long time intervals (e.g. 30 days)</li> <li>PMM-7133: Incorrect descriptions for data links in dashboards</li> <li>PMM-7103: VictoriaMetrics build logs not deleted from PMM Server Docker image</li> <li>PMM-6904: <code>pmm-admin annotate</code> command crashes for non-generic node types</li> <li>PMM-6902: No query Examples on PostgreSQL 12 with pg_stat_monitor</li> <li>PMM-6838: ProxySQL Instance Summary dashboard: Incorrect \u201cHostgroup Size\u201d formula</li> <li>PMM-6490: <code>rds_exporter</code> crashes when more than 100 AWS RDS instances added (Thanks to https://github.com/vlinevych for fixing this)</li> <li>PMM-6096: <code>pmm-agent</code> connection checker does not check authentication for MongoDB</li> <li>PMM-7303: Disk Details, Nodes Compare dashboards: \u2018Disk Utilization\u2019 description is confusing</li> </ul>"},{"location":"release-notes/2.15.0.html","title":"Percona Monitoring and Management 2.15.0","text":"Date: March 01, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.15.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>PMM 1 vs. 2 Parity</p> <p>Disable collectors during adding node/service to monitoring</p> <p>With this feature users can disable any collector used by PMM to get metrics. When metrics cannot be collected or are no longer needed, disabling the collector(s) prevents PMM from flooding logs and saves infrastructure resources.</p> <p>Our vision for PMM collectors is to provide \u201cstop from collecting\u201d functionality to prevent possible harm to the user environment. This \u201cdisable\u201d feature is an initial step towards the ideal functionality. The full and flexible management for \u201cWhat metrics to collect and in what resolution\u201d is slated for future releases.</p> <p>External services monitoring</p> <p>Since PMM 1.4.0, users had the ability to monitor external services Percona didn\u2019t currently support (e.g., Redis). This blog article from 2018 nicely described external services monitoring at that time. (At that time Percona was not natively supporting a PostgreSQL monitoring service and so this was listed as an external service. Today, PostgreSQL is natively supported by PMM.)</p> <p>Until now, PMM 2.x didn\u2019t support external services monitoring. With this release, any non-natively supported by PMM service will now become supported with external services monitoring. You can see the list of possible exporters to be used in https://prometheus.io/docs/instrumenting/exporters/. Natively-supported services will continue to deliver an expanded set of metrics and insights.</p> <p>Provide summary information for  systems (<code>pt-*-summary actions</code>)</p> <p>With the addition of <code>pt-*-summary</code> in PMM 2, users can now view summary information about services and nodes on PMM\u2019s dashboard. This summary information is in the industry common format of <code>pt-*-summary</code> tools output to simplify portability of this data. This format will also be preserved in the snapshot of the dashboard shared with Percona Support to simplify investigations of issues.</p> <p>Note: <code>pt-*-summary</code> includes formats for:</p> <ul> <li><code>pt-mysql-summary</code></li> <li><code>pt-mongodb-summary</code></li> <li><code>pt-pg-summary</code></li> <li><code>pt-summary</code></li> </ul> </li> <li> <p>HAProxy support by PMM</p> <p>Users are able to add HAProxy Services for monitoring in PMM2. The support level of them in PMM will be the same we have for ProxySQL, so they will be presented in Inventory and on Dashboard. This will allow users who use HAProxy in their HA configuration to also have this component monitored by PMM. In future releases PMM will start use HAProxy by default for the DBaaS feature and will also use this functionality to monitor HAProxy.</p> </li> <li> <p>DBaaS Preview improvements (Technical  Preview)</p> <p>From now you will be able to see the progress of internal steps the system makes when executing some operations with DBaaS. The Progress Bar will not be time-related and will present only steps. The Progress Bar component will also reflect the K8s/Operator-related errors to the user, so in the case of errors, you will have the error text on the UI, and no need to use K8s tools to see the error. With the same UI, you will be able to see the latest logs from K8s so they will have even more information about why the error happened.</p> <p>Known Limitations: The progress bar will not provide valuable information for the Delete operation (will be in a later version when we\u2019ll change the API with Operators Team), Operation of DB Cluster Modification will have \u201cstrange\u201d behavior and will start changes from non-zero values of steps. (This will be modified after API changes.)</p> </li> </ul>"},{"location":"release-notes/2.15.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-4172, PMM-4306, PMM-5784, PMM-7177: Services and Nodes Summary presentation. Present information about DB\u2019s and Node status using <code>pt-mysql-summary</code>, <code>pt-mongodb-summary</code>, <code>pt-pg-summary</code> outputs (in API and on Dashboards).</li> <li>PMM-7123: Ability to add External Services via the UI in PMM server.</li> <li>PMM-6711: Add <code>external-group</code> flag for <code>pmm-admin inventory</code> commands for simpler work with External services.</li> <li>PMM-7405: Check connection response format when adding External Service to monitoring.</li> <li>PMM-6797: HAProxy monitoring: Ability to add HAProxy services with <code>pmm-admin [inventory] add [service] haproxy</code> command.</li> <li>PMM-7487: HAProxy monitoring: Check connection to HAProxy services when adding them for monitoring.</li> <li>PMM-7496: HAProxy monitoring: New HAProxy PXC dashboards.</li> <li>PMM-6943: HAProxy monitoring: Show HAProxy type services in PMM Inventory.</li> <li>PMM-6924: Integrated Alerting: Show \u2018breadcrumbs\u2019 navigation aid on non-dashboard pages as well as Grafana dashboard pages.</li> <li>PMM-7294: Integrated Alerting: Pagination for viewing large numbers of Alert Rules.</li> <li>PMM-7417: Security Threat Tool: Show list of all available security checks.</li> <li>PMM-7418: Security Threat Tool: Ability to disable specific security checks.</li> <li>PMM-7419: DBaaS: Ability to see DB Cluster creation/modification logs.</li> <li>PMM-7266: DBaaS: Cluster creation progress bar \u2013 You can now see the progress of DBaaS DB cluster creation. (The progress bar is based on the number of back-end technical steps, not the time required to perform the tasks.)</li> </ul>"},{"location":"release-notes/2.15.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-4679: Docker: <code>:latest</code> tag for <code>pmm-server</code> and <code>pmm-client</code> images has been moved from v1 latest release to v2 latest release.  Note: use of the latest tag is not recommended in production environments, instead use <code>:2</code> tag.</li> <li>PMM-7472: Remove Prometheus data source \u2013 If you were using custom dashboards with a specified data source (not using empty to use default one) you may need to edit your dashboards to use the proper data source. PMM is no longer using Prometheus but uses compatible storage for metrics from VictoriaMetrics. We renamed the data source to be more technology-agnostic.</li> <li>PMM-6695: Software update: Grafana 7.1.3 to 7.3.7 (See What\u2019s new in Grafana 7.2 and What\u2019s new in Grafana 7.3.)</li> <li>PMM-7471: Software update: VictoriaMetrics 1.52.0 to 1.53.1 (See VictoriaMetrics 1.53.0 and VictoriaMetrics 1.53.1.)</li> <li>PMM-6693: API keys usage \u2013 PMM users can now use API keys (generated in Grafana UI) for interaction with PMM server instead of username/password pairs. The API key should have the same level of access (Admin or Viewer) as is required for username/password pairs.</li> <li>PMM-7240: DBaaS: Change from Dashboard to Grafana Page \u2013 We changed the DBaaS page from a Grafana Dashboard to a Grafana Page to be better aligned with the DBaaS enable/disable status and avoid confusion when DBaaS is disabled.</li> <li>PMM-7328: Security Threat Tool: Download and run checks when activated, immediately, repeating every 24 hours thereafter (Previously, downloading and running new checks happened every 24 hours but the cycle didn\u2019t begin when STT was activated.)</li> <li>PMM-7329: Security Threat Tool: Hide check results tab if STT is disabled.</li> <li>PMM-7331: Security Threat Tool: Failed checks have \u2018Read more\u2019 links with helpful content.</li> <li>PMM-7422: Security Threat Tool: View all active and silenced alerts.</li> <li>PMM-7257, PMM-7433: Integrated Alerting: Easier-to-read rule details in Alert Rules list (API and UI presentation).</li> <li>PMM-7259: Integrated Alerting: Better UI error reporting for disabled Integrated Alerting. (Hint to users how to enable it.)</li> <li>PMM-5533: Better indentation of columns in <code>pmm-admin list</code> output.</li> <li>PMM-5888: Improve <code>pmm-admin --help</code> descriptions for external services.</li> </ul>"},{"location":"release-notes/2.15.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5837: <code>pmm-agent</code> reports \u201cMalformed DSN\u201d error when adding PostgreSQL instance with a PMM user password containing <code>=</code> (equals sign) (Thanks to Alexandre Barth for reporting this issue).</li> <li>PMM-5969: Removing Services or Nodes with <code>pmm-admin ... --force</code> mode does not stop running agents, VictoriaMetrics continues collecting data from exporters.</li> <li>PMM-6685: In low screen resolutions Services submenu wraps, becomes obscured, and can\u2019t be accessed.</li> <li>PMM-6681: Not all PMM admin users can download diagnostic logs, only those with Grafana admin rights.</li> <li>PMM-7227: Table stats metrics not being collected in instances with millions of tables.</li> <li>PMM-7426: <code>vmagent</code> continually restarts, blocking comms between <code>pmm-agent</code> &amp; <code>pmm-managed</code> \u2013 Users running multiple services on the same PMM agent in \u2018push\u2019 mode could face this issue when restarting the agent after bulk-adding services.</li> <li>PMM-6636: Dashboards: MySQL Replication Summary: \u2018Binlog Size\u2019, \u2018Binlog Data Written Hourly\u2019, \u2018Node\u2019 not being charted when the instance is RDS.</li> <li>PMM-7325: Dashboards: MySQL User Details: user labels unreadable with high number (&gt;20) of users (Thanks to Andrei Fedorov for reporting this issue).</li> <li>PMM-7416: Dashboards: PostgreSQL Instance Summary: Some panels (e.g. Tuple) not using selected database.</li> <li>PMM-7235: Integrated Alerting: Filtered out alerts are shown in the UI as firing.</li> <li>PMM-7324: Integrated Alerting: Add Pager Duty Notification Channel: after user pastes copied key Add button is not enabled.</li> <li>PMM-7346: Integrated Alerting: It is possible to create Alert Rule with negative duration time.</li> <li>PMM-7366: Integrated Alerting: Entities (e.g. templates, channels, rules) are in inconsistent states.</li> <li>PMM-7467: Integrated Alerting: <code>&lt;</code> (less-than symbol) wrongly interpreted by Alert templates (as <code>&amp;lt;</code>).</li> <li>PMM-7591: Integrated Alerting: User can not receive notifications on email after password update.</li> <li>PMM-7343: Security Threat Tool: Check results show previously failed checks after STT re-enabled.</li> <li>PMM-7250: DBaaS: Confusing error \u201cCannot get PSMDB/PXC cluster\u201d appears after removing DB cluster.</li> <li>PMM-7193: DBaaS: Number of Nodes can be set as float.</li> <li>PMM-7349: DBaaS: Host and Password occasionally disappearing from Connection column.</li> </ul>"},{"location":"release-notes/2.15.1.html","title":"Percona Monitoring and Management 2.15.1","text":"Date: March 18, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.15.1.html#release-highlights","title":"Release Highlights","text":"<p>This patch release fixes performance issues discovered in systems, together with other small fixes.</p>"},{"location":"release-notes/2.15.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7635: Fix high CPU consumption by Grafana server after upgrade by docker replacement to 2.15.0 with large numbers of services in \u2018push\u2019 mode.</li> <li>PMM-7713: Fix high CPU and Memory consumption by Victoria Metrics after upgrade by docker replacement to 2.15.0 with large numbers of services in \u2018pull\u2019 mode.</li> <li>PMM-7470: MongoDB exporter <code>IndexStatsCollections</code> is assigned values from wrong flag (intended for 2.15.0, omitted due to missing merge cutoff) (Thanks to Tim for reporting this issue).</li> <li>PMM-1531: Metrics not being collected due to rename of MySQL 8 information schema tables.</li> </ul>"},{"location":"release-notes/2.16.0.html","title":"Percona Monitoring and Management 2.16.0","text":"Date: April 15, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.16.0.html#important-note-for-users-of-pmm-2160","title":"Important note for users of PMM 2.16.0","text":"<p>If you started using PMM from version 2.16 and have already upgraded to 2.17, 2.18, or 2.19, you might have some problems with PMM Server monitoring, Remove Monitoring, or RDS/Azure monitoring. If you experience a problem, we recommend you upgrade and replace the Docker container by following the official instructions for an upgrade here: https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/docker.html#upgrade.</p> <p>If you can\u2019t do this, then you need to perform additional steps after upgrading to 2.20.</p> <ol> <li>Enter the container: <code>docker exec -it pmm-server bash</code></li> <li>Roll back <code>pmm2-client</code> package to stable version: <code>yum downgrade -y pmm2-client</code></li> </ol>"},{"location":"release-notes/2.16.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Amazon RDS PostgreSQL monitoring</p> <p>AWS monitoring in PMM now covers PostgreSQL RDS and PostgreSQL Aurora types. PMM will include them in a Discovery UI where they can be added which will result in node related metrics as well as PostgreSQL database performance metrics. Before this release, this was available only to MySQL-related instances from Amazon RDS.</p> </li> <li> <p>Azure Discovery and Node metrics extraction</p> <p>Technical Preview: PMM will have the same level of support for Microsoft Azure Database as a Service (DBaaS) as we have for AWS\u2019s DBaaS (RDS/Aurora on MySQL or PostgreSQL). You will be able to easily discover and add Azure databases for monitoring by PMM complete with node-level monitoring. This feature is available only if you explicitly activate it on the PMM Settings page. Deactivating it will not remove added services from monitoring, but will just hide the ability to discover and add new Microsoft Azure Services.</p> <p>(This is a feature technical preview because we want to release it as soon as possible to get feedback from users. We are expecting to do more work on this feature to make it more API and resource efficient.)</p> </li> <li> <p>Security Threat Tool Scheduling - Manage execution and execution intervals</p> <p>Security Threat Tool users are now able to control the Security Check execution time intervals for groups of checks, move checks between groups, and disable individual checks if necessary.</p> </li> <li> <p>Support for pg_stat_monitor 0.8</p> <p>Added compatibility with pg_stat_monitor plugin v 0.8.0. This is not exposing the new features for the plugin in PMM yet, but ensures Query Analytics metrics are collected to the same degree it was with version 0.6.0 of the plugin.</p> </li> <li> <p>Consistent support of Technical Preview Features</p> <p>Reworked the PMM Settings page to make it clear what features are in Technical Preview vs General Availability (GA) and to simplify activation/deactivation of technical preview features. We also provide a better definition of what a Technical Preview is.</p> </li> <li> <p>Migration of Settings and other service pages in PMM from Grafana dashboards</p> <p>The PMM Settings page and several others (including Add Instance and Inventory) are being converted to Grafana pages and will no longer be presented as dashboards. Additionally, we\u2019re moving the menu to the sidebar navigation for consistency and more flexibility compared to the older menu structure.</p> </li> <li> <p>Integrated Alerting improvements</p> <p>We released the next stage of improvements in Integrated Alerting functionality of PMM to simplify the usage of the feature. Together with improvements, we continue fixing known bugs in this feature.</p> </li> <li> <p>[DBaaS] Resource planning and prediction (Resource calculator)</p> <p>Technical preview: While creating a DB cluster a user can see a prediction of the resources this cluster will consume with all components as well as the current total and available resources in the K8s. Users will be warned that if they attempt to create a DB cluster it may be unsuccessful because of available resources in the K8s.</p> </li> <li> <p>[DBaaS] PSMDB 1.7.0 operator support</p> <p>DBaaS in PMM will be using the recently-released Percona Kubernetes Operator for Percona Server for MongoDB 1.7.0 to create MongoDB clusters.</p> </li> </ul>"},{"location":"release-notes/2.16.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-7313, PMM-7610: Ability to discover and monitor Amazon RDS PostgreSQL instances with collecting PostgreSQL and RDS node metrics (Thanks to Daniel Guzman Burgos for reporting this issue).</li> <li>PMM-7345: Expose metrics for all available databases on a PMM monitored PostgreSQL server.</li> <li>PMM-7344: Update postgres_exporter version from 0.4.6 to 0.8.0. (See the full list of improvements in the changelog.)</li> <li>PMM-7767, PMM-7696: Implement feature flag to enable Microsoft Azure monitoring. Users can use the UI or set an environment variable (<code>ENABLE_AZUREDISCOVER=1</code>) during container creation.</li> <li>PMM-7684, PMM-7498: Ability to discover running and supported Microsoft Azure Databases instances in a provided account.</li> <li>PMM-7678, PMM-7679, PMM-7676, PMM-7499, PMM-7691: Prepare, modify and use <code>azure_exporter</code> to collect Node related metrics.</li> <li>PMM-7681: Use Microsoft Azure metrics on Node/OS-related dashboards to show the metrics on panels.</li> <li>PMM-7339: Security Threat Tool: Ability to execute security checks individually and on-demand.</li> <li>PMM-7451, PMM-7337: Security Threat Tool: Ability to change intervals for security checks on the PMM Settings page.</li> <li>PMM-7772, PMM-7338: Security Threat Tool: Ability to change default execution interval per check.</li> <li>PMM-7336: Security Threat Tool: Execute checks based on execution interval they belong to.</li> <li>PMM-7335: Security Threat Tool: Ship security check files with predefined execution interval.</li> <li>PMM-7748: Add an additional experimental menu for Dashboards on the left side panel.</li> <li>PMM-7688: Unify UX and layout of all PMM specific pages like Settings, Add Instance etc.</li> <li>PMM-7687: Modify links in menus to ensure both menus are working as expected after dashboard URL change.</li> <li>PMM-7705: Simplify display of features in technical preview to easily identify them and their current state.</li> <li>PMM-7522, PMM-7511: Integrated Alerting: Improve Notification Channels UX by Pagination for the Notification list.</li> <li>PMM-7521, PMM-7510: Integrated Alerting: Improve Alert Rule Templates UX by Pagination on Rule Templates list.</li> <li>PMM-7652, PMM-7674, PMM-7503, PMM-7486: DBaaS: While creating the DB cluster see all and available resources in the K8s cluster, such as Disk, CPU &amp; Memory.</li> <li>PMM-7508, PMM-7488: DBaaS: See predicted resource usage for selected DB Cluster configuration.</li> <li>PMM-7364: DBaaS: Show warning before starting creating the cluster if there are not enough resources in the K8s cluster to create DB Cluster with requested configuration.</li> <li>PMM-7580, PMM-7359: DBaaS: Users can select the database version to use during DB Cluster creation.</li> </ul>"},{"location":"release-notes/2.16.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-7506: Security Threat Tool: Reduce False Positives due to Roles automatically created in PXC with no password but cannot be used to login.</li> <li>PMM-7569: Make PMM compatible with pg_stat_monitor 0.8 release.</li> <li>PMM-7571: Modified Percona Platform Account registration flow from PMM server UI.</li> <li>PMM-7513: Integrated Alerting: Ability to see default values and Threshold values during the Alert Rule creation.</li> <li>PMM-7461: Integrated Alerting: Improve UX of tables presentation and loading on UI.</li> <li>PMM-7375: Integrated Alerting: Inform users about the template that they are editing and warn them about the limitations.</li> <li>PMM-7260: Integrated Alerting: Make it clearer what rule is being edited.</li> </ul>"},{"location":"release-notes/2.16.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7131, PMM-7555: QAN for PostgreSQL attempts to connect to a database with the same name as the username. (Thanks to Daniel Guzman Burgos for reporting this issue)</li> <li>PMM-7481: Query Analytics is not showing \u201cQuery with Errors\u201d in the Profile section.</li> <li>PMM-7464: NGINX misconfiguration leads to log storm in push mode</li> <li>PMM-7434: Integrated Alerting: Unknown parameters [threshold] error during Add/Update Alert Rule.</li> <li>PMM-7231: Integrated Alerting: Disabling channels does nothing.</li> <li>PMM-7379: Integrated Alerting: Can not edit Alert Rule Name through API.</li> <li>PMM-7232: Integrated Alerting: Disabling IA does not disable rules evaluation and notifications sending.</li> <li>PMM-7119: Integrated Alerting: Update error notification for adding/update Alert rule Template \u2013 There was inconsistent behavior if you tried to add a new Rule Template with an already-used name.</li> <li>PMM-7543: Integrated Alerting: selected section disappears from a breadcrumb after clicking the tab for a second time.</li> <li>PMM-7766: DBaaS: PMM Upgrade breaks DBaaS get credentials method.</li> <li>PMM-7351: DBaaS: Safari does not accept float numbers as a custom option in the \u201cCreate Cluster\u201d dialogue.</li> <li>PMM-7701: DBaaS: PSMDB clusters stuck in initializing due to special characters in secrets.</li> </ul>"},{"location":"release-notes/2.17.0.html","title":"Percona Monitoring and Management 2.17.0","text":"Date: May 11, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.17.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Custom certificates help define proper security levels for remotely monitored MySQL instances, including Google Cloud SQL.</p> </li> <li> <p>Usability improvements to the External Monitoring UI. When filling parameters, you can enter the parts of an endpoint (scheme, host, path) or let PMM automatically extract them from a URL.</p> </li> <li> <p>pg_stat_monitor 0.9.0 support. This change will give you compatibility with the latest version. Support for new features will be in an upcoming release.</p> </li> <li> <p>Single-line install of PMM Server on supported Linux distributions (this feature is in Technical Preview).</p> </li> <li> <p>DBaaS Changes: (this feature is in Technical Preview)</p> <ul> <li>It is easier to experience DBaaS functionality; you can quickly turn it ON/OFF in Advanced settings on the Settings page. (Read more)</li> <li>Database components management will enable PMM administrators to limit users in your organization to specific (admin-approved) database versions in their DBaaS DB Clusters.</li> <li>For PXC clusters created using DBaaS, HAProxy will now be used by default.  Please note: Monitoring of the HAProxy in DBaaS will be enabled in an upcoming release.</li> </ul> </li> <li> <p>Changes to Sign in to Percona Platform. From this release, Registration of the Percona account will be more secure and require additional confirmation.</p> </li> </ul>"},{"location":"release-notes/2.17.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-7863: DBaaS: Ability to specify in K8s configuration the version of HAProxy to be used for DB creation</li> <li>PMM-7848, PMM-7847, PMM-7421: Add support for using SSL certificates between pmm-admin and monitored MySQL databases</li> <li>PMM-7883: Single-line install of PMM Server on supported Linux distributions - [Technical Preview]</li> <li>PMM-7013, PMM-7819: DBaaS: Use HAProxy by default instead of ProxySQL for MySQL DB clusters</li> <li>PMM-7356, PMM-7581: DBaaS: Management of available versions of DB components</li> <li>PMM-7358, PMM-7576: DBaaS: Management of default versions of DB components</li> </ul>"},{"location":"release-notes/2.17.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-7572: Add TLS options to mysqld_exporter</li> <li>PMM-7783: Support of pg_stat_monitor 0.9.0</li> <li>PMM-7064: Integrated Alerting: Presenting severity of the Alert Rule using different colors</li> <li>PMM-7946: Better error message on PMM client if server doesn\u2019t support HAProxy</li> <li>PMM-7932: Usability improvements on UI for adding External Services</li> <li>PMM-7641, PMM-7820: Add DBaaS to Technical Preview section and allow user to Enable/Disable via UI</li> <li>PMM-7966: Telemetry: Collect enabled/disabled status for Integrated Alerting and Security Threat Tool features</li> </ul>"},{"location":"release-notes/2.17.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7911: DBaaS: Invalid Number of Nodes results in an annoying error message pop-up</li> <li>PMM-7884: DBaaS: Fix DB Cluster tab loading</li> <li>PMM-7917: PostgreSQL exporter has high CPU usage during Restart</li> <li>PMM-8037: User can create a Percona Platform account without proper confirmation</li> <li>PMM-7702: DBaaS: Cannot edit already-created PSMDB clusters</li> <li>PMM-7991: MySQL Summary panel doesn\u2019t exist on MySQL Summary dashboard</li> <li>PMM-7939: Inconsistent format of version reporting in pmm-admin</li> <li>PMM-7920: PostgreSQL Exporter has increased memory usage with pmm-client 2.15.1 &amp; pmm-server 2.16.0</li> <li>PMM-7700: Integrated Alerting: Rule API crashing with more than two parameters or invalid values</li> <li>PMM-7616: Integrated Alerting: Incorrect title of the page in a browser</li> <li>PMM-7396: Integrated Alerting: Alerts tab error if user deletes Alert Rule which has Firing alerts</li> </ul>"},{"location":"release-notes/2.18.0.html","title":"Percona Monitoring and Management 2.18.0","text":"Date: June 1, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.18.0.html#release-highlights","title":"Release Highlights","text":"<p>The goal for this small release was to eliminate a lot of bugs and complete some features.</p> <ul> <li> <p>DBaaS</p> <p>Added the ability for PMM to install the latest versions of the K8s operator into the K8s cluster. There is no longer any need to install the operator manually. Just connect PMM to your K8s cluster and let PMM do the rest.</p> </li> <li> <p>Backup Management</p> <p>Backup functionality was released as a Technical Preview feature and will require specific prerequisites from the user side to be installed. Currently, PMM will allow you to:</p> <ul> <li>manage storage for backups (S3 only);</li> <li>execute a backup for MySQL and Mongo instances;</li> <li>restore a MySQL backup to the same instance from where it was taken (via the UI).</li> </ul> <p>Restore in other cases is not yet implemented on the UI.</p> </li> </ul>"},{"location":"release-notes/2.18.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-7509: Integrated Alerting: Pagination for Alerts list</li> </ul>"},{"location":"release-notes/2.18.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8029: DBaaS: PSMDB 1.8 operator support</li> <li>PMM-7548: Integrated Alerting: Disable edit and delete buttons for templates manually staged by user directly on the file system</li> </ul>"},{"location":"release-notes/2.18.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8053: Better error handling for non-admins who try to access the settings page</li> <li>PMM-7941: Wrong replication status for MongoDB Replica Set</li> <li>PMM-7302: Webhook usage with <code>max_alerts</code> attribute for Alertmanager configuration causes errors for PMM</li> <li>PMM-7224: Instance Overview dashboards behave inconsistently</li> <li>PMM-6864: MongoDB Oplog Recovery Window dashboard is broken (Thanks to Clyde Shillingford for reporting this issue)</li> <li>PMM-7910: MongoDB Query metrics stops being collected if the cursor is failed once (Thanks to Yann Rouillard for reporting this issue)</li> <li>PMM-6451: Passing parameters between Query Analytics and Dashboards is broken</li> <li>PMM-5368: Unclear message \u201cFailed to get PMM Server parameter\u201d after configuration (Thanks to Martin Wittwer for reporting this issue)</li> <li>PMM-5135: Query Example is often empty for MySQL 8+ (Thanks to Mikhail Solovyev for reporting this issue)</li> <li>PMM-8083: Better configuration file checking during configuration</li> <li>PMM-7958: Databases cannot be deleted while PostgreSQL is being monitored</li> <li>PMM-6553: Slow log size units are not defined in help</li> <li>PMM-5931: Graph and values in Query Analytics are identical for TOTAL and case when data is Not Available</li> <li>PMM-5538: Heavy Load with Distinct Queries on Slowlog enabled could cause no data being reported</li> <li>PMM-8095: The link to the Community section in the PMM footer is broken</li> <li>PMM-7982: Query Analytics: Sorting element for the columns is hard to access</li> <li>PMM-6676: Terms and Privacy pages opened in the current tab complicates registration process</li> <li>PMM-6552: Do not register with server if configuration file fails to create on client</li> <li>PMM-6505: Inconsistent style for error messages on Add RDS instance page.</li> <li>PMM-8069: Integrated Alerting: Alert template now accepts <code>.yaml</code> extension in addition to <code>.yml</code> when manually staging on the file system</li> <li>PMM-7673: Integrated Alerting: Actions column is transparent</li> <li>PMM-7916: DBaaS: Wrong required resources when editing a cluster</li> <li>PMM-7753: DBaaS: Edit DB Cluster shows wrong values by default</li> <li>PMM-7184: DBaaS: Connection column showing different values after deleting DB cluster</li> <li>PMM-8088: DBaaS: In case of error, the kubeconfig file is left in the system</li> </ul>"},{"location":"release-notes/2.19.0.html","title":"Percona Monitoring and Management 2.19.0","text":"Date: June 30, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>Visit our forum to comment on this release.</p>"},{"location":"release-notes/2.19.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Backup Management can now be enabled from the UI. Go to  Configuration \u2192  Settings \u2192 Advanced Settings, and you will see it in the Technical Preview section. We also added support for MongoDB services on-demand backup and restore. For now, it only supports ReplicaSet on S3-compatible storage.</p> </li> <li> <p>Dashboards improvements</p> <ul> <li> <p>There are several community-driven improvements to ProxySQL data collection, with new dashboards to expose such metrics like: Queries Latency histograms and <code>SHUNNED_REPLICATION_LAG</code> state.</p> </li> <li> <p>Fixes for Amazon Aurora service detection on the dashboard, MongoDB ReplicaSet Summary, and other MongoDB memory-related panels.</p> </li> </ul> </li> <li> <p>Improvements to DBaaS secrets by generating strong passwords for operators. This is an improvement to the Automated Operator Installation released in PMM 2.18, which will greatly enhance security.</p> </li> </ul>"},{"location":"release-notes/2.19.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-7639: Backup Management: Ability to remove Backup Location even if there are some backup artifacts on it</li> <li>PMM-7567: Backup Management: Simple backup for MongoDB ReplicaSet</li> <li>PMM-7568: Backup Management: Simple restore for MongoDB ReplicaSet</li> </ul>"},{"location":"release-notes/2.19.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8112: Dashboards: Collect and present histograms from ProxySQL on Queries Latency dashboard (Thanks to foosinn for helping with this improvement)</li> <li>PMM-8081: Dashboards: Add collection and presentation for <code>SHUNNED_REPLICATION_LAG</code> state to <code>proxysql_connection_pool_status</code> (Thanks to spaceform for helping with this improvement)</li> <li>PMM-7584: Components Upgrade: VictoriaMetrics 1.53.1 to 1.60.0</li> <li>PMM-8001: Better error handling when <code>pg_stat_monitor</code> is an unsupported version</li> <li>PMM-7659: DBaaS: Ability to specify the type of connection for DBaaS cluster during DB Cluster creation</li> <li>PMM-7828: DBaaS: Select Database Type by default if only one operator is installed</li> <li>PMM-8153: Backup Management: Disable \u2018Restore\u2019 button for backups whose service has been deleted</li> </ul>"},{"location":"release-notes/2.19.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7194: \u2018Share with Percona\u2019 option doesn\u2019t export data from collapsed panels</li> <li>PMM-8060: User cannot add remote instances after OVF/AMI upgrade (previously was Known Issue)</li> <li>PMM-7104: Slowlog rotation by pmm-agent causing additional unexpected rotation of binary logs (Thanks to Arthur Tokarchuk for reporting this issue)</li> <li>PMM-8125: Error of monitoring GCP based PostgreSQL because of internal database <code>cloudsqladmin</code></li> <li>PMM-6778: Can\u2019t specify custom labels during node addition/configuration</li> <li>PMM-8090: Multi-request protection breaks metrics gathering (Thanks to Francisco Miguel Biete for fixing this bug)</li> <li>PMM-5248: InnoDB TableSpace data is not collected for Percona Server 8</li> <li>PMM-4665: User\u2019s log file contains error messages about TokuDB and heartbeat despite not being used</li> <li>PMM-8014: Error when adding Amazon RDS MySQL with TLS over API</li> <li>PMM-3352: Low file descriptors limit (1024) with AMI or OVF images causes errors</li> <li>PMM-7948: <code>pmm-admin list</code> reports the wrong Node for External Services</li> <li>PMM-6295: Unclear/Incorrect statuses of the pmm-agent when Agent or PMM server went down (Thanks to Mikhail Solovyev for reporting this issue)</li> <li>PMM-5917: pmm-agent moves slow logs without checking privileges</li> <li>PMM-8021: \u201cQuery Analytics\u201d misspelled on left side menu</li> <li>PMM-5283: Inconsistency with lengths of Example and Fingerprints in Query Analytics</li> <li>PMM-8121: Error message and help for \u201cRemove Service\u201d command is not helpful</li> <li>PMM-8196: Additional spaces in email/passwords fields on Sign up/Login pages causes Authentication problems</li> <li>PMM-8009: Long First/Last names causes errors when used in Register/Login form</li> <li>PMM-8220: Dashboards: Active Time Series Changes on Victoria Metrics dashboard report no data</li> <li>PMM-8202: Dashboards: No Amazon Aurora services are available on MySQL Amazon Aurora Details dashboard for selection</li> <li>PMM-8085: Dashboards: Wrong units are used in MongoDB dashboards on memory-related panels</li> <li>PMM-7154: Dashboards: No data on some panels from MongoDB ReplSet Summary dashboard</li> <li>PMM-8115: DBaaS: Delete PSMDB cluster action takes too long</li> <li>PMM-7737: DBaaS: Replace all default passwords in operator secrets during installation</li> <li>PMM-7970: DBaaS: Confusing message for Cluster name pattern on DB Cluster creation screen</li> <li>PMM-7755: DBaaS: Clusters with longer name not initializing</li> <li>PMM-7528: DBaaS: Error after Kubernetes cluster destroyed or removed externally to DBaaS</li> <li>PMM-8013: Backup Management: Unable to get Backup Artifact list after Service removal</li> </ul>"},{"location":"release-notes/2.2.0.html","title":"Percona Monitoring and Management 2.2.0","text":"Date: December 24, 2019 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance. You can run PMM in your own environment for maximum security and reliability. It provides thorough time-based analysis for MySQL, MongoDB, and PostgreSQL servers to ensure that your data works as efficiently as possible.</p> <p>Main improvements in this release are:</p> <ul> <li>Alternative installation methods available for PMM 1.x are re-implemented for PMM 2: now PMM Server can be installed as a virtual appliance, or run using AWS Marketplace</li> <li>AWS RDS and remote instances monitoring re-added in this release include AWS RDS MySQL / Aurora MySQL instances, and remote PostgreSQL, MySQL, MongoDB, and ProxySQL ones</li> <li>The new Settings dashboard allows configuring PMM Server via the graphical interface</li> </ul> <p>For PMM install instructions, see Installing PMM Server and Installing PMM Client.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p>"},{"location":"release-notes/2.2.0.html#improvements-and-new-features","title":"Improvements and new features","text":"<ul> <li>PMM-4575: The new PMM Settings dashboard allows users to configure various PMM Server options: setting metrics resolution and data retention, enabling or disabling send usage data statistics back to Percona and checking for updates; this dashboard is now the proper place to upload your public key for the SSH login and to download PMM Server logs for diagnostics</li> <li>PMM-4907 and PMM-4767: The user\u2019s AMI Instance ID is now used to setup running PMM Server using AWS Marketplace as an additional verification on the user, based on the Amazon Marketplace rules</li> <li>PMM-4950 and PMM-3094: Alternative AWS partitions  are now supported when adding an AWS RDS MySQL or Aurora MySQL Instance to PMM</li> <li>PMM-4976: Home dashboard clean-up: \u201cSystems under monitoring\u201d and \u201cNetwork IO\u201d <code>singlestats</code> were refined to be based on the <code>host</code> variable; also avoiding using color as an indicator of state; \u201cAll\u201d row elements were relinked to the \u201cNodes Overview\u201d dashboard with regards to the selected host.</li> <li>PMM-4800: The <code>pmm-admin add mysql</code> command has been modified to make help text more descriptive: now when you enable <code>tablestats</code> you will get more detail on if they\u2019re enabled for your environment and where you stand with respect to the auto-disable limit</li> <li>PMM-4969: Update Grafana to version 6.5.1</li> <li>PMM-5053: A tooltip was added to the Head Block graph on the Prometheus dashboard</li> <li>PMM-5068: Drill-down links were added to the Node Summary dashboard graphs</li> <li>PMM-5050: Drill-down links were added to the graphs on all Services Compare dashboards</li> <li>PMM-5037: Drill-down links were added to all graphs on the Services Overview dashboards</li> <li>PMM-4988: Filtering in Query Analytics have undergone improvements to make group selection more intuitive: Labels unavailable under the current selection are shown as gray/disabled, and the percentage values are dynamically recalculated to reflect Labels available within the currently applied filters</li> <li>PMM-4966: All passwords are now substituted with asterisk signs in the exporter logs for security reasons when not in debug mode</li> <li>PMM-527: <code>node_exporter</code> is now providing hardware monitoring information such as CPU temperatures and fan statuses; while this information is being collected by PMM Server, it will not be shown until a dedicated dashboard is added in a future release</li> <li>PMM-3198: Instead of showing All graphs for all services by default, MySQL Command/Handler Counters Compare dashboard now shows the predefined set of ten most informative ones, to reduce load on PMM Server at its first open</li> </ul>"},{"location":"release-notes/2.2.0.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-4978: The \u201cTop MySQL Questions\u201d <code>singlestat</code> on the MySQL Instances Overview dashboard was changed to show ops instead of percentage</li> <li>PMM-4917: The \u201cSystems under monitoring\u201d and \u201cMonitored DB Instances\u201d <code>singlestats</code> on the Home dashboard now have a sparkline to make situation more clear with recently shut down nodes/instances</li> <li>PMM-4979: Set decimal precision <code>2</code> for all the elements, including charts and <code>singlestats</code>, on all dashboards</li> <li>PMM-4980: Fix \u201cLoad Average\u201d <code>singlestat</code> on the Node Summary dashboard to show decimal value instead of percent</li> <li>PMM-4981: Disable automatic color gradient in filled graphs on all dashboards</li> <li>PMM-4941: Some charts were incorrectly showing empty fragments with high time resolution turned on</li> <li>PMM-5022: Fix outdated drill-down links on the Prometheus Exporters Overview and Nodes Overview dashboards</li> <li>PMM-5023: Make the All instances <code>uptime singlestat</code> on the Home dashboard to show <code>Min</code> values instead of <code>Avg</code></li> <li>PMM-5029: Option to upload dashboard snapshot to Percona was disappearing after upgrade to 2.1.x</li> <li>PMM-4946: Rename singlestats on the Home dashboard for better clarity: \u201cSystems under monitoring\u201d to \u201cNodes under monitoring\u201d and \u201cMonitored DB Instances\u201d to \u201cMonitored DB Services\u201d, and make the last one to count remote DB instances also</li> <li>PMM-5015: Fix format of Disk Page Buffers singlestat on the Compare dashboard for PostgreSQL to have two digits precision for the consistency with other singlestats</li> <li>PMM-5014: LVM logical volumes were wrongly sized on a new AWS deployment, resulting in \u201cno space left on device\u201d errors.</li> <li>PMM-4804: Incorrect parameters validation required both <code>service-name</code> and <code>service-id</code> parameters of the <code>pmm-admin remove</code> command to be presented, while the command itself demanded only one of them to identify the service.</li> <li>PMM-3298: Panic errors were present in the <code>rds_exporter</code> log after adding an RDS instance from the second AWS account</li> <li>PMM-5089: The <code>serialize-javascript</code> package was updated to version 2.1.1 because of the possibility of regular expressions cross-site scripting vulnerability in it (CVE-2019-16769). Please note PMM versions were not affected by this vulnerability, as <code>serialize-javascript</code> package is used as a build dependency only.</li> <li>PMM-5149: Disk Space <code>singlestat</code> was unable to show data for RDS instances because of not taking into account sources with unknown file system type</li> </ul>"},{"location":"release-notes/2.2.1.html","title":"Percona Monitoring and Management 2.2.1","text":"Date: January 23, 2020 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>For PMM install instructions, see Installing PMM Server and Installing PMM Client.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p> <p>PMM Server version 2.2.0 suffered an unauthenticated denial of service vulnerability (CVE-2020-7920). Any other PMM versions do not carry the same code logic, and are thus unaffected by this issue. Users who have already deployed PMM Server 2.2.0 are advised to upgrade to version 2.2.1 which resolves this issue.</p>"},{"location":"release-notes/2.2.1.html#improvements-and-new-features","title":"Improvements and new features","text":"<ul> <li>PMM-5229: The new RDS Exporter section added to the Prometheus Exporter Status dashboard shows singlestats and charts related to the <code>rds_exporter</code></li> <li>PMM-5228 and PMM-5238: The Prometheus dashboard and the Exporters Overview dashboard were updated to include the <code>rds_exporter</code> metrics in their charts, allowing better understanding of the impacts of monitoring RDS instances</li> <li>PMM-4830: The consistency of the applied filters between the Query Analytics and the Overview dashboards was implemented, and now filters selected in QAN will continue to be active after the switch to any of the Overview dashboards available in the Services menu</li> <li>PMM-5235: The DB <code>uptime</code> <code>singlestats</code> in node rows on the Home dashboard were changed to show minimal values instead of average ones to be consistent with the top row</li> <li>PMM-5127: The \u201cSearch by\u201d bar on the Query Analytics dashboard was renamed to \u201cFilter by\u201d to make its purpose more clear</li> <li>PMM-5131: The Filter panel on the Query Analytics dashboard now shows the total number of available Labels within the \u201cSee all\u201d link, which appears if the Filter panel section shows only top 5 of its Labels</li> </ul>"},{"location":"release-notes/2.2.1.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-5232: The <code>pmm-managed</code> component of the PMM Server 2.2.0 is vulnerable to DoS attacks, that could be carried out by anyone who knows the PMM Server IP address (CVE-2020-7920). Versions other than 2.2.0 are not affected.</li> <li>PMM-5226: The handlebars package was updated to version 4.5.3 because of the Prototype Pollution vulnerability in it (CVE-2019-19919). Please note PMM versions were not affected by this vulnerability, as handlebars package is used as a build dependency only.</li> <li>PMM-5206: Switching to the Settings dashboard was breaking the visual style of some elements on the Home dashboard</li> <li>PMM-5139: The breadcrumb panel, which shows all dashboards visited within one session starting from the root, was unable to fully show breadcrumb longer than one line</li> <li>PMM-5212: The explanatory text was added to the Download PMM Server Logs button in the Diagnostic section of the PMM Settings dashboard, and a link to it was added to the Prometheus dashboard which was the previous place to download logs</li> <li>PMM-5215: The unneeded <code>mariadb-libs</code> package was removed from the PMM Server 2.2.0 OVF image, resulting in both faster updating with the <code>yum update</code> command and avoiding dependency conflict messages in the update logs</li> <li>PMM-5216: PMM Server Upgrade to 2.2.0 was showing Grafana Update Error page with the Refresh button which had to be clicked to start using the updated version</li> <li>PMM-5211: The \u201cWhere do I get the security credentials for my Amazon RDS DB instance\u201d link in the Add AWS RDS MySQL or Aurora MySQL instance dialog was not targeted at the appropriate instruction</li> <li>PMM-5217: PMM 2.x OVF Image memory size was increased from 1 Gb to 4 Gb with the additional 1 Gb swap space because the previous amount was hardly housing the PMM Server, and it wasn\u2019t enough in some cases like performing an upgrade</li> <li>PMM-5271: LVM logical volumes were wrongly resized on AWS deployment, resulting in \u201cno space left on device\u201d errors</li> <li>PMM-5295: InnoDB Transaction Rollback Rate values on the MySQL InnoDB Details dashboard were calculated incorrectly</li> <li>PMM-5270: PXC/Galera Cluster Summary dashboard was showing empty Cluster drop-down list, making it impossible to choose the cluster name</li> <li>PMM-4769: The wrongly named \u201cTimeout value used for retransmitting\u201d <code>singlestat</code> on the Network Details dashboard was renamed to \u201cThe algorithm used to determine the timeout value\u201d and updated to show the algorithm name instead of a digital code</li> <li>PMM-5260: Extensive resource consumption by <code>pmm-agent</code> took place in case of Query Analytics for PostgreSQL; it was fixed by a number of optimizations in the code, resulting in about 4 times smaller memory usage</li> <li>PMM-5261: CPU usage charts on all dashboards which contain them have undergone colors update to make <code>softIRQ</code> and Steal curves better differentiated</li> <li>PMM-5244: High memory consumption in the PMM Server with a large number of agents sending data simultaneously was fixed by improving bulk data insertion to the ClickHouse database</li> </ul>"},{"location":"release-notes/2.2.2.html","title":"Percona Monitoring and Management 2.2.2","text":"Date: February 4, 2020 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>For PMM install instructions, see Installing PMM Server and Installing PMM Client.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p>"},{"location":"release-notes/2.2.2.html#improvements-and-new-features","title":"Improvements and new features","text":"<ul> <li>PMM-5321: The optimization of the Query Analytics parser code for PostgreSQL queries allowed us to reduce the memory resources consumption by 1-5%, and the parsing time of an individual query by 30 to 40%</li> <li>PMM-5184: The <code>pmm-admin summary</code> command have gained a new <code>--skip-server</code> flag which makes it operating in a local-only mode, creating summary file without contacting the PMM Server</li> </ul>"},{"location":"release-notes/2.2.2.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-5340: The Scraping Time Drift graph on the Prometheus dashboard was showing wrong values because the actual metrics resolution wasn\u2019t taken into account</li> <li>PMM-5060: Query Analytics Dashboard did not show the row with the last query of the first page, if the number of queries to display was 11</li> </ul>"},{"location":"release-notes/2.20.0.html","title":"Percona Monitoring and Management 2.20.0","text":"Date: August 3, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.20.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li>The Easy-install script for PMM Server is checksum verified.</li> <li>PMM will use Grafana 7.5 instead of 7.3. We are also preparing for Grafana 8.</li> <li>PostgreSQL monitoring with the <code>pg_stat_monitor</code> plugin enabled exposes new metrics such as Plan Times, WAL Fpi/Bytes/Records.</li> <li>For users who deploy PMM Server through the AWS Marketplace, AWS RDS service discovery will be executed without AWS credentials and tuning IAM roles.</li> <li>For Backup Management (Technical Preview), we added the ability to schedule backups so you can schedule and see already scheduled backups in the UI.</li> </ul>"},{"location":"release-notes/2.20.0.html#important-note-for-users-of-pmm-who-started-out-using-the-docker-image-of-2160","title":"Important note for users of PMM who started out using the Docker image of 2.16.0","text":"<p>If you installed PMM version 2.16 as a new Docker image and have since used the home dashboard upgrade widget to upgrade to any of 2.17, 2.18, or 2.19, you might experience problems with monitoring the PMM server itself, Remote Monitoring, or RDS/Azure monitoring. If you experience any of these problems, you can simply run the following commands to get your instance working and it will be automatically resolved in the next release:</p> <ol> <li>Enter the container: <code>docker exec -it pmm-server bash</code></li> <li>Roll back <code>pmm2-client</code> package to stable version: <code>yum downgrade -y pmm2-client</code></li> </ol> <p>Alternatively, you can replace the existing Docker container with a fresh install of the latest release by following the official instructions for an upgrade. (This will guide you through taking a backup of your PMM Server and restoring it after installing a fresh docker image of PMM Server.)</p>"},{"location":"release-notes/2.20.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-8157: Backup Management: Show scheduled backups \u2013 A new view that shows the list of scheduled backups with quick actions to enable/disable, edit, copy, and delete.</li> <li>PMM-8155: Backup Management: Scheduling of backups \u2013 Support for Backup Scheduling has been added so that users can define backup jobs to run automatically in the future with the option of making the schedules recurring.</li> <li>PMM-7010: Option to unregister current node (<code>pmm-admin unregister</code>)</li> </ul>"},{"location":"release-notes/2.20.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-7552: PMM Server Docker image: Add labels to PMM Server Docker image (Thanks to Nicolas for reporting this issue)</li> <li>PMM-8266: PMM Server Docker image: Decommission and remove Prometheus binaries and configuration</li> <li>PMM-8040: PMM Server Docker image: Remove yum cache to reduce size of image</li> <li>PMM-7809: Grafana upgrade from 7.3.7 to 7.5.7 \u2013 Read more at grafana.com</li> <li>PMM-8386: Overview text on the Home page is missing PostgreSQL as a supported technology</li> <li>PMM-7722: DBaaS: Announce new supported version of operator \u2013 Shows that a new version of the operator is available.</li> <li>PMM-6278: Modification of MySQL \u2018Delete\u2019 queries to provide \u2018Explain\u2019 information</li> <li>PMM-8468: Forbid the use of outdated ciphers for HTTPS protocol on exporters</li> <li>PMM-7649: Security Checks: Show \u201cInsufficient access permissions\u201d in UI for non admin users</li> <li>PMM-8059: Update Query Analytics UI to clarify estimated results on MySQL \u2018explain\u2019 response where we modified original query</li> <li>PMM-8043: Return Service Name in <code>GetCheckResults</code> API response</li> <li>PMM-8000: Expose new numbered metrics available in <code>pg_stat_monitor</code> 0.9</li> </ul>"},{"location":"release-notes/2.20.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8299: Backup Management: Remove storage location shows wrong notification \u2013 When removing a storage location, PMM presents misleading information to the user in the form of two notification messages for both error and success.</li> <li>PMM-8283: Backup Management: Error when removing location with \u2018force delete\u2019 option</li> <li>PMM-8064: Dashboards: Size of Temp Files Report Metric value has wrong unit on PostgreSQL Instance Summary Dashboard</li> <li>PMM-6981: Dashboards: Wrong version is shown for MariaDB services</li> <li>PMM-7738: Integrated Alerting: Alerts for some built-in templates missing service name label</li> <li>PMM-6877: <code>mongodb_exporter</code> doesn\u2019t recognize being on a mongos host and fills the syslog with <code>replSetGetStatus</code> errors (Thanks to Clyde Shillingford for reporting this issue)</li> <li>PMM-7627: Consistent PMM Server log management \u2013 Adds consistency to the log management of <code>nginx</code>, <code>postgresql</code> and <code>clickhouse-server</code>, which is now delegated to <code>supervisord</code>. Removes the <code>logrotate</code> daemon from the image.</li> <li>PMM-8492: PMM Client version is 2.21.0 inside PMM Server after upgrade from 2.16.0</li> </ul>"},{"location":"release-notes/2.20.0.html#known-issues-unfixed-problems-that-you-should-be-aware-of","title":"Known Issues (unfixed problems that you should be aware of)","text":"<ul> <li>PMM-8414: Backup Scheduler not working if user specifies explicit job start time</li> </ul>"},{"location":"release-notes/2.21.0.html","title":"Percona Monitoring and Management 2.21.0","text":"Date: August 26, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.21.0.html#release-highlights","title":"Release Highlights:","text":"<ul> <li> <p>Custom certificates support: We have added support for custom TLS certificates for remote monitoring of PostgreSQL and MongoDB services, configurable on the command line with <code>pmm-admin</code> or through the UI.</p> </li> <li> <p>Backup scheduling with retention (Technical Preview): When scheduling a backup you can now specify how many of the most recent backups to keep. Backups not in this range are automatically deleted to free space for new ones.</p> </li> <li> <p>New supported versions:</p> <ul> <li>DBaaS functionality now supports Kubernetes Operator for MongoDB version 1.9.0.</li> <li>PMM Client packages now support Debian 11 (\u201cBullseye\u201d).</li> </ul> </li> </ul>"},{"location":"release-notes/2.21.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-8158: Backup Management: Delete option \u2014 When deleting a backup from Backup Management inventory a new option lets you also delete the data file from storage.</li> <li>PMM-8156: Backup Management: Retention \u2014 You can now define how many of the most recent scheduled backups to keep.</li> <li>PMM-8214: Ability to collect Kubernetes cluster metrics \u2014 Collection only, metrics are not currently presented on any PMM dashboard.</li> <li>PMM-7477: Support custom TLS certificates when monitoring remote MongoDB instances</li> <li>PMM-7888: Custom TLS certificates now allow SSL connections to PostgreSQL instances (Thanks to Jyoti Prakash for reporting this issue)</li> </ul>"},{"location":"release-notes/2.21.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8267: Backup Management: Active progress indicator</li> <li>PMM-8549: Backup Management: Show loading status on delete window</li> <li>PMM-8542: Backup Management: Inform that times should be entered in UTC timezone format</li> <li>PMM-8316: DBaaS: PSMDB 1.9 operator support \u2014For what\u2019s new see release notes.</li> <li>PMM-7612: Integrated Alerting: Validate communication settings \u2018From\u2019 email address format</li> <li>PMM-7570: Specify Custom Basic Auth password for Agents when adding Services</li> <li>PMM-8560: Add support for Debian 11 (\u201cBullseye\u201d) to <code>pmm-client</code> package</li> <li>PMM-7087: Rename custom query file to <code>example-queries-postgres.yml</code> and include warning that the file will be overwritten on upgrade; user should create a copy with a new name to prevent losing metrics collection on future upgrades. (Thanks to Daniel Guzman Burgos for reporting this issue)</li> <li>PMM-8568: Use latest CentOS patches for creating OVA, AMI and Azure images</li> <li>PMM-5291: Update ClickHouse version from 19.7.5.27 to 21.3-lts</li> <li>PMM-8091: Collect and present additional ProxySQL metrics taken from <code>runtime_mysql_servers</code> table</li> </ul>"},{"location":"release-notes/2.21.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8616: Backup Management: No \u2018Delete from storage\u2019 action on backup inventory</li> <li>PMM-8543: Backups are not visible after PMM Server upgrade</li> <li>PMM-8458: Backup Management: Inconsistent auto-fill of \u2018Vendor\u2019 field with on-demand backup</li> <li>PMM-8404: Dashboard image rendering plugin renders image that includes error message</li> <li>PMM-7286: Query Analytics can\u2019t handle colon character (<code>:</code>) in service names (Thanks to Daniel Guzman Burgos for reporting this issue)</li> <li>PMM-7278: <code>mongo_exporter</code> fails to authorize when MongoDB running with <code>authMechanism=MONGODB-X509</code> (Thanks to Lena D for reporting this issue)</li> <li>PMM-8307: Default configuration limits for allowed connections prevents monitoring large numbers (500+) of DB servers</li> <li>PMM-2168: <code>rds_exporter</code> not stopped when all RDS instances are removed or disabled</li> <li>PMM-8219: PMM Server update panel \u201cCurrent version\u201d empty if no internet connectivity</li> <li>PMM-8559: Unauthorized error appears while logging in</li> </ul>"},{"location":"release-notes/2.21.0.html#known-issues","title":"Known Issues","text":"<ul> <li>Failure to upgrade when using a dashboard with custom tags.</li> </ul> <p>Important</p> <p>In some cases users may not be able to complete the upgrade to 2.21.0 and we have linked this back to dashboards with custom tags.  This is to be fixed in our upcoming 2.22.0 release but there are steps (more in the ticket) that you can take if you\u2019re already impacted by this:</p> <pre><code>curl -LJOs https://raw.githubusercontent.com/percona/pmm-server/c2e92bc3aec123affda5f1992c96c95ac74f4a2d/import-dashboards.py\ndocker cp import-dashboards.py pmm-server:/usr/share/percona-dashboards/\ndocker exec -it pmm-server chmod a+x /usr/share/percona-dashboards/import-dashboards.py\n</code></pre>"},{"location":"release-notes/2.22.0.html","title":"Percona Monitoring and Management 2.22.0","text":"Date: September 23, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.22.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li>DBaaS (Technical preview): DBaaS users can now use the PMM UI to upgrade existing Clusters to the newer version of the operator without interacting directly with Kubernetes.</li> </ul>"},{"location":"release-notes/2.22.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-8396: Backup Management: Add an ability to specify the number of retries for Scheduled backups before operation fails</li> <li>PMM-8079: DBaaS: Percona Operators inside Kubernetes cluster managed by PMM can now be upgraded</li> <li>PMM-8077: DBaaS: Show the current version of Operators used in Kubernetes Cluster</li> <li>PMM-7924: MySQL Performance Details dashboard: Add \u201cPerformance Schema Status Monitoring\u201d chart</li> </ul>"},{"location":"release-notes/2.22.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8688: Backup Management: When adding a new Backup, the action button now reads \u201cCreate Backup\u201d instead of \u201cEdit\u201d to reflect the action happening</li> <li>PMM-8311: Integrated Alerting: Disable edit/delete buttons for Percona-sourced Templates</li> <li>PMM-8509: Management of ability to update PMM Server in the same way as this implemented to other Settings for PMM. Users can use API, UI, or docker Environment Variables to change the setting responsible for the Update process.  As with all PMM settings, environment variables have higher priority and can\u2019t be changed with the API or in the UI.</li> <li>PMM-7392: DBaaS: Change Number of Nodes when editing Topology</li> </ul>"},{"location":"release-notes/2.22.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8613: Backup Management: Unable to restore MySQL backup</li> <li>PMM-8463: Backup Management: State stuck on \u201cPending\u201d when creating backup with already existing name</li> <li>PMM-8408: DBaaS: Development version of PMM Client was used for monitoring DB Clusters created by DBaaS</li> <li>PMM-8584: Wrong CPU metric labels in dashboards for RDS instances</li> <li>PMM-8421: Listen-port ignored/removed for external services after server update to PMM 2.19 and higher (Thanks to Rainer Plischke for reporting this issue). Please make sure to upgrade PMM Server to avoid loss of external exporter listen port (PMM-8829) and always upgrade PMM Server before PMM Client (PMM-8854).</li> <li>PMM-8703: Custom dashboard prevents PMM Server Docker update from 2.20 to 2.21 (Thanks to Hubertus Krogmann for reporting this issue)</li> <li>PMM-7690: AWS discovery and monitoring based on IAM roles is not working</li> </ul> <p>If you have problems upgrading your <code>pmm-2-client</code> packages, try clearing caches with:</p> <pre><code>sudo apt-get clean\n</code></pre> <p>and remove files manually with:</p> <pre><code>cd /var/cache/apt/archives &amp;&amp; sudo rm -rf ./*\n</code></pre>"},{"location":"release-notes/2.23.0.html","title":"Percona Monitoring and Management 2.23.0","text":"Date: October 21, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.23.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Grafana Upgrade Embedded Grafana version was upgraded from 7.5.7 to 7.5.11 to improve some Grafana instrumentation metrics. Also, the upgrade is delivering a security fix that impacted Grafana. Please upgrade to the latest version of PMM ASAP. Read more about CVE issue here</p> </li> <li> <p>Backup Management (Technical preview):</p> <ul> <li>An ability to view logs of the backup process for better visibility over the backup process</li> <li>An ability to schedule Point-In-Time-Recoverable backup from MongoDB clusters with the correct configuration. Note: there is no UI  to restore PITR for MongoDB at the moment. It will come with future releases, but it is possible to restore a PITR backup with Percona Backup for MongoDB manually</li> </ul> </li> <li> <p>DBaaS (Technical preview):  From this release on, PMM users who are using the DBaaS feature will be able to update versions of their DBaaS controlled Databases by the push of a button according to each DB\u2019s compatibility matrix. Please note that we recently found a bug PMM-8723 that was causing significant problems with DBaaS usage. This bug was fixed in this release, and no additional actions will be required.</p> </li> </ul>"},{"location":"release-notes/2.23.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-8269: Backup Management: Ability to schedule Point-In-Time-Recoverable backups for MongoDB</li> <li>PMM-8159: Backup Management: Ability to see a logs of backup process for MongoDB</li> <li>PMM-7519: Backup Management: Version compatibility check prior to attempted MySQL data restoration</li> <li>PMM-8200: DBaaS: Admin can now initiate a DB version upgrade with just a button click</li> <li>PMM-8273: Integrated Alerting: Alert templates delivery from Percona.com for anonymous PMM servers</li> </ul>"},{"location":"release-notes/2.23.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8973: Grafana upgrade from 7.5.7 to 7.5.11 Includes better Grafana instrumentation metrics and fix for CVE-2021-39226 (read more on Grafana blog)</li> <li>PMM-8653: Added titles to Home Dashboard panels for better readability</li> <li>PMM-8669: Integrated Alerting: Create a clearer distinction about using PMM Alerting as preferred method vs using an external Alertmanager</li> <li>PMM-8539: Wrong Cluster Role presentation on MongoDB Cluster Summary</li> <li>PMM-7559: Integrated Alerting: Improve error message when trying to delete a channel that is used by a rule</li> <li>PMM-6763: Better color contrast in Time distribution in QAN details</li> <li>PMM-5669: New flag \u2013paths-base in pmm-agent to avoid problems with hard-coded paths. Please note: this is possible if you run pmm-agent separately from pmm-admin. The ability to specify base paths over pmm-admin is not yet implemented</li> </ul>"},{"location":"release-notes/2.23.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-7985: Users were losing manually installed Grafana plugins after upgrade via Docker</p> <p>Caution</p> <p>The issue is fixed automatically since 2.23.0 version forward. For the upgrades from versions before 2.23.0 please backup plugins first.</p> </li> <li> <p>PMM-8767: Copied dashboards with tags were ending up in unexpected folder after upgrade</p> </li> <li>PMM-8635: MyRocks WAL panel from MySQL MyRocks Details Dashboard presented data in wrong units</li> <li>PMM-8527: Dashboards: ProxySQL/HAProxy DB Conns, DB QPS, DB uptime metrics were missing on Home dashboard panels</li> <li>PMM-8749: Adding more than 1 <code>mongos</code> was breaking MongoDB Cluster Summary dashboard</li> <li>PMM-8004: Fixed broken metrics reporting in case of lost connection to MongoDB. (Thanks to \u00c1lvaro L\u00f3pez L\u00f3pez for reporting this issue)</li> <li>PMM-8489: Failed to get topology labels when target server is <code>mongos</code></li> <li>PMM-6877: Fixed error flooding from when monitoring mongos (Thanks to Clyde Shillingford for reporting this issue)</li> <li>PMM-8851: Can\u2019t monitor GCP Cloud SQL or other PostgreSQL with custom SSL certificates (Thanks to Jyoti Prakash for reporting this issue)</li> <li>PMM-8646: PostgreSQL services monitoring was stalled after intermittent connection latency</li> <li>PMM-8723: PMM wouldn\u2019t restart DBaaS functionality and would break it after upgrade via UI. Affecting versions starting from 2.17.0</li> </ul>"},{"location":"release-notes/2.24.0.html","title":"Percona Monitoring and Management 2.24.0","text":"Date: November 18, 2021 Installation: Installing Percona Monitoring and Management <p>Important note for users of PMM 2.24.0</p> <p>2.24.0 AMI image has only 8GB available for the data, it is a bug (see PMM-9298). To resize a disk to full size you need to login to AMI instance with SSH and use the following command:</p> <pre><code>curl https://raw.githubusercontent.com/percona/pmm-update/main/ansible/playbook/tasks/create-lvm.yml -o lvn-fix.yml &amp;&amp; sudo ansible-playbook lvn-fix.yml\n</code></pre> <p>For instructions about how to access your instances by using an SSH client, see Connecting to Your Linux Instance Using SSH Make sure to replace the user name ec2-user used in this document with admin.</p> <p>What this command does:</p> <ol> <li>Downloads Ansible playbook and runs it</li> <li>Copy your data from /srv to the temporary directory</li> <li>Create lvm partition</li> <li>Copy data from system disk to a new LVM partition</li> </ol> <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.24.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li>Enhanced PostgreSQL monitoring</li> <li>Beginning with this release, PMM now supports monitoring of PostgreSQL 14, both - Community edition and Percona Distribution for PostgreSQL.</li> <li> <p>We\u2019ve made significant improvements in exposed data and added additional features if you monitor PostgreSQL together with the pg_stat_monitor extension (Part of Percona distribution for PostgreSQL). These features include:</p> <ul> <li>The PostgreSQL queries will have complete Query Execution Plan information. This will help with future optimization of queries and give a clear understanding of query performance</li> <li>Query execution histograms collection and presentation inside Query Analytics for a much more detailed understanding of query executions.</li> <li>Query analytics will both show and let the user drill down to the Top Query of the particular query if it\u2019s a subquery and have this parent query. This feature will allow users to see the dependencies between queries better and understand the impact of subqueries.</li> <li>Query Analytics can filter PostgreSQL queries by query commands like SELECT, UPDATE, etc., and by Application Name if it\u2019s set for PostgreSQL connection from the application.</li> </ul> </li> <li> <p>Integrated Alerting (Technical preview):</p> <ul> <li>Alerting in PMM now has an additional notification channel type - webhooks. So now, users can integrate Alerting with any tool they use for Incident management.  Read more about new notification channels and how to set them up in our documentation</li> </ul> </li> </ul>"},{"location":"release-notes/2.24.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-8027: Integrated Alerting: New notification channel added: Webhooks</li> <li>PMM-8301: Add data collection support and visualization for newly added dimensions in pg_stat_monitor such as Application Name,Top Query, Plan in Query Analytics</li> <li>PMM-8588: PostgreSQL Histograms added to QAN when using pg_stat_monitor extension</li> <li>PMM-8632: New Filter: \u201cCommand Type\u201d allows filtering queries based on type (SELECT, INSERT, UPDATE, DELETE, n/a) when pg_stat_monitor extension enabled</li> </ul>"},{"location":"release-notes/2.24.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8803: Backup Management: Improved error messages to indicate incompatible versions of software</li> <li>PMM-8636: Integrated Alerting: Additional context to alerts to better convey issue detected</li> <li>PMM-8644: Integrated Alerting: API should allow textual TLS configurations for webhooks</li> <li>PMM-8122: Integrated Alerting: UI does not indicate a port is needed in configuration for SMTP communication channel</li> <li>PMM-8484: Added support for PostgreSQL 14 and Percona Distribution for PostgreSQL 14</li> <li>PMM-7297: Updated plugin for ClickHouse data source  from 2.1.0 to 2.3.1. This fixes some bugs and eliminates noise from warnings in logs as well as adding support of new types (<code>DateTime64</code>) and improved ARRAY JOIN parsing</li> </ul>"},{"location":"release-notes/2.24.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8975: Backup Management: long presentation of recurrent intervals in Backup scheduling</li> <li>PMM-8541: Navigating through PMM Settings link at Failed security checks panel takes more than 30 seconds</li> <li>PMM-8387: MySQL InnoDB Details dashboard is not in the left menu</li> <li>PMM-8858: Dashboards: No Host uptime on Homepage for RDS instances</li> <li>PMM-8611: Dashboards: PMM Agents status presented as DOWN while there is no recent data yet on the status</li> <li>PMM-8393: Integrated Alerting: Alert rules not executed after upgrading PMM Server running as Docker container</li> <li>PMM-8058: Integrated Alerting: Firing alerts disappear after PMM server restart</li> <li>PMM-8089: PMM is not exposing data for memory used by MongoDB when it\u2019s mapped with the journal. This was inconsistent behavior compared to older versions of PMM.</li> <li>PMM-9100: Dashboards: Binary Log related metrics on MySQL Replication dashboard are not prevented and not collected for MySQL 8</li> <li>PMM-8633: Unfinished queries are included in Query Analytics for PostgreSQL with pg_stat_monitor usage because of incorrect use of <code>state_code</code>.</li> <li>PMM-8859: Increased memory consumption on Client-side for PostgreSQL monitoring when executing either too many custom queries or some queries against too many tables</li> <li>PMM-9046: Incorrect link to instructions about installing Image Rendering Plugin</li> <li>PMM-8952: Query Analytics: No table/indexes information for Views when PostgreSQL server monitored with pg_stat_monitor</li> </ul>"},{"location":"release-notes/2.25.0.html","title":"Percona Monitoring and Management 2.25.0","text":"Date: December 14, 2021 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>Important note for users considering docker way upgrade to PMM 2.25.0</p> <p>If you upgrade from a PMM version less than or equal to 2.23.0 using docker, it will fail if your PMM does not have external access (access to <code>repo. percona.com</code>). Thus, it is recommended to upgrade to PMM 2.26.0 instead. See PMM-9416 for more details.</p>"},{"location":"release-notes/2.25.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>Percona Platform (Technology Preview):</p> <ul> <li>Connect Percona Monitoring and Management (PMM) to Percona Platform to boost the monitoring capabilities of your PMM installations and access all your Percona accounts and services from one single, centralized location. For more information, see the Percona Platform Portal documentation</li> </ul> </li> <li> <p>Enhanced PostgreSQL monitoring</p> <ul> <li> <p>You can now specify custom database names when adding PostgreSQL Servers for monitoring. Previous PMM versions always used the default <code>postgres</code> name instead.</p> </li> <li> <p>Added support for the new version of <code>pg_stat_monitor</code> extension. Release Candidate v1.0.0-rc.1 brings many new PostgreSQL metrics, Dashboards and Query Analytics! To find out about all the features available in the new <code>pg_stat_monitor</code> version, see the pg_stat_monitor User guide</p> </li> <li> <p>Added compatibility for the latest Percona Distributions for PostgreSQL 14, 13, 12, 11 updated on December 7, 2021, which includes the newest version of the <code>pg_stat_monitor</code> extension.</p> </li> </ul> </li> <li> <p>Grafana usability enhancements</p> <ul> <li> <p>PMM is now using the native Grafana provisioning mechanism for adding dashboards, plug-ins, and data sources. This ensures faster and more reliable upgrading to newer PMM versions. Your existing plug-ins and dashboard changes are preserved during upgrades, but always make sure to back them up before upgrading and check that everything transferred correctly afterward.</p> </li> <li> <p>Added option to change the time zone on dashboards. This selection is preserved while you navigate over Dashboards. If you need to change this setting permanently for your account, change it in your preferences by the URL: <code>https://YOUR_PMM_SERVER/graph/profile</code></p> </li> </ul> </li> <li> <p>DBaaS (Technical Preview)</p> <ul> <li>You can now deploy and update your DBaaS created PXC clusters to the latest version of Percona Distribution for MySQL Operator 1.9.0. This enables you to take advantage of the latest features and fixes.</li> </ul> </li> <li> <p>PMM environment enhancements</p> <ul> <li> <p>The pmm-client docker container can now be started as a sidecar.  For users that use PMM client in Kubernetes or build automation around it, you can now start the client as a sidecar container simply by passing a flag.  The client will also gracefully handle any instances where the connection to DB  is not available. For more details, see the PMM Client documentation</p> </li> <li> <p>Removed support for Ubuntu 16.04. With the support of new products and new versions of already supported products, we also removed old, unsupported software. As of this release, we are no longer supporting Ubuntu 16.04 in PMM according to recent announcements</p> </li> </ul> </li> </ul>"},{"location":"release-notes/2.25.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-9050: Connect PMM Server to Percona Platform for additional account info in PMM and value added content</li> </ul>"},{"location":"release-notes/2.25.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-8545: DBaaS: Support of Percona Distribution for MySQL Operator 1.9.0 in PMM</li> <li>PMM-7677: Docker container for <code>pmm-client</code>: Option to change behavior and follow sidecar pattern The flags <code>PMM_AGENT_SIDECAR</code> and <code>PMM_AGENT_SIDECAR_SLEEP</code> does this. Read more in documentation</li> <li>PMM-3516: Optimize provisioning mechanism of plugins, dashboards, and data sources in PMM</li> <li>PMM-8674: Integrated Alerting: Add Tooltips to <code>Add Alert Rule</code> fields to make it easier to understand what information is needed</li> <li>PMM-8505: Integrated Alerting: Clarify description of the \u2018Low memory\u2019 Alert Template</li> <li>PMM-8503: Integrated Alerting: Field validation in Email and Slack tabs when updating settings</li> <li>PMM-7527: Integrated Alerting: Improvements to overall user experience for action buttons in Alerting</li> <li>PMM-7079: Integrated Alerting: New \u2018information\u2019 icon to give additional details about Alerts without cluttering screen</li> <li>PMM-8259: Better clarification of error messages in <code>pmm-admin</code> when PMM server can\u2019t be unregistered</li> <li>PMM-8972: Add ability to specify custom base path to exporters and tools using <code>pmm-admin</code> command</li> <li>PMM-8282: Improved messaging for TLS option when adding Remote instances in PMM over UI</li> </ul>"},{"location":"release-notes/2.25.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-9169: Security Advisor Checks are not working for MongoDB instances</li> <li>PMM-8982: Backup Management: User is not able to see MongoDB backup logs if backup was taken on older version of pmm-server</li> <li>PMM-9157: Dashboards: Changing the timezone on dashboards does not persist navigation</li> <li>PMM-7116: Dashboards: Incorrect STARTUP state on MongoDB ReplSet Summary dashboard</li> <li>PMM-8993: Integrated Alerting: Sending email using Gmail fails</li> <li>PMM-7802: PMM can\u2019t monitor MongoDB arbiter nodes (Thanks to Artem Meshcheryakov for reporting this issue)</li> <li>PMM-6937: Can\u2019t add PostgreSQL instances to PMM without <code>postgres</code> DB in PostgreSQL server (Thanks to Daniel Kowalewski for reporting this issue)</li> <li>PMM-7447: Can\u2019t add into PMM instances of PostgreSQL with <code>SCRAM-SHA-256</code> authentication</li> <li>PMM-9085: PMM Server crashes after upgrading to 2.22 every 4 hours</li> <li>PMM-9156: <code>pmm-agent</code> paths-base option not working for <code>pmm2-client</code> binary installation in PMM 2.23.0</li> <li>PMM-8461: DBaaS: Confusing error when accessing DBaaS pages when it\u2019s disabled</li> <li>PMM-8110: DBaaS: Registering K8s cluster with operators already installed can cause error</li> <li>PMM-8694: Query Analytics: URLs in Query Analytics with a selected query and a timestamp range does not select the query</li> <li>PMM-9227: Pagination Reset on QAN after Time Range change doesn\u2019t work, results in wrong results</li> <li>PMM-9298: PMM AMI image in 2.24.0 has only 8GB space for data and Volume Size Check fails while upgrading to 2.25.0</li> </ul> <p>Important note for users of PMM 2.24.0</p> <p>2.24.0 AMI image has only 8GB available for the data, it is a bug (see PMM-9298). To resize a disk to full size you need to login to AMI instance with SSH and use the following command:</p> <pre><code>curl https://raw.githubusercontent.com/percona/pmm-update/main/ansible/playbook/tasks/create-lvm.yml -o lvn-fix.yml &amp;&amp; sudo ansible-playbook lvn-fix.yml\n</code></pre> <p>For instructions about how to access your instances by using an SSH client, see Connecting to Your Linux Instance Using SSH Make sure to replace the user name ec2-user used in this document with admin.</p> <p>What this command does:</p> <ol> <li>Downloads Ansible playbook and runs it</li> <li>Copy your data from /srv to the temporary directory</li> <li>Create lvm partition</li> <li>Copy data from system disk to a new LVM partition</li> </ol>"},{"location":"release-notes/2.25.0.html#known-issues","title":"Known issues","text":"<ul> <li>PMM-9255: After connecting PMM to Percona Platform, PMM occasionally shows a false permission issue notification, incorrectly suggesting that the connection could not be established due to missing permissions. Reload the page to remove the incorrect notification and confirm the connection.</li> <li>PMM-9312: It\u2019s not possible to enable <code>collStats</code>, <code>indexStats</code> and <code>-max-collections-limit</code> for MongoDB</li> </ul>"},{"location":"release-notes/2.26.0.html","title":"Percona Monitoring and Management 2.26.0","text":"Date: February 8, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.26.0.html#release-highlights","title":"Release Highlights","text":"<ul> <li>Experimental Dashboards</li> </ul> <p>New experimental dashboards are introduced that will be shipped to the PMM users. These dashboards will be uploaded to the Experimental folder to enable the users to test them in their environment and provide feedback.</p> <p>The following Dashboards are being shipped as part of this release:</p> <ul> <li> <p>K8s monitoring dashboard</p> </li> <li> <p>Environment Overview dashboard</p> </li> <li> <p>Environment Summary dashboard</p> </li> </ul> <p>Important</p> <p>These experimental dashboards are subject to change. It is recommended to use these dashboards for testing purposes only.   </p> <ul> <li>SMTP Configuration Verification</li> </ul> <p>When configuring an SMTP email server for sending out email notifications, you now have the option to test that your specified settings are correct. The Email tab under Configuration &gt; Settings &gt; Communication now includes a Test button to send a test alert through the specified server. For more information about setting up an SMTP email server, see Configure.</p> <ul> <li>Breaking change for Integrated Alerting (Technical Preview)</li> </ul> <p>This release introduces major changes to the core structure of rule templates. As a result, alert rules and templates created in previous PMM versions are not compatible with PMM 2.26.0 and cannot be migrated to this new version. After upgrading, make sure to manually recreate any custom alert rules and rule templates that you want to transfer to PMM 2.26.0.</p> <p>Disclaimer</p> <p>Integrated Alerting is still a Preview functionality and, as such, subject to change. We recommend that early adopters use this feature for testing purposes only.</p>"},{"location":"release-notes/2.26.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-9059: Following the recently introduced support for connecting PMM to Percona Platform, you now have the option to also unlink any servers that are no longer relevant to your Platform organization.  To disconnect a PMM server, go to Configuration &gt; Settings &gt; Percona Platform and click Disconnect.  You can check the list of servers connected to an organization in Percona Platform by clicking View instances on the Dashboard page. For more information, see Configure for more details.</li> <li>PMM-9312: Tech Preview Feature: PMM now captures the MongoDB metrics such as <code>dbStats</code>, <code>collStats</code>, <code>indexStats</code>, and <code>topmetrics</code>. See Documentation for more details.</li> </ul>"},{"location":"release-notes/2.26.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-9176: DBaaS - PMM now supports Percona Distribution for MongoDB Operator 1.10.0.</li> <li>PMM-9159: DBaaS - PMM now supports Percona Kubernetes Operator for Percona XtraDB Cluster 1.10.0.</li> <li>PMM-9180: Integrated Alerting &gt; Add Alert Rule - Added the Template expression in a collapsible panel for an enhanced user experience (default view as collapsed) as the technical message could confuse the users.</li> <li>PMM-7781: Integrated Alerting - Alert rules no longer depend on their source rule template after creation. This means that you can now update or delete rule templates without impacting existing rules that are based on that template. For more information, see Integrated Alerting.</li> <li>PMM-9356: Added new experimental Environment dashboards in PMM.</li> <li>PMM-9296: Disclaimer about Technical Preview feature added to Percona Platform - Connect PMM to Percona portal page.</li> </ul>"},{"location":"release-notes/2.26.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-9416: Upgrading to PMM 2.25.0 using docker (replacing the image) fails when upgrading from versions less than or equal to 2.23.0.</li> </ul> <p>Caution</p> <p>It is recommended to upgrade directly to PMM 2.26.0 instead of 2.25.0 when updating from versions less than or equal to PMM 2.23.0 if your PMM doesn\u2019t have external access (access to <code>repo.percona.com</code>).</p> <ul> <li>PMM-8867: Fixed an issue for PMM Client installation using the tarball script (without using RPMs) where the configuration was getting lost due to the configuration file <code>pmm-agent.yml</code> being recreated.</li> <li>PMM-8094: DBaaS - Fixed an issue for paused clusters that froze with PSMDB v1.8 operators when all the pods were terminated, providing no cluster resumption option.</li> <li>PMM-8535: DBaaS - Repeating error after force unregister </li> <li>PMM-9144: Dashboard - Fixed the Add inventory page issue that indicated AWS RDS/Aurora supported only MySQL.</li> <li>PMM-9289: Get from Browser on settings page does not fetch port in Public address field breaking the integration for Platform authentication.</li> <li>PMM-9255: On connecting the PMM server to Percona Platform for an admin user insufficient access rights error message is thrown.</li> <li>PMM-9049: Eliminated confusion around the current and available version date by adding a tooltip with an explanation for these dates.</li> <li>PMM-9181: Integrated Alerting - Modified the label for the enable/disable button in order to avoid confusion.</li> <li>PMM-5405: Fixed an issue where the <code>pmm-admin summary</code> command fails if a null value is passed for the <code>--filename</code> parameter.</li> <li>PMM-8141: Fixed an issue where the metrics were not captured as the cleanup of the temporary folder on the client node deleted the requisite configuration file.</li> </ul>"},{"location":"release-notes/2.27.0.html","title":"Percona Monitoring and Management 2.27.0","text":"Date: April 14, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of the PMM instance. This ensures that you access the latest features of the underlying components, such as VictoriaMetrics, with all the bug fixes in place. One of the critical features of VictoriaMetrics is stream parsing mode, which enhances the performance of PMM and saves memory when scraping targets expose millions of metrics.</p>"},{"location":"release-notes/2.27.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.27.0.html#pmm-and-percona-portal-integration","title":"PMM and Percona Portal Integration","text":"<ul> <li> <p>Enhanced UX for connecting PMM server to Percona Portal</p> <p>To leverage Percona Platform\u2019s recent support for federated identity, PMM now uses access-token authorization for connecting PMM instances to Percona Platform. </p> <p>This replaces the former username/password authentication used in PMM 2.26.0 and older versions.</p> <p>For more information, see Integrate PMM with Percona Platform. </p> </li> <li> <p>Access to account information for Percona customers</p> <p>When you connect your PMM instances to Percona Platform as a Percona customer, you can now check all your Percona Platform account information on the new Entitlements and Support Tickets tab on the main menu.      </p> <p>For more information, see Check your account information in the online Help.</p> </li> </ul>"},{"location":"release-notes/2.27.0.html#advisors","title":"Advisors","text":"<ul> <li> <p>Broader database health assessments with Advisors</p> <p>With this release, we are renaming Security Checks to Advisors and grouping them according to the functionality and recommendations they provide. To reflect these changes, the old Security Threat Tool option is now called Advisors.</p> <p>In addition, we have added new checks for MySQL and MongoDB.  To check the list of checks and the tier for which they are available, see Advisor checks for PMM in the Percona Platform online Help.</p> </li> <li> <p>New Paid tier and special Advisor checks for customers</p> <p>In addition to Registered Checks, Percona customers who connect PMM to Percona Platform now also have access to Paid Advisor checks, which offer more advanced database health information.</p> <p>For more information, see Working with Advisor checks.</p> </li> <li> <p>Advisor checks have been extended with two new query types: <code>GetDiagnosticData</code> and <code>replSetGetStatus</code>.</p> </li> <li> <p>Improved the documentation around developing checks.</p> </li> </ul>"},{"location":"release-notes/2.27.0.html#dbaas","title":"DBaaS","text":"<p>Simplified experience in registering EKS cluster with kubeconfig generated by <code>eksctl</code>.</p>"},{"location":"release-notes/2.27.0.html#components-upgrade","title":"Components upgrade","text":"<ul> <li>Grafana: PMM 2.27.0 has now migrated to Grafana 8.3.5. This version of Grafana is loaded with a gamut of exciting features. For more information, see What\u2019s new in Grafana v8.0.</li> <li>VictoriaMetrics: VictoriaMetrics has been upgraded to 1.72.0.</li> </ul>"},{"location":"release-notes/2.27.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-9718: PMM and Percona Portal Integration: Federated connections to Percona Platform.</p> </li> <li> <p>PMM-9305, PMM-8661: PMM and Percona Portal Integration: Visibility over Percona Platform Entitlements and Support Tickets.</p> </li> <li> <p>PMM-9473: Advisors: Additional abilities for MongoDB Advisor Checks.</p> </li> <li> <p>PMM-8800: DBaaS: With PMM, you can now have a simplified experience in registering your EKS cluster with kubeconfig generated by <code>eksctl</code>. Copy-paste the configuration by selecting Using Amazon Elastic Kubernetes Service (EKS) check-box, and your K8s cluster is registered. For more information, see Documentation.</p> </li> <li> <p>PMM-8434: Support for passing PMM Server Public Address as an environment variable while starting the PMM server. For more information, see Documentation.</p> </li> </ul>"},{"location":"release-notes/2.27.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-9319: PMM and Percona Portal Integration: Synchronized Platform and PMM roles: We have updated PMM permissions to ensure that Administrators of Percona Portal organizations are also granted Admin role in PMM. - </p> </li> <li> <p>PMM-9339: Integrated Alerting: The Use TLS option in webhook settings has been renamed to Show TLS setting to better reflect its functionality.</p> </li> <li> <p>PMM-9182: Integrated Alerting: Added Silence All option for when you want to stop notifications from all alerting rules at once.</p> </li> <li> <p>PMM-9164: Integrated Alerting: You can now use an existing rule as a source for new ones instead of using a template.</p> </li> <li> <p>PMM-9635: Advisors: Extended security checks to Advisors to cover broader database health checks.</p> </li> <li> <p>PMM-9148: QAN: You can now share a link for Query Analytics at the click of a button with the Copy Link.</p> </li> <li> <p>PMM-8045: DBaaS: With this version of PMM, we have added a warning about the deletion of API keys so that the user is forewarned before deleting the API key.</p> </li> <li> <p>PMM-9452: With this release of PMM, we have implemented a simplified password change method for the default admin user using the command line parameter <code>change-admin-password</code>.</p> </li> <li> <p>PMM-9542: PMM now predefines certain flags that allow users to set all other VictoriaMetrics parameters as environment variables. For more information see Documentation.</p> </li> <li> <p>PMM-8794: For consistency, we have implemented a unified 24 hours time format for backup management.</p> </li> <li> <p>PMM-9306: VictoriaMetrics has been upgraded to 1.72.0. </p> </li> <li> <p>PMM-8412: Grafana has been upgraded to 8.x.</p> </li> <li> <p>PMM-9648: With PMM 2.27.0 migrating to Grafana 8.0, the Singlestat Panel has been deprecated and replaced with Stat Panel in Grafana for an enhanced user experience.</p> </li> </ul>"},{"location":"release-notes/2.27.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-9797: Fixed an issue where the data on the Home Dashboard was represented incorrectly on the Stat Panel, which could potentially confuse the user.</p> </li> <li> <p>PMM-9757: Fixed an issue where the metrics for MongoDB were not being exposed when the database connection was getting lost.</p> </li> <li> <p>PMM-9603: PMM and Percona Portal Integration: Fixed \u201cInsufficient access rights\u201d error that was displayed  for admin user after connecting  PMM server connect to Percona Portal.</p> </li> <li> <p>PMM-9323: PMM and Percona Portal Integration: Ensured PMM no longer downloads checks and templates from Percona Portal when the Telemetry option is disabled in the PMM Advanced Settings.</p> </li> <li> <p>PMM-8986: Advisors: Fixed an issue where the Advisors check on the PMM servers monitoring a large number of database services was causing a timeout. </p> </li> <li> <p>PMM-9570: DBaaS: Create DB Cluster dialog box was closing automatically while trying to create  a database cluster and had to be opened twice. This issue has been fixed now.</p> </li> <li> <p>PMM-9496: DBaaS: Fixed an issue where the host and database were not being monitored in DBaaS.</p> </li> <li> <p>PMM-9783: QAN: Fixed an issue where QAN failed to work after an upgrade.</p> </li> <li> <p>PMM-9661: QAN: Fixed an issue where QAN layout breaks while resizing the window.</p> </li> <li> <p>PMM-9797: Dashboard: Fixed an issue where the data on the Home Dashboard was represented incorrectly on the Stat Panel, which could potentially confuse the user.</p> </li> <li> <p>PMM-9757: Fixed an issue where the metrics for MongoDB were not being exposed when the database connection was getting lost.</p> </li> <li> <p>PMM-9671: Fixed an issue where an upgrade to 2.26.0 failed as PMM crashed.</p> </li> <li> <p>PMM-9413: Fixed an issue where the PMM management daemon was getting deadlocked when a PMM agent was getting connected with a duplicate <code>agent_id</code>.</p> </li> <li> <p>PMM-9015: Fixed an issue where PMM does not display when PostgreSQL is down, thus failing to capture the metrics for PostgreSQL.</p> </li> <li> <p>PMM-8203: Fixed an issue where the <code>pmm-agent.log</code> is cluttered with unnecessary errors when MariaDB database versions 10.2, 10.3, 10.4, and 10.5 are added for monitoring.</p> </li> <li> <p>PMM-5831: Fixed an issue where <code>pmm-admin</code> uses the default value of \u2018listen port\u2019 rather than picking up the value from the agent configuration file.</p> </li> <li> <p>Fixed the following CVE\u2019s:</p> <ul> <li>PMM-9726: Fixed a critical CVE that was affecting some versions of Go.</li> <li>PMM-9722: Fixed a CVE for ClickHouse DBMS.</li> <li>PMM-9327: Fixed a vulnerability in the Network Security Services (NSS) package.</li> <li>PMM-9502: Fixed multiple JavaScript Common Vulnerabilities and Exposures (CVE) for PMM AMI setup.</li> </ul> </li> </ul>"},{"location":"release-notes/2.27.0.html#known-issues","title":"Known Issues","text":"<p>PMM-9992: Error while using reverse proxy (like Nginx)</p> <p>While using a reverse proxy (for example, Nginx) in front of PMM, you can run into the error <code>origin not allowed</code> after upgrading to PMM 2.27.0 or newer versions.</p> <p>Solution</p> <p>Add the <code>Host</code> header to the reverse proxy configuration file.</p> <p>Example </p> <p>For Nginx, add the following:</p> <p><code>proxy_set_header Host $http_host;</code></p>"},{"location":"release-notes/2.28.0.html","title":"Percona Monitoring and Management 2.28.0","text":"Release date: May 12, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.28.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.28.0.html#advisors","title":"Advisors","text":"<ul> <li> <p>Advisor checks enabled by default</p> <p>Starting with the previous release and continuing with this one, we have added significant improvements to the Advisors Checks functionality in performance, assessment coverage, and user experience.</p> <p>As a mature and generally useful feature, this option is now enabled by default for easier access to automatic checks and better insight into database health and performance, delivered by Percona Platform.</p> <p>Note</p> <p>Upgrading to PMM will automatically enable this feature for existing PMM instances. You can disable it at any time from your PMM dashboard on the Advanced Settings page.</p> </li> <li> <p>Run individual advisor checks</p> <p>In addition to running all available advisors at once, you now have the option to run each advisor check individually.</p> <p>This gives you more granular control over the checks on your connected databases. Running checks individually also means that you get the results for relevant advisors faster and that you can focus on resolving failed checks one at a time. For more information, see Working with Advisor checks.</p> </li> <li> <p>Enhanced Advisor checks</p> <p>PMM 2.28 includes a new major version of Advisors that features some important enhancements. The most significant changes are:</p> <ul> <li>Support for multiple queries</li> <li>Support for Victoria Metrics as a data source</li> </ul> <p>In a nutshell, these changes will allow experts to create more intelligent advisor checks to continue delivering more value to your connected PMM instances. The file format in which Advisors checks are written has been updated to support the new functionality provided by the Advisors service part of Percona Platform.</p> <p>This is a breaking change, so we recommend upgrading your PMM instance to benefit from these enhancements. For more information, see Develop Advisors.</p> </li> </ul>"},{"location":"release-notes/2.28.0.html#ubuntu-2204-lts-support","title":"Ubuntu 22.04 LTS support","text":"<p>We are providing binaries for the recently released version of Ubuntu from this release.</p>"},{"location":"release-notes/2.28.0.html#components-upgrade","title":"Components upgrade","text":"<ul> <li> <p>VictoriaMetrics: VictoriaMetrics has been upgraded to 1.76.1.</p> </li> <li> <p>Node exporter: Node Exporter has now been updated to 1.3.1.</p> <p>Important</p> <p>If you customized the disabled collectors, the list could change. Check the available collectors in Documentation.</p> </li> </ul>"},{"location":"release-notes/2.28.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-9749: Advisors: Possibility to run individual advisor checks separately.</p> </li> <li> <p>PMM-9469: Advisors: Ability to have multiple queries in a single check.</p> </li> <li> <p>PMM-9468: Advisors: Ability to query VictoriaMetrics as a data source.</p> </li> </ul>"},{"location":"release-notes/2.28.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-9841: Advisors: Advisor checks are now enabled by default.</p> </li> <li> <p>PMM-8326: Advisors: Changed the icon for the Edit Check Rule option with a more suggestive one that better reflects this functionality.</p> </li> <li> <p>PMM-9907: <code>pmm2-client</code> now supports Ubuntu 22.04 LTS.</p> </li> <li> <p>PMM-9780: VictoriaMetrics has been upgraded to 1.76.1.</p> </li> <li> <p>PMM-5871: Node Exporter has now been updated to 1.3.1.</p> </li> <li> <p>PMM-9958: The PMM logs button, which is used to download PMM logs for troubleshooting, is added to the help panel for better accessibility and enhanced user experience.</p> </li> <li>PMM-9672: Minor UI improvements to the visual elements in the breadcrumb trails to visually align them to the look-and-feel of Grafana pages and improve overall UI consistency.</li> </ul>"},{"location":"release-notes/2.28.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-9854: Advisors: In some scenarios, PMM was not displaying the complete list of advisors available for instances connected to Percona Platform. This issue is now fixed.</p> </li> <li> <p>PMM-9848: Advisors: Fixed text contrast issue on the Failed Advisor Checks page that was visible when navigating the list of results while using PMM with the Light theme.</p> </li> <li> <p>PMM-9426: DBaaS: Fixed an issue related to K8s monitoring where the K8s monitoring failed with K8s version 1.22 and higher.</p> </li> <li> <p>PMM-9885: Dashboard: Fixed the documentation links on the Advanced settings page on the PMM dashboard.</p> </li> <li> <p>PMM-9828: Fixed an issue with the QAN dashboard navigator/explorer where if you open QAN from a dashboard and try to navigate to a different dashboard, the explorer keeps closing/refreshing, making it impossible to navigate.</p> </li> <li> <p>PMM-9363: PMM users logged in via SSO would still have access to PMM after disconnecting. This issue is now fixed and PMM correctly terminates SSO sessions after disconnecting.</p> </li> <li> <p>PMM-9415: Backup Management: Fixed an issue where initial data restore on AWS instances fails. However, consecutive data restore attempts were successful.</p> </li> </ul>"},{"location":"release-notes/2.28.0.html#known-issues","title":"Known Issues","text":"<p>PMM-9992: Error while using reverse proxy (like Nginx)</p> <p>While using a reverse proxy (for example, Nginx) in front of PMM, you can run into the error <code>origin not allowed</code> after upgrading to PMM 2.27.0 or newer versions.</p> <p>Solution</p> <p>Add the Host header to the reverse proxy configuration file.</p> <p>Example </p> <p>For Nginx, add the following:</p> <p><code>proxy_set_header Host $http_host;</code></p>"},{"location":"release-notes/2.29.0.html","title":"Percona Monitoring and Management 2.29.0","text":"Release date: July 19, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.29.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.29.0.html#guided-tour-of-pmm","title":"Guided tour of PMM","text":"<p>PMM now includes a short in-app tutorial that automatically pops up when you first launch the application. </p> <p>If you are a new user, this is your virtual unboxing of key PMM features to help you get started easier. </p> <p>If you are an Intermediate or Advanced user, use the tour as a checklist of features worth exploring to ensure you\u2019re making the most out of your PMM.</p>"},{"location":"release-notes/2.29.0.html#deploying-pmm-in-various-environments","title":"Deploying PMM in various environments","text":""},{"location":"release-notes/2.29.0.html#k8s","title":"K8s","text":"<p>Disclaimer</p> <p>Deploying PMM on Kubernetes is still technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Starting with PMM 2.29.0, we have introduced the helm chart supported by Percona to seamlessly deploy your PMM instances on Kubernetes (k8s), a prominent container orchestration system. With the Helm chart, you can customize your deployment. You can tweak your PMM installation by setting these various parameters. For more information, see the documentation.</p> <p>Before introducing the helm chart for PMM, if you wanted to deploy PMM, you would need a separate virtual machine to run PMM, but with the helm chart, that is not required. Helm Charts provide the ability to leverage Kubernetes packages at the click of a button or a single CLI command.</p>"},{"location":"release-notes/2.29.0.html#podman","title":"Podman","text":"<p>Disclaimer</p> <p>Podman support is still  technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Starting with PMM 2.29.0, get your PMM instances up and running quickly with the Podman. Using Podman makes it easy to run, build, and deploy PMM.</p> <p>Deployment of PMM with the Podman is far more secure as it does not require root privileges to create, run and manage containers. It lets you run containers as a non-root user, so you never have to give a user root permission on the host. Thus it adds a new security layer, which is crucial in the event of a security breach. Podman also allows multiple unprivileged users to run containers on the same machine. For more information on deploying PMM on Podman, see the documentation.</p>"},{"location":"release-notes/2.29.0.html#local-file-system","title":"Local file system","text":"<p>You can start your PMM instances without a data container using your local file system. </p> <p>You can use docker volume or host directory with the <code>-v</code> docker-cli option for storing PMM state (databases, configs, etc.)</p>"},{"location":"release-notes/2.29.0.html#rhel-9-support-client","title":"RHEL 9 support (client):","text":"<p>PMM client now supports RHEL 9.</p>"},{"location":"release-notes/2.29.0.html#monitoring","title":"Monitoring","text":""},{"location":"release-notes/2.29.0.html#meta-metrics","title":"Meta metrics","text":"<p>We have added some metrics for Mongodb exporters to monitor the time it takes to collect data for different collectors. With these metrics, you can identify the monitoring cost of various collectors by the MongoDB exporters. </p>"},{"location":"release-notes/2.29.0.html#pxc-cluster-dashboard","title":"PXC Cluster dashboard","text":"<p>Important</p> <p>This experimental dashboard is subject to change. It is recommended to use this dashboard for testing purposes only.</p> <p>Created a new experimental PXC/Galera Cluster Summary dashboard to make it simple, intuitive, and provide at-a-glance visibility for better decision making. Critical data for the PXC cluster is put together in this dashboard to obtain feedback from our users. For more information, refer to the documentation.</p> <p>Earlier, the PXC Cluster data was distributed over different dashboards. The users had to browse the MySQL compare dashboard to check for the data like slow queries and network overviews that were not in the PXC nodes compare dashboard. This made it time-consuming to identify any possible issues with the database. With the new PXC dashboard, we aim to solve this problem and gain insightful data about the cluster and services. Now the users can have an overview of the PXC clusters from this dashboard. Also, users with beginner to intermediate levels of expertise can effortlessly analyze the data on this dashboard.</p>"},{"location":"release-notes/2.29.0.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"release-notes/2.29.0.html#managing-logs","title":"Managing logs","text":"<p>As a PMM user, you can explicitly set a detailed level of logging so that, by default, you will have meaningful logs to see, thereby enhancing your troubleshooting experience. </p> <p>If you want detailed logging, you can set <code>--log-level</code> to INFO. By default, INFO is not logged. Thus, you have more control over the logs you want to view with the <code>--log-level</code> parameter with the flexibility to choose options such as warning, error, fatal, and info.</p> <p>For example, to set the log level to <code>fatal</code> for a MySQL database:</p> <p><code>pmm-admin add mysql --username=XXX --password=XXX --log-level=fatal</code></p>"},{"location":"release-notes/2.29.0.html#additional-parameters-added-in-commands","title":"Additional parameters added in commands","text":"<ul> <li> <p>Added the agent (exporter) port to the output of the <code>pmm-admin</code> commands, which is crucial during debugging.</p> <pre><code>pmm-admin list\npmm-admin status\npmm-admin inventory list agents\n</code></pre> </li> <li> <p>Added new flag <code>--agent-password</code> to the following commands to support a custom password via the CLI to make it more secure:</p> <pre><code>pmm-admin register --agent-password=AGENT-PASSWORD\npmm-admin config --agent-password=AGENT-PASSWORD`\n</code></pre> </li> <li> <p>You can use the <code>pprof</code> parameter in the <code>pmm-admin</code> summary command.</p> <pre><code>pmm-admin summary --pprof\n</code></pre> <p><code>pprof</code> reads a collection of profiling data from the PMM server, enabling you to generate reports in textual and graphical formats to visualize and analyze data. </p> <p>You can analyze CPU, Memory usage, heap size, and thread count for your PMM components with the data obtained.</p> </li> </ul>"},{"location":"release-notes/2.29.0.html#percona-platform-integration","title":"Percona Platform Integration","text":""},{"location":"release-notes/2.29.0.html#terminate-percona-platform-connections-as-an-admin","title":"Terminate Percona Platform connections as an Admin","text":"<p>When regular users are not able to disconnect a server (for example, when PMM was moved to a network segment without outbound connections to public networks), PMM Admins can now terminate such connections instead.</p> <p>The Disconnect option under Settings &gt; Percona Platform now enables PMM Admins to retire PMM instances from Percona Platform even if they are not logged in with a Percona Account.</p> <p>When disconnecting servers without a Percona Account, the lingering servers are not automatically removed from the list of PMM instances in Percona Platform. As a Percona Platform Admin, you can ensure that your list of PMM instances stays up-to-date by manually removing those unavailable servers via PMM instances.</p>"},{"location":"release-notes/2.29.0.html#easier-access-to-your-percona-support-specialist","title":"Easier access to your Percona Support Specialist","text":"<p>If you are a Percona customer, you can now find the contact details of your dedicated Percona Support Specialist on the new  Environment Overview tab on the main menu.</p> <p>The Percona Contacts section here shows the name and email of the Customer Success Manager assigned to your organization, who can help with any PMM queries. This new tab will soon be populated with more useful information about your PMM environment.</p>"},{"location":"release-notes/2.29.0.html#advisors","title":"Advisors","text":""},{"location":"release-notes/2.29.0.html#extended-severities-for-advisor-checks-and-alerts","title":"Extended severities for advisor checks and alerts","text":"<p>We have extended and unified the list of severity levels for the notifications coming from Integrated Alerting and Advisor Checks.  When you create a new alert rule, you can now choose from a broader range of severity labels: Emergency, Alert, Critical, Error, Warning, Notice, Info, Debug. </p> <p>The same severities are now also available for notifications coming from failed checks under Advisor Checks &gt; Failed Checks. We\u2019ve also made a small UX improvement to the way failed checks are grouped by severity in the table.</p>"},{"location":"release-notes/2.29.0.html#use-filters-to-explore-available-advisors-checks","title":"Use filters to explore available advisors checks","text":"<p>As we\u2019re constantly adding more advisors for checking the health of your connected databases, you may find it useful to now be able to drill-down through this constantly growing list.    </p> <p>Use the filters on the Advisors Checks &gt; All Checks page to search advisors by Name, Description, Status or Interval. If you need to share the filtered results with your team members, send them the PMM URL, which saves your search criteria and results. </p>"},{"location":"release-notes/2.29.0.html#dbaas","title":"DBaaS","text":"<p>Simplified the API such that it requires fewer parameters to run the API. </p> <p>With this new implementation, the only mandatory field is the Kubernetes cluster name. All other fields such as resource parameters, image field, params field, and name filed are optional. The API sets these to default values if these fields are not specified. </p> <p>Also, the documentation has been enhanced for these APIs.</p>"},{"location":"release-notes/2.29.0.html#components-upgrade","title":"Components upgrade","text":"<ul> <li>Upgraded VictoriaMetrics operator to version 0.24.</li> <li>Upgraded the ClickHouse plugin to 2.4.4, which fixes some of the CVEs.</li> <li>With this release, we are upgrading grpc-gateway to version 2.0, which deprecates the error field in error responses. If you are using the PMM API, ensure to replace this with the new message field from the Google Cloud API Error model. </li> <li>Upgraded the mysqld exporter to the upstream version 0.14.0.</li> </ul>"},{"location":"release-notes/2.29.0.html#important-bug-fixes","title":"Important bug fixes","text":"<ul> <li> <p>PMM-9981: Fixed excessive space usage for Group replication monitoring. Services with enabled group replication and custom queries now take up less disk space and perform faster. To achieve this, we removed the Transactions Details table from the Group Replication dashboard, as these were based on labels that were generating high-cardinality data.</p> <p>If you still have issues with performance in Group Replication dashboard, log into PMM as an admin, and use     https://pmm_server_url/prometheus/api/v1/admin/tsdb/delete_series?match[]=  to remove all time series for the following metrics:</p> <ul> <li>mysql_perf_schema_replication_group_worker_rep_delay_seconds</li> <li>mysql_perf_schema_replication_group_worker_transport_time_seconds</li> <li>mysql_perf_schema_replication_group_worker_time_RL_seconds</li> <li>mysql_perf_schema_replication_group_worker_apply_time_seconds</li> <li>Mysql_perf_schema_replication_group_worker_lag_in_secondds</li> </ul> <p>For example, to remove all time series for the mysql_perf_schema_replication_group_worker metric use the following URL: https://PMM_SERVER_URL/prometheus/api/v1/admin/tsdb/delete_series?match[]=mysql_perf_schema_replication_group_worker_rep_delay_seconds</p> </li> <li> <p>PMM-9510: Fixed incorrect and duplicate information displayed on the Dashboard for MongoDB Replica Set.</p> </li> </ul>"},{"location":"release-notes/2.29.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-10133: New User Onboarding: Added a guided tour that highlights the main PMM components on your first onboarding journey.</p> </li> <li> <p>PMM-10059: Advisors: Extended and unified list of severity levels for the notifications coming from Integrated Alerting and Advisor Checks. </p> </li> <li> <p>PMM-7110: You can now obtain profiling data with the pprof tool that helps analyze CPU, Memory usage, heap size, and thread count for your PMM components.</p> </li> <li> <p>PMM-8660: Percona customers can now find the contact details of their dedicated Percona Support Specialist on the new Environment Overview tab on the main menu. </p> </li> <li> <p>PMM-7925: [Technical Preview]: Starting with PMM 2.29.0, you can now deploy your PMM instances using Podman, which is considered far more secure as it does not require root access.</p> </li> <li> <p>PMM-9613: [Technical Preview]: You can now scale and deploy your PMM instances faster using the Kubernetes clusters.</p> </li> <li> <p>PMM-9919: We have added some additional metrics to Mongodb exporters to monitor the time it takes to collect data for different collectors that would allow us to identify the monitoring cost of various collectors by MongoDB exporters.</p> </li> </ul>"},{"location":"release-notes/2.29.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-9766: Advisors: Added filters on the Advisors Checks &gt; All Checks page to narrow the list of available advisor checks. </p> </li> <li> <p>PMM-7491: Alerting: We\u2019ve redefined the Filters option under Integrated Alerting &gt; Alert Rules &gt; New Rule to simplify the way you target specific services or nodes for your alert rules. </p> </li> <li> <p>Instead of typing an exact filter pattern, you can now intuitively create a filter by choosing from the available operators and filling in the predefined fields. So instead of typing: service_name=name123, just fill in the following fields:     </p> </li> <li> <p>PMM-9704: With the implementation of a simplified API for DBaaS, you only have to specify the Kubernetes cluster name. All the other fields are optional, and the API will set the default values for these fields if not specified.</p> </li> <li> <p>PMM-8222: DBaaS: Enhanced the documentation for the API.</p> </li> <li> <p>PMM-9611: PMM now warns you if your current domain is different than the one specified in the Grafana .INI configuration file. Since this can generate incorrect short URLs when sharing the link to a PMM dashboard, make sure to correct this mismatch if you see a warning on the Share Panel &gt; Link page. </p> </li> <li> <p>PMM-7326: You now have more control over the logs you want to view with the \u2013log-level parameter. With this enhancement, you can experience more pronounced logging with the flexibility to choose options such as warning, error, and fatal.</p> </li> <li> <p>PMM-8566: For enhanced security, you can now specify the custom Basic Auth password for agents when adding a Node.</p> </li> <li> <p>PMM-9362: PMM Admins can now disconnect servers from Percona Platform even if they are not logged in with a Percona Account Percona Account. </p> </li> <li> <p>PMM-6592: PMM now displays the ports used by the exporters in the output of the pmm- admin list and status commands, which are crucial while debugging.</p> </li> <li> <p>PMM-7110: You can now use the pprof parameter in the pmm-admin summary command to obtain profiling data from the PMM server, thereby enabling you to generate reports in textual and graphical formats to visualize and analyze data.</p> </li> <li> <p>PMM-7186: The pmm-admin summary command now retrieves a list of targets scraped by Victoriametrics on the client-side.</p> </li> <li> <p>PMM-8308: To enhance the troubleshooting experience, in addition to the information summary and archive, you can now view the paths for all the exporters managed by the pmm-agent in the diagnostic data.</p> </li> <li> <p>PMM-9650: Created a new experimental dashboard for PXC Cluster Summary to make it simple and intuitive.</p> </li> <li> <p>PMM-10039: VictoriaMetrics operator has been upgraded to 0.24.</p> </li> <li> <p>PMM-10083: Upgraded the ClickHouse plugin to 2.4.4, which fixes some of the CVEs.</p> </li> <li> <p>PMM-10103: Added RHEL 9 support for PMM client.</p> </li> <li> <p>PMM-10155: Access QAN from the main menu instead of the PMM dashboard for better reach and visibility.</p> </li> <li> <p>PMM-2038: Starting with PMM 2.29.0, we have upgraded the mysqld exporter to the upstream version.</p> </li> <li> <p>PMM-9913: PMM removes all the unnecessary temporary files created while adding a monitoring service, which might impact your PMM server\u2019s performance if not deleted.</p> </li> <li>PMM-10067: Updated the version of Percona Toolkit to 3.4.0.</li> </ul>"},{"location":"release-notes/2.29.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-10127: Alerting: Fixed issue where changing the page under Integrated Alerting &gt; Alerts would not update the list of results.</p> </li> <li> <p>PMM-10110: DBaas: Fixed an issue where an incorrect operator version was installed.</p> </li> <li> <p>PMM-9965: DBaas: Fixed an issue where re-registering a K8s cluster returned an error.</p> </li> <li> <p>PMM-7143: DBaaS: Fixed an issue where proper node metrics were not exposed for database instances created with DBaaS.</p> </li> <li> <p>PMM-8677: DBaaS: Fixed the names of the operators used in PMM on the DBaaS UI to reflect their official names rather than short forms.</p> </li> <li> <p>PMM-9998: Fixed an issue where \u2018Unknown column\u2026\u2019 errors are thrown when monitoring MariaDB from the Debian package (10.2, 10.3, 10.4, 10.5).</p> </li> <li> <p>PMM-10144: Fixed an issue where if an already existing service was added via CLI, incorrect output was being displayed. </p> </li> <li> <p>PMM-9320: Fixed an issue where it was impossible to add MongoDB to PMM when the password contained \u201c+.\u201d</p> </li> <li> <p>PMM-9909:  Fixed an issue where the redirection from Home Dashboard Stats Panel to Node Summary did not work.</p> </li> <li> <p>PMM-10049: Removed unnecessary error messages from the pmm-agent log.</p> </li> <li> <p>PMM-8819: Fixed an issue where the metric data displayed in the table was not appropriately aligned.</p> </li> <li> <p>PMM-10087: PMM would show an \u201cInternal server error\u201d for custom alert rules created with a \u201cia=1\u201d label. This issue is now fixed.</p> </li> <li> <p>PMM-7462: Fixed an issue where you can update the PMM settings via the UI if they are not provided as an Environment variable.</p> </li> <li> <p>PMM-9510: Fixed incorrect and duplicate information displayed on the Dashboard for MongoDB Replica Set.</p> </li> <li> <p>PMM-9910: Fixed an issue where upgrading PMM from 2.26.0 to 2.27.0 via the UI failed due to a GRPC error.</p> </li> <li> <p>PMM-9981: Enormous space usage and slow queries for Group replication monitoring</p> </li> <li> <p>PMM-10069: Fixed a typo in the tooltip for InnoDB Random Read Ahead.</p> </li> <li> <p>PMM-10161: Removed unnecessary breadcrumb navigation panel from all dashboards.</p> </li> </ul>"},{"location":"release-notes/2.29.1.html","title":"Percona Monitoring and Management 2.29.1","text":"Release date: July 28, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.29.1.html#release-highlights","title":"Release Highlights","text":"<p>Fixed the following CVE:</p> <p>PMM-10338: We have updated Grafana to fix critical CVE\u2019s impacting Alerting in PMM.</p>"},{"location":"release-notes/2.3.0.html","title":"Percona Monitoring and Management 2.3.0","text":"Date: February 19, 2020 <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>For PMM install instructions, see Installing PMM Server and Installing PMM Client.</p> <p>Caution</p> <p>PMM 2 is designed to be used as a new installation \u2014 please don\u2019t try to upgrade your existing PMM 1 environment.</p>"},{"location":"release-notes/2.3.0.html#improvements-and-new-features","title":"Improvements and new features","text":"<ul> <li>PMM-5064 and PMM-5065: Starting from this release, users will be able to integrate PMM with an external Alertmanager by specifying the Alertmanager URL and the Alert Rules to be executed inside the PMM server (This feature is for advanced users only at this point)</li> <li>PMM-4954: Query Analytics dashboard now shows units both in the list of queries in a summary table and in the Details section to ease understanding of the presented data</li> <li>PMM-5179: Relations between metrics are now specified in the Query Analytics Details section</li> <li>PMM-5115: The CPU frequency and temperature graphs were added to the CPU Utilization dashboard</li> <li>PMM-5394: A special treatment for the node-related dashboards was implemented for the situations when the data resolution change causes new metrics to be generated for existing nodes and services, to make graphs show continuous lines of the same colors</li> </ul>"},{"location":"release-notes/2.3.0.html#fixed-bugs","title":"Fixed bugs","text":"<ul> <li>PMM-4620: The high CPU usage by the pmm-agent process related to MongoDB Query Analytics was fixed</li> <li>PMM-5377:  <code>singlestats</code> showing percentage had sparklines scaled vertically along with the graph swing, which made it difficult to visually notice the difference between neighboring <code>singlestats</code>.</li> <li>PMM-5204: Changing resolution on the PMM settings page was breaking some <code>singlestats</code> on the Home and MySQL Overview dashboards</li> <li>PMM-5251: Vertical scroll bars on the graph elements were not allowed to do a full scroll, making last rows of the legend unavailable for some graphs</li> <li>PMM-5410: The \u201cAvailable Downtime before SST Required\u201d chart on the PXC/Galera Node Summary dashboard was not showing data because it was unable to use metrics available with different scraping intervals</li> </ul>"},{"location":"release-notes/2.30.0.html","title":"Percona Monitoring and Management 2.30.0","text":"Release date: Aug 24, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.30.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.30.0.html#new-experimental-dashboards","title":"New Experimental dashboards","text":"<p>Important</p> <p>These experimental dashboards are subject to change. It is recommended to use these dashboards for testing purposes only.</p> <ul> <li> <p>We have introduced a more user-friendly and insightful experimental Home Dashboard in PMM version 2.30.0. With this new Home Dashboard, you can experience a boost in performance while monitoring a large number of nodes or services in PMM. Repeated rows (for a large number of nodes) on the dashboard can take a considerable time to load the Home Dashboard UI.    Our new experimental dashboard ensures fast retrieval of data on the Home Dashboard. For more information, see documentation.</p> </li> <li> <p>We have introduced the following new real-time experimental dashboards to collect more metrics and data for MongoDB:</p> <ul> <li> <p>Experimental MongoDB Collection Overview</p> <p>This dashboard contains panels for data about the Hottest Collections in the MongoDB database. For more information, see documentation. </p> </li> <li> <p>Experimental MongoDB Collection Details</p> <p>This experimental dashboard provides detailed information about the top collections by document count, size, and document read for MongoDB databases. For more information, see documentation.</p> </li> <li> <p>Experimental MongoDB Oplog Details</p> <p>This real-time dashboard contains Oplog details such as Recovery Window, Processing Time, Buffer Capacity, and Oplog Operations. For more information, see documentation.</p> </li> </ul> </li> </ul>"},{"location":"release-notes/2.30.0.html#database-as-a-service-dbaas","title":"Database as a Service (DBaaS)","text":"<p>Enhanced the user experience by simplifying the configuration and deployment of DBaaS database clusters:</p> <ul> <li> <p>With PMM 2.30.0, you can add a DB cluster literally at the click of a button. All the fields will be automatically populated with the default value. Click Register, and your DB cluster is added. For more information, see documentation.</p> </li> <li> <p>Starting with PMM 2.30.0, we have simplified the DBaaS configuration and deployment of database clusters by providing suggestions on the k8s cluster name based on the kubeconfig file.</p> </li> <li> <p>We have simplified DBaaS and Percona Platform connection configuration by suggesting and automatically setting the public address of the PMM server if it\u2019s not set up. This happens when connecting to Percona Platform, adding a Kubernetes (K8s) cluster, or adding a DB cluster.</p> </li> </ul>"},{"location":"release-notes/2.30.0.html#operators-support","title":"Operators support","text":"<p>PMM now supports Percona Operator for MySQL based on Percona XtraDB Cluster (1.11).</p>"},{"location":"release-notes/2.30.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-9652: Dashboard: New experimental dashboards for MongoDB are now available with more MongoDB metrics and data like Hottest collections, Data Size, Recovery Window, Processing Time, Buffer Capacity, Oplog Operations, and so on.</p> </li> <li> <p>PMM-10367: Dashboard: We have introduced a new user-friendly and insightful experimental Home Dashboard in PMM version 2.30.0. This Home Dashboard improves the performance while monitoring a large number of nodes or services in PMM.</p> </li> <li> <p>PMM-10327:  You can add a free K8s cluster via Percona Platform Portal and use it for testing DBaaS in PMM. Read more in the Private DBaaS with Free Kubernetes Cluster blogpost.</p> <p>This feature will be available on https://portal.percona.com/ with the PMM 2.30.0 GA release.</p> </li> </ul>"},{"location":"release-notes/2.30.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-10340: DBaaS: Enhanced user experience to simplify DBaaS configuration and deployment of Database clusters with suggestions on k8s cluster name based on k8s config file.</p> </li> <li> <p>PMM-10368: Simpler DBaaS and Percona Platform connection configuration by suggesting the public address of the PMM server.</p> </li> <li> <p>PMM-5680: Logs: For an enhanced and simplified troubleshooting experience, we have added the following logs in a ZIP file in the pmm-agent directory, which you can obtain from the pmm-admin summary command:</p> <ul> <li>exporter logs</li> <li>qan agent logs</li> <li>pmm-agent log</li> </ul> </li> <li> <p>PMM-5492: Logs: We have added the profiling data files to the logs directory to boost the troubleshooting process. You can obtain this by executing the <code>pmm-admin summary --pprof</code> command.</p> </li> <li> <p>PMM-5005: Logs: Added a more pronounced error message for the PMM agent to help you distinguish between potential problems, such as connectivity issues, unconfigured agent issues, connection time-out issues, etc.</p> </li> <li> <p>PMM-10147: To minimize resource consumption and DB connections, we have limited the number of concurrent jobs and actions that PMM Agent can execute concurrently. By default, PMM Agent will now run maximum 32 jobs and actions in parralel. You can configure this limit with the flag <code>--runner-capacity=&lt;some number&gt;</code> or environment variable <code>PMM_AGENT_RUNNER_CAPACITY=&lt;some number&gt;</code>. </p> </li> <li> <p>PMM-9914: PMM generates config files into the <code>/tmp</code> directory when a service is added to monitoring. Files in <code>/tmp</code> can get deleted by the Operating system. With PMM 2.30.0, we have ensured that the pmm-agent successfully restarts the child agents even though the config files in the  <code>/tmp</code>  directory are deleted and the scraper/exporter processes are killed, thereby ensuring that the exporter is not broken.</p> </li> <li> <p>PMM-9994: QAN: Improved the description of the QAN filter in the user guide for better clarity.</p> </li> <li> <p>PMM-9632: For flexibility, we have added the ability to change some of the pg_stat_monitor settings. Previously, this was hardcoded.</p> </li> <li> <p>PMM-10122: Applied the pmm-agent <code>--log-level</code> to the exporter\u2019s output so that each message from the exporter with <code>log-level=WARN</code> will be logged in pmm-agent with the same <code>log-level=WARN</code>.</p> </li> <li> <p>PMM-9921: Migrated pmm2-client Docker image to ubi-micro to reduce the number of packages and the image size.</p> </li> <li> <p>PMM-10085: Support for Percona XtraDB Cluster (PXC) 1.11.0 in PMM.</p> </li> <li> <p>PMM-10351: DBaaS: Full form of DBaaS (Database as a Service) is displayed on the Dashboard for clarity for the new users.  </p> </li> </ul>"},{"location":"release-notes/2.30.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-10474: Fixed an issue where the PMM tour gets in the way when sharing a dashboard via a rendered image with an error message at the top (HTTP 404).</p> </li> <li> <p>PMM-10483: Fixed an issue where the QAN dashboard was not reloading after modifying the filters, refresh rate, sorting, etc.</p> </li> <li> <p>PMM-10299: Fixed an issue where the MongoDB ReplSet Dashboard overview section shows incorrect information for the Cluster and ReplSet members count and does not change even after selecting a different cluster name.</p> </li> <li> <p>PMM-10494: Fixed an issue where the Confirm action modal is stuck until the cluster is registered.</p> </li> <li> <p>PMM-9987: Fixed an issue in QAN where the metrics values did not match those on the Query details panel.</p> </li> <li> <p>PMM-10159: Fixed an issue where the <code>logs.zip</code> directory contained the credenatials.</p> </li> <li> <p>PMM-9398: Fixed an issue where an error was thrown on the MySQL InnoDB Details dashboard for too many data points.</p> </li> </ul>"},{"location":"release-notes/2.31.0.html","title":"Percona Monitoring and Management 2.31.0","text":"Release date: Sep 26, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.31.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.31.0.html#enhanced-query-building-navigation-and-alerting","title":"Enhanced query building, navigation and Alerting","text":"<p>We have upgraded Grafana to version 9.1 in PMM 2.31.0. With this upgrade, you can get a simplified user interface, enhanced visualizations, and a default unified Alerting experience. For more information, see What\u2019s new  in Grafana.</p> <p>The following features have been introduced with PMM 2.31.0:</p> <ul> <li> <p>Expandable main menu</p> <p>For an enhanced user experience, we have expanded and designed the main menu by moving the dashboard navigation from the PMM Dashboards menu to the main menu for quick access. So you can now browse dashboards like Operating System (OS), MySQL, MongoDB, PostgreSQL, ProxySQL, and HAProxy directly from the navbar.  </p> </li> <li> <p>Prometheus Query Builder</p> <p>We have introduced a new UI query builder using which you can write Prometheus queries effortlessly. Prometheus queries can be complex to grasp, but with this Grafana release, it becomes easier. </p> </li> <li> <p>Starred dashboards</p> <p>To enhance user experience further, we have introduced Starred, where you can access your favorite dashboards directly from the main menu. </p> </li> <li> <p>Explore to dashboard</p> <p>You can now create panels and dashboards directly from Explore. You can also create a panel in a new or existing dashboard by clicking Add to dashboard in the Explore toolbar. The generated panel contains all the pane\u2019s queries, and the default visualization automatically picked from the current results shown in Explore.</p> </li> <li> <p>Improvements to dashboard search</p> <p>For a more effective search experience, we have introduced search by title as well as panel. With this, the overall performance has been enhanced as querying and sorting have become much faster.</p> </li> <li> <p>Command Palette</p> <p>You can now pull up a palette of commands for easier navigation using cmd+k (macOS) or ctrl+k (Linux/Windows).</p> </li> </ul>"},{"location":"release-notes/2.31.0.html#general-availability-of-percona-alerting","title":"General availability of Percona Alerting","text":"<p>With this release, we are streamlining the PMM alert setup process with an overhauled, unified alerting system based on Grafana. </p> <p>All previous Integrated Alerting and Grafana Alerting functionality are now consolidated on the Alerting page. From here, you can configure, create and monitor alerts based on Percona or Grafana templates. </p> <p>The Alert Rules tab has also evolved into a more efficient interface with an added layer for simplifying complex Grafana rules. You\u2019ll find that the new Percona templated alert option here offers the same functionality available in the old Integrated Alerting, but uses a friendlier interface, powered by Grafana\u2019s advanced alerting capabilities. </p> <p>As an important and generally useful feature, this new Alerting feature is now enabled by default and ready to use in production! </p> <p>For more information about Percona Alerting, check out Percona Alerting.</p>"},{"location":"release-notes/2.31.0.html#deprecated-integrated-alerting","title":"Deprecated Integrated Alerting","text":"<p>The new Percona Alerting feature fully replaces the old Integrated Alerting available in previous PMM versions. The new alerting brings full feature parity with Integrated Alerting, along with additional benefits like Grafana-based alert rules and a unified alerting command center. </p> <p>If you have been using Integrated Alerting in the previous PMM version, your custom alert rule templates will be automatically migrated to PMM 2.31. After upgrading to this new version, you will find all your alert templates under Alerting &gt; Alert Templates.  These templates are also available for creating new alert rules using the new Percona templated alerts option on the Alert Rules tab. </p> <p>However, alert rules created with Integrated Alerting are not automatically migrated to Percona Alerting. After upgrading, make sure to manually migrate any custom alert rules that you want to transfer to PMM 2.31 using the Integrated Alerting Migration Script.</p>"},{"location":"release-notes/2.31.0.html#vacuum-monitoring-dashboard","title":"Vacuum monitoring dashboard","text":"<p>Important</p> <p>This experimental dashboard is subject to change. It is recommended to use this dashboard for testing purposes only.</p> <p>A new experimental dashboard has been released to help our users gain timely insights into the autovacuum process in PostgreSQL. This dashboard is designed to help fine-tune the vacuum configuration and to prevent a XID wraparound - both of which directly contribute to improved performance of the database.</p> <p>This dashboard contains the following:</p> <ul> <li> <p>Dead tuples - Identifies the number of dead rows in each table even though the rows are physically removed from the table.</p> </li> <li> <p>Last time vacuum ran - Tracks the last time a vacuum or autovacuum process successfully ran on each of your tables.</p> </li> <li> <p>Number of rows modified since last Analyze - The number of rows changed since the last time ANALYZE ran.</p> </li> <li> <p>Manual vacuum events - Tracks the number of times a manual vacuum was run on each table. </p> </li> <li> <p>Table disk usage - Tracking the disk space used by each table is crucial as it enables you to gauge expected changes in the query performance over time - but it can also help you detect potential vacuuming-related issues.</p> </li> </ul> <p>For more information, see documentation</p>"},{"location":"release-notes/2.31.0.html#new-official-ga-deployment-method-podman","title":"New official (GA) deployment method - Podman","text":"<p>We are excited to announce the General Availability (GA) of Podman support for Deploying PMM 2.31.0. We had introduced it in 2.29.0 as a preview feature, but now we are production ready with this feature.</p>"},{"location":"release-notes/2.31.0.html#simplied-deployment-with-database-as-a-service-dbaas","title":"Simplied deployment with Database as a Service (DBaaS)","text":"<p>In our constant endeavor and focus on an enhanced user experience, in PMM 2.31.0, we have simplified the deployment and configuration of DBaaS as follows:</p> <ul> <li> <p>With PMM 2.31.0, you can easily add a DB cluster from the newly created K8s cluster. All the DB cluster window fields are auto-populated with the values based on the existing K8s cluster. </p> </li> <li> <p>For PMM 2.31.0, while accessing DbaaS, if you have an existing Kubernetes cluster configured for DBaaS, you will be automatically redirected to the DB Cluster page. Otherwise, you would be redirected to the Kubernetes Cluster page.</p> </li> </ul>"},{"location":"release-notes/2.31.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-10089: We have upgraded Grafana to 9.1 in PMM 2.31.0.</p> </li> <li> <p>PMM-10092: We have expanded and improved the main menu for PMM 2.31.0 based on Grafana 9.1. The main menu contains crucial elements, one of them being starred dashboards. </p> </li> <li> <p>PMM-10467: Integrated Alerting: Alert rules created with the Integrated Alerting feature in previous PMM versions can be migrated to the new Percona Alerting using the script that will be provided for the public release of PMM 2.31.</p> </li> <li> <p>PMM-10443: Dashboards: We have released a new experimental dashboard for collecting metrics for vacuum monitoring to help our users gain insight into the autovacuum process in PostgreSQL.</p> </li> </ul>"},{"location":"release-notes/2.31.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-10560: Dashboard: We have improved the MongoDB Collection Details Dashboard. The Collection Activity panel is now collapsed by default, and the graphs are visible only when the<code>--enable-all-collectors</code> parameter is passed in pmm-admin command.</p> </li> <li> <p>PMM-10349: DBaaS: For Simplified DBaaS experience, you will be automatically redirected to the DB Cluster page if you have an existing Kubernetes cluster configured for DBaaS. Otherwise, you would be redirected to the Kubernetes Cluster page.</p> </li> <li> <p>PMM-10064: Introduced UI changes on the PMM Inventory pages for better readability and user experience.</p> </li> <li> <p>PMM-10076: For an improved UI experience, we have enforced the enter button for the date picker, which performs the same action as clicking apply time range.</p> </li> <li> <p>PMM-10018: Lowered the default values of CPU and memory for haproxy while deploying a DBaaS Percona XtraDB Cluster (PXC) cluster to avoid wasting resources.</p> </li> <li> <p>PMM-9118: Refined the error message thrown when a secure connection cannot be established while adding a monitoring database to PMM, thus making it much more contextual and easy to troubleshoot.</p> </li> <li> <p>PMM-10516: Added support for MongoDB physical backups. With this, PMM backup management now supports both logical and physical backups for MongoDB services that are based on Percona Server for MongoDB.</p> <p>Percona Backup for MongoDB (PBM) compatibility: MongoDB backups in PMM require Percona Backup for MongoDB version 1.8.x. Make sure not to install the latest BPM version via the percona-release tool, as this automatically installs BPM v.2.0 which is not yet compatible with PMM. </p> </li> <li> <p>PMM-10095: While removing the service with pmm-admin, now you do not have to specify the service name for a single service. PMM will automatically look up this service and remove it.</p> </li> <li> <p>PMM-10495: By default, Swagger UI attempts to validate specs against swagger.io\u2019s online validator. For PMM 2.31.0, we have disabled it to safeguard your privacy.</p> </li> <li> <p>PMM-7806: Upgraded <code>postgres_exporter</code> version used in pmm from 0.8.0 to 0.10.1. With this upgrade, you can access the latest features with all the bug fixes in place. </p> </li> </ul>"},{"location":"release-notes/2.31.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-10628: While adding MongoDB or PostgreSQL database via socket, PMM was throwing an error. This has been fixed in PMM 2.31.0.</p> </li> <li> <p>PMM-10624: Empty dataname label after PostgreSQL upgraded in PMM.</p> </li> <li> <p>PMM-10608: Fixed issues pertaining to the new Home Dashboard, such as high CPU panel unreadable for a higher number of nodes (more than ten nodes), filtering for the environment as well as node name not working correctly, time range not working as expected, some panels on the dashboard not displaying data for selected filters, and so on.</p> </li> <li> <p>PMM-10587: Fixed an issue where if you hover over the telemetry icon stacktrace with error appears.</p> </li> <li> <p>PMM-10513: Fixed an issue where pmm-admin summary stored PMM password in client/status.json, thus posing a security risk.</p> </li> <li> <p>PMM-10065: Fixed an issue encountered while monitoring a large number of nodes (1000) and services. Here, the changing scrape frequency led to data not being captured on the dashboard and throwing a templating error.</p> </li> <li> <p>PMM-9973: Fixed an issue where the CPU utilization for Postgres Exporter was on the higher side.</p> </li> <li> <p>PMM-10044: Fixed an issue where QAN displayed enormously high values.</p> </li> <li> <p>PMM-10218: Fixed an issue for corrupted pprof file on concurrent pprof request.</p> </li> </ul>"},{"location":"release-notes/2.32.0.html","title":"Percona Monitoring and Management 2.32.0","text":"Release date: Nov 8, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.32.0.html#release-highlights","title":"Release Highlights","text":"<p>The release highlights are also available in video format. Watch the What\u2019s new in PMM 2.32 video</p>"},{"location":"release-notes/2.32.0.html#backup-management-for-mongodb-is-now-generally-available","title":"Backup Management for MongoDB is now generally available","text":"<p>We are happy to announce that the Backup Management for MongoDB has reached General Availability and is no longer in Technical Preview.</p> <p>This change comes with significant functionality enhancements and added UX improvements:</p> <ul> <li>Point-in-time recovery (PITR) restores for MongoDB backups: This enables you to restore Amazon S3-compatible backups from any checkpoint in the past.</li> <li>Local client storage: In addition to Amazon S3-compatible, we have now also enabled the Local Client location option, which saves backups on the remote folder mounted to PMM client host.  </li> <li>Key UX improvements: You can now create on-demand and scheduled backups from the same window instead of using separate modals.     In addition, we have added more icons and renamed tabs columns to better label the actions available behind important options.</li> </ul> <p>For more information, see the Backup and Restore topic in the documentation.</p>"},{"location":"release-notes/2.32.0.html#state-of-the-art-new-home-dashboard","title":"State-of-the-art new Home dashboard","text":"<p>In our continued effort to enhance user experience, we have added another feather to our cap by replacing the existing home dashboard with a brand new Home dashboard in PMM 2.32.0.</p> <p>We are releasing this dashboard as the default Home dashboard. This dashboard was released in PMM 2.30.0 as an experimental dashboard. After considering your feedback and working meticulously on this dashboard, we have developed an enhanced version in PMM 2.32.0. Read more in the blogpost.</p> <p>Highlights of the new Home dashboard include:</p> <ul> <li>Optimized performance to handle a large number of nodes concurrently</li> <li>Scalable to accommodate varying loads at all times</li> <li>Easy anomaly detection to check the health of your nodes from the Home dashboard</li> <li>Color-coded states on panels for a quick visual representation of the problem areas</li> <li>Comprehensive and easy-to-use dashboard to reduce cognitive load</li> </ul> <p>For detailed information, see documentation.</p>"},{"location":"release-notes/2.32.0.html#enhanced-main-menu","title":"Enhanced main menu","text":"<ul> <li> <p>In PMM 2.32.0, you can easily access all dashboards for monitored services due to the contemporized navigation structure. All the dashboards in the services folder that were not accessible from the main menu are now accessible from the main menu via Other Dashboards. Also, your custom dashboards can be accessed easily from the main menu via Other Dashboards.</p> <p>For example, to access the dashboards for MySQL, go to MySQL &gt; Other dashboards.</p> </li> <li> <p>Only monitored services are now included in the main menu, enhancing the user experience and minimizing cognitive load to maximize usability.</p> <p>For example, you will only see MongoDB dashboards in the main menu if you monitor the MongoDB database rather than all the other dashboards.</p> </li> </ul>"},{"location":"release-notes/2.32.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-9366: [Backup Management]: Added possibility to restore MongoDB PITR backups. This option is available under Backup &gt; All Backups &gt; Actions &gt; Restore this backup for any PITR-type backups available in the table.</li> <li>PMM-9368: [Backup Management]: Added support for local client storage: When adding storage locations under Backup &gt; Storage Location, you can now also select Local Client option as the location type for storing future backups.</li> <li>PMM-10599, PMM-10503: [Backup Management]:  Refactored User Interface for creating backups to enable you to create on-demand and scheduled backups from the same window instead of using separate modals. </li> <li>PMM-10470: [Backup Management]: Following the support for MongoDB physical backups introduced in PMM 2.31, we have now added the possibility to restore these backups.  Restoring MongoDB physical backups requires additional manual operations after the restore and is only available with Percona Server for MongoDB.</li> <li> <p>PMM-10502, PMM-10831: [Backup Management]: Improved User Experience and labels on all four tabs of the Backup section: </p> <ul> <li>Added icons to better illustrate failed and successful backups.</li> <li>Added Service Name column to show the service from where the backup was retrieved.</li> <li>Renamed DB Vendor tab to DB Technology.</li> <li>Improved Actions menu with clearer labeled options.</li> </ul> </li> <li> <p>PMM-10742: [Backup Management]: Extended PMM compatibility with Percona Backup for MongoDB (PBM) to support the latest version, v. 2.0 PBM.</p> </li> <li> <p>PMM-10829: [Backup Management]: The backups table under Backup &gt; All Backups now includes a new Location column which displays the service where the backup came from (S3 or Local Storage).</p> </li> <li> <p>PMM-8792,  PMM-9055, PMM-9056 - PMM 2.32.0 introduces the parameter <code>--max-query-length</code> in the <code>pmm-admin</code> command for MySQL, PostreSQL, and MongoDB databases. It can also be set up through the UI while adding the service. You can see a new input field on the UI, where you can set the value for <code>max-query-length</code>. With these changes, queries longer than 2048 characters are not truncated if this parameter is set to <code>-1</code> (which means no limit), and the Explain and Examples tabs on the QAN dashboard do not throw an error (PMM-1899). These tabs provide contextual information pertaining to the query, thus enhancing user experience. For more information, see documentation.</p> </li> <li> <p>PMM-9545: To monitor Kubernetes clusters, PMM now collects Kubernetes metrics from kube-state-metrics. For more information on kube-state-metrics, see  documentation.</p> <p>Disclaimer</p> <p>This feature is still technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> </li> <li> <p>PMM-10579: [Dashboard]: Only monitored services are displayed on the main menu for a clean and simple User Interface.</p> </li> <li>PMM-10512: [Alerting]:  When creating new alert rules. you can now use two new labels (application_name and usename) for pg_stat_activity_ metrics.</li> </ul>"},{"location":"release-notes/2.32.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-9946: [DBaaS]: To enhance user experience, once PMM is deployed to a Kubernetes cluster and a user wants to use DBaaS, PMM automatically registers that Kubernetes cluster to DBaaS.</p> </li> <li> <p>PMM-10733: [DBaaS]: We have moved another step forward in simplifying the use of DBaaS by simplifying the selection of the database version.</p> </li> <li> <p>PMM-10723: [DBaaS]: To make the content legible, we have changed the color of the notification block.</p> </li> <li> <p>PMM-10156: [Dashboard]: Starting with PMM 2.32.0, we have an enhanced PMM dashboard that gives a birds-eye view of the services, infrastructure, and critical issues (if any).</p> </li> <li> <p>PMM-10612: [Dashboard]: You can now easily access all dashboards for monitored services. Dashboards in the services folder (MySQL dashboards) that were not accessible from the main menu are now accessible from Other Dashboards.</p> </li> <li> <p>PMM-10695: [Dashboard]: For precision, we have added a unit (%) for the CPU Anomalies panel.</p> </li> <li> <p>PMM-10487: [Dashboard]: Our Experimental MongoDB dashboards are now equipped with tooltips to help you understand the information provided in the panels.</p> </li> <li> <p>PMM-10692: [Dashboard]: Enhanced the High CPU Usage, High Disk Queue, and High Memory Usage panels to make the troubleshooting process easier and more actionable. Just click the node name on the panel to see the details of the problem.</p> </li> <li> <p>PMM-10751: [Dashboard]: For the Vacuum dashboard, when filtering by Service name, the first panel that shows the service name and resolution was hidden due to the Disclaimer. It has now been moved above the Disclaimer to make it readable.</p> </li> <li> <p>PMM-10690: [Dashboard]: Starting with PMM 2.32.0, we have enabled sparklines for Disk Read and Write panels to visually represent and show trends in the data.</p> </li> <li> <p>PMM-10697: [Dashboard]: We have improved the visualization of the Used Memory Anomaly Panel on the Home Dashboard so that all the anomalies are visible.</p> </li> <li> <p>PMM-10694: [Dashboard]: Added and refined tooltips for all the panels on the dashboard.</p> </li> <li> <p>PMM-10721: On the Explore dashboard, Metrics panel, removed the links pointing to the Grafana discussion board.</p> </li> <li> <p>PMM-10662, PMM-10633, PMM-10631, PMM-10600: An additional MySQL and MongoDB related datapoints have been added to Telemetry.</p> </li> <li> <p>PMM-10926: [Backup Management]: Updated the documentation with information about required user permissions for creating Mongo BM backups. For more information, see the MongoDB topic.</p> </li> <li> <p>PMM-10393: The panel for total time taken for scraping metrics by Postgres exporter is improved. Instead of showing coarse-grained measurements of the total time taken by the exporter, it now shows the total time taken per collector.</p> </li> <li> <p>PMM-10555: Runtime for collectors in MongoDB exporter is pushed via Telemetry to  PMM. This information detects considerable scrape time for collectors and improves collector performance in future releases.</p> </li> </ul>"},{"location":"release-notes/2.32.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-10944: [Backup Management]: Fixed an issue that was preventing QAN to retrieve data after a restore for MongoDB with authentication enabled.</p> </li> <li> <p>PMM-10840: [Alerting]: Fixed embedded templates that are using expressions like x == 0  or x != 0.  PMM servers connected to Percona Platform already include this fix, since Percona Platform delivered it via Automatic Template Updates, a couple of weeks ago.</p> </li> <li> <p>PMM-10759: [Alerting]:  Renamed the Alerting option in the PMM Settings to Percona Alerting. Since this option refers to Percona Alert Rule Templates, this new label reflects better the fact that this option is different from the basic, built-in Alerting functionality.</p> </li> <li> <p>PMM-10810: [Alerting]:  Fired alerts now show the correct summary, which includes the node or service name specified in the template annotations.</p> </li> <li> <p>PMM-10500: [DBaaS]: DBaaS: Fixed an issue where a database cluster for an unregistered k8s cluster was still being displayed on the UI.</p> </li> <li> <p>PMM-10640: [DBaaS 1.10, 1.11]: Fixed an issue where a MongoDB 5.0.x cluster was not getting created.</p> </li> <li> <p>PMM-9874: [Dashboard]: Fixed an issue where the current ReplSet State stat is unreadable after modifying or restarting the database cluster for MongoDB Dashboard.</p> </li> <li> <p>PMM-10339: [Dashboard]: Fixed the duplicate values displayed on the CPU usage charts for MongoDB and MySQL dashboards.</p> </li> <li> <p>PMM-10802: [Advisors]: Fixed MongoDBGetDiagnosticData and MongoDBReplSetGetStatus query type for Advisors Checks V2.</p> </li> <li> <p>PMM-10688: This bug fix restores the ability to copy existing kubeconfig and register a new cluster by provided copy. However, AWS secrets will be hidden in the UI.</p> </li> </ul>"},{"location":"release-notes/2.32.0.html#known-issues","title":"Known Issues","text":"<p>PMM-11029: pmm-agent: killed when \u2013max-query-length &lt;=3</p> <p>If the value of the parameter <code>max-query-length</code> is set to 3, 2 or 1, the PMM agent will get terminated.</p> <p>Solution</p> <p>The value of the parameter should be greater than 3.</p> <p>PMM-11126: PMM server cannot be upgraded to version 2.32.0</p> <p>A bug in PMM Server ansible scripts caused PMM to upgrade Nginx\u2019s dependencies without updating Nginx itself. Due to this, PMM throws an error while upgrading and cannot upgrade to a newer version.</p> <p>Important</p> <p>This issue persists on versions prior to PMM 2.32.0.</p> <p>Solution</p> <p>Log in to PMM server and execute the following command:</p> <pre><code>sed -i 's/- nginx/- nginx*/' /usr/share/pmm-update/ansible/playbook/tasks/update.yml\n\n[PMM-10858](https://jira.percona.com/browse/PMM-10858): **PMM server doesnt show the latest versions available with the instances created from AWS**\n\n\nIn specific environments, including AWS, some EPEL repository mirrors did not respond within the time limit defined by `pmm-update,` currently set to 30 seconds. It was causing `supervisord `to kill `pmm-update-checker`, the component responsible for determining if a newer PMM Server is available for upgrade.\n\n!!! caution alert alert-warning \"Important\"\n    This issue persists on PMM 2.32.0 and all versions prior to PMM 2.32.0.\n\n**Solution**\n\nLog in to the PMM Server and run the following command as a root user:\n\n```sh\n   $ yum-config-manager --setopt=epel.timeout=1 --save\n</code></pre>"},{"location":"release-notes/2.33.0.html","title":"Percona Monitoring and Management 2.33.0","text":"Release date: Dec 13, 2022 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>PMM upgrade fails for versions prior to 2.33.0. Although there is a workaround, we highly recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components with all the bug fixes in place.</p>"},{"location":"release-notes/2.33.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.33.0.html#offline-metric-collection","title":"Offline metric collection","text":"<p>Starting with PMM 2.33.0, we have introduced a new solution to prevent data collection interruption in PMM, via offline metric collection. A network outage between the PMM server and the client prevented metrics from being collected. As a result, the historical data was lost, which can be useful when analyzing trends, diagnosing problems, or investigating issues from a previous period.</p> <p>In order to address the problem mentioned above, for the PMM server and PMM client running version 2.33.0, in case of a brief outage or network issue, metrics are stored on the monitored instance until the PMM server is up and running. At this point, the metrics will be pushed to the server. It only applies to PMM Clients that run in push mode, which is the default mode. The same holds when a brief network outage occurs on the client side.</p> <p>Caution</p> <p>The client node can currently store only 1 GB of offline data. So, for example, if your instance is down for three days, all the data will not be retrieved.</p> <p>With the implementation of the above feature, we have taken the first step toward PMM HA. Furthermore, we are happy to provide a roadmap for PMM HA implementation, a much-anticipated solution by our users. In the event of a failover, your PMM setup will experience near-zero downtime, and monitoring will continue with the offline metric collection.</p> <p>To ensure a smooth rollout, PMM HA will be introduced in phases, in line with your requirements and feedback.</p> <p>Important</p> <p>PMM HA will be rolled out in three stages. Stage one of PMM HA is the implementation to prevent data collection interruption with VictoriaMetrics integration for short outages included as part of PMM 2.33.0. HA stages two and three will be rolled out next year.</p> <p>The following features/use cases will be covered as part of the various stages of PMM HA:</p> Stages of PMM HA Solutions Provided Stage one (included in PMM 2.33.0) As an initial step towards preventing data collection interruption, we have developed the following:Prevent data collection interruption with VM integration for short outages Stage two (will be rolled out in 2023) As part of PMM HA stage two, we plan to implement the following:HA data sourcesAs part of stage two we will let the users use external data sources, thereby decreasing dependency on the file system. Stage three (will be rolled out in 2023) As part of PMM HA stage three, we plan to implement the following:Clusterized HAClustered PMM will be the focus of stage three. Detailed information will be included in the upcoming release notes."},{"location":"release-notes/2.33.0.html#guided-tour-of-percona-alerting","title":"Guided tour of Percona Alerting","text":"<p>Following the recent improvements to PMM Alerting, we have added a short tutorial to help you explore our streamlined alerting system based on Grafana. The in-app tutorial automatically pops up when you first open the Alerting page to help you uncover the fundamentals of Percona Alerting.</p>"},{"location":"release-notes/2.33.0.html#restore-mongodb-backups-easier","title":"Restore MongoDB backups easier","text":"<p>Building on the significant improvements for MongoDB Backup Management introduced in the previous release. We are now simplifying the process for restoring physical MongoDB backups. Starting with this release, you can restore physical backups straight from the UI, and PMM will handle the process end-to-end. Prior to this, you would require to perform additional manual steps to restart your MongoDB database service so that your applications could make use of the restored data.</p>"},{"location":"release-notes/2.33.0.html#components-upgrade","title":"Components Upgrade","text":"<ul> <li>VictoriaMetrics has been upgraded from 1.77.1 to 1.82.1.</li> <li>As part of PMM 2.33.0, Grafana has been updated to 9.2.5, which fixes some critical vulnerabilities. For more information, see Grafana 9.2.5</li> </ul>"},{"location":"release-notes/2.33.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-10889 - Starting with PMM2.33.0, while using the pmm-admin CLI command, you do not have to know the entire command. Just type the initial command and press Tab. The rest of the command will be autocompleted.</p> <p>Depending on the shell you are using, add the following to your shells .rc file for autocomplete to work:</p> <pre><code>source &lt;(pmm-admin completion -c &lt;your shell&gt;)\nE.g. source &lt;(pmm-admin completion -c bash)\n</code></pre> </li> <li> <p>PMM-10955: [Backup Management]: After restoring a backup, you can now check the time when the restore was finalized. For PITR backups, you can also check the time to which the restore was performed.    This information is available on the tab Backup &gt; Restores page, in the new Finished at column, and in the PITR timestamp field under the Actions menu.</p> </li> </ul>"},{"location":"release-notes/2.33.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-7000: [HA]: Staring with PMM 2.33.0, if the PMM Server goes down, metrics will be buffered on the monitored instance until PMM Server goes back online, which is when metrics will get pushed to the PMM Server. </p> </li> <li> <p>PMM-10901: [Documentation]: To enable the users to use High Availability easily, we have added exclusive documentation for HA.</p> </li> <li> <p>PMM-8516: [Backup Management]:  When creating a backup, the Vendor field was not automatically populated in the Back-up on demand dialog. This issue is now fixed. </p> </li> <li> <p>PMM-10627: [DBaaS]: You can now create a single node cluster for PSMDB. </p> </li> <li> <p>PMM-10855: Avoid massive gRPC messages formatting for disabled log level</p> </li> <li> <p>PMM-10903: [DBaaS]: To simplify DBaas, you no longer have to manually enter the Public Address on the PMM Settings &gt; Advanced Settings page. With DBaaS enabled, PMM will automatically detect and populate the Public Address.</p> </li> <li> <p>PMM-11085: [Backup Management]: We\u2019ve removed the Create backup option under All backups page &gt; Actions menu because this option can only create on-demand backups. You can continue to create both on-demand and scheduled backups using the Create backup button on this page. </p> </li> <li> <p>PMM-10881: [CVE]: As part of PMM 2.33.0, Grafana was updated to 9.2.5, which fixes some critical vulnerabilities. For more information, see Grafana 9.2.5.</p> </li> <li> <p>PMM-10385: Starting with PMM 2.33.0, for MySQL, the Explain tab is supported without the Examples tab. If a query in the Explain tab contains sensitive data, placeholders will replace them.</p> </li> <li> <p>PMM-8655: Latest state of agents is now available on the PMM server after the connection is re-established between the client and server.</p> </li> <li> <p>PMM-10969: VictoriaMetrics operator has been upgraded from 0.24 to 0.29.0.</p> </li> <li> <p>PMM-10554: Postgres collector now provides runtime duration for scrapes at the collector level. As a result, we can identify collectors who take too long. By utilizing this data, corrective action can be taken.</p> </li> <li> <p>PMM-10629: [Components Upgrade]: VictoriaMetrics has been upgraded from 1.77.1 to 1.82.1.</p> </li> </ul>"},{"location":"release-notes/2.33.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-10858: In specific environments, including AWS, some EPEL repository mirrors did not respond within the time limit defined by <code>pmm-update</code>, currently set to 30 seconds. This was causing <code>supervisord</code> to kill <code>pmm-update-checker</code>, the component responsible for verifying if a newer version of the PMM Server is available for upgrade. This issue has been resolved now.</p> </li> <li> <p>PMM-10683: [DBaaS]: While registering a K8s cluster on the Manage Components Versions modal, the versions were not getting unchecked. The issue has now been resolved.</p> </li> <li> <p>PMM-11082: When adding RDS MySQL instances to PMM, some queries pertaining to table stats were executed, despite table stats being disabled.</p> </li> <li> <p>PMM-10637: Fixed an issue where the queries for some panels on the PostgreSQL Instance Summary dashboards were broken.</p> </li> <li> <p>PMM-11029: Whenever the <code>max-query-length</code> parameter was set to 3, 2, or 1, the PMM agent would be terminated. The issue has now been resolved.</p> </li> <li> <p>PMM-10732: Checking the select all checkbox on the Services, Agents, and Nodes modal in the PMM Inventory window deleted all entries on all the pages. The issue has been resolved now.</p> </li> <li> <p>PMM-10062: While monitoring a large number of nodes, some dashboards had incredibly long load times, resulting in an unresponsive UI. The issue has been fixed now.</p> </li> <li> <p>PMM-10983: Some panels on the dashboards were showing only short names. The issue has been resolved now.</p> </li> <li> <p>PMM-11041: There was typo on the Home dashboard: COMMAND CENTER graphs. This has been fixed now.</p> </li> <li> <p>PMM-10996: [Backup Management]: Fixed an issue where the initial description text for a storage location could not be updated.</p> </li> <li> <p>PMM-10718: [Backup Management]: When taking backups, PMM now shows a clearer error if the pmm-agent is incompatible with the specified backup operation.</p> </li> <li> <p>PMM-10558: Top 5 Collections by Documents Changed panel on the MongoDB Collection Details dashboard did not display data correctly based on the selected filters. It has now been resolved.</p> </li> <li> <p>PMM-10493: [Portal Integration]: In some specific scenarios, disconnecting from Platform Portal as an Administrator would sometimes show a token error. This issue is now fixed. </p> </li> <li> <p>PMM-10845: [Advisors] Fixed specific error that occurred when working with Advisors that do not specify a frequency for executing the advisor check.</p> </li> <li> <p>PMM-10029: There was a potential issue with the network request exceeding the maximum message size. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/2.33.0.html#known-issues","title":"Known issues","text":"<ul> <li> <p>PMM-11126: PMM server cannot be upgraded to version 2.32.0</p> <p>A bug in PMM Server ansible scripts caused PMM to upgrade Nginx\u2019s dependencies without updating Nginx itself. Due to this, PMM throws an error while upgrading and cannot upgrade to a newer version.</p> <p>Important</p> <p>This issue has been resolved for PMM version 2.33.0. However, the issue persists on all the versions prior to 2.33.0.</p> <p>Solution</p> <p>While PMM is being upgraded, log in to the PMM server and run the following command:</p> <pre><code>sed -i 's/- nginx/- nginx*/' /usr/share/pmm-update/ansible/playbook/tasks/update.yml\n</code></pre> </li> <li> <p>PMM-10858: PMM server does not show latest versions available with the instances created with AWS</p> <p>For PMM versions prior to 2.33.0, in specific environments, including AWS, some EPEL repository mirrors did not respond within the time limit defined by pmm-update (currently set to 30 seconds). It was causing supervisord to kill pmm-update-checker, which determines if a newer PMM Server is available for upgrade.</p> <p>Solution</p> <p>Log in to the PMM Server and run the following command as a root user:</p> <pre><code>$ yum-config-manager --setopt=epel.timeout=1 --save\n</code></pre> </li> </ul>"},{"location":"release-notes/2.34.0.html","title":"Percona Monitoring and Management 2.34.0","text":"Release date: January 30, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.34.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.34.0.html#various-ux-enhancements-to-backup-management","title":"Various UX enhancements to Backup Management","text":"<p>With this release, we are updating the Backup and Restore functionality with key usability enhancements, including:</p> <ul> <li>Filtering on services at backup creation time. This makes it considerably easier to find the right service for a backup when working with multiple servers.</li> <li>Automatic redirection to the Restores page after initiating a restore. From here you can immediately monitor the restore process, and see the restore history for your PMM instance.</li> <li>Added information about the type of storage for the backup artifacts on the  All backups page. This helps you get a more comprehensive overview of your current backups.</li> <li>Design and usability improvements on the Create Backup and All Backups page to increase consistency with other PMM UI controls.</li> </ul>"},{"location":"release-notes/2.34.0.html#dbaas-migration","title":"DBaaS migration","text":"<p>Starting with PMM 2.34.0, PMM installs and manages operators using Operator Lifecycle Manager (OLM) and database clusters using <code>dbaas-operator</code>. Nonetheless, these changes are backward incompatible, and you must perform these additional steps:</p> <ol> <li>Force unregister the Kubernetes cluster from PMM (select Ignore errors checkbox) and register it back. PMM will install OLM and <code>dbaas-catalog</code> to manage the lifecycle of PXC, PSMDB, and DBaaS operators.</li> <li>Create a database cluster for each cluster you have created in PMM. You can use the script to do it automatically during the maintenance window. Migration scripts use the default configuration to connect to Kubernetes clusters and run migrations against them.</li> </ol>"},{"location":"release-notes/2.34.0.html#new-components","title":"New components","text":"<p>We have a newly added component, <code>VMProxy</code> starting with PMM 2.34.0. <code>VMProxy</code> is a stateless reverse proxy that proxies requests to VictoriaMetrics and optionally adds <code>extra_filters</code> query based on the provided configuration.</p>"},{"location":"release-notes/2.34.0.html#new-features","title":"New Features","text":"<p>PMM-11031 - To enhance the DBaaS experience, the UI has been extended to include the following:</p> <ul> <li>Network and Security - DBaaS users can set a source range from which they can connect to their DB clusters with the Expose field. You can modify the exposure level using the Source Range field. Additionally, the Source Range field allows you to choose the network from which you can connect.</li> <li>Configuring the database engine - Copy-paste the config string into the Configuration text box to configure the database engine.</li> <li>Configuring storage classes - You can choose from the available classes.</li> </ul>"},{"location":"release-notes/2.34.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-11024 - [DBaaS]: Move from dbaas-controller to dbaas-operator</li> <li>PMM-10873 - [DBaaS]: Create DB Cluster: We have modified the UI to include a separate window rather than a popup so that creating a DB cluster is easier.</li> <li>PMM-11132 - [DBaaS]: During K8s cluster registration, a new state called Provisioning is added. Provisioning is the default state, and once that is completed, the state will change to Active.</li> <li>PMM-11134 - [DBaaS]: Edit DB Cluster: We have modified the UI to include a separate window rather than a popup so that editing a DB cluster is easier.</li> <li>PMM-9262   - [Backups]: After starting a backup restore from the All Backups page, PMM now automatically redirects you to the Restores tab, where you can check the status of your new restore.</li> <li>PMM-11086 - [Backups]: Improved design for the On Demand and Schedule Backup cards on the Create Backup page. In addition, the Created column on the Restores tab has been replaced with Started at and Ended columns to provide more insight into the restore process.</li> <li>PMM-10924 - [Backups]: The Location column on the All Backups page has been enhanced to include information about the storage type used for the backup: Local or S3-compatible.</li> <li>PMM-11171 - [Backups]: The Service name field on the Create Backup page is now searchable. This makes it easier to find the right service for a new backup when working with multiple servers. Just paste the name of the server you\u2019re looking for, or start typing to see the list of matching servers.</li> <li>PMM-9079 - [Backups]: Added Target Service column under Backup &gt; Restores to show the service to which a backup was restored.</li> <li>PMM-10773 - [Alerting]: Added option to unsilence alerts from the Actions menu under Alerting &gt; Fired Alerts.</li> <li>PMM-11230 - [Alerting]: The Fired alerts page under Alerting now auto-refreshes more frequently to ensure that any new alerts are displayed in real-time.</li> <li>PMM-11255 - [Alerting]: PMM no longer transfers the name of the current alert rule when switching from Percona templated alert to Grafana managed alert.</li> <li>PMM-11090 - The Logs feature has been moved from the <code>dbaas-controller</code> to PMM, providing users with the ability to see the events for each pod and the logs for every container properly populated within PMM.</li> <li>PMM-11179 - Starting with PMM 2.34.0, we support push metrics mode while updating labels.</li> <li>PMM-11189 - Starting With PMM 2.34.0, we have implemented vmproxy integration and frontend API changes.</li> <li>PMM-10705 - [DBaaS]: As of PMM 2.34.0, Operator Lifecycle Management (OLM) is used for handling the installation and updating of operators for PMM in an effective, automated, and scalable manner.</li> <li>PMM-11069 - [Backups]: PMM no longer allows creating backup tasks with a name that already exists. After upgrading to PMM 2.34, any backup tasks with duplicate names are automatically renamed to apply the new naming constraints.</li> </ul>"},{"location":"release-notes/2.34.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-7350   - [DBaaS]: Fixed an issue where DB Cluster did not restart all PXC servers and proxy SQL servers on restarting.</li> <li>PMM-11333 - [DBaaS]: Fixed an issue where the API key was missing on K8s cluster registration after moving to Operator Lifecycle Management (OLM).</li> <li>PMM-9505   - [DBaaS]: The options to update, restart, and view logs were enabled for paused clusters. This issue has now been resolved by disabling these options.</li> <li>PMM-11221 - [DBaaS]: Fixed an issue where the page did not load when DBaaS was disabled.</li> <li>PMM-7958   - During Postgres monitoring, databases were not getting deleted. This issue has been resolved now.</li> <li>PMM-9977   - [Backups]: After deleting an expanded row from the Backup &gt; All Backups page, PMM would automatically expand the next row in the table. This issue is now fixed and PMM refreshes the list of backups artifacts without automatically expanding any rows.</li> <li>PMM-10942 - [Backups] - The scheduler for PITR backups now use clearer text labels to better define the Start time and the Frequency for the backups being created.</li> <li>PMM-10853 - [Alerting]: Removed Save button from the Create alert rule page as this was duplicating the functionality of the Save and exit button.</li> <li>PMM-10871 - [Alerting]: Fixed broken Percona Alerting link on the Settings &gt; Alertmanager integration page. The link now correctly redirects to the Alerting page.</li> <li>PMM-11049 - Fixed a typo that was present in enhanced metrics scraper for <code>rds_exporter</code>.</li> <li>PMM-11137 - An issue with the MongoDB exporter not showing the version for MongoDB instance has been resolved.</li> <li>PMM-11210 - Whenever a cluster was unavailable or deleted, the K8s cluster list was empty. The issue has been resolved now.</li> <li>PMM-11239 - Despite removing pmm-server packages before upgrading PMM server, the packages were still present during upgrade. The issue has been resolved now.</li> <li>PMM-11372 - The user interface was broken after PMM was upgraded. This issue has been resolved now.</li> </ul>"},{"location":"release-notes/2.34.0.html#known-issues","title":"Known issues","text":"<ul> <li>Starting with PMM 2.34.0, the recommended version for running Percona XtraDB cluster is 8.0.27. It\u2019s impossible to create Percona XtraDB clusters using a version older than 8.0.27. All previously created clusters are not affected and will be migrated without any issues.</li> <li>PMM-11474: If more than two Kubernetes clusters are registered with PMM, and database cluster credentials are requested, an internal server error may occur.</li> </ul>"},{"location":"release-notes/2.35.0.html","title":"Percona Monitoring and Management 2.35.0","text":"Release date: Feb 23, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.35.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.35.0.html#access-control-limit-access-to-metrics","title":"Access Control: Limit access to metrics","text":"<p>Important/Caution</p> <p>Disclaimer:  PMM Access Control is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>We are pleased to announce that PMM 2.35.0 marks the first step towards introducing PMM Access Control. Label-based access control in PMM allows you to manage who has access to metrics based on labels. </p> <p>By creating roles, you can specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related to test environments. Using this feature, you can associate multiple labels with a role, ensuring only data from series that match your defined labels is returned. </p> <p>This feature provides a standardized method for granting, changing, and revoking access to metrics, giving you a powerful and flexible way to manage access to metrics and ensure secure access to the information you need. For more information, see documentation.</p>"},{"location":"release-notes/2.35.0.html#ga-deployment-of-pmm-in-kubernetes-with-helm-chart","title":"GA: Deployment of PMM in Kubernetes with Helm Chart","text":"<p>We are happy to announce the General Availability of PMM deployment in Kubernetes with the Helm chart. PMM deployment via Helm chart in Kubernetes has been available as Tech Preview since PMM v2.29, but now we\u2019re delighted to offer it to users as a fully supported feature. For more information, see documentation.  </p>"},{"location":"release-notes/2.35.0.html#dbaas-add-a-backup-schedule-while-creating-db-clusters","title":"DBaaS: Add a backup schedule while creating DB clusters","text":"<p>Starting with PMM 2.35.0, you can add a backup schedule while creating DB clusters in DBaaS. This feature is a fusion of backup management and DBaaS in PMM. Currently, DBaaS only supports scheduled backups, which can only be enabled when a database cluster is created.</p> <p>DBaaS does not support on-demand backups. For more information, see documentation.  </p>"},{"location":"release-notes/2.35.0.html#dbaas-restore-cluster-from-backup-stored-on-s3","title":"DBaaS: Restore cluster from backup stored on S3","text":"<p>You can now create a DBaaS cluster from a backup stored on S3. You can use backups taken from existing cluster and use them to spin-up a new database cluster from this backup. Attempts to use it to restore a previous version of the cluster will result in downtime since the system will treat it as a creation of a new cluster.</p> <p>DBaaS does not support on-demand restore. For more information, see documentation.</p>"},{"location":"release-notes/2.35.0.html#more-pre-run-checks-for-mongodb-backups","title":"More pre-run checks for MongoDB backups","text":"<p>With this release, PMM runs additional verifications to ensure infrastructure compliance and prevent backup execution errors:</p>"},{"location":"release-notes/2.35.0.html#tool-compatibility-check","title":"Tool compatibility check","text":"<p>Before initiating backups for MongoDB, PMM now examines the current MongoDB node to ensure that the connected PMM Agents have the tools to execute and finalize the backup.</p> <p>If the requirements are not met, PMM reports what tools or tool versions are missing, similarly to the existing prerequisites check for MySQL backups.</p>"},{"location":"release-notes/2.35.0.html#overlapping-jobs-check","title":"Overlapping  jobs check","text":"<p>To avoid conflicting jobs, PMM proactively disables the creation of  Point-in-time Recovery (PITR), or snapshot backups, when other backups are scheduled for running.</p> <p>Similarly, creating PITR backups for different services of the same cluster is now automatically restricted.</p>"},{"location":"release-notes/2.35.0.html#cluster-membership-check","title":"Cluster membership check","text":"<p>To avoid execution errors, PMM no longer allows scheduling backups on MongoDB Services that are not managed as a cluster.</p> <p>You can check which of your current Services are not members of a cluster on the PMM Inventory &gt; Services page. Services that do not specify a cluster name in the Other Details column should be removed and re-added using the following set of commands:</p> <pre>pmm-admin add mongodb\nusername=pmm_mongodb --password=password \nquery-source=profiler --cluster=mycluster</pre>"},{"location":"release-notes/2.35.0.html#backup-restore-logs-accessible-from-pmm","title":"Backup restore logs accessible from PMM","text":"<p>With this release, we are adding the option to view the logs for restores from a MongoDB database backup. This complements the existing option to view the logs for the backup process and makes it easier to gather data for compliance, auditing, and troubleshooting purposes.</p> <p>Instead of having to look through PBM log files, you can now access the Log option in PMM, which is now automatically displayed next to each MongoDB backup restore entry on the Backup &gt; Restores page.</p>"},{"location":"release-notes/2.35.0.html#components-upgrade","title":"Components Upgrade","text":"<p>MongoDB exporter has been upgraded to 0.37.0.</p>"},{"location":"release-notes/2.35.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-10325 - Starting with PMM 2.35.0, for enhanced security, you can change the admin password even after <code>pmm-agent</code> is registered on the PMM Server.</p> </li> <li> <p>PMM-10550 - [Backup Management]: PMM now automatically displays a <code>Logs</code> option next to each MongoDB backup restore entry on the Backup &gt; Restores page.</p> </li> <li> <p>PMM-11302 - [DBaaS]: Starting with PMM 2.35.0, you can add a backup schedule while creating DB clusters in DBaaS. You can also restore the cluster from backup stored on S3.</p> </li> <li> <p>PMM-10962 - Starting with PMM 2.35.0, we have introduced Access Control. Roles are a vital part of Access Control that provide the users with access to specified metrics. You can create, edit, and delete user roles. The roles can be assigned to the users with the Configuration &gt; Users tab. For more information, see documentation.</p> </li> </ul>"},{"location":"release-notes/2.35.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-10471 - [Backup Management]: PMM now automatically checks the current MongoDB node to ensure that the connected PMM Agents have the tools to execute and finalize the backup.</p> </li> <li> <p>PMM-11113 - Enhanced user experience for the Percona Platform page under Configuration &gt; Settings. The new version of this page highlights the advantages of connecting your PMM instance to Percona Platform and makes it easier to generate and use a connection token.  </p> </li> </ul>"},{"location":"release-notes/2.35.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li> <p>PMM-9446 - Fixed an issue with the MySQL/MySQL Details dashboard, where the users\u2019 names were overlapping.</p> </li> <li> <p>PMM-10016 - [Advisors]: The list of checks in the Failed Checks table would randomly rearrange after clicking on any of the checks in the list. This issue is now resolved.</p> </li> <li>PMM-10109 - [DBaaS]: Fixed an issue that prevented the creation of DB clusters when performing a <code>List</code> query.</li> <li>PMM-11290 - [DBaaS] Fixed an issue where the Advance option in Edit DB cluster disabled  the Edit/Save option.</li> <li>PMM-11474 - [DBaaS]: An internal server error was thrown on the UI while upgrading PMM to 2.34.0, and DB clusters were not visible in the UI. The issue has been resolved now.</li> <li>PMM-11062 - Fixed an issue where the Check update button was not visible.</li> <li>PMM-11116 - Despite PMM-gent being connected, the status of all other agents was <code>Unknown</code>. The issue has been resolved now.</li> <li>PMM-11154 - Fixed an issue where all agents except <code>pmm-agent</code> display NULL values in <code>version</code> and <code>runs_on_node_id</code> fields in the <code>agents</code> table of internal PostgreSQL database.</li> <li>PMM-11186 - Check that service is a member of a cluster before MongoDB backup/restore</li> <li>PMM-11274 - \u201cPostgresql exporter error\u201d was thrown for all nodes after upgrading from 2.29.0 to 2.33.0. The issue has been resolved now.</li> <li>PMM-11298 - While monitoring the performance of VictoriaMetrics with PMM 2.33.0, the CPU usage shown on Node Summary or VictoriaMetrics dashboard overview panel did not match the value shown on the system Level Metrics panel. The issue has been resolved now.</li> <li>PMM-11357 - [Percona Alerting]: Fixed an issue where the name of an alert rule was not inherited correctly from the alert template.</li> <li>PMM-11399 - [Percona Alerting]: The pop-up message that confirmed saving an alert rule would not display the name of the rule correctly. This issue is now resolved.</li> <li>PMM-11517 - [Backup Management]: Fixed a PBM synchronization issue that made PMM unable to restore local physical backups after the first attempt.</li> </ul>"},{"location":"release-notes/2.35.0.html#coming-soon","title":"Coming Soon","text":""},{"location":"release-notes/2.35.0.html#access-management","title":"Access Management","text":"<p>The following features/use cases will be covered as part of the various stages of PMM Access Management:</p> <p>Role-based access control (RBAC), including access limitations to the features like Alerting and Backup with read-edit-delete permissions.</p>"},{"location":"release-notes/2.35.0.html#pmm-high-availability","title":"PMM High Availability","text":"<p>PMM High Availability (HA) feature will be available soon!</p> <p>The planned phases will be launched soon. </p>"},{"location":"release-notes/2.36.0.html","title":"Percona Monitoring and Management 2.36.0","text":"Release date: Mar 23, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.36.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.36.0.html#pg_stat_monitor-20-support-in-qan","title":"pg_stat_monitor 2.0 support in QAN","text":"<p>We are excited to announce PMM 2.36 now supports pg_stat_monitor 2.0 (PGSM 2.0) in QAN, a powerful PostgreSQL query performance monitoring tool. By downloading this update, you will have access to the latest improvements and fixes covered by PGSM2, including:</p> <ul> <li>Improved internal architecture that results in fewer lock acquisitions and increases performance by approximately 20%.</li> <li>Support for PostgreSQL 15 </li> <li>Enhanced consistency with <code>pg_stat_statements</code> so that the <code>pg_stat_monitor</code> view has identical column names, columns, and data types as <code>pg_stat_statements</code> for every major version of PostgreSQL from versions 11 to 15.</li> <li>A bucket status indication (done vs. current) eliminates the need for the tool to evaluate bucket status and facilitates accurate data display.</li> <li>The generation of a unique ID for a query makes it easier to monitor query planning, execution, and performance regardless of version, database, user, or schema.</li> </ul> <p>For more information on the enhancements in PGSM2, refer to the full list.</p> <p>Important</p> <p>PMM 2.36 and PGSM 2.0 now support PG 13, 14, and 15. Support for older versions (PG 11 and 12) will be introduced in PMM 2.37.</p>"},{"location":"release-notes/2.36.0.html#revamped-advisors-page","title":"Revamped Advisors page","text":"<p>We\u2019ve improved the structure of the Advisors page to group Advisors by categories and clearly show the Advisors available for your current subscription. </p> <p>With this change, we have renamed all the tabs on the page, and added an option to easily integrate with Percona Platform for extra Advisors for free:</p> <p></p>"},{"location":"release-notes/2.36.0.html#postgresql-advisors-executed-against-more-databases-dbs","title":"PostgreSQL Advisors executed against more databases (DBs)","text":"<p>To give you additional insights on your PostgreSQL DBs, PostgreSQL Advisors now try to perform checks on all the databases accessible with the credentials used during pmm-client setup. In most cases, these are the databases available for the PMM database account user. For more information, see the Create a database account for PMM topic in the PMM online Help.\u201d</p>"},{"location":"release-notes/2.36.0.html#backup-management-enabled-by-default","title":"Backup Management enabled by default","text":"<p>Since the PMM 2.32 release, we have continuously improved the Backup Management functionality in terms of backup locations, restore options and user experience.</p> <p>As a mature and generally useful feature, this option is now enabled by default for easier access to your backups and restore artifacts.</p> <p>Note</p> <ul> <li>Upgrading to PMM will automatically enable this feature for existing PMM instances. You can disable it at any time from your PMM dashboard on the Advanced Settings page or using the Docker environment variable <code>DISABLE_BACKUP_MANAGEMENT=1</code>.</li> <li>While we have GA\u2019ed Backup Management for MongoDB since PMM 2.32, Backup Management for MySQL still  in technical preview, and, therefore, subject to change. For more information, see the Percona Release Lifecycle.</li> </ul>"},{"location":"release-notes/2.36.0.html#components-upgrade","title":"Components upgrade","text":"<p>Grafana has been upgraded to version 9.2.13.</p>"},{"location":"release-notes/2.36.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-9474 - PostgreSQL Advisors are now executed against all the available databases (DBs), not only the one connected to PMM</li> <li>PMM-11363 - Starting with PMM 2.36.0, you no longer need to unassign a role before deleting it. If you try to delete a role assigned to a user, you will see a dropdown with replacement roles. As a result, the selected role will be assigned to the user.</li> </ul>"},{"location":"release-notes/2.36.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-11640 - [Backup Management]: The Backup Management feature is now enabled by deault forf easier access to your backups and restore artifacts.</p> </li> <li> <p>PMM-11182 - [Platform integration]: Renamed the Disconnect button on the confirmation message that pop-ups when you are terminating Percona Platform connections as an Administrator. The button is now called Force disconnect to better differentiate between situations where you are disconnecting using a Percona Platform Account.</p> <p>Force-disconnecting only clears the connection in PMM without automatically removing the disconnected servers from Percona Platform. We recommend that you always disconnect while logged in with your Percona Account. Otherwise, make sure to manually remove the force-disconnected servers from your list of PMM instances in Percona Platform.</p> </li> <li> <p>PMM-11381 - Starting with PMM 2.36.0, you can scrape Kubelet metrics with DBaaS or VictoriaMetrics operator. Using Kubelet metrics, you can gather volume-related information.</p> </li> <li> <p>PMM-11566 - You now have Admin Access to PMM Demo instances so that you can experiment with all the features of PMM.</p> </li> <li> <p>PMM-11699 - Improved documentation and descriptions for Advisor checks.</p> </li> <li> <p>PMM-10974 - Usage of pg_stat_monitor by default.</p> </li> </ul>"},{"location":"release-notes/2.36.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-11291 - [DBaaS]: There was a difference in the shape and color of the DB Cluster Status box compared to the Kubernetes Cluster status box. The issue has been resolved now.</li> <li>PMM-11296 - [DBaaS]: Fixed an issue where the DB Cluster creation page did not load when DBaaS was disabled.</li> <li>PMM-11358 - [DBaaS]: Connection to the DB cluster displayed a loader when the DB cluster was suspended/paused. The issue has been resolved now.</li> <li>PMM-11613 - [DBaaS]: Backups could not be created when uppercase letters were used in the storage name. The issue has been resolved now.</li> <li>PMM-11568 - [DBaaS]: Disabled the selection of MySQL versions less than 8.0.27.</li> <li>PMM-11766 - [DBaaS]: The status of an unavailable cluster was displayed as Active. When this cluster was unregistered, an error was thrown. The issue has been resolved now.</li> <li>PMM-11428 - [DBaaS]: Fixed an issue where editing DB clusters was broken.</li> <li>PMM-10254 - [Dashboards]: On the MySQL/Mongo dashboards, the Memory Available graph showed incorrect values. The issue has been resolved now.</li> <li>PMM-11209 - [Backup Management]: Improved error handling for partially successful restores. Restore jobs that finished successfully on some nodes and failed on others are no longer locked in a Pending state. Instead, PMM now shows a PartlyDone error and populates the logs with specific details on the restore status for the replica set and nodesup restores.</li> <li>PMM-10606 - Fixed an issue for the incorrect link for node name on the mysql instance summary dashboard.</li> <li>PMM-11001 - Fixed an error that occurred in certain scenarios when expanding alert rules nested in folders.</li> <li>PMM-11004 - Fixed issue that ignored the database name provided when adding PG server to PMM.</li> <li>PMM-11408 - Navigation from the New Home dashboard panel to certain dashboards is broken. The issue has been resolved now.</li> <li>PMM-11421 - Improved error message that is displayed when trying to connect PMM to Percona Platform over HTTP Proxies: \u201cPMM Platform connection does not support proxy\u201d.</li> <li>PMM-11526 - On the Summary dashboard, the error message exit status 1 has been replaced with a more meaningful message.</li> <li>PMM-11588 - Fixed an issue where the database instance count on the OS Overview dashboard was incorrect.</li> <li>PMM-11636 - The Grafana Admin page crashed when filtering users. The issue has been resolved now.</li> <li>PMM-11654 - There was no data displayed on the PXC Galera replication latency dashboard. The issue has been resolved now.</li> <li>PMM-11664 - Fixed an issue for the environment filter missing from the OS dashboards.</li> <li>PMM-11717 - Mysql exporter agent stopped working after upgrading the server to PMM 2.36.0. The issue has been resolved now.</li> </ul>"},{"location":"release-notes/2.37.0.html","title":"Percona Monitoring and Management 2.37.0","text":"Release date: May 02, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.37.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.37.0.html#improved-inventory-view","title":"Improved Inventory view","text":"<p>This release of PMM starts the series of enhancements that will improve the way you work with Services and Nodes in PMM.  With this first set of changes, we\u2019re revamping the Inventory page to give you more context on your inventory objects, and more actionable information for exploring and fixing possible issues. </p> <p>Here are all the specific changes: </p> <ul> <li>Improved design of the Inventory page for a clearer presentation of all the objects registered by PMM. </li> <li>Services now show their database status, which is based on the monitoring metrics. This enables you to quickly check the status of the databases when you are working with the inventory.  </li> <li>New Monitoring column showing the live status for the monitoring Agents assigned to a Service. This enables you to quickly spot any possible issues with the Agents.</li> <li>Quick access to the Service Summary Dashboard and to QueryAnalytics results so that you can easily explore important related information. </li> <li>New Details section grouping together all the relevant parameters and labels for a Service. To keep things clean, this section is collapsed by default, so that you can view extra information only when you need it. </li> </ul> <p>Here\u2019s what\u2019s coming:</p> <p>Building up on these changes, subsequent releases will further improve PMM Inventory with:</p> <ul> <li>More useful features to filter and better connect Services and Nodes.</li> <li>Services organized in clusters so that you can capture the bigger picture, instead of working at of individual Service-level.</li> </ul>"},{"location":"release-notes/2.37.0.html#new-experimental-dashboards-for-kubernetes-monitoring","title":"New Experimental Dashboards for Kubernetes Monitoring","text":"<p>Important</p> <p>These experimental dashboards are subject to change. It is recommended to use these dashboards for testing purposes only.</p> <p>We are pleased to announce the release of PMM 2.37, which introduces three new experimental dashboards:</p> <ul> <li>Kubernetes Cluster Summary</li> <li>Kubernetes Pods Status</li> <li>Kubernetes Volumes </li> </ul> <p>These dashboards are designed to provide valuable insights into the status and performance of your Kubernetes cluster, pods, and volumes, helping you to identify and troubleshoot issues quickly and easily.</p> <p>We welcome your feedback as we continue to enhance PMM with these new dashboards.</p> <p>Experimental Kubernetes Cluster Summary Dashboard</p> <p>Kubernetes Cluster Summary provides a comprehensive overview of your Kubernetes cluster, including:</p> <ul> <li>Components</li> <li>Node</li> <li>Pod</li> <li>PVC status</li> <li>CPU</li> <li>Memory overview, and more. </li> </ul> <p>This dashboard displays all workloads running in the cluster, enabling you to take action and optimize its performance.</p> <p>Experimental Kubernetes Pods Status Dashboard</p> <p>Kubernetes Pods Status dashboard provides detailed information about the state and performance of your pods, including CPU, Memory, and Network metrics. </p> <p>This dashboard can help you quickly pinpoint any issues affecting your pods and ensure they continue to operate smoothly.</p> <p>Experimental Kubernetes Volume Dashboard</p> <p>Kubernetes Volumes dashboard  provides insights into your Kubernetes volumes, including capacity and usage, in real time. With this dashboard, you can easily monitor the performance and usage of your volumes and take proactive measures to ensure their performance.</p> <p>Refer to the documentation to learn more about these new experimental dashboards and how to use them.</p> <p>Here are the steps to create a new folder and move all experimental dashboards to the new folder for quick access and internal use:</p> <p>Note</p> <p>You should have at least an Editor role to create a new folder and move all experimental dashboards.</p> <ol> <li>Navigate to the Main menu and hover on the  Dashboards icon.</li> <li>Click New folder.</li> <li>Provide a name for your folder, and then select Create.</li> <li>Navigate to  Dashboards from the Main menu and click Browse.</li> <li>Select the dashboard that you want to move and click Move.</li> <li>On the Choose Dashboard dialogue box, from the dropdown under Folder option, choose the folder where you want to move the dashboard.</li> <li>To apply your changes, select Save Dashboard.</li> </ol>"},{"location":"release-notes/2.37.0.html#components-upgrade","title":"Components upgrade","text":"<p>VictoriaMetrics has been upgraded to version [1.89.1].</p>"},{"location":"release-notes/2.37.0.html#new-features","title":"New Features","text":"<ul> <li> <p>PMM-10913 - Starting with PMM 2.37.0, you can use an external PostgreSQL server as data storage for PMM. Thus, even if PMM fails, your data will be stored in an external source, reducing the risk associated with data loss. Furthermore, clustered PostgreSQL instances also enhance performance.</p> </li> <li> <p>PMM-11281 - We have written a query for the postgres exporter to deal with lock conflicts in databases that block several transactions, thus impacting performance. With this query, you can find the PID of the blocking session and how many sessions it blocked. The proactive approach enables customers to address non-responsive databases quickly by understanding the underlying causes.</p> </li> <li> <p>PMM-11384 and PMM-11834 - PMM 2.37.0 now supports PSMDB operator versions 1.13 and 1.14.</p> </li> <li> <p>PMM-11438 - Starting with PMM 2.37.0, PMM administrators can disable the internal PostgreSQL server, which helps to fine-tune the server.</p> </li> <li> <p>PMM-11439 - Starting with PMM 2.37.0, a PMM administrator can now view metrics from an external PostgreSQL server.</p> </li> </ul>"},{"location":"release-notes/2.37.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-11412 - We have enhanced our dashboards to be more user-oriented, displaying the DB cluster\u2019s status along with its components, such as metrics of stateful, pods, and so on. Also, you can apply filters based on DB name or DB type.</li> <li>PMM-11832 - When hovering over the Backup option on the main menu, PMM now displays the subcategories for easier navigation.</li> <li>PMM-11522 - With the newly added support for Clickhouse as a datasource for Advisors, Advisors can now use data produced by Query Analytics (QAN) to run checks on databases.</li> <li>PMM-11544 - Improved functionality for EXPLAIN query in QAN.</li> <li>PMM-11926 - Updated the format of the Upgrade to a Premium plan URL on the Advisor Insights page. </li> <li>PMM-11078 - Following the replacement of Integrated Alerting with Percona Alerting in PMM 2.311, we have now phased out all the APIs related to this deprecated feature.</li> </ul>"},{"location":"release-notes/2.37.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-8690 - Fixed an issue where the Replica set lag displayed incorrect values on the MongoDB ReplSet Summary dashboard for an ARBITER node.</li> <li>PMM-9775 - QAN: PMM failed to display the set timezone for QAN despite it being set to UTC.</li> <li>PMM-10687 - DBaaS: Fixed an issue where DB cluster creation failed when using an unreleased version of pmm-server.</li> <li>PMM-11121 - DBaaS: Fixed an issue where the list of DB clusters did not load if one of the K8s clusters was unresponsive.</li> <li>PMM-11226 - Fixed an issue where different operator versions and names were displayed for each K8s cluster.</li> <li>PMM-11313 - Rows Fetched/Read and Users by Rows Read dashboards are not working in the MySQL User Details dashboard</li> <li>PMM-11555 - For thousands of client connections for ProxySQL, the graph for Active Frontend connections did not render due to sluggish performance. Furthermore, this could affect the rendering and usage of the ProxySQL Instance summary dashboard. The issue has been resolved now.</li> <li>PMM-11829 - PMM Agent does not work with PG 12 and PGSM 2.0. This issue has been resolved now.</li> <li>PMM-11844 - Fixed an issue where a user failed to add PSMDB with pmm-admin using native LDAP authentication and TLS.</li> <li>PMM-11862 - Fixed inconsistent naming of the Advisors feature across PMM UI.</li> <li>PMM-11875 - Fixed an issue where the users could not select and compare multiple nodes on the Summary dashboard.</li> <li>PMM-11904 - Index Size and Concurrent Inserts panels were broken on the Insight / VictoriaMetrics dashboard after updating to version 1.89.1.</li> <li>PMM-10795 - Node summary was not visible under MongoDB ReplSet Summary when the node name contained a dot (.) in the name.</li> <li>PMM-11465 - Fixed problem with empty output for EXPLAIN in QAN.</li> <li>PMM-11729 - Fixed syntax issues with placeholders for EXPLAIN in QAN.</li> <li>PMM-11849 - Fixed issue that affected Advisors, where Actions and Jobs would always be executed on the primary node in a MongoDB cluster. </li> <li>PMM-11934 - Product tour is now correctly displaying the Advisors information.</li> </ul>"},{"location":"release-notes/2.37.1.html","title":"Percona Monitoring and Management 2.37.1","text":"Release date: Jun 5, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Important</p> <p>We recommend using the latest version of PMM. This ensures that you have access to the latest PMM features and that your environment runs on the latest version of the underlying components, such as VictoriaMetrics, with all the bug fixes in place.</p>"},{"location":"release-notes/2.37.1.html#release-highlights","title":"Release Highlights","text":"<ul> <li> <p>We have identified and fixed CVE-2023-34409 in PMM 2.37.1:</p> <p>PMM-12182: PMM authentication bypass vulnerability</p> <p>Workaround</p> <p>If you are unable to update PMM you can resolve this issue as follows:</p> <ol> <li> <p>Make changes to the NGINX configuration on the running PMM instance. To do so, create a Bash script with the code from this script on GitHub. </p> </li> <li> <p>Apply the code using this <code>docker</code> command on a server running the PMM Docker container (as root or using sudo):     <pre><code>docker exec -it pmm-server bash -c 'curl -fsSL https://raw.githubusercontent.com/percona/pmm/main/scripts/authfix.sh  | /bin/bash '\n</code></pre></p> </li> <li>If you are running PMM via a virtual appliance (OVF or AMI), use SSH to shell into the PMM server and run this command:     <pre><code>curl -fsSL https://raw.githubusercontent.com/percona/pmm/main/scripts/authfix.sh  | /bin/bash\n</code></pre></li> </ol> <p>For more details see, blogpost.</p> </li> <li> <p>An Enterprise Linux 9 (el9) version of PMM was released through oversight. This was intended to be a technical preview. There are several known issues with this el9-based version. Thus, we do not recommend running it in production until the official GA announcement.</p> <p>The images from the <code>percona</code> Docker repository have been removed. However, those who want to test them can locate them in the perconalab Docker repository.</p> </li> </ul>"},{"location":"release-notes/2.38.0.html","title":"Percona Monitoring and Management 2.38.0","text":"Release date: Jul 3, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.38.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.38.0.html#important-security-updates","title":"Important security updates","text":""},{"location":"release-notes/2.38.0.html#oracle-linux-9-as-new-base-os-for-pmm","title":"Oracle Linux 9 as new base OS for PMM","text":"<p>As security is paramount to us, PMM 2.38.0 adds a solid and modernized enterprise-grade foundation to PMM. This release migrates our base operating system on which we build our PMM image from CentOS 7 to Oracle Linux 9.  Thus, starting with PMM 2.38.0, PMM is publicly available on Oracle Linux 9.</p> <p>This transition brings many benefits:</p> <ul> <li>a large number of CVEs automatically fixed</li> <li>improved upstream response time to security-related issues</li> <li>better compatibility with new technologies</li> <li>modern libraries for our team to build on</li> </ul> <p>Since not all users will be able to seamlessly make the move, we will be rolling this out in phases:</p>"},{"location":"release-notes/2.38.0.html#automated-migration-paths","title":"Automated migration paths","text":"<p>The following users will be able to take advantage of this immediately:</p> <ul> <li> <p>New installations of PMM:</p> <ul> <li>Docker containers from our Docker hub: <code>percona/pmm-server:2</code></li> <li>OVF: Download directly from our website</li> <li>AMI: Loaded from AWS Marketplace</li> </ul> </li> <li> <p>Docker/Podman users who do full container replacement upgrades to newer versions of PMM.     Your existing <code>docker pull</code> or <code>docker run</code> commands will use the new image.</p> </li> </ul>"},{"location":"release-notes/2.38.0.html#manual-upgrade-options","title":"Manual upgrade options","text":"<p>For users upgrading AMI, OVF, or Docker-based installations via the UI, the Upgrade Now button on the Home dashboard will upgrade your PMM version to the latest PMM 2 release. This upgrade will provide access to all the new features and bug fixes available in this version. However, the PMM base operating system will remain on EL7 (CentOS 7) and will not be upgraded to EL9 (Oracle Linux 9). This means that certain CVEs related to the base operating system will remain unpatched.</p> <p>While we work on providing automated migration paths for these deployment types, you have the option to manually upgrade your PMM installation to take advantage of the updated Oracle Linux 9 base operating system and associated security enhancements.</p> <p>To manually upgrade your PMM installation to the new Oracle Linux 9 base, check out the instructions in the PMM is getting a modernized enterprise-grade foundation blog post.</p>"},{"location":"release-notes/2.38.0.html#grafana-upgrade","title":"Grafana upgrade","text":"<p>PMM now uses Grafana to 9.2.20, which fixes some critical vulnerabilities. For more information, see Grafana\u2019s release blog.</p>"},{"location":"release-notes/2.38.0.html#exporters","title":"Exporters","text":"<p>Updated the mysqld_exporter, node_exporter, postgres_exporter, and mongo_exporter to fix the CVEs.</p>"},{"location":"release-notes/2.38.0.html#clickhouse-plugin","title":"ClickHouse plugin","text":"<p>We have migrated from the Altinity Clickhouse datasource to the Grafana Clickhouse datasource due to the vulnerabilities discovered. </p> <p>Due to this migration, we have also updated our experimental Environment Overview Dashboard.</p> <p>Important</p> <p>Though we have removed the datasource from PMM, we are still reusing the same name (ClickHouse) to keep the changes minimal. Thus, if you are using the old datasource in your dashboards, ensure that you upgrade the underlying queries that will pull the data from the new datasource.</p>"},{"location":"release-notes/2.38.0.html#example","title":"Example","text":"<p>The following example shows the difference in the query before and after migration.</p> <p>Before migration:</p> <pre><code>// Altinity ClickHouse datasource\nSELECT $timeSeries as t, \n    sum(m_query_time_sum)/sum(m_query_time_cnt) as QLatency,\n    environment\nFROM $table\nWHERE $timeFilter and environment != ''\nGROUP BY t,environment\nORDER BY t\n</code></pre> <p>After migration:</p> <pre><code>// Grafana ClickHouse datasource\nSELECT period_start as t,\n    sum(m_query_time_sum)/sum(m_query_time_cnt) as QLatency,\n    environment\nFROM pmm.\"metrics\" \nWHERE $__timeFilter(period_start) AND environment != ''\nGROUP BY t, environment\nORDER BY t\n</code></pre> <p>Altinity data sources used macros like <code>$timeSeries</code>, <code>$timeFilter</code>, and <code>$table</code>, which are no longer present in the Grafana datasource. As a result, the query needs to be rewritten to use the new macros instead of the old ones.  You will notice that in the example above, the macro <code>$timeFilter</code> has changed to <code>$__timeFilter</code>, and now it requires a parameter, which should be a column of type datetime.</p> <p>Depending on which macros you have used, your migration effort will vary. However, we recommend checking the plugin documentation to apply the new syntax correctly, including macros and template variables.</p>"},{"location":"release-notes/2.38.0.html#improved-nodes-view-on-the-inventory-page","title":"Improved nodes view on the Inventory page","text":"<p>In our continuing endeavor to enhance user experience, we further improved the Inventory page by improving the Nodes tab. With this change, you can get more context on your inventory objects, such as nodes, and more actionable information for exploring and resolving possible issues.</p> <p>Here is the change as part of PMM 2.38.0:</p> <ul> <li> <p>Check the number of agents running on any particular node. When you click on any node, the UI navigates to the view of agents, which is filtered to display only agents related to that specific node.</p> <p>To see the details of the agents running:</p> <p>On the Nodes tab, under the Monitoring column, click OK or Failed, depending on the status of the node that you have selected. A page that provides the user with crucial information regarding the total number of agents deployed on that node is displayed.     </p> </li> <li> <p>View comprehensive information about each agent, including key attributes such as node type, IP address, and associated services. This gives you a complete overview of the nodes at a glance.</p> <p></p> </li> <li> <p>Check the health status of the agents to see if they are running or have failed.</p> </li> </ul>"},{"location":"release-notes/2.38.0.html#backup-enhancements","title":"Backup enhancements","text":""},{"location":"release-notes/2.38.0.html#better-folder-management-for-enhanced-pbm-compatibility","title":"Better folder management for enhanced PBM compatibility","text":"<p>We\u2019ve added a new Folder field to the Create Backup pages. Use this to set a specific target directory within the selected local or S3-compatible location for the backup.  </p> <p>Organizing backups in folders makes grouping PBM backups for clusters easier, and it improves PMM-PBM (Percona Backup for MongoDB) integration workflows.</p> <p>The Folder field is automatically populated with the value of the cluster label. You can change this default folder from PMM\u2019s Advanced Settings, but make sure you understand how your custom folder will impact PBM integration workflows.</p>"},{"location":"release-notes/2.38.0.html#sharded-cluster-mongodb-backup-support","title":"Sharded cluster MongoDB backup support","text":"<p>This release introduces support for working with backups for sharded clusters. PMM handles the backup process end-to-end, but restoring such artifacts is currently possible only via the CLI, using Percona Backup for MongoDB.</p> <p>For information on restoring sharded backups, check the PBM documentation.</p>"},{"location":"release-notes/2.38.0.html#sql-comments-support-in-qan","title":"SQL comments support in QAN","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>You can now collect labels from the comments placed in SQL queries. You can tag the query by key value in the query comment. This helps in query management and optimization. This feature is currently supported for MySQL and PostgreSQL.</p> <p>For example:</p> <p><pre><code>SELECT * /* cluster=\u2019east\u2019 */ FROM city;   \n</code></pre> You can enable this feature as follows:</p> <ul> <li>CLI - Pass the parameter <code>comments-parsing</code></li> <li> <p>UI - It is enabled by default. To disable, uncheck the Disable comments parsing checkbox in the Additional Options section. This is supported for PostgreSQL and MySQL.</p> <p></p> </li> </ul>"},{"location":"release-notes/2.38.0.html#new-pmm-agent-down-alert-template","title":"New PMM Agent Down alert template","text":"<p>We\u2019ve added a new default alert template to Percona Alerting. </p> <p>The new PMM Agent down alert template monitors your Node status to notify if the Agent is down. Before using this template:</p> <ul> <li>ensure the PMM Agent is healthy and present on the Database Node.</li> <li>check that PMM Client is on version 2.38 version or later.</li> </ul> <p></p>"},{"location":"release-notes/2.38.0.html#grafana-upgrade_1","title":"Grafana upgrade","text":"<p>PMM now uses Grafana v9.2.20, which includes fixes for some critical vulnerabilities. For more information, see Grafana\u2019s release blog.</p>"},{"location":"release-notes/2.38.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-2852 -   [QAN]: Starting with PMM 2.38.0, MySQL and PostgreSQL supports collection of labels from the comments placed in the SQL queries.</li> <li>PMM-11961 - [Inventory]: Starting with PMM 2.38.0, we have enhanced the Inventory page by improving the Nodes tab. With this change, you can get more context on your inventory objects, such as node, and more actionable information for exploring and resolving possible issues.</li> <li>PMM-11962 - [Inventory]: Starting with PMM 2.38.0, you can filter the nodes and services on the Inventory page using the parameters such as ID, names, status, etc., instead of scrolling through an exhaustive list of nodes or services.</li> <li>PMM-12087 - [Inventory]: Added tooltips to explain the meaning of the different service statuses in the Inventory view.   </li> </ul>"},{"location":"release-notes/2.38.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-9367 -   [Backups]: Added support for working with backups for sharded clusters.</li> <li>PMM-11250 - [Backup]: Added option to specify target directory for the selected backup location to improve PMM-PBM integration workflows.</li> <li>PMM-12038 - [Backup]: Extended support for MongoDB backups to cover all authentication mechanisms available for MongoDB (including LDAP, x509 certs).</li> <li>PMM-9544 -   [Alerting]: Added new default alert template to Node status and notify if the Agent is down.</li> <li>PMM-12114 - Upgraded Grafana to 9.2.18 to fix to CVEs.</li> <li>PMM-12136 - We have migrated our base operating system on which we build our base image from CentOS 7 to Oracle Linux 9 to fix the CVEs.</li> </ul>"},{"location":"release-notes/2.38.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-11578 - [Alerting]: The Last notified column under Alerting &gt; Fired Alerts has been renamed to Last triggered. This better illustrates the fact that triggered alerts may not always generate a notification. This can happen when the contact points are not correctly configured. In addition, the Suppressed status in the State column has been renamed to Silenced to keep consistency with how this status is displayed on other Alerting pages.</li> <li>PMM-12067 - [QAN]: Fixed vulnerability in Vitess package.</li> <li>PMM-12105 - [QAN]: Fixed an issue where QAN was broken due to wrong pgsm_query_ids.</li> <li>PMM-10063 - [QAN]: The QAN filter section could display the available list of services/nodes. But the load time was too much, with the UI  being unresponsive. This issue has been resolved now. The entire list is loaded with the count displayed on the upper right side.</li> <li>PMM-11386 - [QAN]: MongoDB QAN query time metrics was showing the wrong unit. It should be ms. The issue has been resolved now.</li> <li>PMM-12024 - [QAN]: Fixed an issue where a QAN agent couldn\u2019t start due to an expected return value type.</li> <li>PMM-12091 - [QAN]: The tooltip for QAN &gt; MongoDB &gt; Query Details was displayed in seconds instead of decimals. The issue has been fixed now.</li> <li>PMM-9844 -   [QAN]: Data for a large number of partitions or possible indexes was shown in the QAN Details tab in one scrolling column making it practically impossible to read. The issue has been resolved now.</li> <li>PMM-11938 - [QAN]: Fixed the problem when PMM tried to create <code>pg_stat_monitor_settings</code> view all over again.</li> <li>PMM-11645 - Fixed mysql service detection when this is not loaded in systemd.</li> <li>PMM-9541 - PostgreSQL exporter now works as expected with <code>--socket</code>.</li> <li>PMM-10799 - Now in the EXPLAIN/TABLE tab you can get results even for queries with table alias.</li> <li>PMM-11692 - On the MySQL Instances Overview dashboard, the <code>Top MySQL Active Client Threads</code> panel color was misleading. The issue has been resolved now.</li> <li>PMM-11715 - CPU Utilization Graph for RDS instances was not matching what Cloudwatch reported. The issue has been resolved now.</li> <li>PMM-11950 - Non-admin roles are calling restricted endpoints after login or page refresh.</li> <li>PMM-12085 - Fixed an issue where SSH access to AMI and OVF images for Oracle Linux 9-based images did not work. The issue has been resolved now.</li> <li>PMM-12118 - Addressed the Grafana ClickHouse DS plugin CVEs.</li> <li>PMM-12119 - When a user successfully adds an RDS service to PMM, the RDS exporter\u2019s status does not change from \u201cUNKNOWN\u201d (the initial status of all exporters) to \u201cRUNNING.\u201d  This issue has been resolved.</li> <li>PMM-9224 - Data from Arbiter nodes is now correctly displayed on the MongoDB ReplSet Summary dashboard.</li> </ul>"},{"location":"release-notes/2.38.1.html","title":"Percona Monitoring and Management 2.38.1","text":"Release date: July 13, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.38.1.html#fixed-issue","title":"Fixed issue","text":"<p>PMM-12293 - With this update, we are fixing an authentication issue that occurred when trying to relog into PMM using a Percona Account.  Second and subsequent logins no longer result in a \u201cUser already exists\u201d error.</p>"},{"location":"release-notes/2.39.0.html","title":"Percona Monitoring and Management 2.39.0","text":"Release date: Aug 14, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.39.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.39.0.html#mongodb-backups-ui-based-restore-on-a-new-replica-set-cluster","title":"MongoDB backups: UI-based restore on a new replica set cluster","text":"<p>Building on the recent MongoDB backup management enhancements, we have now added the option to restore backups on different clusters with the same configuration. This enables you to test restore data before deploying it on Dev environments. </p> <p>Restoring on different clusters is not available for sharded clusters. This is a complicated process that still requires manual intervention. For more information, see Restoring from a sharded cluster</p>"},{"location":"release-notes/2.39.0.html#query-analytics-meta-information","title":"Query Analytics - Meta information","text":"<p>QAN is an important tool that can help filter data and identify problematic queries. However, it can be challenging to determine which services, nodes, and other labels are linked to these queries. </p> <p>PMM 2.39.0 now includes a metadata table for QAN to address this issue. This table contains information such as Node name, Node name, Service name, Service type, and user name for each selected query. With this feature, you can easily identify the services, nodes, and labels associated with your identified queries.</p> <p>To view the metadata table, navigate to the Main menu and click on Query Analytics (QAN). This will bring you to the Query Analytics page. Next, select the desired query and expand the Metadata tab. The metadata for that specific query will then be displayed.</p> <p></p>"},{"location":"release-notes/2.39.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6279 - [QAN]: PMM 2.39.0 now includes a metadata table for each query. This table contains information such as Node name, Node name, Service name, Service type, and user name for each selected query.</li> <li>PMM-10270 - [Backup Management]: Enhanced MongoDB Backup Management to support restoring to different replica set clusters with the same configuration.</li> <li>PMM-11999, PMM-12257 - [Advisors] - The Advisors page now contains a new Technology column that shows the database type for each advisor. This helps you distinguish between MongoDB, MySQL, and PostgreSQL advisors.</li> <li>PMM-11206 - [Alerting]: You can now easily add multiple Alert rule templates at once, whether through the API or UI. When added in bulk, each template will be displayed separately on the Alert rule templates page. This makes it quicker and more efficient to manage your alert rules.</li> <li>PMM-11637 - PMM UI now reflects the new PMM logo as per the new branding.</li> <li>PMM-12070 - We have updated the deprecated Boomtable plugin to the Grafana table plugin.</li> <li>PMM-12389 - The postgres_exporter now provides more comprehensive logs that display the specific namespace and error message for any issue.</li> </ul>"},{"location":"release-notes/2.39.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-12151 - [QAN]: The Explain plan was not displayed in a few scenarios. The issue has been resolved now.</li> <li>PMM-11658 - Fixed issue that caused the pmm-agent to crash on AMI and OVF distributions.</li> <li>PMM-11992 - Postgres databases with names other than Postgres could not be added. The issue has been resolved now.</li> <li>PMM-12263 - On the MongoDB Cluster Summary dashboard, the Replication Lag by Set graph showed the wrong value if rs was in the primary-secondary-arbiter (PSA) configuration. It calculated the arbiter\u2019s lag from the beginning of the UNIX time (currently &gt;54 years instead of a few seconds). The issue has been resolved now.</li> <li>PMM-12280 - Fixed an issue where the Service Summary Panel on Home Dashboard used the incorrect units to display <code>Available Memory</code>.</li> <li>PMM-10665 - Fixed issue that caused QAN to show incorrect values when setting non-default values for performance schema. Make sure to restart pmm-agent after changing the settings for perfschema in MySQL.</li> <li>PMM-10391 - PMM did not work with external Clickhouse versions greater than 22.5.2. The issue has been resolved now.</li> <li>PMM-12231 - In the recent versions of PMM, users have encountered issues with installing, updating and removing plugins from PMM. For more information on this issue, see Troubleshooting Plugin issues.</li> </ul>"},{"location":"release-notes/2.4.0.html","title":"Percona Monitoring and Management 2.4.0","text":"Date: March 18, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.4.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-3387: Prometheus custom configuration is now supported by PMM Server. The feature is targeted at experienced users and is done by adding the base configuration file into the PMM Server container to be parsed and included into the managed Prometheus configuration.</li> <li>PMM-5186: Including <code>\u2013-pprof</code> option in the <code>pmm-admin summary</code> command adds <code>pprof</code> debug profiles to the diagnostics data archive</li> <li>PMM-5102: The new \u201cNode Details\u201d dashboard now displays data from the hardware monitoring sensors in <code>hwmon</code>. The new dashboard is based on the <code>hwmon</code> collector data from the <code>node_exporter</code>. Please note that data may be unavailable for some nodes because of the configuration or virtualization parameters.</li> </ul>"},{"location":"release-notes/2.4.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-4915: The Query Analytics dashboard now shows Time Metrics in the Profile Section as \u201cAVG per query\u201d instead of \u201cAVG per second\u201d</li> <li>PMM-5470: ClickHouse query optimized for Query Analytics to improve its speed and reduce the load on the back-end</li> <li>PMM-5448: The default high and medium metrics resolutions were changed to 1-5-30 and 5-10-60 sec. To reduce the effect of this change on existing installations, systems having the \u201cold\u201d high resolution chosen on the PMM Settings page (5-5-60 sec.) will be automatically re-configured to the medium one during an upgrade. If the resolution was changed to some custom values via API, it will not be affected</li> <li> <p>PMM-5531: A health check indicator was implemented for the PMM Server Docker image. It is based on the Docker HEALTHCHECK. This feature can be used as follows:</p> <pre><code>docker inspect -f {{.State.Health.Status}}\nuntil [ \"`docker inspect -f {{.State.Health.Status}} pmm-server`\" == \"healthy\" ]; do sleep 1; done\n</code></pre> </li> <li> <p>PMM-5489: The \u201cTotal\u201d line in all charts is now drawn with the same red color for better consistency</p> </li> <li>PMM-5461: Memory graphs on the node-related dashboards were adjusted to have fixed colors that are more distinguishable from each other</li> <li>PMM-5329: Prometheus in PMM Server was updated to version 2.16.0. This update has brought several improvements. Among them are significantly reduced memory footprint of the loaded TSDB blocks, lower memory footprint for the compaction process (caused by the more balanced choice of what to buffer during compaction), and improved query performance for the queries that only touch the most recent 2 hours of data.</li> <li>PMM-5210: Data Retention is now specified in days instead of seconds on the PMM Settings page. Please note this is a UI-only change, so the actual data retention precision is not changed</li> <li>PMM-5182: The <code>logs.zip</code> archive available on the PMM Settings page now includes additional self-monitoring information in a separate <code>client</code> subfolder. This subfolder contains information collected on the PMM Server and is equivalent to the one collected on a node by the <code>pmm-admin summary</code> command.</li> <li>PMM-5112: The Inventory API List requests now can be filtered by the Node/Service/Agent type</li> </ul>"},{"location":"release-notes/2.4.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5178: Query Detail Section of the Query Analytics dashboard didn\u2019t show tables definitions and indexes for the internal PostgreSQL database</li> <li>PMM-5465: MySQL Instance related dashboards had row names not always matching the actual contents. To fix this, elements were re-ordered and additional rows were added for better matching of the row name and the corresponding elements</li> <li>PMM-5455: Dashboards from the Insight menu were fixed to work correctly when the low resolution is set on the PMM Settings page</li> <li>PMM-5446: A number of the Compare Dashboards were fixed to work correctly when the low resolution is set on the PMM Settings page</li> <li>PMM-5430: MySQL Exporter section on the Prometheus Exporter Status dashboard now collapsed by default to be consistent with other database-related sections</li> <li>PMM-5445, PMM-5439, PMM-5427, PMM-5426, PMM-5419: Labels change (which occurs e.g. when the metrics resolution is changed on the PMM Settings page) was breaking dashboards</li> <li>PMM-5347: Selecting queries on the Query Analytics dashboard was generating errors in the browser console</li> <li>PMM-5305: Some applied filters on the Query Analytics dashboard were not preserved after changing the time range</li> <li>PMM-5267: The Refresh button was not working on the Query Analytics dashboard</li> <li>PMM-5003: pmm-admin list and status use different JSON naming for the same data</li> <li>PMM-5526: A typo was fixed in the Replication Dashboard description tooltip</li> </ul> <p>Help us improve our software quality by reporting any bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.40.0.html","title":"Percona Monitoring and Management 2.40.0","text":"Release date: Oct 05, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>Caution</p> <p>If you are using the Library Panels on the PMM dashboard, avoid upgrading to PMM 2.40.0 due to a known issue. Instead, we recommend waiting for the release of PMM 2.40.1.</p>"},{"location":"release-notes/2.40.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.40.0.html#inventory-improvements","title":"Inventory improvements","text":""},{"location":"release-notes/2.40.0.html#ability-to-update-labels-for-existing-services-to-pmm","title":"Ability to update labels for existing services to PMM","text":"<p>Starting with PMM 2.40.0, editing labels for existing services is easier and much more efficient. You can edit a service label directly from the PMM UI without removing and re-adding it. For more information on editing labels, see documentation.</p> <p></p> <p>Furthermore, in our continued effort  to enhance user experience, we have redesigned the following pages to make them more user-friendly and intuitive:</p> <ul> <li>Select service type page</li> <li>Add service page</li> </ul>"},{"location":"release-notes/2.40.0.html#connecting-services-and-nodes","title":"Connecting Services and Nodes","text":"<p>Starting with PMM 2.40.0, you can click on the link in the Node Name column to view the node on which a specific service is running and analyze how node-level resource utilization impacts the performance of those services.</p> <p>Before introducing this feature, locating the running services on a node was cumbersome. However, with this new feature, you can effortlessly access a list of services running on a specific node and identify the node name where the service is being utilized. Additionally, the filters implemented make navigation a lot simpler.</p> <p></p> <p>Furthermore, you can also see the service running on that specific node when you click on the link in the Services column.</p> <p></p>"},{"location":"release-notes/2.40.0.html#cluster-view-for-inventory","title":"Cluster view for Inventory","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for evaluation purposes only.</p> <p>Understanding the structure of your inventory is crucial. With the release of PMM 2.40.0, we\u2019ve introduced an experimental feature that categorizes all your Services by Cluster, making it easier for you to understand your inventory. By using the Organize by Clusters toggle, you can view a group of services as a single cluster. PMM utilizes the cluster label to display services that belong to the same cluster.</p> <p></p> <p>For detailed information on this feature, see documentation.</p>"},{"location":"release-notes/2.40.0.html#mongodb-backup-monitoring","title":"MongoDB Backup Monitoring","text":"<p>With this release, we are shipping the first version of a the Backup failed alert template which notifies of any failed MongoDB backups. This uses a new, dedicated metric, <code>pmm_managed_backups_artifacts</code>, for checking the state of backup artifacts. </p> <p>This new template is currently in Technical Preview and we are keen to get your feedback around this change before we move it to General Availability.</p> <p> </p> <p>For information on working with this new template, see the Percona Alerting topic.</p>"},{"location":"release-notes/2.40.0.html#components-upgrade","title":"Components Upgrade","text":"<p>VictoriaMetrics has been upgraded v1.93.4.</p>"},{"location":"release-notes/2.40.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-11963 - Starting with PMM 2.40.0, you can click on the link in the Node Name column to view the node on which a specific service is running.</li> <li>PMM-11148 - [Inventory]: We have redesigned the Select service type and Add service pages to make them more user-friendly and intuitive.</li> <li>PMM-11423 - [Inventory]: Starting with PMM 2.40.0, you can now edit service labels directly from the PMM UI without having to remove and re-add them.</li> <li>PMM-12378 - [Inventory]: We have introduced an experimental feature that categorizes all your Services by Cluster, making it easier for you to understand your inventory. By using the Organize by Clusters toggle, you can view a group of services as a single cluster. </li> <li>PMM-12384 - [Alerting]: Added a new built-in alert template,  Backup failed which you can use to create alert rules that notify of failed MongoDB backups. </li> <li>PMM-9374 - [Technical Preview]: Starting with PMM 2.40.0, you can now use an external VictoriaMetrics database for monitoring in PMM. This provides multiple benefits, including scalability, resource isolation, reduced load on the PMM server,  customization, etc.</li> </ul>"},{"location":"release-notes/2.40.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-4466 - Grafana now uses PostgreSQL instead of SQLite, resulting in improved performance, stability for user auth requests, data integrity, reliability, security, etc.</li> <li>PMM-12310 - Links from PMM to documentation may change, causing \u201cbroken links\u201d in older PMM versions due to document structure changes. We have replaced all links with Short.io links specific to each document to address this. This way, we can maintain the PMM-to-doc links using a URL shortener. This ensures that the links remain accessible even if the document structure changes.</li> <li>PMM-12457 - We have added a new <code>node_name</code> property to the PMM agent down alert template in PMM. This allows users to easily identify the node where the failure occurred.</li> <li>PMM-12488 - VictoriaMetrics has been updated to v1.93.4.</li> <li>PMM-12500 - [Technical Preview]: For Percona Operator users, we have introduced a new dashboard for K8s monitoring with PMM 2.40.0.</li> <li>PMM-11770 - PMM now automatically sets the server domain value in <code>grafana.ini</code> to the public address specified in PMM\u2019s Advanced Settings. This ensures that links generated by Grafana, such as links in alert emails, also carry that address.</li> </ul>"},{"location":"release-notes/2.40.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-10145 - When we installed an AMI image in AWS and added an Amazon RDS instance in the creating state, it caused errors. The issue has been resolved now.</li> <li>PMM-12173 - On adding several clients to PMM, unexpected and unauthorized errors caused PMM to stop responding. The issue has since been resolved now.</li> <li>PMM-12344 - An error was displayed on the Explain tab after selecting a PostgreSQL query. The issue has been resolved now.</li> <li>PMM-12361 - The command <code>pmm-admin inventory</code> returned GO errors. The issue has been reolved now.</li> <li>PMM-12382 - Fixed an issue where the upper-case custom labels were not being accepted.</li> <li>PMM-11371 - Usage of <code>pmm-admin</code> config subcommand shutdown pmm-agent. The issue has been resolved now.</li> <li>PMM-11603 - When running <code>pmm-agent</code> outside of systemd, adding an agent causes errors. The issue has been resolved now.</li> <li>PMM-11651 - When a user has both full access and limited access roles, only the limited role\u2019s metrics are displayed. The issue has been resolved now.</li> <li>PMM-12146 - Dead Tuples graph on PostgreSQL Vacuum Monitoring Dashboard displayed invalid percentage. The issue has been resolved now.</li> <li>PMM-12448 - Can\u2019t start backup if artifact with empty <code>service_id</code> exists.</li> </ul>"},{"location":"release-notes/2.40.0.html#known-issues","title":"Known issues","text":"<ul> <li> <p>PMM-12517 - If you have set custom dashboards as your Home dashboard in version 2.26.0, they may be lost after upgrading to version 2.40.0. To prevent this, we recommend that you back up your custom dashboard before upgrading and recover it after the upgrade.</p> </li> <li> <p>PMM-12576 - After upgrading PMM from version 2.39.0 to 2.40.0 (not el7) using Docker, the admin user cannot access the PMM UI. Refer to the documentation for information on the solution.</p> </li> <li> <p>PMM-12592 - If you are using the Library Panels on the PMM dashboard, avoid upgrading to PMM 2.40.0 due to a known issue.</p> </li> </ul>"},{"location":"release-notes/2.40.1.html","title":"Percona Monitoring and Management 2.40.1","text":"Release date: Oct 20, 2023 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.40.1.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>PMM-12592 - Fixed an issue where the Library Panels for the PMM dashboard were not working after upgrade to PMM 2.40.0.</li> <li>PMM-12576 - After upgrading to PMM 2.40.0, changing the Admin user\u2019s password from the terminal was not functioning. The issue has been resolved now.</li> <li>PMM-12587 - After upgrading to PMM 2.40.0, some users may experience incorrect mappings between dashboards, folders, users, and groups. This can result in either a successful upgrade or a <code>500 internal server error</code>. The issue has now been resolved.</li> <li>PMM-12590 CVE-2023-4911 is a vulnerability in the OS that PMM is based on. It has been fixed in the base OS, and the fix is available in PMM.</li> </ul>"},{"location":"release-notes/2.40.1.html#how-to-upgrade-from-2400-to-pmm-2401","title":"How to upgrade from 2.40.0 to PMM 2.40.1","text":"<p>Important</p> <p>The steps below are only applicable to users who have upgraded to 2.40.0 and have been experiencing the following issues:</p> <ul> <li>PMM-12592</li> <li>PMM-12587</li> </ul> <p>To upgrade to PMM 2.40.1:</p> <ol> <li> <p>Copy the file from <code>/srv/backup/grafana/grafana.db</code> to <code>/srv/grafana/grafana.db</code></p> <p>Caution</p> <p>This step will result in the loss of all changes made to Grafana upon upgrading to version 2.40.0.</p> <pre><code>docker exec -t pmm-server cp /srv/backup/grafana/grafana.db /srv/grafana/grafana.db\n</code></pre> </li> <li> <p>Set permissions:</p> <pre><code>chmod 640 /srv/grafana/grafana.db\n\nchown grafana:grafana /srv/grafana/grafana.db\n</code></pre> </li> <li> <p>Upgrade to 2.40.1 as usual.</p> </li> </ol>"},{"location":"release-notes/2.41.0.html","title":"Percona Monitoring and Management 2.41.0","text":"Release date Dec 12, 2023 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p>"},{"location":"release-notes/2.41.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.41.0.html#streamlined-database-problem-reporting-to-percona","title":"Streamlined database problem reporting to Percona","text":"<p>To improve the gathering and sharing of PMM metrics and data, we\u2019ve now integrated the pmm_dump client utility into PMM. Initially a standalone client for PMM Server, PMM Dump is now accessible in the PMM user interface.</p> <p>This integration enables you to collect PMM data to share with our Support team.</p> <p>To get started, in the main menu, go to Help &gt; PMM Dump and select either to export a dataset locally or upload it to our SFTP servers using the credentials generated through your Percona Support ticket.</p>"},{"location":"release-notes/2.41.0.html#postgresql-monitoring-optimizing-performance","title":"PostgreSQL monitoring: optimizing performance","text":"<p>PMM 2.41.0 introduces limit for Auto-discovery in PostgreSQL, a feature that dynamically discovers all databases in your PostgreSQL instance. Limiting Auto-discovery reduces connections and prevents high CPU and RAM usage caused by multiple databases, thus optimizing performance.</p> <p></p> <p>For details, see documentation.</p>"},{"location":"release-notes/2.41.0.html#pmm-dbaas-functionality-evolution-into-percona-everest","title":"PMM DBaaS functionality evolution into Percona Everest","text":"<p>We have decided to separate our DBaaS offering into an independent product. Consequently, we are discontinuing the DBaaS functionality in PMM and offering a migration path to Everest.</p> <p>While the DBaaS functionality will remain available in PMM versions 2.x, all future updates and enhancements will be exclusively accessible through the Percona Everest interface. For a more streamlined and robust database deployment experience, try Percona Everest.</p>"},{"location":"release-notes/2.41.0.html#technical-preview-of-pmm-in-high-availability-ha-mode","title":"Technical Preview of PMM in high availability (HA) mode","text":"<p>Important</p> <p>Disclaimer: This feature has been added in PMM 2.41.0 and is currently in Technical Preview. Early adopters are advised to use this feature for testing purposes only as it is subject to change.</p> <p>Starting with this release, PMM can now be run in high availability mode with several PMM server applications and independent data sources.</p> <p>Currently, PMM servers provide high availability, but users are responsible for maintaining the high availability of the data sources used by PMM.</p> <p>These data sources are:</p> <ul> <li>ClickHouse: An open-source, fast analytical database.</li> <li>VictoriaMetrics: A scalable, long-term storage solution for time series data.</li> <li>PostgreSQL: A powerful open-source relational database management system used in this setup to store PMM data like inventory, settings, and other feature-related data.</li> </ul> <p>If you\u2019re looking to dive deep into this feature, see our comprehensive documentation.  </p>"},{"location":"release-notes/2.41.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-12459 - The pmm_dump client utility previously available as a standalone client for PMM Server is now readily accessible within the PMM user interface.</li> </ul>"},{"location":"release-notes/2.41.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-11341 - PMM 2.41.0 introduces limit for Auto-discovery in PostgreSQL, a feature that dynamically discovers all databases in your PostgreSQL instance. Limiting Auto-discovery reduces connections and prevents high CPU and RAM usage caused by multiple databases, thus optimizing performance.</li> <li>PMM-12375 - Starting with PMM 2.41.0, each instance of a service gets a <code>version</code> attribute in the PMM Inventory UI.</li> <li>PMM-12422 - PMM 2.41.0 introduces a new flag called <code>--expose-exporter</code>. When you enable this flag any IP address, either from a local system or from anywhere on the internet, can access exporter endpoints. If the flag is not enabled, the exporter will be available only locally.</li> <li>PMM-12544 - Added deprecation notices to the PMM documentation DBaaS pages. For a more streamlined and robust database deployment experience, try Percona Everest.</li> <li>PMM-12549 - Added support for the latest MongoDB version. You can now use PMM to monitor MongoDB 7 databases.</li> </ul>"},{"location":"release-notes/2.41.0.html#components-upgrade","title":"Components upgrade","text":"<ul> <li>PMM-12154 - Updated <code>postgres_exporter</code> to version 0.14.0. With this update, we have resolved several performance issues and eliminated the creation of multiple connections per database.</li> <li>PMM-12223 - Clickhouse has been updated to version 23.8.2.7, which optimizes memory and CPU usage to improve system performance.</li> </ul>"},{"location":"release-notes/2.41.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-4712 - We have addressed the issue where the pprof heap reports for postgres_exporter were missing. </li> <li>PMM-12626 - Due to the packages being built on an outdated Go version, there was a potential vulnerability. We have updated Go to the latest version to mitigate this risk.</li> <li>PMM-12414 - Fixed an issue with an unexpected behavior (502 response) when accessing the <code>logs.zip</code> endpoint. This was caused by the <code>group_by</code> parameter being included in the Alertmanager configuration. Additionally, we removed AlertManager-related files from <code>logs.zip</code> since we stopped using AlertManager.</li> <li>PMM-11714 - Registering a node with the Grafana Admin flag enabled but a non-admin role was failing. This issue has now been resolved.</li> <li>PMM-12660 - Prior to version 2.41.0 of PMM, the endpoint <code>/v1/management/Agent/List</code> could deliver database certificates to the PMM UI, allowing an authenticated admin user to view the output of TLS certificates. This posed a security issue since certificates should be consumed by the backend only. We have resolved this issue now.</li> <li>PMM-12630 - When users attempted to upgrade PMM versions lower than or equal to 2.37.1, the upgrade process got stuck in a loop and failed. The issue has been resolved now.</li> <li>PMM-12725 - Fixed the pagination for QAN.</li> <li>PMM-12658 - Corrected a typo in the MongoDB cluster summary dashboard.</li> </ul>"},{"location":"release-notes/2.41.1.html","title":"Percona Monitoring and Management 2.41.1","text":"Release date Feb 1<sup>st</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and execute database management operations\u2014regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.41.1.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes/2.41.1.html#improved-support-for-arbiter-nodes","title":"Improved support for Arbiter nodes","text":"<p>We\u2019ve made it easier to add and monitor MongoDB Arbiter nodes in PMM, as this no longer requires workarounds for cases where authorization is enabled on the MongoDB replica set. Additionally, Arbiter nodes are now displayed correctly on the dashboards:</p> <p></p>"},{"location":"release-notes/2.41.1.html#new-metric-for-sharded-mongodb-insights","title":"New metric for sharded MongoDB insights","text":"<p>We\u2019ve added a new metric to our MongoDB exporters: <code>mongodb_shards_collection_chunks_count</code>. This metric is available for sharded Mongo instances, offering insights into the distribution of collection chunks across different shards.</p> <p>While this version is not currently integrated into any dashboard, you have the flexibility to incorporate it into your custom dashboards. For comprehensive instructions on managing dashboards, check out this video tutorial and the documentation.</p>"},{"location":"release-notes/2.41.1.html#new-experimental-mongodb-instance-summary-dashboard","title":"New experimental MongoDB Instance Summary dashboard","text":"<p>This release also introduces a new MongoDB dashboard that offers a simplified view of the most critical MongoDB metrics. You can find the new MongoDB Instance Summary dashboard in the Experimental folder of your PMM installation. This dashboard is currently in Technical preview so we encourage you to evaluate its performance with your MongoDB instance and share your valuable feedback on our forum.</p>"},{"location":"release-notes/2.41.1.html#improvements","title":"Improvements","text":"<ul> <li>PMM-12390 - [Backup Management]: The Service name field on the Create Backup pages is now case-insensitive, allowing for more comprehensive and accurate results retrieval.</li> <li>PMM-12712 - MongoDB sharded cluster metrics now include a new metric to represent database and collection distribution across different shards. This helps gain insights into the overall balance of shards within MongoDB setups.</li> <li>PMM-12510 - Improved workflow for adding MongoDB Arbiter nodes to PMM, which also ensures that Arbiter nodes are now displayed correctly on the dashboards.</li> <li>PMM-12750 - [Dashboards]: Introduced an experimental MongoDB Instance Summary dashboard to provide a rapid overview of key MongoDB metrics.</li> <li>PMM-12866 - [Dashboards]: Minor UX improvements to the K8s experimental dashboard (Tech Preview).</li> </ul>"},{"location":"release-notes/2.41.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-12652 - Fixed issue where PMM failed to start after an upgrade, due to SELinux restrictions on accessing a PMM file created with root ownership on Podman. This fix applies to upgrades from PMM 2.41.0 to newer versions.</li> <li>PMM-9825 - [QAN]: PostgreSQL databases, monitored using the pg_stat_monitor extension v2.0+, were previously displayed with User IDs rather than actual User Names in the Service Name column on the Query Analytics (QAN) page. This issue is now fixed.</li> <li>PMM-12290 - [QAN]: Fixed bugs with SQL comments parsed in queries when they were not intentionally enabled for remotely added PostgreSQL and MySQL.</li> <li>PMM-12621 - [Dashboards]: Added support for the Anonymous mode to show all Service types on the main menu. This ensures users can access the dashboards, even when PMM is configured in Anonymous mode.</li> <li>PMM-12425 - [QAN]: The Absolute time range time picker on the Query Analytics (QAN) page no longer displays an error when using \u2018now\u2019 instead of a specific timestamp for filtering dashboard data.</li> <li>PMM-12473 - Fixed monitoring of external services when query string parameters are passed to <code>--metrics-path</code>.</li> <li>PMM-9407 - Fixed missing custom <code>queries.yaml</code> file for medium-resolution in Debian packages for PostgreSQL.</li> <li>PMM-12350 - Fixed issue of flood logs in <code>mongod_exporter</code> when connected to Mongos.</li> <li>PMM-12738 - Fixed issue that prevented PMM from running when using Helm with customer certificates.</li> <li>PMM-12781 - Corrected a permission error that was flooding PostgreSQL logs by ensuring proper execution permissions for the <code>pg_ls_waldir</code> function.</li> </ul>"},{"location":"release-notes/2.41.2.html","title":"Percona Monitoring and Management 2.41.2","text":"Release date March 20<sup>th</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and execute database management operations\u2014regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.41.2.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/2.41.2.html#debian-12bookworm-pmm-client-packages","title":"Debian 12(Bookworm) pmm-client packages","text":"<p>Starting with PMM 2.41.2, we now offer pmm-client packages for the latest version of Debian. You can install these packages by following the instructions in our documentation.</p>"},{"location":"release-notes/2.41.2.html#experimental-dashboards","title":"Experimental dashboards","text":"<p>warning</p> <p>These experimental dashboards are subject to change. It is recommended to use these dashboards for testing purposes only. </p> <p>As part of PMM 2.41.2, we have added the following experimental dashboards.</p> <ul> <li>Reworked Kubernetes dashboards</li> <li>Databases overview dashboard</li> <li>PostgreSQL Instance Summary dashboard</li> <li>PostgreSQL Checkpoints, Buffers and WAL Usage dashboard</li> <li>PostgreSQL Patroni dashboard</li> </ul> <p>To access the experimental dashboards, go to the PMM home page and then navigate to Dashboards &gt; Experimental from the side menu.</p> <p></p> <p>Alternatively, go to the PMM home page, navigate to Dashboards from the side menu, and enter the dashboard name in the Search for dashboards  field.</p>"},{"location":"release-notes/2.41.2.html#reworked-kubernetes-dashboards","title":"Reworked Kubernetes dashboards","text":"<p>PMM 2.41.2 now features redesigned Kubernetes dashboards that offer improved clarity and usability.</p> <ul> <li>The redundant information has been removed from some of these dashboards.</li> <li>The Overview dashboard, which has now been renamed as Kubernetes Cluster Overview, has been reorganized and improved for better functionality.</li> <li>The DB Cluster dashboard has been renamed as Databases on Kubernetes and now displays dynamic information. Furthermore, it separates database/proxy details and shows resource limits. </li> </ul> <p>These changes aim to improve user experience while adhering to PMM standards, particularly for managing multiple clusters.</p> <p></p>"},{"location":"release-notes/2.41.2.html#databases-overview-dashboard","title":"Databases overview dashboard","text":"<p>The latest release introduces a new dashboard that offers a simplified overview of the databases being monitored by PMM. This dashboard aims to provide a centralized and unified place where the crucial parameters for database performance can be easily accessed. </p> <p>If you\u2019re looking for more information on this dashboard, see the blog post.</p> <p></p>"},{"location":"release-notes/2.41.2.html#postgresql-instance-summary-dashboard","title":"PostgreSQL Instance Summary dashboard","text":"<p>The PostgreSQL Instance Summary dashboard is a newly designed feature that displays the critical PostgreSQL metrics. This dashboard aims to assist DBAs and developers in identifying PostgreSQL issues quickly.</p> <p></p>"},{"location":"release-notes/2.41.2.html#postgresql-checkpoints-buffers-and-wal-usage-dashboard","title":"PostgreSQL Checkpoints, Buffers and WAL Usage dashboard","text":"<p>In our continuous effort to enhance our dashboards, we have introduced this new experimental dashboard that provides more data about your PostgreSQL instances.</p> <p>By leveraging this data, administrators can gain insights into their PostgreSQL servers and fine-tune their performance. Understanding and managing checkpoints, buffers, and WAL usage contribute to a well-performing and reliable PostgreSQL environment.</p> <p>If you\u2019re looking for in-depth insights into this dashboard, refer to our blog post.</p> <p></p>"},{"location":"release-notes/2.41.2.html#postgresql-patroni-dashboard","title":"PostgreSQL Patroni dashboard","text":"<p>Starting with PMM 2.41.2, we have included a new dashboard designed to monitor Patroni as an external service. For more information, see our documentation on external services.</p> <p>This dashboard facilitates gathering more data for your PostgreSQL cluster inside PMM. </p> <p>Read our blog post to learn more about this dashboard and how to add Patroni monitoring.</p> <p></p> <p>Important</p> <p>We would appreciate your feedback on these experimental dashboards to help us enhance it further.</p>"},{"location":"release-notes/2.41.2.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-10974 - Starting from PMM version 2.41.2, PMM has improved its stat tracking feature. In case <code>pg_stat_monitor</code> is not available, PMM will now use <code>pg_stat_statements</code> as a fallback option.</p> </li> <li> <p>PMM-12884 - In PMM dump, the Address field on the Send to Support screen now comes with the address and port pre-filled, making it easier to send logs to support.</p> </li> <li> <p>PMM-12887 - [Tech Preview] This new experimental dashboard has been added in PMM 2.41.2 for monitoring PostgreSQL checkpoints, buffers and WAL usage.</p> </li> <li> <p>PMM-12888 - [Tech Preview] This new experimental dashboard has been added in PMM 2.41.2 to monitor Patroni as an external service.</p> </li> <li> <p>PMM-12960 - [Tech Preview] The latest PMM release includes redesigned Kubernetes dashboards with improved clarity and usability.</p> </li> <li> <p>PMM-12981 - Starting with PMM 2.41.2, PMM can now collect wraparound metrics for PostgreSQL. By monitoring these wraparound-related metrics, PostgreSQL administrators can proactively manage wraparound risks and prevent potential data corruption and downtime.</p> </li> <li> <p>PMM-12894 - We have limited the number of connections used by postgres_exporter. Additionally, we have fixed an issue where connections are closed as soon as they are no longer needed, thereby preventing any hanging or idle connections.</p> </li> <li> <p>PMM-12897 - Previously, two heavy queries were running for each database in the PostgreSQL server at medium resolution, which impacted the performance. These queries have now been moved to low resolution to improve performance.</p> </li> </ul>"},{"location":"release-notes/2.41.2.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-12806 - In previous versions, PMM Server used certain non-configurable Victoria Metrics settings with default values. With this release, we are updating this behavior to enable you to modify default values for Victoria Metrics settings using environment variables. Previously, environment variables were overlooked as Victoria metrics prioritized specific command line flags passed by PMM over environment variables.</p> </li> <li> <p>PMM-12348 - The ClickHouse engine was updated from the ordinary engine to the Atomic engine, which is the most robust engine, after upgrading PMM to version 2.41.0.</p> </li> <li> <p>PMM-12785 - Fixed an issue where VictoriaMetrics scrape configuration contained unsupported parameters. </p> </li> <li> <p>PMM-12805 - While monitoring MongoDB servers, the disk space was being consumed due to the <code>CommandNotSupportedOnView</code> message in the logs. This issue has now been resolved.</p> </li> <li> <p>PMM-12809 - Fixed several CVEs in PMM versions v2.40.1 and above.</p> </li> <li> <p>PMM-12852 - An internal server error was thrown while attempting to modify any setting in PMM. This issue has been resolved now.</p> </li> <li> <p>PMM-12986 - The <code>PostgreSQL connections in use</code> alert was triggering false positive notifications, but the issue has been resolved now.</p> </li> <li> <p>PMM-12948 - Fixed an issue where the wrong information was being displayed regarding the uptime of the PostgreSQL instance.</p> </li> <li> <p>PMM-12997 - The <code>pmm-agent</code> output was changed from <code>stdout</code> to <code>stderr</code>, which caused the automation to break. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/2.42.0.html","title":"Percona Monitoring and Management 2.42.0","text":"Release date June 11<sup>th</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and execute database management operations regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.42.0.html#whats-new-in-this-release","title":"What\u2019s new in this release","text":"<p>This release introduces support for Ubuntu 24.04, configurable metrics resolutions per service, improved connection management for PostgreSQL and PMM Agent, and experimental dashboards for PMM self-monitoring and MongoDB.</p> <p>The release also brings enhancements to MySQL Query Response Time Details, adds new metrics and labels for PostgreSQL, and addresses several issues related to MongoDB monitoring, upgrades, and Query Analytics and High Availability documentation.</p> <p>Experimental dashboards in PMM are new or redesigned dashboards that are released as a preview feature for you to test and provide feedback, as we hope to include them as defaults in a future release.</p> <p>Keep in mind that these dashboards are not considered fully stable or complete, and their design, functionality, and metrics may change in future releases based on user feedback and further development.</p>"},{"location":"release-notes/2.42.0.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/2.42.0.html#ubuntu-2404-noble-numbat-support","title":"Ubuntu 24.04 Noble Numbat support","text":"<p>PMM now officially supports monitoring of databases running on the recently released Ubuntu 24.04 Noble Numbat operating system.</p> <p>With this addition, PMM continues to provide comprehensive coverage across a wide range of Linux distributions commonly used in database deployments.</p> <p>Check the full list of supported platforms on the Percona Software Support Lifecycle webpage.</p> <p>For information on installing the PMM Client on Linux, see Set up PMM Client.</p>"},{"location":"release-notes/2.42.0.html#configurable-metrics-resolutions-per-service","title":"Configurable metrics resolutions per service","text":"<p>You can now configure metrics resolutions on a per-service basis by setting Low-Resolution (LR), Medium-Resolution (MR), and High-Resolution (HR) settings for each exporter individually.</p> <p>Customizing the resolution settings for individual services means that you can fine-tune your PMM setup to balance data granularity and resource consumption. This will enable you to:</p> <ul> <li>Allocate resources efficiently by focusing on high-resolution data for key services</li> <li>Reduce storage requirements by lowering resolution for less important components</li> <li>Align your monitoring setup with the specific needs of your environment</li> </ul> <p>This feature is currently accessible via the PMM API and will be integrated into the user interface in a future release.</p> <p>For more information on configuring per-service metrics resolution, see Configure metrics resolution per-service.</p>"},{"location":"release-notes/2.42.0.html#improved-connection-management-for-postgresql-services-and-pmm-agent","title":"Improved connection management for PostgreSQL Services and pmm-agent","text":"<p>PMM now offers enhanced connection management capabilities for PostgreSQL services and the PMM Agent, to optimize resource utilization and prevent potential performance issues caused by excessive connections.</p>"},{"location":"release-notes/2.42.0.html#postgresql-services","title":"PostgreSQL services","text":"<p>When adding a new PostgreSQL services, you can now set a maximum limit on the number of connections that the PostgreSQL exporter can open to the same PostgreSQL instance.</p> <p>This feature, previously available only through the CLI, is now also accessible through the PMM web interface as well:</p> <ul> <li>PostgreSQL service: PMM Configuration &gt; Add Service &gt; PostgreSQL &gt; Configuring PostgreSQL Service</li> <li>RDS PostgreSQL service: PMM Configuration &gt; Add Service &gt; Amazon RDS &gt; Discover with Amazon Credentials &gt; RDS PostgreSQL</li> </ul> <p></p> <p>By setting a maximum connection limit, you can prevent excessive connections during concurrent operations, and ensure that connections are closed promptly to avoid idle connections.</p> <p>When adjusting the maximum number of connections, consider the following:</p> <ul> <li>higher values might be needed for larger or busier instances.</li> <li>setting the limit too high can impact performance.</li> <li>if no limit is specified or the option is disabled, the server will manage the connection limits automatically.</li> </ul>"},{"location":"release-notes/2.42.0.html#pmm-agent","title":"PMM Agent","text":"<p>Similarly, you can now limit the number of connections that the PMM Agent opens to monitored databases for QAN, Advisors, and other systems.</p> <p>Starting with this release, pmm-agent tracks all required resources (primarily connections), and opens no more than two connections per database instance simultaneously.</p> <p>You can change this default value by setting a parameter or environment variable when starting the pmm-agennt.</p> <p>For more information on configuring the PMM Agent and available parameters, see the PMM Agent help documentation by running <code>pmm-agent --help</code>.</p>"},{"location":"release-notes/2.42.0.html#experimental-pmm-self-monitoring-dashboard","title":"Experimental PMM self-monitoring dashboard","text":"<p>We\u2019ve added a new experimental PMM Health dashboard to provide detailed insights into the health and performance of PMM itself.</p> <p>The dashboard reflects the PMM architecture and covers key components such as overall component status, node health, Query Analytics, PMM-managed, Grafana, VictoriaMetrics, ClickHouse, and PostgreSQL metrics.</p> <p>This initial version is available in the Experimental folder after updating PMM and contains a starter set of key metrics to help identify potential issues and ensure optimal operation.</p> <p>For more information about this new dashboard, see the Keeping an eye on the eye blog post.</p> <p></p>"},{"location":"release-notes/2.42.0.html#experimental-mongodb-dashboards-sharded-cluster-and-replica-set","title":"Experimental MongoDB dashboards: Sharded Cluster and Replica Set","text":"<p>Along with the PMM Health Dashboard, we\u2019re also introducing experimental updates to two key MongoDB dashboards: the Cluster Summary and ReplicaSet dashboards. These new versions, accessible from the MongoDB section within PMM, have been redesigned to address feedback regarding readability and data density.</p> <p>The design and navigation are simplified here, to focus on the essential parameters and metrics most relevant to MongoDB performance monitoring.</p> <p>We encourage you to explore these experimental dashboards and provide feedback in the PMM forum to help us refine them.</p> <p></p> <p></p>"},{"location":"release-notes/2.42.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-3303 - We\u2019ve introduced an experimental PMM Health dashboard in the Experimental folder, offering detailed insights into PMM\u2019s health and performance by covering key components such as node health, Query Analytics, Grafana, VictoriaMetrics, ClickHouse, and PostgreSQL metrics.</p> </li> <li> <p>PMM-13123 - Enhanced the Query Response Time Distribution graphs in the MySQL Query Response Time Details dashboard to provide more granular insights into query performance. Previously, the graphs did not include buckets for queries with response times less than 100 milliseconds, the range which many queries typically fall into. This limitation made it difficult to analyze the performance of sub-100ms queries, especially those in the sub-1ms range.</p> </li> <li> <p>PMM-13075 - Added support for Ubuntu 24.04 support.</p> </li> <li> <p>PMM-12896, PMM-12895, PMM-12971 - Added per-database metrics collection and control of parameters, enabling more granular data gathering without overusing connections.</p> </li> <li> <p>PMM-12994 - Added labels to the <code>pg_replication_slot_slot_is_active</code> and <code>slot_current_wal_lsn</code> metrics in the postgres_exporter to identify the replication type (logical or physical) and the plugin used for the slot.</p> </li> <li> <p>PMM-12753 - Added experimental versions of the MongoDB Cluster Summary and ReplicaSet dashboards with a streamlined design and simplified navigation, focusing on essential metrics for monitoring MongoDB performance.</p> </li> <li> <p>PMM-11583 - Added support for the <code>innodb_redo_log_capacity</code> variable introduced in MySQL 8.0, ensuring accurate and consistent data representation in the InnoDB Logging graphs.</p> </li> <li> <p>PMM-11278 - Improved the Query Analytics documentation to explain how QAN collects data. For more information, see the Query Analytics under the hood section in the Query Analytics topic.</p> </li> <li> <p>PMM-13119 - Improved the High Availability documentation Improved the High Availability documentation to clearly outline the available options for HA in PMM. For more information, see the Set up PMM for HA topic.</p> </li> </ul>"},{"location":"release-notes/2.42.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-12349 - Fixed an issue in the MongoDB RepSet Summary dashboard where incorrect data was displayed when a node in the replica set was down, ensuring that the dashboard accurately reflects the status and version information of the nodes even when they are unavailable.</p> </li> <li> <p>PMM-12522 - Resolved an issue where high resolution collection of MongoDB sharding information caused timeouts.</p> </li> <li> <p>PMM-12880 - Fixed an issue where the <code>pmm-admin --tls-skip-verify</code> flag did not work correctly when using x509 authentication for MySQL, ensuring that the flag now properly skips certificate verification when connecting to MySQL instances with self-signed or untrusted certificates.</p> </li> <li> <p>PMM-12962 -  Updated the balancer metrics in MongoDB exporter to accurately calculate and report the <code>mongodb_mongos_sharding_balancer_enabled</code> metric, providing a correct indication of whether the balancer is currently enabled or disabled in the sharded cluster. Additionally, the <code>mongodb_mongos_sharding_chunks_is_balanced</code> metric has been renamed to <code>mongodb_mongos_sharding_chunks_is_balancer_running</code>. Update any alerts or dashboards using the old metric name to ensure they continue working correctly.</p> </li> <li> <p>PMM-12989 - Fixed an issue where incorrect log entries persisted when monitoring Arbiter nodes in a MongoDB replica set.</p> </li> <li> <p>PMM-12998 - Fixed an issue where upgrading PMM Server from versions older than 2.41.0 using Amazon Machine Image (AMI) or Open Virtualization Format (OVF) was unstable, causing the upgrade process to fail.</p> </li> <li> <p>PMM-9403 - Fixed an issue where the MongoDB Replication Lag graph displayed incorrect and identical values for all nodes, by updating the metric to differentiate between instances and accurately represent the replication lag of each node in the cluster.</p> </li> </ul>"},{"location":"release-notes/2.43.0.html","title":"Percona Monitoring and Management 2.43.0","text":"Release date September 19<sup>th</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and execute database management operations regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.43.0.html#whats-new-in-this-release","title":"What\u2019s new in this release","text":"<p>PMM 2.43 brings a host of updates, including new and redesigned dashboards, new collectors and metrics, enhanced troubleshooting capabilities, strengthened security, and initial steps towards expanded platform support with experimental ARM compatibility for PMM Client.</p> <p>Additionally, this release features many bug fixes and performance enhancements to improve your user experience.</p>"},{"location":"release-notes/2.43.0.html#mongodb-dashboard-improvements-and-ga-of-recent-experimental-dashboard","title":"MongoDB dashboard improvements and GA of recent experimental dashboard","text":"<p>We\u2019ve made some significant enhancements to MongoDB monitoring, focusing on redesigned dashboards, streamlined navigation, and general availability (GA) of previously experimental dashboards.</p>"},{"location":"release-notes/2.43.0.html#redesigned-dashboards","title":"Redesigned dashboards","text":"<p>We\u2019ve overhauled two critical MongoDB dashboards to provide more value, especially for complex, multi-environment setups:</p> <ul> <li>Replica Set Summary</li> <li>Sharded Cluster Summary (formerly Cluster Summary)</li> </ul> <p>These dashboards now offer enhanced usability, improved insights, and optimized visualizations for complex environments.</p> <p>They focus on highlighting potential database issues for faster resolution and provide centralized, actionable insights without clutter.</p>"},{"location":"release-notes/2.43.0.html#general-availability-of-experimental-dashboards","title":"General availability of Experimental dashboards","text":"<p>The redesigned dashboards, along with the following previously experimental dashboards, are now generally available:</p> <ul> <li>MongoDB Oplog Details</li> <li>MongoDB Collection Overview</li> <li>Replica Set Summary</li> <li>Sharded Cluster Summary (formerly Cluster Summary)</li> </ul> <p>Experimental vs. GA</p> <p>Experimental dashboards are newly developed or redesigned dashboards that are initially released as preview features. Once these dashboards have proven their value and stability, they are transitioned to GA status, which indicates that they are fully stable and ready for general use.</p>"},{"location":"release-notes/2.43.0.html#new-experimental-mongodb-router-summary-dashboard","title":"New experimental MongoDB Router Summary dashboard","text":"<p>We\u2019ve created a new experimental MongoDB Router Summary dashboard to enhance your experience when monitoring MongoS (routers) of MongoDB sharded clusters.</p> <p>This dashboard provides:</p> <ul> <li>MongoS availability (UP or DOWN) with a chart showing the state of all MongoS instances, similar to the Replica Set Summary dashboard</li> <li>MongoS version</li> <li>CPU, Memory, Disk metrics, and much more</li> </ul> <p>To access the new dashboard, go to MongoDB&gt; High availability &gt; Router summary.</p>"},{"location":"release-notes/2.43.0.html#accessing-the-new-dashboards","title":"Accessing the new dashboards","text":"<p>You can find the updated dashboards in the MongoDB and Dashboards sections of the main menu. They replace the previous versions as the default dashboards for MongoDB monitoring.</p> <p>The old dashboards have been moved to the Experimental folder and renamed with (Old) appended to their names. Future releases will remove these older versions.</p>"},{"location":"release-notes/2.43.0.html#updated-mongodb-menu-structure","title":"Updated MongoDB menu structure","text":"<p>To complement the dashboard improvements, we\u2019ve also restructured the MongoDB section on the main menu for better navigation and accessibility:</p> <ul> <li>reorganized menu for a more intuitive navigation, prioritizing the two updated GA dashboards above.</li> <li>decluttered view by moving older dashboards to the Experimental folder or removing them from the menu.</li> <li> <p>added MongoDB Instance Summary, Collection Overview and MongoDB Oplog Details the main menu:</p> <p></p> </li> </ul> <p>We encourage you to start using the new dashboards to benefit from their enhanced monitoring capabilities. We also invite you to share your feedback in the PMM forum so we can continue to improve them.</p>"},{"location":"release-notes/2.43.0.html#new-mongodb-collector-currentop","title":"New MongoDB collector: CurrentOp","text":"<p>The MongoDB exporter now includes the CurrentOp collector, offering visibility into active operations, including the new <code>mongodb_currentop_query_uptime</code> metric.</p> <p>To start the MongoDB exporter with the CurrentOp collector enabled, use the <code>--enable-all-collectors</code> flag when adding MongoDB services to your PMM instance:</p> <pre><code>pmm-admin add mongodb --enable-all-collectors ...\n</code></pre> <p>Specifying a limit with <code>--max-collections</code> for this collector is not necessary.</p> <p>For more information on MongoDB collectors and metrics, see the pmm-admin commands documentation.</p> <p>Operation collection limitation</p> <p>To minimize impact on disk usage, the CurrentOp collector is designed to collect only operations that have been running for longer than 1 minute. This limitation helps focus on potentially problematic long-running operations while keeping data volume manageable.</p>"},{"location":"release-notes/2.43.0.html#monitoring-percona-backup-for-mongodb-pbm","title":"Monitoring Percona Backup for MongoDB (PBM)","text":"<p>PMM now supports monitoring Percona Backup for MongoDB (PBM) setups through a dedicated collector in the MongoDB exporter, providing key insights into <code>pbm-agent</code> statuses, PITR configuration, and backup statuses.</p> <p>New metrics for this include:</p> <ul> <li> <p><code>mongodb_pbm_cluster_backup_configured</code>: indicates if PBM is configured for the cluster (1 = configured, 0 = not configured).</p> </li> <li> <p><code>mongodb_pbm_agent_status</code>: shows the status of each PBM agent connected to the cluster nodes (0 = functioning, \u22651 = down, e.g., 2 for unreachable agents).</p> </li> <li> <p><code>mongodb_pbm_cluster_pitr_backup_enabled</code>: specifies whether PITR is enabled in the current PBM configuration (1 = enabled, 0 = not enabled).</p> </li> <li> <p><code>mongodb_pbm_backup_size_bytes</code>: displays the size of each backup in PBM\u2019s history, with labels for operation ID (<code>opid</code>), status (<code>status</code>), and backup name (<code>name</code>).</p> </li> <li> <p><code>mongodb_pbm_backup_duration_seconds</code>: shows the duration of each PBM backup operation, using the same labels as <code>mongodb_pbm_backup_size</code>.</p> </li> </ul> <p>These metrics are enabled by default, so if you\u2019re already using PBM, you\u2019ll automatically start receiving them. To access them, go to Explore &gt; Metrics, search for mongodb_pbm, and run your query.</p> <p>This is just the beginning! While you can create custom dashboards with these metrics, we\u2019re developing dedicated PBM dashboards for a quick overview of your backup status, along with alert templates to help you proactively monitor your PBM setup.</p>"},{"location":"release-notes/2.43.0.html#improved-troubleshooting","title":"Improved troubleshooting","text":"<p>We\u2019ve enhanced PMM\u2019s troubleshooting capabilities to provide you with better insights and more efficient problem-solving tools:</p>"},{"location":"release-notes/2.43.0.html#enhanced-pmm-server-logs","title":"Enhanced PMM Server logs","text":"<p>The default number of log lines for each log file returned by <code>https://&lt;pmm-server&gt;/logs.zip</code> endpoint has been increased from 1,000 to 50,000.</p> <p>Additionally, the endpoint now includes a customizable line-count parameter in the download URL, allowing you to specify a custom number of log lines or opt for unlimited log size. For more information, see the API documentation.</p>"},{"location":"release-notes/2.43.0.html#streamlined-kubernetes-diagnostics","title":"Streamlined Kubernetes diagnostics","text":"<p>New PMM Client Docker images now include essential troubleshooting tools:</p> <ul> <li><code>tar</code> enables easier file transfer in and out of containers using the <code>kubectl cp</code> command.</li> <li><code>curl</code> allows direct checking of exporters to verify their proper functioning.</li> </ul>"},{"location":"release-notes/2.43.0.html#improved-security","title":"Improved security","text":"<p>This update addresses several security issues related to the GNU C Library (Glibc), specifically affecting the Name Service Cache Daemon (nscd). Additionally, it resolves multiple security vulnerabilities by upgrading various third-party packages.</p>"},{"location":"release-notes/2.43.0.html#important-changes-to-pmm-update-process","title":"Important changes to PMM Update process","text":"<p>To ensure you can access the most up-to-date and secure versions, we\u2019ve implemented two key changes to the update process:</p>"},{"location":"release-notes/2.43.0.html#transition-to-a-dedicated-repository","title":"Transition to a dedicated repository","text":"<p>Since July 1<sup>st</sup> 2024, PMM updates are distributed exclusively through the dedicated <code>repo.percona.com/pmm2-client</code> repository.</p> <p>To smoothly transition to this repository and verify that your system is correctly configured, download and run our automated script from GitHub: check_percona_packages.py.</p> <p>For detailed instructions and more information about this change, read our recent blog post Ensure the Correct Repositories are Enabled for Percona Packages and updated installation instructions.</p>"},{"location":"release-notes/2.43.0.html#update-process-for-older-pmm-versions","title":"Update process for older PMM versions","text":"<p>If you\u2019re using PMM version 2.38 or earlier, you might encounter issues when updating to the latest version via the UI Update button. These issues arise due to Red Hat\u2019s discontinuation of CentOS 7 repositories, which impacts PMM installations based on CentOS 7.</p> <p>To ensure your PMM installation continues to receive updates and transitions smoothly away from the discontinued CentOS 7 base:</p> <ul> <li>for Docker instances: perform a one-time Docker update to migrate your installation to the Oracle Linux 9-based image.</li> <li>for Non-Docker Instances (OVF/AMI): follow the upgrade instructions outlined in our PMM Modernization blog post.</li> </ul>"},{"location":"release-notes/2.43.0.html#experimental-arm-support-for-pmm-client","title":"Experimental ARM support for PMM Client","text":"<p>PMM 2.43 introduces experimental support for ARM architecture in PMM Clients, responding to the growing adoption of ARM in data centers and cloud environments.</p> <p>For this, PMM now includes pre-built ARM binaries for key features like <code>node_exporter</code> and <code>mysqld_exporter</code>, enabling monitoring of ARM-based infrastructure while maintaining compatibility with existing PMM Server installations.</p> <p>You can install PMM Client on ARM systems using the same process as for non-ARM platforms.</p> <p>As an experimental feature, ARM support is suitable for testing purposes but not recommended for production environments yet. We wil refine and stabilize it in future releases.</p> <p>Test this feature and share your experience on the PMM forum to help accelerate its path to GA.</p>"},{"location":"release-notes/2.43.0.html#end-of-support-for-centos-7","title":"End of support for CentOS 7","text":"<p>As of PMM 2.43.0, support for CentOS 7 has officially ended, continuing the transition to Oracle Linux 9 that began with PMM 2.38.0. With this change, we will no longer provide CentOS 7-based native packages (RPMs and DEBs) or EL7-based Docker images.</p> <p>This decision allows us to focus on modern operating systems that offer better security, enhanced compatibility, and access to the latest libraries, streamlining both development and support.</p> <p>If your infrastructure still relies on CentOS 7, we recommend planning a migration to a supported OS before upgrading to PMM 2.43.0 or any later versions. Be sure to review our blog post Update Process for Percona Monitoring and Management 2.38 and Earlier for key details about the update process, including potential issues and steps for a successful upgrade.</p> <p>For assistance with migrating to Oracle Linux 9, our expert team is available to support you. For more information, contact Percona Support.</p>"},{"location":"release-notes/2.43.0.html#maintenance-qan-update-and-postgresql-9x-support-changes","title":"Maintenance: QAN Update and PostgreSQL 9.x support changes","text":"<p>As part of our ongoing maintenance efforts, we have upgraded the <code>pg_query_go</code> package to version 5. This latest version helps parse PostgreSQL queries in QAN, provides improved functionality, and enables subsequent upgrades of important dependencies.</p> <p>However, with this change, QAN will no longer be able to list PostgreSQL database tables for versions 9.4, 9.5, and 9.6. Since all PostgreSQL 9.x versions have already reached their end-of-life status, we recommend upgrading to a supported version of PostgreSQL.</p> <p>If you\u2019re looking to upgrade, you can easily install the latest version of Percona Distribution for PostgreSQL.</p> <p>Need help with the upgrade process? Our team of PostgreSQL experts can guide you through a smooth and efficient upgrade. Contact Percona Support or our Sales team to learn more about our professional upgrade services and ensure a seamless transition to a supported PostgreSQL version.</p>"},{"location":"release-notes/2.43.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-13257: [Dashboards] - PMM 2.43 delivers refined MongoDB dashboards with standardized layouts, improved visual consistency, and enhanced usability across Replica Set, Cluster, Collections, and Oplog views, ensuring a more intuitive and efficient monitoring experience.</p> </li> <li> <p>PMM-13003: [Dashboards] - The MongoDB ReplSet Summary dashboard now features a clearer, more organized layout with separate rows for CPU usage, CPU saturation, disk I/O, and network traffic for each node in replica sets with more than three nodes, improving visibility and analysis of multi-node deployments.</p> </li> <li> <p>PMM-12982: [Dashboards] - The MongoDB ReplSet Summary dashboard now displays replica set roles (Primary, Secondary, Arbiter) for each node, enhancing visibility and simplifying identification of node functions within the replica set topology.</p> </li> <li> <p>PMM-13258: [Dashboards] - Revamped MongoDB dashboard structure, featuring new and updated dashboards for improved monitoring of various MongoDB aspects including replicas, sharded clusters, collections, and oplogs, while moving older dashboards to the Experimental folder.</p> </li> <li> <p>PMM-13227: [Dashboards] - Renamed the MongoDB Cluster Summary dashboard to MongoDB Sharded Cluster Summary to more accurately reflect its focus on sharded cluster environments, reducing potential confusion for users monitoring different MongoDB topologies.</p> </li> <li> <p>PMM-13217: [Dashboards] - The MongoDB Sharded Cluster Summary dashboard now displays the versions of mongoS routers alongside shard and config server versions, providing a more comprehensive view of the entire sharded cluster infrastructure.</p> </li> <li> <p>PMM-13183: [Dashboards] - The Node States chart in the MongoDB ReplSet Summary dashboard now auto-adjusts its size to display all nodes without scrolling, enhancing visibility and ease of monitoring for larger replica sets.</p> </li> <li> <p>PMM-13029: [Dashboards] - Improved filtering consistency across all charts on the MongoDB Oplog Details dashboard, including the Oplog GB/Hour view, ensuring accurate data representation for selected MongoDB nodes.</p> </li> <li> <p>PMM-13159: [Dashboards] - We have removed the experimental MongoDB Collection Details dashboard from PMM. You can now find up-to-date collection information on the new Mongo Cluster Summary dashboard, which provides a more comprehensive and accurate view of MongoDB collection metrics. If you have been using the Collection Details dashboard, make sure to now check the new MongoDB Cluster Summary dashboard for similar information.</p> </li> <li> <p>PMM-13030: [Dashboards] - The MongoDB Collections Overview dashboard has been refined to ensure consistent data filtering across all charts, including Top 5 Hottest Collections views, aligning with user-selected database contexts for improved clarity and more accurate per-database analysis.</p> </li> <li> <p>PMM-13243: We\u2019ve added a new <code>cluster_role</code> label to the <code>mongodb_up</code> metric, which identifies the type of node: <code>mongos</code> for query routers, <code>mongod</code> for database instances and <code>arbiter</code> for arbiter nodes.</p> <p>This label makes it easier to understand and monitor your MongoDB cluster by allowing you to filter and group metrics based on node roles. When querying the <code>mongodb_up</code> metric, the <code>cluster_role</code> label provides immediate insight into each instance\u2019s role, improving the visibility and management of your MongoDB infrastructure.</p> </li> <li> <p>PMM-13141 - Introduced new MongoDB metrics for Feature Compatibility Version (FCV),  enhancing monitoring capabilities for multi-version deployments.</p> <p>This metric, collected automatically via the MongoDB exporter, provides insights into individual node compatibility and supports upcoming PMM advisors. </p> </li> <li> <p>PMM-12333: [Installation] - The PMM Client tarball installation process has been improved with more user-friendly features, including clearer error messages for permission issues, a helpful usage guide, and better overall guidance, making the setup process more intuitive and less error-prone for users.</p> </li> <li> <p>PMM-13243: Improved identification and monitoring of MongoDB cluster member roles, particularly for mongos instances, enabling clearer topology visualization and laying the groundwork for more precise alerting in sharded cluster environments.</p> </li> <li> <p>PMM-12957: Introduced alerting capabilities for Percona Backup for MongoDB (PBM), leveraging newly added PBM-specific metrics to enable proactive monitoring of backup statuses, configurations, and performance across MongoDB deployments.</p> </li> <li> <p>PMM-13054: The default number of log lines returned by the <code>/logs.zip</code> endpoint has been increased from 1,000 to 50,000, with an added option to customize the line count or allow unlimited log size via a parameter in the download URL.</p> </li> <li> <p>PMM-13292: Introduced an improved mechanism to resolve port conflicts when starting multiple PMM agents on the same machine, enhancing reliability and reducing manual intervention in complex monitoring setups.</p> </li> <li> <p>PMM-13133: Improved QAN functionality through pg_query_go upgrade, encouraging transition to supported PostgreSQL versions for enhanced performance and security.</p> </li> </ul>"},{"location":"release-notes/2.43.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-13002: [Dashboards] - Fixed a bug in the MongoDB ReplSet Summary dashboard where the Node Summary section only displayed information for one node. It now correctly shows data for all nodes in a replica set when All is selected, providing a comprehensive view of multi-node deployments.</p> </li> <li> <p>PMM-13277: PMM 2.43 is now available on the AWS Marketplace, resolving the previous temporary unavailability issue of PMM 2.42.0. Users can directly install or upgrade to PMM 2.43.0 through AWS Marketplace or the PMM UI for access to the latest features and improvements.</p> </li> <li> <p>PMM-13246: Addressed four security vulnerabilities (CVEs) related to the GNU C Library (Glibc), specifically affecting the Name Service Cache Daemon (nscd): CVE-2024-33599, CVE-2024-33600, CVE-2024-33601, CVE-2024-33602.</p> </li> <li> <p>PMM-13255: Resolved two issues with the MongoDB Replication Lag Alert: one where an error occurred during the import of the alert rule template, and another where the alert description displayed an incorrect current value for the replication lag.</p> </li> <li> <p>PMM-13288: Fixed an issue where queries longer than 2048 characters in PostgreSQL were not properly parsed for table extraction, now allowing accurate monitoring and analysis of long queries without generating error messages in logs.</p> </li> <li> <p>PMM-12965: We\u2019ve improved the MongoDB replication lag is high alert template to make sure it:</p> <ul> <li>now triggers only for <code>SECONDARY</code> nodes that are up and exceed the lag threshold, eliminating false alarms during maintenance.</li> <li>excludes <code>PRIMARY</code> nodes from alerts, as they cannot lag behind themselves.</li> </ul> <p>To ensure you\u2019re using the updated alert logic, make sure to recreate any alerts based on this alert rule template.</p> </li> <li> <p>PMM-12451 and PMM-13017 - Resolved an issue with parsing JSON objects into the correct data types and aligned the explain functionality with the official MongoDB client. These updates enhance consistency with MongoDB\u2019s native tools and provide improved performance insights.</p> </li> <li> <p>PMM-13071: The Explain tab on the Query Analytics (QAN) page now properly handles unsupported MongoDB query types. For operations like <code>INSERT</code>, which don\u2019t support explain functionality, you will now see a clear message saying that the operation is not explainable.</p> <p>This replaces the previous, confusing error message about duplicate BSON fields, offering more accurate feedback in QAN.</p> </li> </ul>"},{"location":"release-notes/2.43.1.html","title":"Percona Monitoring and Management 2.43.1","text":"Release date October 2<sup>nd</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them, and execute database management operations regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.43.1.html#fixed-issue-pmm-2430-upgrade-failure","title":"Fixed issue: PMM 2.43.0 upgrade failure","text":"<p>This release addresses the upgrade failure to PMM 2.43.0 via the UI. The issue affected PMM Servers running versions prior to 2.43.0, where an outdated version of <code>percona-release</code> resulted in a missing <code>percona-telemetry-agent</code> package during the PostgreSQL 14 upgrade process.</p>"},{"location":"release-notes/2.43.1.html#resolution","title":"Resolution","text":"<p>Upgrading directly to PMM 2.43.1 will bypass this issue entirely.</p>"},{"location":"release-notes/2.43.1.html#workaround-for-ongoing-2430-upgrades","title":"Workaround for ongoing 2.43.0 upgrades","text":"<p>If you\u2019ve already initiated an upgrade to 2.43.0 and wish to complete this specific installation, follow the workaround below for Docker installations:</p> <p>Before retrying the upgrade run <code>docker exec -t pmm-server dnf clean all</code>, then proceed with the 2.43.0 upgrade.</p> <p>This command refreshes package metadata, resolving dependency issues and allowing the upgrade to proceed smoothly.</p>"},{"location":"release-notes/2.43.2.html","title":"Percona Monitoring and Management 2.43.2","text":"Release date October 30<sup>th</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them, and execute database management operations regardless of whether your databases are located on-premises or in the cloud.</p>"},{"location":"release-notes/2.43.2.html#postgresql-17-support-for-query-analytics-qan","title":"PostgreSQL 17 support for Query Analytics (QAN)","text":"<p>This patch release adds PostgreSQL 17 support for Query Analytics with updates to the <code>pg_stat_statements</code> and <code>pg_stat_monitor</code> extensions.</p> <p>To align with PostgreSQL 17 standards, we\u2019ve renamed the <code>blk_read_time</code> field to <code>shared_blk_read_time</code> and the <code>blk_write_time</code> field to <code>shared_blk_write_time</code>.</p> <p>All dashboards reflect these changes, and the API supports both old and new field names, for backward compatibility.</p>"},{"location":"release-notes/2.43.2.html#secure-grafana-image-rendering","title":"Secure Grafana image rendering","text":"<p>PMM Server now supports secure Grafana image rendering capabilities through a dedicated container deployment, providing isolated rendering operations without impacting PMM Server resources.</p> <p>Previously installed directly within PMM Server, the Grafana Image Renderer plugin now runs in a separate container, offering secure HTTPS communication and custom CA certificate configuration through the PMM API.</p> <p>To update the plugin installation:</p> <ol> <li>Deploy the Grafana Image Renderer container (<code>grafana/grafana-image-renderer:latest</code>) alongside PMM Server within the same Docker network.</li> <li> <p>Configure PMM Server with the following environment variables, where <code>renderer</code> is the hostname of the Grafana Image Renderer container, and <code>pmm-server</code> is the hostname of PMM Server within the Docker network: </p> <ul> <li><code>GF_RENDERING_SERVER_URL=http://renderer:8081/render</code></li> <li><code>GF_RENDERING_CALLBACK_URL=https://pmm-server:8443/graph/</code></li> </ul> </li> </ol>"},{"location":"release-notes/2.43.2.html#fixed-high-memory-consumption-in-mongodb-exporter","title":"Fixed: High memory consumption in MongoDB exporter","text":"<p>We have updated the MongoDB exporter to address a critical issue present in version 2.43.1 where unclosed connections led to increasingly high memory consumption over time.</p> <p>This resolves the <code>Failed to get PBM configuration</code> error, the users may have encountered as a result of the memory leak, and significantly reduces the rate of increase in total memory allocations.</p>"},{"location":"release-notes/2.43.2.html#cve-2023-34409-vulnerability-mitigation","title":"CVE-2023-34409: Vulnerability mitigation","text":"<p>CVE scanners may flag CVE-2023-34409 in relation to the <code>dbaas-controller</code> component within PMM. This vulnerability, tied to an authentication function, was addressed in PMM version 2.37.1.  Although <code>dbaas-controller</code> imports older PMM packages, it does not actually use the affected authentication function and is therefore unaffected by this CVE.</p> <p>In addition, the upcoming PMM 3 release will fully remove this component and its legacy imports from the Docker container, further enhancing security and eliminating this CVE from scan results.</p>"},{"location":"release-notes/2.44.0.html","title":"Percona Monitoring and Management 2.44.0","text":"Original release date December 13<sup>th</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them, and execute database management operations regardless of whether your databases are located on-premises or in the cloud.</p> <p>Release update - January 16<sup>th</sup>, 2025 </p>"},{"location":"release-notes/2.44.0.html#updated-docker-image-labels-for-openshift-compatibility","title":"Updated Docker image labels for OpenShift compatibility","text":"<p>We\u2019ve published an update to this release that modifies the PMM Client Docker image labels (<code>vendor</code>, <code>maintainer</code>, and others) to meet Red Hat certification requirements.</p> <p>The PMM Client image update was required to ensure compatibility with Percona Operator for MongoDB (PSMDB) Operator 1.19.0 and enables seamless deployment in OpenShift environments.</p> <p>This change only impacts the PMM Client image. OpenShift compatibility for PMM Server is planned for PMM v3.</p>"},{"location":"release-notes/2.44.0.html#support-for-version-80-of-percona-server-for-mongodb-psmdb-mongodb-community-and-mongodb-enterprise","title":"Support for version 8.0 of Percona Server for MongoDB (PSMDB), MongoDB Community, and MongoDB Enterprise","text":"<p>The latest version of MongoDB Community edition, along with the upcoming PSMDB 8.0, introduce numerous improvements and significant performance enhancements.</p> <p>We have updated PMM 2 to include support for these new versions, including changes to <code>mongodb_exporter</code> to accommodate the revised metrics structure (e.g., <code>wiredTiger.concurrentTransactions</code> is now <code>queues.execution</code>).</p> <p>The MongoDB Oplog Details dashboard has also been adapted to support MongoDB 8.0\u2019s new oplog metrics, with updated panels for Oplog Buffered Operations and Buffer Capacity.</p> <p></p> <p>Important notes</p> <ul> <li> <p>This enhancement requires PMM Agent version 2.43.1 or later.</p> </li> <li> <p>MongoDB 8.0 introduces significant changes to its internal metrics structure. While we have updated PMM\u2019s built-in dashboards to reflect these changes, you may need to update any custom dashboards to align with the new metrics.</p> </li> <li> <p>When using the <code>--enable-all-collectors</code> flag, monitor memory usage carefully with MongoDB clusters, especially in sharded environments with multiple collections. If you frequently create new collections or work with many collections, disable the <code>collstats</code> collector to prevent memory consumption issues.</p> </li> </ul>"},{"location":"release-notes/2.44.0.html#improved-postgresql-17-metrics-collection","title":"Improved PostgreSQL 17 metrics collection","text":"<p>PMM 2.44.0 strengthens monitoring capabilities for PostgreSQL 17, building on the recent support for Query Analytics (QAN) introduced in PMM 2.43.2.</p> <p>This previous release updated field names for PostgreSQL 17 compatibility (e.g., <code>blk_read_time</code> to <code>shared_blk_read_time</code>).</p> <p>This release further enhances PostgreSQL monitoring with updated queries aligned with PostgreSQL 17\u2019s schema changes to ensure accurate metrics collection in the PostgreSQL Instances Overview dashboard.</p> <p>We\u2019ve also improved collector support, including proper recognition of PostgreSQL 17 columns like <code>checkpoints_timed</code> in the <code>stat_bgwriter</code> collector.</p>"},{"location":"release-notes/2.44.0.html#fixed-metrics-collection-for-mongodb-backups","title":"Fixed metrics collection for MongoDB backups","text":"<p>We\u2019ve resolved an issue where Percona Backup for MongoDB (PBM) metrics were not being scraped by default and required the <code>--enable-all-collectors</code> flag.</p> <p>With this fix, PBM metrics are now automatically collected when MongoDB services are added to PMM, without requiring additional configuration.</p> <p>However, PBM metrics collection is disabled for PMM Clients 2.43.0 and 2.43.1 due to a memory leak identified in these versions. This functionality is supported starting with PMM Client 2.43.2 and later.</p>"},{"location":"release-notes/2.5.0.html","title":"Percona Monitoring and Management 2.5.0","text":"Date: April 14, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.5.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-5042 and PMM-5272: PMM can now connect to MySQL instances by specifying a UNIX socket. This can be done with a new <code>--socket</code> option of the <code>pmm-admin add mysql</code> command. (Note: Updates to both PMM Client and PMM Server were done to allow UNIX socket connections.)</li> <li>PMM-4145: Amazon RDS instance metrics can now be independently enabled/disabled for Basic and/or Enhanced metrics.</li> </ul>"},{"location":"release-notes/2.5.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-5581: PMM Server Grafana plugins can now be updated on the command line with the <code>grafana-cli</code> command-line utility.</li> <li>PMM-5536: Three Grafana plugins were updated to the latest versions: <code>vertamedia-clickhouse-datasource</code> to 1.9.5, <code>grafana-polystat-panel</code> to 1.1.0, and <code>grafana-piechart-panel</code> to 1.4.0.</li> <li>PMM-4252: The resolution of the PMM Server <code>favicon</code> image has been improved.</li> </ul>"},{"location":"release-notes/2.5.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5547: PMM dashboards were failing when presenting data from more than 100 monitored instances (error message <code>proxy error: context canceled</code>).</li> <li>PMM-5624: Empty charts were being shown in some Node Temperature dashboards.</li> <li>PMM-5637: The Data retention value in Settings was incorrectly showing the value as minutes instead of days.</li> <li>PMM-5613: Sorting data by Query Time was not working properly in Query Analytics.</li> <li>PMM-5554: Totals in charts were inconsistently plotted with different colors across charts.</li> <li>PMM-4919: The force option (<code>--force</code>) in <code>pmm-admin config</code> was not always working.</li> <li>PMM-5351: The documentation on MongoDB user privileges has been corrected.</li> </ul> <p>Help us improve our software quality by reporting any bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.6.0.html","title":"Percona Monitoring and Management 2.6.0","text":"Date: May 11, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.6.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-5728: Technical preview of External Services monitoring feature. A new command provides integration with hundreds of third-party systems (https://prometheus.io/docs/instrumenting/exporters/) via the Prometheus protocol so that you can monitor external services on a node where PMM agent is installed.</li> <li>PMM-5822: PMM now includes a Security Threat Tool to help users avoid the most common database security issues.</li> <li>PMM-5559: Global annotations can now be set with the <code>pmm-admin annotate</code> command.</li> <li>PMM-4931: PMM now checks Docker environment variables and warns about invalid ones.</li> </ul>"},{"location":"release-notes/2.6.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-1962: The PMM Server API (via <code>/v1/readyz</code>) now also returns Grafana status information in addition to that for Prometheus.</li> <li>PMM-5854: The Service Details dashboards were cleaned up and some unused selectors were removed.</li> <li>PMM-5775: It is now clearer which nodes are Primary and which are Secondary on MongoDB Instance dashboards.</li> <li>PMM-5549: PMM\u2019s Grafana component is now the latest, 6.7.3.</li> <li>PMM-5393: There\u2019s a new \u2018Node Summary\u2019 row in the services Summary and Details dashboards summarizing the system update, load average, RAM and memory.</li> <li>PMM-4778: <code>mongodb_exporter</code> is now the latest version, 0.11.0.</li> <li>PMM-5734: Temporary files activity and utilization charts (<code>rate</code> &amp; <code>irate</code>) were added to the PostgreSQL Instance overview.</li> <li>PMM-5695: The error message explains better when using the <code>\u2013-socket</code> option incorrectly.</li> </ul>"},{"location":"release-notes/2.6.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-4829: The MongoDB Exporter wasn\u2019t able to collect metrics from hidden nodes without either the latest driver or using the <code>connect-direct</code> parameter.</li> <li>PMM-5056: The average values for Query time in the Details and Profile sections were different.</li> <li>PMM-2717: Updating MongoDB Exporter resolves an error (<code>Failed to execute find query on 'config.locks': not found.</code>) when used with <code>shardedCluster</code> 3.6.4.</li> <li>PMM-4541: MongoDB exporter metrics collection was including system collections from <code>collStats</code> and <code>indexStats</code>, causing \u201clog bloat\u201d.</li> <li>PMM-5913: Only totals were shown in QAN when filtering on <code>Cluster=MongoDB</code>.</li> <li>PMM-5903: When applying a filter the QAN Overview was being refreshed twice.</li> <li>PMM-5821: The Compare button was missing from HA Dashboard main menus.</li> <li>PMM-5687: Cumulative charts for Disk Details were not showing any data if metrics were returning <code>NaN</code>           results.</li> <li>PMM-5663: The \u2018version\u2019 value was not being refreshed in various MySQL dashboards.</li> <li>PMM-5643: Advanced Data Exploration charts were showing \u2018N/A\u2019 for Metric Resolution and \u2018No data to show\u2019 in the Metric Data Table.</li> <li>PMM-4756: Dashboards were not showing services with empty environments.</li> <li>PMM-4562: MongoDB and MySQL registered instances with empty cluster labels (<code>\u2013environment=&lt;label&gt;</code>) were not visible in the dashboard despite being added instances.</li> <li>PMM-4906: The MongoDB exporter for MongoDB 4.0 and above was causing a \u201clog bloat\u201d condition.</li> </ul> <p>Help us improve our software quality by reporting any bugs you encounter using our bug tracking system.</p>"},{"location":"release-notes/2.6.1.html","title":"Percona Monitoring and Management 2.6.1","text":"Date: May 18, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.6.1.html#improvements","title":"Improvements","text":"<ul> <li>PMM-5936: Improved Summary dashboard for Security Threat Tool \u2018Failed Checks\u2019</li> <li>PMM-5937: Improved Details dashboard for Security Threat Tool \u2018Failed Database Checks\u2019</li> </ul>"},{"location":"release-notes/2.6.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5924: Alertmanager not running after PMM Server upgrade via Docker</li> <li>PMM-5915: <code>supervisord</code> not restarting after restart of PMM Server virtual appliances (OVF/AMI)</li> <li>PMM-5945: \u2018Updates\u2019 dashboard not showing available updates</li> <li>PMM-5870: MySQL Table Details dashboard not showing separate service names for tables</li> </ul>"},{"location":"release-notes/2.7.0.html","title":"Percona Monitoring and Management 2.7.0","text":"Date: June 9, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p> <p>In this release, we have updated Grafana to version 6.7.4 to fix  CVE-2020-13379. We recommend updating to the latest version of PMM as soon as possible.</p>"},{"location":"release-notes/2.7.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-5257, PMM-5256, &amp; PMM-5243: <code>pmm-admin</code> socket option (<code>\u2013-socket</code>) to specify UNIX socket path for connecting to MongoDB, PostgreSQL, and ProxySQL instances</li> </ul>"},{"location":"release-notes/2.7.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-2244: <code>pmm-admin status</code> command output shows both <code>pmm-admin</code> and <code>pmm-agent</code> versions</li> <li>PMM-5968: Disallow PMM Server node or agent removal via API</li> <li>PMM-5946: MySQL Table Details dashboard filter on Service Name prevents display of services without data</li> <li>PMM-5926: Expose PMM agent version in <code>pmm-admin status</code> command</li> <li>PMM-5891: PMM Home page now includes News panel</li> <li>PMM-5906: Independent update of PMM components deactivated</li> </ul>"},{"location":"release-notes/2.7.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6004: MySQL exporter reporting wrong values for cluster status (<code>wsrep_cluster_status</code>)</li> <li>PMM-4547: MongoDB dashboard replication lag count incorrect</li> <li>PMM-5524: Prometheus alerting rule changes needs docker restart to activate</li> <li>PMM-5949: Unwanted filters applied when moving from QAN to Add Instance page</li> <li>PMM-5870: MySQL Table Details dashboard not showing separate service names for tables</li> <li>PMM-5839: PostgreSQL metrics disparity between query time and block read/write time</li> <li>PMM-5348: Inventory page has inaccessible tabs that need reload to access</li> <li>PMM-5348: Incorrect access control vulnerability fix (CVE-2020-13379) by upgrading Grafana to 6.7.4</li> </ul>"},{"location":"release-notes/2.8.0.html","title":"Percona Monitoring and Management 2.8.0","text":"Date: June 25, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.8.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-544: Agents, Services and Nodes can now be removed via the \u2018PMM Inventory\u2019 page</li> <li>PMM-5706: User-installed Grafana plugins unaffected by PMM upgrade</li> </ul>"},{"location":"release-notes/2.8.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-6153: PMM 2.7.0 inoperable when no Internet connectivity</li> <li>PMM-5365: Client fails to send non-UTF-8 query analytics content to server (Thanks to user <code>romulus</code> for reporting this issue)</li> <li>PMM-5920: Incorrect metric used in formula for \u201cTop Users by Rows Fetched/Read\u201d graph</li> <li>PMM-6084: Annotations not showing consistently on dashboards</li> <li>PMM-6011: No data in MongoDB Cluster summary, RocksDB &amp; MMAPv1 details</li> <li>PMM-5987: Incorrect total value for virtual memory utilization</li> </ul>"},{"location":"release-notes/2.9.0.html","title":"Percona Monitoring and Management 2.9.0","text":"Date: July 14, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.9.0.html#release-highlights","title":"Release Highlights","text":"<p>This release brings a major rework of the Query Analytics (QAN) component, completing the migration from Angular to React, and adding new UI functionality and features.</p> <p>For details, see:</p> <ul> <li>PMM-5125: Implement new version of QAN</li> <li>PMM-5516: QAN migration to React and new UI implementation</li> </ul> <p>You can read more in the accompanying blog post (here).</p>"},{"location":"release-notes/2.9.0.html#new-features","title":"New Features","text":"<ul> <li>PMM-6124: New dashboards: MongoDB Replica Set Summary and MongoDB Cluster Summary</li> <li>PMM-1027: New dashboard: MySQL User Details (<code>INFORMATION_SCHEMA.CLIENT_STATISTICS</code>)</li> <li>PMM-5604: User interface for MongoDB EXPLAIN</li> <li>PMM-5563: Per-Service and per-Node Annotations (This completes the work on improvements to the Annotation functionality.)</li> </ul>"},{"location":"release-notes/2.9.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6114: Sort Agents, Nodes, and Services alphabetically by name in Inventory page (Thanks to user <code>debug</code> for reporting this issue)</li> <li>PMM-6147: Update Grafana plugins to latest versions</li> </ul>"},{"location":"release-notes/2.9.0.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5800: QAN explain and tables tabs not working after removing MySQL metrics agent</li> <li>PMM-5812: Prometheus relabeling broken (<code>relabel_configs</code> un-marshal errors) (Thanks to user <code>b4bufr1k</code> for reporting this issue)</li> <li>PMM-6184: MongoDB Instances Compare dashboard shows MySQL metric</li> <li>PMM-5941: Stacked Incoming/Outgoing Network Traffic graphs in MySQL Instances Overview dashboard prevents comparison</li> <li>PMM-6194: Missing UID for Advanced Data Exploration dashboard</li> <li>PMM-6191: Incorrect computation for Prometheus Process CPU Usage panel values in Prometheus dashboard</li> <li>PMM-6175: Node Overview dashboard shows unit for unit-less value \u2018Top I/O Load\u2019</li> </ul>"},{"location":"release-notes/2.9.1.html","title":"Percona Monitoring and Management 2.9.1","text":"Date: August 4, 2020 Installation: Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is a free and open-source platform for managing and monitoring MySQL, MongoDB, and PostgreSQL performance.</p>"},{"location":"release-notes/2.9.1.html#improvements","title":"Improvements","text":"<ul> <li>PMM-6230: Custom dashboards set as Home remain so after update</li> <li>PMM-6300: Query Analytics Dashboard: Column sorting arrows made easier to use (Thanks to user debug for reporting this issue)</li> <li>PMM-6208: Security Threat Tool: Temporarily silence viewed but un-actioned alerts</li> <li>PMM-6315: Query Analytics Dashboard: Improved metrics names and descriptions</li> <li>PMM-6274: MySQL User Details Dashboard: View selected user\u2019s queries in Query Analytics Dashboard</li> <li>PMM-6266: Query Analytics Dashboard: Pagination device menu lists 25, 50 or 100 items per page</li> <li>PMM-6262: PostgreSQL Instance Summary Dashboard: Descriptions for all \u2018Temp Files\u2019 views</li> <li>PMM-6253: Query Analytics Dashboard: Improved SQL formatting in Examples panel</li> <li>PMM-6211: Query Analytics Dashboard: Loading activity spinner added to Example, Explain and Tables tabs</li> <li>PMM-6162: Consistent sort order in dashboard drop-down filter lists</li> <li>PMM-5132: Better message when filter search returns nothing</li> </ul>"},{"location":"release-notes/2.9.1.html#bugs-fixed","title":"Bugs Fixed","text":"<ul> <li>PMM-5783: Bulk failure of SHOW ALL SLAVES STATUS scraping on PS/MySQL distributions triggers errors</li> <li>PMM-6294: Query Analytics Dashboard doesn\u2019t resize well for some screen resolutions (Thanks to user debug for reporting this issue)</li> <li>PMM-6420: Wrong version in successful update pop-up window</li> <li>PMM-6319: Query Analytics Dashboard: Query scrolls out of view when selected</li> <li>PMM-6302: Query Analytics Dashboard: Unnecessary EXPLAIN requests</li> <li>PMM-6256: Query Analytics Dashboard: <code>InvalidNamespace</code> EXPLAIN error with some MongoDB queries</li> <li>PMM-6329: Query Analytics Dashboard: Unclear origin of sparkline tool-tip on mouse-over</li> <li>PMM-6259: Query Analytics Dashboard: Slow appearance of query time distribution graph for some queries</li> <li>PMM-6189: Disk Details Dashboard: Disk IO Size chart larger by factor of 512</li> <li>PMM-6269: Query Analytics Dashboard: Metrics drop-down list obscured when opened</li> <li>PMM-6247: Query Analytics Dashboard: Overview table not resizing on window size change</li> <li>PMM-6227: Home Dashboard redirection to Node Summary Dashboard not working</li> </ul>"},{"location":"setting-up/index.html","title":"Setting up","text":"<p>There are three stages to installing and setting up PMM.</p> <p>Summary</p> <ol> <li>Set up a PMM Server.</li> <li>Set up PMM Client(s).</li> <li>Add services.</li> </ol>"},{"location":"setting-up/index.html#set-up-pmm-server","title":"Set up PMM Server","text":"<p>Install and run at least one PMM Server.</p> <p>Choose from:</p> Use Benefits Drawbacks Docker 1. Quick.2. Simple. 1. Docker installation required.2. Additional network configuration required. Podman 1. Quick.2. Simple.3. Rootless. 1. Podman installation required. Helm 1. Quick.2. Simple.3. Cloud. 1. Requires running Kubernetes cluster. Virtual appliance 1. Easily import into Hypervisor of your choice 1. More system resources compared to Docker footprint. Amazon AWS 1. Wizard-driven install. 1. Non-free solution (infrastructure costs)."},{"location":"setting-up/index.html#set-up-pmm-client","title":"Set up PMM Client","text":"<p>Install and run PMM Client on every node where there is a service you want to monitor.</p> <p>The choices:</p> <ul> <li>With Docker;</li> <li>Natively, installed from:<ul> <li>Linux package (installed with <code>apt</code>, <code>apt-get</code>, <code>dnf</code>, <code>yum</code>);</li> <li>Binary package (a downloaded <code>.tar.gz</code> file).</li> </ul> </li> </ul> <p>Binary is only way to install PMM client without root permissions</p>"},{"location":"setting-up/index.html#add-services","title":"Add services","text":"<p>On each PMM Client, you configure then add to PMM Server\u2019s inventory the node or service you want to monitor.</p> <p>How you do this depends on the type of service. You can monitor:</p> <ul> <li>MySQL (and variants: Percona Server for MySQL, Percona XtraDB Cluster, MariaDB);</li> <li>MongoDB;</li> <li>PostgreSQL;</li> <li>ProxySQL;</li> <li>Amazon RDS;</li> <li>Microsoft Azure;</li> <li>Google Cloud Platform (MySQL and PostgreSQL);</li> <li>Linux;</li> <li>External services;</li> <li>HAProxy;</li> <li>Remote instances.</li> </ul>"},{"location":"setting-up/client/index.html","title":"Set up PMM Client","text":"<p>There are different ways to install PMM Client on a node and register it with PMM Server. Choose from:</p> <ul> <li> <p>Docker: Run PMM Client as a Docker container.</p> </li> <li> <p>Package manager:</p> <ul> <li>On Debian or Red Hat Linux, install <code>percona-release</code> and use a Linux package manager (<code>apt</code>/<code>dnf</code>) to install PMM Client.</li> <li>On Debian or Red Hat, download <code>.deb</code>/<code>.rpm</code> PMM Client packages and manually install them.</li> </ul> </li> </ul> <p>Binary is only way to install PMM client without root permissions</p> <ul> <li>Binary package: For other Linux distributions, download and unpack generic PMM Client Linux binaries.</li> </ul> <p>When you have installed PMM Client, you must:</p> <ul> <li>Register the node with PMM Server.</li> <li>Configure and add services according to type.</li> </ul> <p>If you need to, you can unregister, remove services or remove PMM Client.</p> <p>Here\u2019s an overview of the choices.</p> <p></p>"},{"location":"setting-up/client/index.html#before-you-start","title":"Before you start","text":"<ul> <li>Set up PMM Server with a known IP address accessible from the client node.</li> <li>You have superuser (root) access on the client host.</li> <li>You have superuser access to any database servers that you want to monitor.</li> <li>These Linux packages are installed: <code>curl</code>, <code>gnupg</code>, <code>sudo</code>, <code>wget</code>.</li> <li>If using it, install Docker.</li> <li> <p>System requirements:</p> <ul> <li>Operating system \u2013 PMM Client runs on any modern 64-bit Linux distribution. It is tested on supported versions of Debian, Ubuntu, CentOS, and Red Hat Enterprise Linux. (See Percona software support life cycle).</li> <li>Disk \u2013 A minimum of 100 MB of storage is required for installing the PMM Client package. </li> </ul> <p>With a good connection to PMM Server, additional storage is not required. However, the client needs to store any collected data that it cannot dispatch immediately, so additional storage may be required if the connection is unstable or the throughput is low. VMagent uses 1 GB of disk space for cache during a network outage. QAN, on the other hand, uses RAM to store cache.</p> </li> </ul>"},{"location":"setting-up/client/index.html#install","title":"Install","text":""},{"location":"setting-up/client/index.html#docker","title":"Docker","text":"<p>The PMM Client Docker image is a convenient way to run PMM Client as a preconfigured Docker container.</p> <ol> <li> <p>Pull the PMM Client docker image:</p> <pre><code>docker pull \\\npercona/pmm-client:2\n</code></pre> </li> <li> <p>Use the image as a template to create a persistent data store that preserves local data when the image is updated:</p> <pre><code>docker create \\\n--volume /srv \\\n--name pmm-client-data \\\npercona/pmm-client:2 /bin/true\n</code></pre> </li> <li> <p>Run the container to start PMM Agent in setup mode. Set <code>X.X.X.X</code> to the IP address of your PMM Server. Do not use the <code>--detach</code> flag as PMM Agent only outputs logs to the console:</p> <pre><code>PMM_SERVER=X.X.X.X:443\ndocker run \\\n--rm \\\n--name pmm-client \\\n-e PMM_AGENT_SERVER_ADDRESS=${PMM_SERVER} \\\n-e PMM_AGENT_SERVER_USERNAME=admin \\\n-e PMM_AGENT_SERVER_PASSWORD=admin \\\n-e PMM_AGENT_SERVER_INSECURE_TLS=1 \\\n-e PMM_AGENT_SETUP=1 \\\n-e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n--volumes-from pmm-client-data \\\npercona/pmm-client:2\n</code></pre> <p>Tips</p> <p>You can find a complete list of compatible environment variables here.</p> </li> <li> <p>Check status:</p> <pre><code>docker exec pmm-client \\\npmm-admin status\n</code></pre> <p>In the PMM user interface you will also see an increase in the number of monitored nodes.</p> </li> </ol> <p>You can now add services with <code>pmm-admin</code> by prefixing commands with <code>docker exec pmm-client</code>.</p> <p>Tips</p> <ul> <li>Adjust host firewall and routing rules to allow Docker communications. (Read more)</li> <li>For help: <code>docker run --rm percona/pmm-client:2 --help</code></li> </ul> <p>In the GUI.</p> <ul> <li>Select  PMM Dashboards \u2192  System (Node) \u2192  Node Overview.</li> <li>In the Node Names menu, select the new node.</li> <li>Change the time range to see data.</li> </ul> <p>Danger</p> <p><code>pmm-agent.yaml</code> contains sensitive credentials and should not be shared.</p>"},{"location":"setting-up/client/index.html#package-manager","title":"Package manager","text":"<p>Tip</p> <p>If you have used <code>percona-release</code> before, disable and re-enable the repository:</p> <pre><code>percona-release disable all\npercona-release enable original release\n</code></pre> Debian-basedRed Hat-based <ol> <li> <p>Configure repositories:     <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre></p> </li> <li> <p>Install the PMM Client package:    !!! hint \u201cRoot permissions\u201d        <pre><code>apt update\napt install -y pmm2-client\n</code></pre></p> </li> <li> <p>Check:    <pre><code>pmm-admin --version\n</code></pre></p> </li> <li> <p>Register the node.</p> </li> </ol> <ol> <li> <p>Configure repositories:    <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre></p> </li> <li> <p>Install the PMM Client package:    <pre><code>yum install -y pmm2-client\n</code></pre></p> </li> <li> <p>Check:    <pre><code>pmm-admin --version\n</code></pre></p> </li> <li> <p>Register the node.</p> </li> </ol>"},{"location":"setting-up/client/index.html#package-manager-manual-download","title":"Package manager \u2013 manual download","text":"<ol> <li>Visit the Percona Monitoring and Management 2 download page.</li> <li>Under Version:, select the one you want (usually the latest).</li> <li>Under Software:, select the item matching your software platform.</li> <li> <p>Click to download the package file:</p> <ul> <li>For Debian, Ubuntu: <code>.deb</code></li> <li>For Red Hat, CentOS, Oracle Linux: <code>.rpm</code></li> </ul> </li> </ol> <p>(Alternatively, copy the link and use <code>wget</code> to download it.)</p> <p>Here are the download page links for each supported platform.</p> <ul> <li>[Debian 9 (Stretch)]</li> <li>Debian 10 (Buster)</li> <li>Debian 11 (Bullseye)</li> <li>Red Hat/CentOS/Oracle 7</li> <li>Red Hat/CentOS/Oracle 8</li> <li>[Ubuntu 18.04 (Bionic Beaver)]</li> <li>Ubuntu 20.04 (Focal Fossa)</li> <li>Ubuntu 22.04 (Jammy Jellyfish)</li> </ul> Debian-basedRed Hat-based <pre><code>dpkg -i *.deb\n</code></pre> <pre><code>dnf localinstall *.rpm\n</code></pre>"},{"location":"setting-up/client/index.html#binary-package","title":"Binary package","text":"<ol> <li> <p>Download the PMM Client package:</p> <pre><code>wget https://downloads.percona.com/downloads/pmm2/2.44.0/binary/tarball/pmm2-client-2.44.0-x86_64.tar.gz\n</code></pre> </li> <li> <p>Download the PMM Client package checksum file:</p> <pre><code>wget https://downloads.percona.com/downloads/pmm2/2.44.0/binary/tarball/pmm2-client-2.44.0-x86_64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Verify the download:</p> <pre><code>sha256sum -c pmm2-client-2.44.0-x86_64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Unpack the package and move into the directory:</p> <pre><code>tar xfz pmm2-client-2.44.0-x86_64.tar.gz &amp;&amp; cd pmm2-client-2.44.0\n</code></pre> </li> <li> <p>Choose one of these two commands (depends on your permissions):</p> <p>Without root permissions</p> <p><pre><code>export PMM_DIR=YOURPATH\n</code></pre> where YOURPATH replace with you real path, where you have required access.</p> <p>With root permissions</p> <pre><code>export PMM_DIR=/usr/local/percona/pmm2\n</code></pre> </li> <li> <p>Run the installer:</p> <p>Root permissions (if you skipped step 5 for non root users)</p> <pre><code>./install_tarball\n</code></pre> </li> <li> <p>Change the path:</p> <pre><code>PATH=$PATH:$PMM_DIR/bin\n</code></pre> </li> <li> <p>Set up the agent (pick the command for you depending on permissions):</p> <p>Root permissions</p> <pre><code>pmm-agent setup --config-file=/usr/local/percona/pmm2/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin\n</code></pre> <p>Non root users</p> <pre><code>pmm-agent setup --config-file=${PMM_DIR}/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin --paths-tempdir=${PMM_DIR}/tmp --paths-base=${PMM_DIR}\n</code></pre> </li> <li> <p>Run the agent:</p> <pre><code>pmm-agent --config-file=${PMM_DIR}/config/pmm-agent.yaml\n</code></pre> </li> <li> <p>Open a new terminal and check:</p> <pre><code>pmm-admin status\n</code></pre> <p>PMM-Agent can be updated from tarball</p> <ol> <li>Download tar.gz with pmm2-client.</li> <li>Extract it.</li> <li>Run ./install_tarball script with the \u201c-u\u201d flag.</li> </ol> <p>The configuration file will be overwritten if you do not provide the \u201c-u\u201d flag while the pmm-agent is updated.</p> </li> </ol>"},{"location":"setting-up/client/index.html#register","title":"Register","text":"<p>Register your client node with PMM Server:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server.</li> <li><code>443</code> is the default port number.</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>Important</p> <p>Clients must be registered with the PMM Server using a secure channel. If you use http as your server URL, PMM will try to connect via https on port 443. If a TLS connection can\u2019t be established you will get an error and you must use https along with the appropriate secure port.</p>"},{"location":"setting-up/client/index.html#examples","title":"Examples","text":"<p>Register on PMM Server with IP address <code>192.168.33.14</code> using the default <code>admin/admin</code> username and password, a node with IP address <code>192.168.33.23</code>, type <code>generic</code>, and name <code>mynode</code>.</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre> <p>Register your client node running on Docker with PMM Server.</p> <pre><code>docker exec pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre>"},{"location":"setting-up/client/index.html#add-services","title":"Add services","text":"<p>You must configure and adding services according to the service type.</p> <ul> <li>MySQL (and variants Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> <li>ProxySQL</li> <li>Amazon RDS</li> <li>Microsoft Azure</li> <li>Google Cloud Platform (MySQL and PostgreSQL)</li> <li>Linux</li> <li>External services</li> <li>HAProxy</li> <li>Remote instances</li> </ul> <p>Tip</p> <p>To change the parameters of a previously-added service, remove the service and re-add it with new parameters.</p>"},{"location":"setting-up/client/index.html#remove","title":"Remove","text":"<p>How to remove (uninstall) PMM Client.</p>"},{"location":"setting-up/client/index.html#docker_1","title":"Docker","text":"<p>Caution</p> <p>These steps delete the PMM Client Docker image and client services configuration data.</p> <ol> <li> <p>Stop pmm-client container:</p> <pre><code>docker stop pmm-client\n</code></pre> </li> <li> <p>Remove containers:</p> <pre><code>docker rm pmm-client\n</code></pre> </li> <li> <p>Remove the image:</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-client\" | awk {'print $3'})\n</code></pre> </li> <li> <p>Remove the volume:</p> <pre><code>docker volume rm pmm-client-data\n</code></pre> </li> </ol>"},{"location":"setting-up/client/index.html#package-manager_1","title":"Package manager","text":"Debian-based distributionsRed Hat-based distributions <ol> <li> <p>Uninstall the PMM Client package:    <pre><code>apt remove -y pmm2-client\n</code></pre></p> </li> <li> <p>Remove the Percona repository:    <pre><code>dpkg -r percona-release\n</code></pre></p> </li> </ol> <ol> <li> <p>Uninstall the PMM Client package:    <pre><code>yum remove -y pmm2-client\n</code></pre></p> </li> <li> <p>Remove the Percona repository:    <pre><code>yum remove -y percona-release\n</code></pre></p> </li> </ol>"},{"location":"setting-up/client/index.html#unregister","title":"Unregister","text":"<p>Unregister PMM Client from PMM Server:</p> <pre><code>pmm-admin unregister --force\n</code></pre> <p>All services monitored by this node will be removed from monitoring.</p>"},{"location":"setting-up/client/index.html#remove-services","title":"Remove services","text":"<p>Specify the service type and service name to remove services from monitoring:</p> <pre><code>pmm-admin remove &lt;service-type&gt; &lt;service-name&gt;\n</code></pre> <code>service-type</code> One of <code>mysql</code>, <code>mongodb</code>, <code>postgresql</code>, <code>proxysql</code>, <code>haproxy</code>, <code>external</code>. <p>See also</p> <ul> <li>Percona release</li> <li>PMM Client architecture</li> </ul>"},{"location":"setting-up/client/aws.html","title":"Amazon RDS","text":""},{"location":"setting-up/client/aws.html#required-settings","title":"Required settings","text":"<p>It is possible to use PMM for monitoring Amazon RDS. In this case, the PMM Client is not installed on the host where the database server is deployed. By using the PMM web interface, you connect to the Amazon RDS DB instance. You only need to provide the IAM user access key (or assign an IAM role) and PMM discovers the Amazon RDS DB instances available for monitoring.</p> <p>First of all, ensure that there is the minimal latency between PMM Server and the Amazon RDS instance.</p> <p>Network connectivity can become an issue for VictoriaMetrics to scrape metrics with 1 second resolution.  We strongly suggest that you run PMM Server on AWS (Amazon Web Services) in the same availability zone as Amazon RDS instances.</p> <p>It is crucial that enhanced monitoring be enabled for the Amazon RDS DB instances you intend to monitor.</p> <p>Set the Enable Enhanced Monitoring option in the settings of your Amazon RDS DB instance.</p> <p></p>"},{"location":"setting-up/client/aws.html#creating-an-iam-user-with-permission-to-access-amazon-rds-db-instances","title":"Creating an IAM user with permission to access Amazon RDS DB instances","text":"<p>It is recommended that you use an IAM user account to access Amazon RDS DB instances instead of using your AWS account. This measure improves security as the permissions of an IAM user account can be limited so that this account only grants access to your Amazon RDS DB instances. On the other hand, you use your AWS account to access all AWS services.</p> <p>The procedure for creating IAM user accounts is well described in the Amazon RDS documentation. This section only goes through the essential steps and points out the steps required for using Amazon RDS with Percona Monitoring and Management.</p> <p>The first step is to define a policy which will hold all the necessary permissions. Then, you need to associate this policy with the IAM user or group. In this section, we will create a new user for this purpose.</p>"},{"location":"setting-up/client/aws.html#creating-a-policy","title":"Creating a policy","text":"<p>A policy defines how AWS services can be accessed. Once defined it can be associated with an existing user or group.</p> <p>To define a new policy use the IAM page at AWS.</p> <p></p> <ol> <li> <p>Select the Policies option on the navigation panel and click the Create policy button.</p> </li> <li> <p>On the Create policy page, select the JSON tab and replace the existing contents with the following JSON document.</p> <pre><code>{ \"Version\": \"2012-10-17\",\n  \"Statement\": [{ \"Sid\": \"Stmt1508404837000\",\n              \"Effect\": \"Allow\",\n              \"Action\": [ \"rds:DescribeDBInstances\",\n                          \"cloudwatch:GetMetricStatistics\",\n                          \"cloudwatch:ListMetrics\"],\n                          \"Resource\": [\"*\"] },\n             { \"Sid\": \"Stmt1508410723001\",\n               \"Effect\": \"Allow\",\n               \"Action\": [ \"logs:DescribeLogStreams\",\n                           \"logs:GetLogEvents\",\n                           \"logs:FilterLogEvents\" ],\n                           \"Resource\": [ \"arn:aws:logs:*:*:log-group:RDSOSMetrics:*\" ]}\n           ]\n}\n</code></pre> </li> <li> <p>Click Review policy and set a name to your policy, such as <code>AmazonRDSforPMMPolicy</code>. Then, click the Create policy button.</p> <p></p> </li> </ol>"},{"location":"setting-up/client/aws.html#creating-an-iam-user","title":"Creating an IAM user","text":"<p>Policies are attached to existing IAM users or groups. To create a new IAM user, select Users on the Identity and Access Management page at AWS. Then click Add user and complete the following steps:</p> <p></p> <ol> <li> <p>On the Add user page, set the user name and select the Programmatic access option under Select AWS access type. Set a custom password and then proceed to permissions by clicking the Permissions button.</p> </li> <li> <p>On the Set permissions page, add the new user to one or more groups if necessary. Then, click Review.</p> </li> <li> <p>On the Add user page, click Create user.</p> </li> </ol>"},{"location":"setting-up/client/aws.html#creating-an-access-key-for-an-iam-user","title":"Creating an access key for an IAM user","text":"<p>To discover an Amazon RDS DB instance in PMM, you either need to use the access key and secret access key of an existing IAM user or an IAM role. To create an access key for use with PMM, open the IAM console and click Users on the navigation pane. Then, select your IAM user.</p> <p>To create the access key, open the Security credentials tab and click the Create access key button. The system automatically generates a new access key ID and a secret access key that you can provide on the PMM Add Instance dashboard to have your Amazon RDS DB instances discovered.</p> <p>In case, the PMM Server and Amazon RDS DB instance were created by using the same AWS account, you do not need create the access key ID and secret access key manually. PMM retrieves this information automatically and attempts to discover your Amazon RDS DB instances.</p>"},{"location":"setting-up/client/aws.html#attaching-a-policy-to-an-iam-user","title":"Attaching a policy to an IAM user","text":"<p>The last step before you are ready to create an Amazon RDS DB instance is to attach the policy with the required permissions to the IAM user.</p> <p>First, make sure that the Identity and Access Management page is open and open Users. Then, locate and open the IAM user that you plan to use with Amazon RDS DB instances. Complete the following steps, to apply the policy:</p> <ol> <li> <p>On the Permissions tab, click the Add permissions button.</p> </li> <li> <p>On the Add permissions page, click Attach existing policies directly.</p> </li> <li> <p>Using the Filter, locate the policy with the required permissions (such as <code>AmazonRDSforPMMPolicy</code>).</p> </li> <li> <p>Select a check-box next to the name of the policy and click Review.</p> </li> <li> <p>The selected policy appears on the Permissions summary page. Click Add permissions.</p> </li> </ol> <p>The <code>AmazonRDSforPMMPolicy</code> is now added to your IAM user.</p> <p></p>"},{"location":"setting-up/client/aws.html#creating-an-iam-role","title":"Creating an IAM role","text":"<p>Instead of creating an IAM user you can create an IAM role for a service, to discover Amazon RDS DB instances automatically without the need for access and secret keys. (But this only works if you are running PMM through AWS.)</p> <p>To create an IAM role open the IAM console and click Roles on the navigation pane.</p> <ol> <li> <p>Click the Create role button.</p> </li> <li> <p>Select AWS service and select EC2 for the use case.</p> </li> <li> <p>Click the Next: Permissions button.</p> </li> <li> <p>Find the policy created previously and select it.</p> </li> <li> <p>Click the Next: Tags button.</p> </li> <li> <p>(Optional) Add a metadata tag to the role.</p> </li> <li> <p>Click the Next: Review button.</p> </li> <li> <p>Fill the role name and description.</p> </li> <li> <p>Click the Create role button</p> </li> </ol> <p>After the role is created EC2 instances running PMM will have permissions to discover RDS DB instances.</p> <p>It\u2019s also possible to create an IAM role to delegate permissions to an IAM user or to add permissions to a user belonging to another AWS account. See the official AWS documentation on creating IAM roles.</p>"},{"location":"setting-up/client/aws.html#setting-up-the-amazon-rds-db-instance","title":"Setting up the Amazon RDS DB Instance","text":"<p>Query Analytics requires Configuring Performance Schema as the query source, because the slow query log is stored on the AWS (Amazon Web Services) side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Amazon RDS.</p> <p>Important</p> <p>Enabling Performance Schema on T2 instances is not recommended because it can easily run the T2 instance out of memory.</p> <p>When adding a monitoring instance for Amazon RDS, specify a unique name to distinguish it from the local instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Amazon RDS instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, UPDATE, DELETE, DROP ON performance_schema.* TO 'pmm'@'%';\n</code></pre>"},{"location":"setting-up/client/aws.html#adding-an-amazon-rds-aurora-or-remote-instance","title":"Adding an Amazon RDS, Aurora or Remote Instance","text":"<p>The preferred method of adding an Amazon RDS database instance to PMM is via the   Configuration \u2192  PMM Inventory \u2192  Add Instance menu option.</p> <p>Important</p> <p>It may take longer for PMM to discover Amazon RDS instances in the <code>creating</code> state. You must wait a bit longer until PMM discovers these instances.</p> <p>This method supports Amazon RDS database instances that use Amazon Aurora, MySQL, or MariaDB engines, as well as any remote PostgreSQL, ProxySQL, MySQL and MongoDB instances.</p> <p>The following steps are needed to add an Amazon RDS database instance to PMM:</p> <ol> <li> <p>In the PMM web interface, go to  Configuration \u2192  PMM Inventory \u2192  Add Instance.</p> </li> <li> <p>Select Amazon RDS \u2013 Add a remote instance.</p> <p></p> </li> <li> <p>Enter the access key ID and the secret access key of your IAM user or leave these fields empty if an IAM role was created.</p> </li> <li> <p>Click the Discover button for PMM to retrieve the available Amazon RDS instances.</p> <p></p> </li> <li> <p>For the instance that you would like to monitor, select the Start monitoring button.</p> </li> <li> <p>You will see a new page with the number of fields. The list is divided into the following groups: Main details, RDS database, Labels, and Additional options. Some already known data, such as already entered AWS access key, are filled in automatically, and some fields are optional.</p> <p></p> <p>The Main details section allows you to specify the DNS hostname of your instance, the service name to use within PMM, the port your service is listening on, and the database user name and password.</p> <p></p> <p>The Labels section allows you to specify labels for the environment, the AWS region and availability zone to be used, the Replication set and Cluster names and also it allows you to set the list of custom labels in a key:value format.</p> <p></p> <p>The Additional options section contains specific flags which allow you to tune the RDS monitoring. They can allow you to skip connection check, to use TLS for the database connection, not to validate the TLS certificate and the hostname, as well as to disable basic and/or enhanced metrics collection for the RDS instance to reduce costs.</p> <p>Also this section contains a database-specific flag, which would allow Query Analytics for the selected remote database:</p> <ul> <li> <p>when adding some remote MySQL, AWS RDS MySQL or Aurora MySQL instance, you will be able to choose using performance schema for the database monitoring;</p> </li> <li> <p>when adding a PostgreSQL instance, you will be able to activate using <code>pg_stat_statements</code> extension;</p> </li> <li> <p>when adding a MongoDB instance, you will be able to choose using Query Analytics MongoDB profiler.</p> </li> </ul> </li> <li> <p>Finally press the Add service button to start monitoring your instance.</p> </li> </ol>"},{"location":"setting-up/client/aws.html#adding-an-amazon-rds-postgresql-instance","title":"Adding an Amazon RDS PostgreSQL instance","text":"<p>For PostgreSQL, use the same method described above.</p> <ol> <li> <p>In the PMM web interface, go to  Configuration \u2192  PMM Inventory \u2192  Add Instance..</p> </li> <li> <p>Select Amazon RDS \u2013 Add a remote instance.</p> <p>At the moment of writing this guide, the Add button doesn\u2019t mention PostgreSQL but the discovery function already supports it.</p> <p></p> </li> <li> <p>Follow steps 4 to 6 as in the previous section. Fill the form and remember to select <code>PG Stat Statement</code> to enable Query Analytics.</p> <p>To get queries for Query Analytics, you need to enable <code>pg_stat_statements</code> in <code>postgres</code> database of your instance by running:</p> <pre><code>CREATE EXTENSION pg_stat_statements SCHEMA public;\n</code></pre> <p> </p> </li> </ol>"},{"location":"setting-up/client/azure.html","title":"Microsoft Azure","text":"<p>Caution</p> <p>Microsoft Azure functionality is currently in technical preview and is subject to change.</p>"},{"location":"setting-up/client/azure.html#activate-microsoft-azure","title":"Activate Microsoft Azure","text":"<p>The Microsoft Azure feature is turned off by default. To turn it on:</p> <ol> <li> <p>Go to  Configuration \u2192  Settings \u2192 Advanced Settings.</p> </li> <li> <p>Click the  toggle in the Technical preview features section of the page.</p> </li> </ol>"},{"location":"setting-up/client/azure.html#required-settings","title":"Required settings","text":"<p>It is possible to use PMM for monitoring Azure database instances like other remote instances. In this case, the PMM Client is not installed on the host where the database server is deployed. By using the PMM web interface, you connect to the Azure DB instance. Discovery is not yet implemented in PMM but it is possible to add known instances by providing the connection parameters.</p> <p>First of all, ensure that there is the minimal latency between PMM Server and the Azure instance.</p> <p>Second, add a firewall rule to enable access from PMM Client like this:</p> <p></p>"},{"location":"setting-up/client/azure.html#setting-up-a-mysql-instance","title":"Setting up a MySQL instance","text":"<p>Query Analytics requires you to configure Performance Schema as the query source, because the slow query log is stored on the Azure side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Azure MySQL databases.</p> <p>When adding a monitoring instance for Azure, specify a unique name to distinguish it from the local MySQL instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Azure MySQL database instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\n</code></pre>"},{"location":"setting-up/client/azure.html#adding-an-azure-instance","title":"Adding an Azure Instance","text":"<p>Follow the instructions for remotes instances explained here, Azure MySQL databases are similar to AWS RDS databases.</p> <p>Example:</p> <p></p> <p>and be sure to set Performance Schema as the query collection method for Query Analytics.</p> <p></p>"},{"location":"setting-up/client/azure.html#mariadb","title":"MariaDB","text":"<p>MariaDB up to version 10.2 works out of the box but starting with MariaDB 10.3 instrumentation is disabled by default and cannot be enabled since there is no SUPER role in Azure-MariaDB. So, it is not possible to run the required queries to enable instrumentation. Monitoring will work but Query Analytics won\u2019t receive any query data.</p>"},{"location":"setting-up/client/azure.html#postgresql","title":"PostgreSQL","text":"<p>For PostgreSQL follow the same methods used for MySQL and MariaDB and enable <code>track_io_timing</code> in the instance configuration to enable Query Analytics.</p> <p></p> <p>For Query Analytics, set the server parameter:</p> <pre><code>pg_stat_statements.track = all\n</code></pre>"},{"location":"setting-up/client/azure.html#to-discover-databases-on-azure","title":"To discover databases on Azure","text":"<p>You need to get the Client ID, Client Secret, Tenant ID and Subscription ID.</p>"},{"location":"setting-up/client/azure.html#get-the-subscription-id","title":"Get the subscription ID","text":"<ol> <li>Search Subscriptions, click on your subscription name </li> <li>Copy the subscription ID </li> </ol>"},{"location":"setting-up/client/azure.html#create-a-new-application-to-get-the-tenant-id-client-id-and-the-client-secret","title":"Create a new application to get the tenant ID, client ID and the client secret.","text":"<ol> <li>Search for Azure Active Directory </li> <li>Register a new application:</li> </ol> <p>  3. At this point you can copy the client and tenant IDs.  4. Create an application secret.   5. Copy the value of the application secret. Once you leave this page you won\u2019t be able to see the secret again and you will have to generate a new    one.  6. Give API access permissions to your application.</p> <pre><code>6.1. Search for **Subscriptions** like in step 1.\n\n6.2. Select your application and grant **Monitor Reader** permissions. This might require you to have admin permissions in your Azure account.\n</code></pre> <p> </p> <p>When you fill in all fields press the Discover button and you will see a list of available databases for monitoring.</p> <p></p> <p>You can monitor 6 types of databases:</p> <ul> <li><code>Microsoft.DBforMySQL/servers</code></li> <li><code>Microsoft.DBforMySQL/flexibleServers</code></li> <li><code>Microsoft.DBforMariaDB/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/flexibleServers</code></li> <li><code>Microsoft.DBforPostgreSQL/serversv2</code></li> </ul> <p>You can find more details on how to create DB on Azure at:</p> <ul> <li>https://docs.microsoft.com/en-us/azure/postgresql/</li> <li>https://docs.microsoft.com/en-us/azure/mysql/</li> </ul> <p>Tip</p> <p>You must set <code>pg_stat_statements.track = all</code> in your PostgreSQL Server settings to use PMM Query Analytics. (Read more.)</p> <p></p> <p>In the list of databases on the Discovery page click Start Monitoring to add the selected Azure Database to PMM.</p> <p>Fill in all required fields and click Add service.</p> <p></p> <p>PMM can use 3 exporters to collect metrics:</p> <ul> <li> <p>Azure Metrics Exporter \u2013 collect \u201csystem\u201d metrics related to DB.</p> <ul> <li><code>node_cpu_average</code></li> <li><code>azure_resource_info</code></li> <li><code>node_filesystem_size_bytes</code></li> <li><code>azure_memory_percent_average</code></li> <li><code>azure_storage_percent_average</code></li> <li><code>azure_storage_used_bytes_average</code></li> <li><code>node_network_receive_bytes_total</code></li> <li><code>node_network_transmit_bytes_total</code></li> </ul> </li> <li> <p><code>mysql_exporter</code> or <code>postgres_exporter</code> \u2013 to collect database related metrics.</p> </li> <li> <p>PMM Agent to collect queries related metrics using <code>pg_stat_statements</code> for PostgreSQL or Performance Schema for MySQL (MariaDB)</p> </li> </ul>"},{"location":"setting-up/client/azure.html#adding-an-azure-instance-on-pmm-client-side","title":"Adding an Azure Instance on pmm-client side","text":"<p>TLS/SSL is enforced on the server by default. So please download the certificate needed to communicate over SSL with your Azure Database. It can be done on Networking tab for your Azure Database instance.</p> <p></p> <p>Also enforced TLS/SSL connection option can be disabled on server side.</p> <p>Command for adding an azure database service for monitoring without TLS/SSL.</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema\n</code></pre> <p>Downloaded certificate is named <code>DigiCertGlobalRootCA.crt.pem</code>.</p> <p>An example of the command for adding an Azure database service for monitoring with TLS/SSL would be:</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema --tls --tls-ca=DigiCertGlobalRootCA.crt.pem --tls-cert=client-cert.pem --tls-key=client-key.pem --tls-skip-verify\n</code></pre>"},{"location":"setting-up/client/external.html","title":"External Services","text":""},{"location":"setting-up/client/external.html#adding-general-external-services","title":"Adding general external services","text":"<p>You can collect metrics from an external (custom) exporter on a node when:</p> <ul> <li>there is already a PMM Agent instance running and,</li> <li>this node has been configured using the <code>pmm-admin config</code> command.</li> </ul>"},{"location":"setting-up/client/external.html#usage","title":"Usage","text":"<pre><code>pmm-admin add external --service-name=&lt;service-name&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre> <pre><code>pmm-admin add external-serverless --external-name=&lt;external-service-name&gt; --host=&lt;hostname&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre>"},{"location":"setting-up/client/external.html#getting-data-from-external-exporters","title":"Getting data from external exporters","text":"<p>There two ways to get metrics from other exporters:</p> <ul> <li> <p><code>external</code> will collect metrics from the exporter that is run on the same host as PMM Client\u2019s connection to it by a port. (See more details with <code>pmm-admin add external --help</code>.)</p> </li> <li> <p><code>external-serverless</code> is useful for collecting metrics from cloud services. You need a host and port number to add it to PMM Server. (See more details with <code>pmm-admin add external-serverless --help</code>.)</p> </li> </ul> <p>Here are the differences between <code>external</code> and <code>external-serverless</code> types.</p> <p>Connection schema of external exporter:</p> <p></p> <p>Connection schema of external serverless exporter:</p> <p></p>"},{"location":"setting-up/client/external.html#how-i-can-add-something-not-supported-by-pmm","title":"How I can add something not supported by PMM","text":"<p>PMM can collect any metrics in Open metrics or Prometheus exposition format. You must specify the host and port of these metrics using the <code>pmm-admin add external</code> or <code>pmm-admin add external-serverless</code> commands.</p> <p>From this point, PMM will collect and store available metrics.</p> <p>To browse and visualize collected metrics as a first step, we can look at the Advanced Data Exploration dashboard and select informative services and metrics.</p> <p></p> <p>Another way is to create a new Grafana Dashboard to PMM as needed.</p> <p>One more way is to search for an already created dashboard at https://grafana.com/grafana/dashboards for the added exporter and import it into PMM.</p>"},{"location":"setting-up/client/external.html#third-party-exporters","title":"Third-party exporters","text":"<p>You can find more exporters on the official Prometheus page.</p>"},{"location":"setting-up/client/external.html#custom-exporter","title":"Custom exporter","text":"<p>You can write a custom external exporter or extend your application to expose metrics in Prometheus format.</p> <p>For more details see https://prometheus.io/docs/instrumenting/writing_exporters/.</p>"},{"location":"setting-up/client/external.html#examples","title":"Examples","text":"<pre><code>root@mysql1:~# pmm-admin add external --group=processes  --listen-port=9256\nExternal Service added.\nService ID  : /service_id/6485f4fd-745b-4dfb-8b72-328e300f8b50\nService name: mysql1-processes\nGroup       : processes\n</code></pre> <ul> <li>Add an exporter running on local port 9256 to the group called <code>processes</code>.</li> <li>Use the group and host names to automatically generate a service name.</li> <li>Use the default scheme and metrics path.</li> </ul>"},{"location":"setting-up/client/external.html#adding-an-external-service-via-ui","title":"Adding an External service via UI","text":"<ol> <li> <p>In the PMM web interface, go to  Configuration \u2192  PMM Inventory \u2192  Add Instance.</p> </li> <li> <p>Select External Service \u2013 Add a remote instance.</p> <p></p> </li> <li> <p>Fill the form and set the external service endpoint.</p> <p>The endpoint can be set manually:</p> <p></p> <p>or by parsing required data from a URL string, in which case you only need to pass a valid URL.</p> <p></p> </li> </ol>"},{"location":"setting-up/client/google.html","title":"Google Cloud Platform","text":"<p>PMM can monitor MySQL or PostgreSQL instances hosted on the Google Cloud Platform.</p> <p>The connection can be direct, or indirect using Cloud SQL Proxy.</p>"},{"location":"setting-up/client/google.html#mysql","title":"MySQL","text":"<ol> <li> <p>Set up a MySQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure Performance Schema on the MySQL server. Using the GCP console\u2019s Cloud Shell or your own <code>gcloud</code> installation, run:</p> <pre><code>gcloud sql instances patch &lt;instance_name&gt; --database-flags performance_schema=on\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select  Configuration \u2192  PMM Inventory \u2192  Add Instance.</p> </li> <li> <p>Click MySQL Add a remote instance.</p> </li> <li> <p>Fill in the details for the remote MySQL instance.</p> <ul> <li>Ensure Use performance schema is selected.</li> </ul> </li> <li> <p>Click Add service.</p> </li> <li> <p>Check for values in the MySQL Instance Overview dashboard and in Query Analytics.</p> </li> </ol>"},{"location":"setting-up/client/google.html#postgresql","title":"PostgreSQL","text":"<ol> <li> <p>Set up a PostgreSQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure <code>pg_stat_statements</code>. Open an interactive SQL session with your GCP PostgreSQL server and run:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select  Configuration \u2192  PMM Inventory \u2192  Add Instance.</p> </li> <li> <p>Select PostgreSQL Add a remote instance.</p> </li> <li> <p>Fill in the details for the remote PostgreSQL instance:</p> <ul> <li>In Stat tracking options, select PG Stat Statements.</li> </ul> </li> <li> <p>Click Add service.</p> </li> <li> <p>Check for values in the PostgreSQL Instance Overview dashboard and Query Analytics.</p> </li> </ol>"},{"location":"setting-up/client/google.html#cloud-sql-proxy","title":"Cloud SQL Proxy","text":""},{"location":"setting-up/client/google.html#mysql_1","title":"MySQL","text":"<ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Enable Performance Schema.</p> </li> <li> <p>Run Cloud SQL Proxy (runs on PMM Client node).</p> <ul> <li> <p>As a Docker container:</p> <pre><code>docker run -d \\\n-v ~/path/to/admin-api-file.json:/config \\\n-p 127.0.0.1:3306:3306 \\\ngcr.io/cloudsql-docker/gce-proxy:1.19.1 \\\n/cloud_sql_proxy \\\n-instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:0.0.0.0:3306 \\\n-credential_file=/config\n</code></pre> </li> <li> <p>On Linux:</p> <pre><code>wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\nchmod +x cloud_sql_proxy\n./cloud_sql_proxy -instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:3306 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> </ul> </li> <li> <p>Add instance.</p> <pre><code>pmm-admin add mysql --host=127.0.0.1 --port=3306 \\\n--username=root --password=secret \\\n--service-name=MySQLGCP --query-source=perfschema\n</code></pre> </li> </ol>"},{"location":"setting-up/client/google.html#postgresql_1","title":"PostgreSQL","text":"<ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Run Cloud SQL Proxy.</p> <pre><code>./cloud_sql_proxy -instances=example-project-NNNN:us-central1:pg-for-pmm=tcp:5432 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> <li> <p>Log into PostgreSQL.</p> </li> <li> <p>Load extension:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Add service:</p> <pre><code>pmm-admin add postgresql --host=127.0.0.1 --port=5432 \\\n--username=\"postgres\" --password=secret --service-name=PGGCP\n</code></pre> </li> </ol>"},{"location":"setting-up/client/haproxy.html","title":"HAProxy","text":""},{"location":"setting-up/client/haproxy.html#adding-haproxy-services","title":"Adding HAProxy services","text":"<p>You can collect metrics from HAProxy on a node when:</p> <ul> <li> <p>There is already a configured haproxy instance.</p> </li> <li> <p>See How to configure HAProxy.</p> </li> <li>After HAProxy is running (default address http://localhost:8404/metrics) you can add it to PMM.</li> <li> <p>Use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</p> </li> <li> <p>There is already a PMM Agent instance running.</p> </li> <li> <p>This node has been configured using the <code>pmm-admin config</code> command.</p> </li> </ul>"},{"location":"setting-up/client/haproxy.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> <p>where <code>listen-port</code> is the port number where HAProxy running. (This is the only required flag.)</p> <p>The output of this command should look as follows:</p> <pre><code>HAProxy Service added.\nService ID  : /service_id/c481183f-70a2-443f-91e5-cae5cecd06a2\nService name: Ubuntu-haproxy\n</code></pre> <p>Additionally, one positional argument can be appended to the command line flags: a service name to be used by PMM. If not specified, they are substituted automatically as <code>&lt;node&gt;-haproxy</code>.</p> <p>During adding here is connection check (can be skipped by flag <code>--skip-connection-check</code>). If HAProxy doesn\u2019t run properly on the given port then you will see an error message:</p> <pre><code>Connection check failed: Get \"http://127.0.0.1:8404/metrics\": dial tcp 127.0.0.1:8404: connect: connection refused.\n</code></pre> <p>Beside positional argument shown above you can specify service name  with the following flags: <code>--username</code>, <code>--password</code>, <code>--metrics-path</code> (path for scraping metrics, default: /metrics) and <code>--scheme</code> (http or https). Here are some examples:</p> <pre><code>pmm-admin add haproxy --listen-port=8404 --username=pmm --password=pmm new-haproxy\npmm-admin add haproxy --listen-port=8404 --metrics-path=/prom-metrics --scheme=https\n</code></pre> <p>Here you can check list of all available flags: pmm-admin.</p> <p>You can also add HAProxy by UI in Grafana: Select  Configuration \u2192  PMM Inventory \u2192  Add Instance.</p> <p>HAProxy data is visible in the Advanced Data Exploration dashboard:</p> <p></p>"},{"location":"setting-up/client/linux.html","title":"Linux","text":""},{"location":"setting-up/client/linux.html#adding-general-system-metrics-service","title":"Adding general system metrics service","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p>"},{"location":"setting-up/client/mongodb.html","title":"MongoDB","text":"<p>How to set up PMM to monitor a MongoDB or Percona Server for MongoDB database instance.</p>"},{"location":"setting-up/client/mongodb.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address or hostname accessible from the client node.</li> <li>PMM Client is installed and the node is registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> <li>You have <code>adminUserAnyDatabase</code> or superuser role privilege to any database servers that you want to monitor.</li> <li>Your MongoDB server is version 4.0 or higher.</li> </ul>"},{"location":"setting-up/client/mongodb.html#create-pmm-account-and-set-permissions","title":"Create PMM account and set permissions","text":"<p>We recommend using a dedicated account to connect PMM Client to the monitored database instance.</p> <p>Run the example codes below in a <code>mongo</code> session to:</p> <ul> <li>create custom roles with the privileges required for creating/restoring backups and working with Query Analytics (QAN)</li> <li>create/update a database user with these roles above, plus the built-in  <code>clusterMonitor</code> role</li> </ul> <p>Important</p> <p>Values for username (<code>user</code>) and password (<code>pwd</code>) are examples. Replace them before using these code snippets.</p>"},{"location":"setting-up/client/mongodb.html#create-a-role-with-monitoring-and-qan-privileges","title":"Create a role with monitoring and QAN privileges","text":"<p>This role grants the essential minimum privileges needed for monitoring and QAN. </p> <pre><code> db.getSiblingDB(\"admin\").createRole({\n   \"role\": \"explainRole\",\n   \"privileges\": [\n      {\n         \"resource\": { \"db\": \"\", \"collection\": \"\"\n         },\n         \"actions\": [ \"dbHash\", \"find\", \"listIndexes\", \"listCollections\"  ]\n      },\n      {\n         \"resource\": { \"db\": \"\", \"collection\": \"system.version\"  },\n         \"actions\": [ \"find\" ]\n      }\n   ],\n   \"roles\": []\n})\n</code></pre>"},{"location":"setting-up/client/mongodb.html#create-a-role-with-backup-management-privileges","title":"Create a role with backup management privileges","text":"<p>This role provides the necessary privileges for using PMM\u2019s backup management features. It is required only if you plan to use this feature.</p> <pre><code> db.getSiblingDB(\"admin\").createRole({\n    \"role\": \"pbmAnyAction\",\n    \"privileges\": [\n      {\n        \"resource\": { \"anyResource\": true  },\n        \"actions\": [ \"anyAction\" ]\n      }\n    ],\n    \"roles\": []\n});\n</code></pre>"},{"location":"setting-up/client/mongodb.html#permissions-for-advanced-metrics","title":"Permissions for advanced metrics","text":"<p>To fetch advanced metrics like usage statistics for collection and indexes, assign the following additional privileges to an existing PMM user:</p> <pre><code>db.getSiblingDB(\"admin\").updateRole(\n  \"explainRole\",\n  {\n    \"privileges\": [\n      {\n        \"resource\": { \"db\": \"\", \"collection\": \"\" },\n        \"actions\": [ \"collStats\", \"dbStats\", \"indexStats\" ]\n      },\n      {\n        \"resource\": { \"db\": \"\", \"collection\": \"system.profile\" },\n        \"actions\": [ \"dbStats\", \"collStats\", \"indexStats\" ]\n      },\n    ]\n  }\n)\n</code></pre>"},{"location":"setting-up/client/mongodb.html#createupdate-user-and-assign-created-roles","title":"Create/update user and assign created roles","text":"<p>Create or update a user with the minimum required privileges for monitoring by assigning the following roles:</p> <pre><code> db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"pmm\",\n    \"roles\": [\n        { \"db\": \"admin\", \"role\": \"explainRole\" },\n        { \"db\": \"local\", \"role\": \"read\" },\n        { \"db\": \"admin\". \"role\": \"clusterMonitor\" }\n    ]\n})\n</code></pre> <p>If you intent to use PMM\u2019s backup management features, also grant these additional permissions: </p> <pre><code> db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"pmm\",\n    \"roles\": [\n        { \"db\" : \"admin\", \"role\": \"explainRole\" },\n        { \"db\" : \"local\", \"role\": \"read\" },\n        { \"db\" : \"admin\", \"role\" : \"readWrite\", \"collection\": \"\" },\n        { \"db\" : \"admin\", \"role\" : \"backup\" },\n        { \"db\" : \"admin\", \"role\" : \"clusterMonitor\" },\n        { \"db\" : \"admin\", \"role\" : \"restore\" },\n        { \"db\" : \"admin\", \"role\" : \"pbmAnyAction\" }\n    ]\n})\n</code></pre>"},{"location":"setting-up/client/mongodb.html#profiling","title":"Profiling","text":"<p>To use PMM Query Analytics, you must turn on MongoDB\u2019s profiling feature.</p> <p>You can set profiling:</p> <ul> <li>permanently, by editing the MongoDB configuration file  and restarting the database instance (recommended);</li> <li>when starting MongoDB, by passing arguments to <code>mongod</code> on the command line;</li> <li>until the next database instance restart, by running a command in a <code>mongo</code> session.</li> </ul> <p>Important</p> <p>Profiling is disabled by default as it may negatively impact the performance of the database server under specific circumstances, such as when busy servers are profiling all queries.</p>"},{"location":"setting-up/client/mongodb.html#set-profiling-in-the-configuration-file","title":"Set profiling in the configuration file","text":"<ol> <li> <p>Edit the configuration file (usually <code>/etc/mongod.conf</code>).</p> </li> <li> <p>Create or add this to the <code>operationProfiling</code> section. (Read more.)</p> <pre><code>operationProfiling:\n  mode: all\n  slowOpThresholdMs: 200\n  rateLimit: 100 # (Only available with Percona Server for MongoDB.)\n</code></pre> <p>Important</p> <p>This is a YAML file. Indentation matters.</p> </li> <li> <p>Restart the <code>mongod</code> service. (Example for <code>systemd</code>.)</p> <pre><code>systemctl restart mongod\n</code></pre> </li> </ol>"},{"location":"setting-up/client/mongodb.html#set-profiling-on-the-command-line","title":"Set profiling on the command Line","text":"<pre><code>mongod --dbpath=DATABASEDIR --profile 2 --slowms 200 --rateLimit 100\n</code></pre> <ul> <li><code>--dbpath</code>: The path to database files (usually <code>/var/lib/mongo</code>).</li> <li><code>--profile</code>: The MongoDB profiling level. A value of <code>2</code> tells the server to collect profiling data for all operations. To lower the load on the server, use a value of <code>1</code> to only record slow operations.</li> <li><code>--slowms</code>: An operation is classified as slow if it runs for longer than this number of milliseconds.</li> <li> <p><code>--rateLimit</code>: (Only available with Percona Server for MongoDB.) The sample rate of profiled queries. A value of <code>100</code> means sample every 100<sup>th</sup> fast query. (Read more.)</p> <p>Caution</p> <p>Smaller values improve accuracy but can adversly affect the performance of your server.</p> </li> </ul>"},{"location":"setting-up/client/mongodb.html#set-profiling-in-a-mongo-session","title":"Set profiling in a <code>mongo</code> session","text":"<p>In a <code>mongo</code> session, the profiler should be enabled per database. For example, to enable the profiler in the <code>testdb</code>, run this:</p> <pre><code>&gt; use testdb\n&gt; db.setProfilingLevel(2, {slowms: 0})\n</code></pre> <p>Important</p> <p>If you have already added the MongoDB service to PMM, make sure to restart the PMM agent service after adjusting the profiling level.</p>"},{"location":"setting-up/client/mongodb.html#add-service","title":"Add service","text":"<p>After configuring your database server, you can add a MongoDB service either through the user interface or via the command line.</p> <p>Important</p> <p>To monitor MongoDB sharded clusters, PMM requires access to all cluster components. Make sure to add all the config servers, shards, and at least 1-2 mongos routers. Otherwise, PMM will not be able to correctly collect metrics and populate dashboards.  Keep in mind that adding all mongos routers may cause excessive overhead.</p>"},{"location":"setting-up/client/mongodb.html#on-the-command-line","title":"On the command line","text":"<p>Use <code>pmm-admin</code> to add the database server as a service using one of these example commands.</p> <p>When successful, PMM Client will print <code>MongoDB Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>-custom-labels</code> options to set tags for the service to help identify them.</p> <p>Tips</p> <ul> <li>When adding nodes to a sharded cluster, ensure to add each node separately using the <code>--cluster mycluster</code> option. This allows the MongoDB Cluster Summary dashboard to populate correctly. </li> <li>You can also use the <code>--replication-set</code> option to specify a replication set, altough they are automatically detected. For instance, you can use <code>--replication-set config</code> for your config servers; <code>--replication-set rs1</code> for your servers in the first replica set, <code>--replication-set rs2</code> for your servers in the second replica set, and so on.</li> <li>When running mongos routers in containers, specify the <code>diagnosticDataCollectionDirectoryPath</code> to ensure that pmm-agent can properly capture mongos metrics. For example: <code>mongos --setParameter diagnosticDataCollectionDirectoryPath=/var/log/mongo/mongos.diagnostic.data/</code></li> </ul>"},{"location":"setting-up/client/mongodb.html#examples","title":"Examples","text":"<p>Add basic data collection: <pre><code>pmm-admin add mongodb \\\n--username=pmm_mongodb --password=password \\\n--query-source=profiler --cluster=mycluster\n</code></pre></p> <p>Add complete data collection with a custom service name: <pre><code>pmm-admin add mongodb \\\n--username=pmm_mongodb --password=password \\\n--service-name=mymongosvc --host=127.0.0.1 --port=27017 \\\n--enable-all-collectors\n</code></pre></p>"},{"location":"setting-up/client/mongodb.html#connecting-via-ssltls","title":"Connecting via SSL/TLS","text":"<pre><code>pmm-admin add mongodb --tls \\\n--tls-certificate-key-file=PATHTOCER \\\n--tls-certificate-key-file-password=IFPASSWORDTOCERTISSET \\\n--tls-ca-file=PATHTOCACERT \\\n--authentication-mechanism=AUTHENTICATION-MECHANISM \\\n--authentication-database=AUTHENTICATION-DATABASE \\\n--cluster=mycluster \\\n--enable-all-collectors\n</code></pre> <p>where:</p> <ul> <li><code>PATHTOCERT</code>: Path to TLS certificate file.</li> <li><code>IFPASSWORDTOCERTISSET</code>: Password for TLS certificate file.</li> <li><code>PATHTOCACERT</code>: Path to certificate authority file.</li> <li><code>AUTHENTICATION-MECHANISM</code>: Authentication mechanism. Default is empty. Use <code>MONGODB-X509</code> for SSL certificates.</li> <li><code>AUTHENTICATION-DATABASE</code>: Authentication database. Default is empty. Use <code>$external</code> for SSL certificates.</li> </ul>"},{"location":"setting-up/client/mongodb.html#with-the-pmm-interface","title":"With the PMM interface","text":"<p>Use this option when you don\u2019t have direct access to the underlying host to install pmm-agent locally.</p> <ol> <li> <p>Select  Configuration \u2192  Inventory.</p> </li> <li> <p>Select MongoDB \u2013 Add a remote instance.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol>"},{"location":"setting-up/client/mongodb.html#check-the-service","title":"Check the service","text":""},{"location":"setting-up/client/mongodb.html#on-the-command-line_1","title":"On the command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services --service-type=mongodb\n</code></pre>"},{"location":"setting-up/client/mongodb.html#with-the-pmm-interface_1","title":"With the PMM interface","text":"<ol> <li>Select  Configuration \u2192  Inventory.</li> <li>In the Services tab, verify the Service name, Addresses, and any other relevant values used when adding the service.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> <li>If your MongoDB instance is configured to use TLS, click on the Use TLS for database connection check box and fill in TLS certificates and keys. If you use TLS, the authentication mechanism is automatically set to <code>MONGODB-X509</code>.</li> </ol>"},{"location":"setting-up/client/mongodb.html#check-data","title":"Check data","text":"<ol> <li>Open the MongoDB Instances Overview dashboard.</li> <li>Set the Service Name to the newly-added service.</li> </ol>"},{"location":"setting-up/client/mongodb.html#query-analytics","title":"Query Analytics","text":"<ol> <li>Open PMM Query Analytics.</li> <li>In the Filters panel:<ol> <li>Under Service Name, select your service.</li> <li>Under Service Type select <code>mongodb</code>.</li> </ol> </li> </ol>"},{"location":"setting-up/client/mongodb.html#remove-service","title":"Remove service","text":""},{"location":"setting-up/client/mongodb.html#on-the-command-line_2","title":"On the command line","text":"<pre><code>pmm-admin remove mongodb SERVICE_NAME\n</code></pre> <ul> <li><code>SERVICE_NAME</code>: The name the service was added as. (Find it with <code>pmm-admin list</code>.)</li> </ul>"},{"location":"setting-up/client/mongodb.html#with-the-pmm-interface_2","title":"With the PMM interface","text":"<p>Use this option only top remove agents installed through the PMM interface.</p> <ol> <li>Select  Configuration \u2192  Inventory.</li> <li>In the first column, click the tick box for the service you want to remove.</li> <li>Click  Delete.</li> <li>On the Confirm action dialog window:<ol> <li>(Optional) Select Force mode to also delete associated agents.</li> <li>Click Proceed.</li> </ol> </li> </ol> <p>See also</p> <ul> <li><code>pmm-admin add mongodb</code></li> <li>Troubleshooting connection difficulties</li> </ul>"},{"location":"setting-up/client/mysql.html","title":"MySQL","text":"<p>How to set up PMM to monitor a MySQL or MySQL-based database instance.</p> <p>PMM Client collects metrics from MySQL, Percona Server for MySQL, Percona XtraDB Cluster, and MariaDB. (Amazon RDS is also supported and explained in a separate section.)</p> <p>Summary</p> <ul> <li>Create PMM account and set permissions.</li> <li>Choose a data source:<ul> <li>Slow query log, or,</li> <li>Performance Schema.</li> </ul> </li> <li>Configure:<ul> <li>Query response time,</li> <li>Tablestats,</li> <li>User statistics.</li> </ul> </li> <li>Add service.</li> <li>Check the service.</li> </ul>"},{"location":"setting-up/client/mysql.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address accessible from the client node.</li> <li>PMM Client is installed and the node is registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> </ul>"},{"location":"setting-up/client/mysql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>It is good practice to use a non-superuser account to connect PMM Client to the monitored database instance. This example creates a database user with name <code>pmm</code>, password <code>pass</code>, and the necessary permissions.</p> MySQL 8.0MySQL 5.7MariaDB 10.5.8+ <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY 'pass' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY 'pass' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY 'pass' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICA MONITOR, RELOAD ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre>"},{"location":"setting-up/client/mysql.html#choose-and-configure-a-source","title":"Choose and configure a source","text":"<p>Decide which source of metrics to use, and configure your database server for it. The choices are Slow query log and Performance Schema.</p> <p>While you can use both at the same time we recommend using only one\u2013there is some overlap in the data reported, and each incurs a small performance penalty. The choice depends on the version and variant of your MySQL instance, and how much detail you want to see.</p> <p>Here are the benefits and drawbacks of Slow query log and Performance Schema metrics sources.</p>  Benefits  Drawbacks Slow query log 1. More detail.2. Lower resource impact (with query sampling feature in Percona Server for MySQL). 1. PMM Client must be on same host as database server or have access to slow query log.2. Log files grow and must be actively managed. Performance Schema 1. Faster parsing.2. Enabled by default on newer versions of MySQL. 1. Less detail."},{"location":"setting-up/client/mysql.html#data-source-recommendations","title":"Data source recommendations","text":"Database server Versions Recommended source MySQL 8.0+ Performance Schema MariaDB 10.0+ Performance Schema Percona Server for MySQL 8.0+ Slow query log Percona XtraDB Cluster 8.0+ Slow query log"},{"location":"setting-up/client/mysql.html#slow-query-log","title":"Slow query log","text":"<p>This section covers how to configure a MySQL-based database server to use the slow query log as a source of metrics.</p>"},{"location":"setting-up/client/mysql.html#applicable-versions","title":"Applicable versions","text":"Server Versions MySQL 5.1-5.5 MariaDB 10.1.2+ Percona Server for MySQL 5.7.10+, 8.0.12+ Percona XtraDB Cluster 5.6, 5.7, 8.0 <p>The slow query log records the details of queries that take more than a certain amount of time to complete. With the database server configured to write this information to a file rather than a table, PMM Client parses the file and sends aggregated data to PMM Server via the Query Analytics part of PMM Agent.</p>"},{"location":"setting-up/client/mysql.html#settings","title":"Settings","text":"Variable Value Description <code>slow_query_log</code> ON Enables the slow query log. <code>log_output</code> <code>'FILE'</code> Ensures the log is sent to a file. (This is the default on MariaDB.) <code>long_query_time</code> 0 The slow query threshold in seconds. In heavily-loaded applications, many quick queries can affect performance more than a few slow ones. Setting this value to <code>0</code> ensures all queries are captured. <code>log_slow_admin_statements</code> ON Includes the logging of slow administrative statements. <code>log_slow_slave_statements</code> ON Enables logging for queries that have taken more than <code>long_query_time</code> seconds to execute on the replica."},{"location":"setting-up/client/mysql.html#examples","title":"Examples","text":"Configuration fileSession <pre><code>slow_query_log=ON\nlog_output=FILE\nlong_query_time=0\nlog_slow_admin_statements=ON\nlog_slow_slave_statements=ON\n</code></pre> <pre><code>SET GLOBAL slow_query_log = 1;\nSET GLOBAL log_output = 'FILE';\nSET GLOBAL long_query_time = 0;\nSET GLOBAL log_slow_admin_statements = 1;\nSET GLOBAL log_slow_slave_statements = 1;\n</code></pre>"},{"location":"setting-up/client/mysql.html#slow-query-log-extended","title":"Slow query log \u2013 extended","text":"<p>Some MySQL-based database servers support extended slow query log variables.</p>"},{"location":"setting-up/client/mysql.html#applicable-versions_1","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.7.10+, 8.0.12+ Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 10.0"},{"location":"setting-up/client/mysql.html#settings_1","title":"Settings","text":"Variable Value Description <code>log_slow_rate_limit</code> 100 Defines the rate of queries captured by the slow query log. A good rule of thumb is 100 queries logged per second. For example, if your Percona Server instance processes 10,000 queries per second, you should set <code>log_slow_rate_limit</code> to <code>100</code> and capture every 100<sup>th</sup> query for the slow query log. Depending on the amount of traffic, logging could become aggressive and resource consuming. This variable throttles the level of intensity of the data capture without compromising information. <code>log_slow_rate_type</code> \u2018query\u2019 Set so that it applies to queries, rather than sessions. <code>slow_query_log_always_write_time</code> 1 Specifies which queries should ignore sampling. With query sampling this ensures that queries with longer execution time will always be captured by the slow query log, avoiding the possibility that infrequent slow queries might not get captured at all. <code>log_slow_verbosity</code> \u2018full\u2019 Ensures that all information about each captured query is stored in the slow query log. <code>slow_query_log_use_global_control</code> \u2018all\u2019 Configure the slow query log during runtime and apply these settings to existing connections. (By default, slow query log settings apply only to new sessions.)"},{"location":"setting-up/client/mysql.html#examples_1","title":"Examples","text":"Configuration file (Percona Server for MySQL, Percona XtraDB Cluster)Configuration file (MariaDB)Session (Percona Server for MySQL, Percona XtraDB Cluster) <pre><code>log_slow_rate_limit=100\nlog_slow_rate_type='query'\nslow_query_log_always_write_time=1\nlog_slow_verbosity='full'\nslow_query_log_use_global_control='all'\n</code></pre> <pre><code>log_slow_rate_limit=100\n</code></pre> <pre><code>SET GLOBAL log_slow_rate_limit = 100;\nSET GLOBAL log_slow_rate_type = 'query';\nSET GLOBAL slow_query_log_always_write_time = 1;\nSET GLOBAL log_slow_verbosity = 'full';\nSET GLOBAL slow_query_log_use_global_control = 'all';\n</code></pre>"},{"location":"setting-up/client/mysql.html#slow-query-log-rotation","title":"Slow query log rotation","text":"<p>Slow query log files can grow quickly and must be managed.</p> <p>When adding a service with the command line use the  <code>pmm-admin</code> option <code>--size-slow-logs</code> to set at what size the slow query log file is rotated. (The size is specified as a number with a suffix. See <code>pmm-admin add mysql</code>.)</p> <p>When the limit is reached, PMM Client will:</p> <ul> <li>remove the previous <code>.old</code> slow log file,</li> <li>rename the current file by adding the suffix <code>.old</code>,</li> <li>execute the MySQL command <code>FLUSH LOGS</code>.</li> </ul> <p>Only one <code>.old</code> file is kept. Older ones are deleted.</p> <p>You can manage log rotation yourself, for example, with <code>logrotate</code>. If you do, you can disable PMM Client\u2019s log rotation by providing a negative value to <code>--size-slow-logs</code> option when adding a service with <code>pmm-admin add</code>.</p>"},{"location":"setting-up/client/mysql.html#performance-schema","title":"Performance Schema","text":"<p>This section covers how to configure a MySQL-based database server to use Performance Schema as a source of metrics.</p>"},{"location":"setting-up/client/mysql.html#applicable-versions_2","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.6, 5.7, 8.0 Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 10.3+ <p>PMM\u2019s MySQL Performance Schema Details dashboard charts the various <code>performance_schema</code> metrics.</p> <p>To use Performance Schema, set the variables below. </p> <p>Important</p> <p>Make sure to restart pmm-agent after making any changes to MySQL perfschema.</p> Variable Value Description <code>performance_schema</code> <code>ON</code> Enables Performance Schema metrics. This is the default in MySQL 5.6.6 and higher. <code>performance-schema-instrument</code> <code>'statement/%=ON'</code> Configures Performance Schema instruments. <code>performance-schema-consumer-statements-digest</code> <code>ON</code> Configures the <code>statements-digest</code> consumer. <code>innodb_monitor_enable</code> all Enables InnoDB metrics counters. <p>Important</p> <p>When dealing with long queries, increasing the value of the variable performance_schema_max_digest_length will avoid having query examples truncated.</p>"},{"location":"setting-up/client/mysql.html#examples_2","title":"Examples","text":"Configuration fileSession <pre><code>performance_schema=ON\nperformance-schema-instrument='statement/%=ON'\nperformance-schema-consumer-statements-digest=ON\ninnodb_monitor_enable=all\n</code></pre> <p>(<code>performance_schema</code> cannot be set in a session and must be set at server start-up.)</p> <pre><code>UPDATE performance_schema.setup_consumers\nSET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\nSET GLOBAL innodb_monitor_enable = all;\n</code></pre>"},{"location":"setting-up/client/mysql.html#mariadb-1057-or-lower","title":"MariaDB 10.5.7 or lower","text":"<p>There is no Explain or Example data shown by default in Query Analytics when monitoring MariaDB instances version 10.5.7 or lower. A workaround is to set this variable.</p> Variable Value Description <code>performance_schema.setup_instruments</code> <code>'statement/%'</code> List of instrumented object classes. <ul> <li> <p>Session.</p> <pre><code>UPDATE performance_schema.setup_instruments SET ENABLED = 'YES', TIMED = 'YES' WHERE NAME LIKE 'statement/%';\nUPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\n</code></pre> </li> <li> <p>Transactions</p> <p>MariaDB doesn\u2019t implement queries history for transactions. All queries executed within a transaction won\u2019t have query examples since PMM relies on the <code>performance_schema.events_statements_history</code> to grab the query example but that table won\u2019t have any query executed as part of a transaction.  </p> <p>This behavior is because MariaDB doesn\u2019t implement these consumers:</p> <pre><code>events_transactions_current\nevents_transactions_history\nevents_transactions_history_long\n</code></pre> </li> </ul>"},{"location":"setting-up/client/mysql.html#query-response-time","title":"Query response time","text":"<p>Query time distribution is a chart in the Details tab of Query Analytics showing the proportion of query time spent on various activities. It is enabled with the <code>query_response_time_stats</code> variable and associated plugins.</p>"},{"location":"setting-up/client/mysql.html#applicable-versions_3","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.7 (not Percona Server for MySQL 8.0.) MariaDB 10.0.4 <p>Set this variable to see query time distribution charts.</p> Variable Value Description <code>query_response_time_stats</code> ON Report query response time distributions. (Requires plugin installation. See below.) <ul> <li> <p>Configuration file.</p> <pre><code>query_response_time_stats=ON\n</code></pre> </li> </ul> <p>You must also install the plugins.</p> <ul> <li> <p>Session.</p> <ol> <li>Check that <code>/usr/lib/mysql/plugin/query_response_time.so</code> exists.</li> <li> <p>Install the plugins and activate.</p> <p>For MariaDB 10.3:</p> <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre> <p>For Percona Server for MySQL 5.7:</p> <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre> </li> </ol> </li> </ul>"},{"location":"setting-up/client/mysql.html#tablestats","title":"Tablestats","text":"<p>Some table metrics are automatically disabled when the number of tables exceeds a default limit of 1000 tables. This prevents PMM Client from affecting the performance of your database server.</p> <p>The limit can be changed when adding a service on the command line with the two <code>pmm-admin</code> options:</p> <code>pmm-admin</code> option Description <code>--disable-tablestats</code> Disables tablestats collection when the default limit is reached. <code>--disable-tablestats-limit=N</code> Sets the number of tables (<code>N</code>) for which tablestats collection is disabled. 0 means no limit. A negative number means tablestats is completely disabled (for any number of tables)."},{"location":"setting-up/client/mysql.html#user-statistics","title":"User statistics","text":""},{"location":"setting-up/client/mysql.html#applicable-versions_4","title":"Applicable versions","text":"<p>User activity, individual table and index access details are shown on the MySQL User Details dashboard when the <code>userstat</code> variable is set.</p> Server Versions Percona Server for MySQL 5.6, 5.7, 8.0 Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 5.2.0+"},{"location":"setting-up/client/mysql.html#examples_3","title":"Examples","text":"Configuration fileSession <pre><code>userstat=ON\n</code></pre> <pre><code>SET GLOBAL userstat = ON;\n</code></pre>"},{"location":"setting-up/client/mysql.html#add-service","title":"Add service","text":"<p>There are two ways to install PMM Client for monitoring your MySQL database:</p> <ol> <li>Local installation: Installs PMM Client directly on the database node, collecting both database and OS/host metrics. This option enables more effective comparison and problem identification.</li> <li>Remote instance: Use when local installation isn\u2019t possible. This method doesn\u2019t provide OS/Node metrics in PMM.</li> </ol>"},{"location":"setting-up/client/mysql.html#install-pmm-client-locally","title":"Install PMM Client locally","text":"<p>Add the MySQL server as a service using one of the following example commands. </p> <p>Upon successful addition, PMM Client will display \u201cMySQL Service added\u201d along with the service\u2019s ID and name. Use <code>--environment</code> and <code>--custom-labels</code> options to set identifying tags for the service.</p> <pre><code>pmm-admin add mysql --username=pmm --password=&lt;your_password&gt; MYSQL_SERVICE_NAME\n</code></pre>"},{"location":"setting-up/client/mysql.html#example-configurations","title":"Example configurations","text":""},{"location":"setting-up/client/mysql.html#tls-connection","title":"TLS connection","text":"<pre><code>pmm-admin add mysql --username=user --password=pass --tls --tls-skip-verify --tls-ca=pathtoca.pem --tls-cert=pathtocert.pem --tls-key=pathtocertkey.pem --server-url=http://admin:admin@127.0.0.1 --query-source=perfschema name localhost:3306\n</code></pre>"},{"location":"setting-up/client/mysql.html#slow-query-log_1","title":"Slow query log","text":"<p>Default query source (<code>slowlog</code>), service name (<code>{node name}-mysql</code>), and service address/port (<code>127.0.0.1:3306</code>), with database server account <code>pmm</code> and password <code>pass</code>.</p> <pre><code>pmm-admin add mysql --username=pmm --password=pass\n</code></pre> <p>Slow query log source and log size limit (1 gigabyte), service name (<code>MYSQL_SERVICE</code>) and service address/port (<code>191.168.1.123:3306</code>).</p> <pre><code>pmm-admin add mysql --query-source=slowlog --size-slow-logs=1GiB --username=pmm --password=pass MYSQL_SERVICE 192.168.1.123:3306\n</code></pre> <p>Slow query log source, disabled log management (use <code>logrotate</code> or some other log management tool), service name (<code>MYSQL_SERVICE</code>) and service address/port (<code>191.168.1.123:3306</code>).</p> <pre><code>pmm-admin add mysql --query-source=slowlog --size-slow-logs=-1GiB --username=pmm --password=pass MYSQL_SERVICE 192.168.1.123:3306\n</code></pre> <p>Default query source (<code>slowlog</code>), service name (<code>{node}-mysql</code>), connect via socket.</p> <pre><code>pmm-admin add mysql --username=pmm --password=pass --socket=/var/run/mysqld/mysqld.sock\n</code></pre>"},{"location":"setting-up/client/mysql.html#performance-schema_1","title":"Performance Schema","text":"<p>Performance schema query source, service name (<code>MYSQL_SERVICE</code>) and default service address/port (<code>127.0.0.1:3306</code>).</p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=pass MYSQL_SERVICE\n</code></pre> <p>Performance schema query source, service name (<code>MYSQL_SERVICE</code>) and default service address/port (<code>127.0.0.1:3306</code>) specified with flags.</p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=pass --service-name=MYSQL_SERVICE--host=127.0.0.1 --port=3306\n</code></pre>"},{"location":"setting-up/client/mysql.html#identifying-services","title":"Identifying services","text":"<p>Default query source (<code>slowlog</code>), environment labeled <code>test</code>, custom labels setting <code>source</code> to <code>slowlog</code>. (This example uses positional parameters for service name and service address.)</p> <pre><code>pmm-admin add mysql --environment=test --custom-labels='source=slowlog'  --username=root --password=password --query-source=slowlog MySQLSlowLog localhost:3306\n</code></pre>"},{"location":"setting-up/client/mysql.html#install-pmm-client-as-a-remote-instance","title":"Install PMM Client as a remote instance","text":"<ol> <li> <p>Select  Configuration &gt;  Inventory &gt;  Add Service.</p> </li> <li> <p>Choose MySQL &gt; Add a remote instance.</p> </li> <li> <p>Complete the required fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p>"},{"location":"setting-up/client/mysql.html#for-mysql-instances-using-tls","title":"For MySQL instances using TLS","text":"<p>If your MySQL instance is configured to use TLS: </p> <ol> <li>Click on the Use TLS for database connections check box.</li> <li>Fill in your TLS certificates and key.</li> </ol> <p></p>"},{"location":"setting-up/client/mysql.html#check-the-service","title":"Check the service","text":""},{"location":"setting-up/client/mysql.html#pmm-user-interface","title":"PMM user interface","text":"<ol> <li>Select  Configuration \u2192  Inventory.</li> <li>In the Services tab, verify the Service name, Addresses, and any other relevant information in the form.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> </ol>"},{"location":"setting-up/client/mysql.html#command-line","title":"Command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services --service-type=mysql\n</code></pre>"},{"location":"setting-up/client/mysql.html#check-data","title":"Check data","text":"<ol> <li>Open the MySQL Instance Summary dashboard.</li> <li>Set the Service Name to the newly-added service.</li> </ol>"},{"location":"setting-up/client/mysql.html#percona-server-for-mysql-mariadb","title":"Percona Server for MySQL, MariaDB","text":"<p>If query response time plugin was installed, check for data in the MySQL Query Response Time Details dashboard or select a query in PMM Query Analytics to see the Query time distribution bar.</p>"},{"location":"setting-up/client/mysql.html#percona-xtradb-cluster","title":"Percona XtraDB Cluster","text":"<p>Open the PXC/Galera Cluster Summary dashboard.</p> <p>See also</p> <ul> <li>Percona Server for MySQL \u2013 Slow Query Log Extended</li> <li>Percona Server for MySQL \u2013 User Statistics</li> <li>MariaDB \u2013 Slow Query Log Overview</li> <li>MariaDB \u2013 Slow Query Log Extended Statistics</li> <li>MariaDB \u2013 User Statistics</li> <li>Percona Blog \u2013 PERFORMANCE_SCHEMA vs Slow Query Log</li> <li>Percona Blog \u2013 MySQL\u2019s INNODB_METRICS table</li> <li>Percona Blog \u2013 Rotating MySQL Slow Logs Safely</li> <li>Percona Blog \u2013 Impact of logging on MySQL\u2019s performance</li> <li>Percona Blog \u2013 Running Custom MySQL Queries in Percona Monitoring and Management</li> </ul>"},{"location":"setting-up/client/postgresql.html","title":"PostgreSQL","text":"<p>How to set up PMM to monitor a PostgreSQL or Percona Distribution for PostgreSQL database instance.</p> <p>Summary</p> <ul> <li>Create PMM account and set permissions.</li> <li>Choose, install and configure an extension:<ul> <li><code>pg_stat_statements</code>, or,</li> <li><code>pg_stat_monitor</code>.</li> </ul> </li> <li>Add service.</li> <li>Check the service.</li> </ul>"},{"location":"setting-up/client/postgresql.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address accessible from the client node.</li> <li>PMM Client is installed and the node is registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> <li>You have superuser access to any database servers that you want to monitor.</li> </ul> <p>(PMM follows PostgreSQL\u2019s end-of-life policy. For specific details on supported platforms and versions, see Percona\u2019s Software Platform Lifecycle page.)</p>"},{"location":"setting-up/client/postgresql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>We recommend creating a PMM database account that can connect to the <code>postgres</code> database with the <code>SUPERUSER</code> role.</p> <ol> <li> <p>Create a user. This example uses <code>pmm</code>. (Replace <code>******</code> with a strong password of your choice.)</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '******';\n</code></pre> <p>If your database runs on Amazon RDS / Aurora PostgreSQL, The SUPERUSER cannot be assigned. So we have to create the user first and then grant the <code>rds_superuser</code> role to it.</p> <p><pre><code>CREATE USER pmm WITH ENCRYPTED PASSWORD '******';\nGRANT rds_superuser TO pmm;\n</code></pre> Optionally, you can also set up a connection limit (only if the user is not a SUPERUSER):</p> <pre><code>ALTER USER pmm CONNECTION LIMIT 10;\n</code></pre> </li> <li> <p>PMM must be able to log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> <p>(Ignore the second line. It is a comment to show field alignment.)</p> </li> <li> <p>Reload the configuration:</p> <pre><code>su - postgres\npsql -c \"select pg_reload_conf()\"\n</code></pre> </li> <li> <p>Check local login.</p> <pre><code>psql postgres pmm -c \"\\conninfo\"\n</code></pre> </li> <li> <p>Enter the password for the <code>pmm</code> user when prompted.</p> </li> </ol>"},{"location":"setting-up/client/postgresql.html#choose-and-configure-an-extension","title":"Choose and configure an extension","text":"<p>Decide which database extension to use, and configure your database server for it. The choices are:</p> <ol> <li> <p><code>pg_stat_statements</code>, the original extension created by PostgreSQL, part of the <code>postgresql-contrib</code> package available on Linux.</p> </li> <li> <p><code>pg_stat_monitor</code> is a new extension created by Percona. <code>pg_stat_monitor</code> has all the features of <code>pg_stat_statements</code> but adds bucket-based data aggregation, provides more accurate data, and can expose Query Examples.</p> </li> </ol> <p>Here are the benefits and drawbacks of each.</p>  Benefits  Drawbacks <code>pg_stat_statements</code> 1. Part of official <code>postgresql-contrib</code> package. 1. No aggregated statistics or histograms2. No query examples 3. No plan execution information <code>pg_stat_monitor</code> 1. Builds on <code>pg_stat_monitor</code> features.2. Bucket-based aggregation. <p>For a more detailed comparison of extensions, see Comparison with pg_stat_statements in the <code>pg_stat_monitor</code> documentation.</p> <p>Bucket-based data aggregation</p> <p><code>pg_stat_monitor</code> collects statistics and aggregates data in a data collection unit called a bucket. These are linked together to form a bucket chain.</p> <p>You can specify:</p> <ul> <li>the number of buckets (the length of the chain);</li> <li>how much space is available for all buckets;</li> <li>a time limit for each bucket\u2019s data collection (the bucket expiry).</li> </ul> <p>When a bucket\u2019s expiration time is reached, accumulated statistics are reset and data is stored in the next available bucket in the chain.</p> <p>When all buckets in the chain have been used, the first bucket is reused and its contents are overwritten.</p> <p>If a bucket fills before its expiration time is reached, data is discarded.</p>"},{"location":"setting-up/client/postgresql.html#pg_stat_statements","title":"<code>pg_stat_statements</code>","text":""},{"location":"setting-up/client/postgresql.html#install","title":"Install","text":"<ul> <li> <p>Debian/Ubuntu</p> <p>Root permissions</p> <pre><code>apt install -y postgresql-contrib\n</code></pre> </li> <li> <p>Red Hat/CentOS</p> <p>Root permissions</p> <pre><code>yum install -y postgresql-contrib\n</code></pre> </li> </ul>"},{"location":"setting-up/client/postgresql.html#configure","title":"Configure","text":"<ol> <li> <p>Add these lines to your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_statements'\ntrack_activity_query_size = 2048 # Increase tracked query string size\npg_stat_statements.track = all   # Track all statements including nested\ntrack_io_timing = on             # Capture read/write stats\n</code></pre> </li> <li> <p>Restart the database server. After the restart, the extension starts capturing statistics from every database.</p> </li> <li> <p>Install the extension. </p> <pre><code>psql postgres postgres -c \"CREATE EXTENSION pg_stat_statements SCHEMA public\"\n</code></pre> <p>This command creates the view where you can access the collected statistics.</p> </li> </ol> <p>We recommend that you create the extension for the <code>postgres</code> database. In this case, you receive access to the statistics collected from every database.    </p> <p>You can now add the service.</p>"},{"location":"setting-up/client/postgresql.html#pg_stat_monitor","title":"<code>pg_stat_monitor</code>","text":"<p><code>pg_stat_monitor</code> has been tested with:</p> <ul> <li>PostgreSQL versions 11, 12, 13, 14, 15.</li> <li>Percona Distribution for PostgreSQL versions 11, 12, 13, 14, 15.</li> </ul>"},{"location":"setting-up/client/postgresql.html#install_1","title":"Install","text":"<ul> <li> <p>If you use Percona Distribution for PostgreSQL, you can install the extension with your Linux package manager. See Installing Percona Distribution for PostgreSQL.</p> </li> <li> <p>If you use PostgreSQL you can install by downloading and compiling the source code. See Installing <code>pg_stat_monitor</code>.</p> </li> </ul>"},{"location":"setting-up/client/postgresql.html#configure_1","title":"Configure","text":"<ol> <li> <p>Set or change the value for <code>shared_preload_library</code>.</p> <p>In your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> <p>Caution</p> <p>If you use both <code>pg_stat_statements</code> and <code>pg_stat_monitor</code>, set <code>pg_stat_monitor</code> after <code>pg_stat_statements</code>:</p> <pre><code>shared_preload_libraries = 'pg_stat_statements, pg_stat_monitor'\n</code></pre> </li> <li> <p>Set configuration values.</p> <p>In your <code>postgresql.conf</code> file: <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre></p> <p>Caution</p> <p>It is important to set maximal length of query to 2048 characters or more for PMM to work properly.</p> <p>You can get a list of other available settings with <code>SELECT * FROM pg_settings WHERE name LIKE 'pg_stat_monitor.%';</code>.</p> <p>Other important parameters are: <pre><code>pg_stat_monitor.pgsm_normalized_query\n</code></pre> and <pre><code>pg_stat_monitor.pgsm_enable_query_plan\n</code></pre></p> <p>If the value for <code>pg_stat_monitor.pgsm_normalized_query</code> is set to 1, the actual query values are replaced by placeholders. If the value is 0, the examples are given in QAN. Examples can be found in QAN details tab example.</p> <p>If <code>pg_stat_monitor.pgsm_enable_query_plan</code> is enabled, the query plans are captured and will be available in the <code>Plan</code> tab on the Query Analytics dashboard.</p> <p>See <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Start or restart your PostgreSQL instance. The extension starts capturing statistics from every database.</p> </li> <li> <p>In a <code>psql</code> session:</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> <p>This command creates the view where you can access the collected statistics.</p> <p>We recommend that you create the extension for the <code>postgres</code> database. In this case, you receive the access to the statistics, collected from every database.</p> </li> <li> <p>Check the version.</p> <pre><code>SELECT pg_stat_monitor_version();\n</code></pre> </li> </ol>"},{"location":"setting-up/client/postgresql.html#add-service","title":"Add service","text":"<p>When you have configured your database server, you can add a PostgreSQL service with the user interface or on the command line.</p>"},{"location":"setting-up/client/postgresql.html#with-the-user-interface","title":"With the user interface","text":"<ol> <li> <p>Select  Configuration \u2192  Inventory \u2192  Add Service.</p> </li> <li> <p>Select PostgreSQL \u2013 Add a remote instance.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p> <p>If your PostgreSQL instance is configured to use TLS, click on the Use TLS for database connections check box and fill in your TLS certificates and key.</p> <p></p> <p>Note</p> <p>For TLS connection to work SSL needs to be configured in your PostgreSQL instance. Make sure SSL is enabled in the server configuration file <code>postgresql.conf</code>, and that hosts are allowed to connect in the client authentication configuration file <code>pg_hba.conf</code>. (See PostgreSQL documentation on Secure TCP/IP Connections with SSL.)</p>"},{"location":"setting-up/client/postgresql.html#auto-discovery-limit","title":"Auto-discovery limit","text":"<p>Starting with PMM 2.41.0 you can set a limit for Auto-discovery in PostgreSQL, a feature that dynamically discovers all databases in your PostgreSQL instance. </p> <p>Limiting Auto-discovery reduces connections and prevents high CPU and RAM usage caused by multiple databases.</p> <p>Caution</p> <p>Limiting auto-discovery may result in fewer metrics being captured from the non-primary databases.  Ensure that you set the limit appropriately:</p> <ul> <li>Setting a high limit may impact performance adversely.</li> <li>Setting a low limit might result in some missing metrics due to Auto-discovery being disabled.</li> </ul> <p>By default, Auto-discovery is enabled (server defined with a limit 10).</p> <p></p> <p>When you select Disabled, the Auto-discovery limit will be set to <code>-1</code>.</p> <p></p> <p>For a custom value, select Custom and enter or choose your preferred value from the Auto-discovery limit field.</p> <p></p>"},{"location":"setting-up/client/postgresql.html#maximum-connection-limit","title":"Maximum connection limit","text":"<p>Starting with PMM 2.42.0, you can set a maximum limit on the number of connections that the PostgreSQL exporter can open to the same PostgreSQL instance.</p> <p>By setting a maximum connection limit, you can prevent excessive connections during concurrent operations, and ensure that connections are closed promptly to avoid idle connections.</p> <p>When adjusting the maximum number of connections, consider the following:</p> <ul> <li>higher values might be needed for larger or busier instances.</li> <li>setting the limit too high can impact performance.</li> <li>if no limit is specified or the option is disabled, the server will manage the connection limits automatically.</li> </ul> <p></p>"},{"location":"setting-up/client/postgresql.html#on-the-command-line","title":"On the command line","text":"<p>Add the database server as a service using one of these example commands. If successful, PMM Client will print <code>PostgreSQL Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>-custom-labels</code> options to set tags for the service to help identify them.</p>"},{"location":"setting-up/client/postgresql.html#examples","title":"Examples","text":"<p>Add instance with default service name (<code>&lt;node&gt;-postgresql</code>).</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls\n</code></pre> <ul> <li><code>&lt;user name&gt;</code>: The PostgreSQL PMM user</li> <li><code>&lt;password&gt;</code>: The PostgreSQL user credentials.</li> </ul> <p>The service name will be automatically chosen.</p> <p>Add instance with specified service name.</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls \\\n--service-name=SERVICE-NAME\n</code></pre> <p>Add instance to connect with a UNIX socket.</p> <pre><code>pmm-admin add postgresql --socket=/var/run/postgresql\n</code></pre> <p>where: - <code>SOCKET</code>: directory containing the socket</p>"},{"location":"setting-up/client/postgresql.html#connecting-via-ssltls","title":"Connecting via SSL/TLS","text":"<pre><code>pmm-admin add postgresql --tls \\\n--tls-cert-file=PATHTOCERT \\\n--tls-ca-file=PATHTOCACERT \\\n--tls-key-file=PATHTOKEY \\\n--host=HOST \\\n--port=PORT \\\n--username=USER \\\n--service-name=SERVICE-NAME\n</code></pre> <p>where:</p> <ul> <li><code>PATHTOCERT</code>: Path to client certificate file.</li> <li><code>PATHTOCACERT</code>: Path to certificate authority file.</li> <li><code>PATHTOKEY</code>: Path to client key file.</li> <li><code>HOST</code>: Instance hostname or IP.</li> <li><code>PORT</code>: PostgreSQL service port number.</li> <li><code>USER</code>: Database user allowed to connect via TLS. Should match the common name (CN) used in the client certificate.</li> <li><code>SERVICE</code>: Name to give to the service within PMM.</li> </ul>"},{"location":"setting-up/client/postgresql.html#automatic-discovery-limit-via-cli","title":"Automatic discovery limit via CLI","text":"<p>Starting with PMM 2.41.0, there is a new flag in <code>pmm-admin</code> to limit Auto-discovery:</p> <p><code>--auto-discovery-limit=XXX</code></p> <ul> <li>If number of databases &gt; Auto-discovery limit, then auto discovery is OFF</li> <li>If number of databases &lt;= Auto-discovery limit, then auto discovery is ON</li> <li>If the Auto-discovery limit is not defined, it takes the default value, which is 0 (server defined with limit 10), and Auto-discovery is ON(if you do not have more than 10 databases).</li> <li>If Auto-discovery limit &lt; 0 then auto discovery is OFF.</li> </ul> <p>Example:</p> <p>If you set the limit to 10 and your PostgreSQL instance has 11 databases, automatic discovery will be disabled.</p> <p><code>pmm-admin add postgresql --username=\"pmm-agent\" --password=\"pmm-agent-password\" --auto-discovery-limit=10</code></p>"},{"location":"setting-up/client/postgresql.html#check-the-service","title":"Check the service","text":""},{"location":"setting-up/client/postgresql.html#check-service-pmm-user-interface","title":"Check service - PMM user interface","text":"<ol> <li>Select  Configuration \u2192  Inventory.</li> <li>In the Services tab, verify the Service name, Address and any other relevant details.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> </ol>"},{"location":"setting-up/client/postgresql.html#check-service-command-line","title":"Check service - Command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services\n</code></pre> <p>If using Docker, use <code>docker exec pmm-client pmm-admin inventory list services</code></p>"},{"location":"setting-up/client/postgresql.html#check-data","title":"Check data","text":"<ol> <li> <p>Open the PostgreSQL Instance Summary dashboard.</p> </li> <li> <p>Set the Service Name to the newly-added service.</p> </li> </ol>"},{"location":"setting-up/client/postgresql.html#running-custom-queries","title":"Running custom queries","text":"<p>The PostgreSQL exporter can run custom queries to add new metrics not provided by default. Those custom queries must be defined in the <code>/usr/local/percona/pmm2/collectors/custom-queries/postgresql</code> in the same host where the exporter is running. There are 3 directories inside it:     - high-resolution/   - every 5 seconds     - medium-resolution/ - every 10 seconds     - low-resolution/ - every 60 seconds</p> <p>Depending on the desired resolution for your custom queries, you can place a file with the queries definition. The file is a yaml where each query can have these fields:</p> <pre><code>query_name:\n   query: the query definition\n   master: boolean to specify if the query should be executed only in the master\n   metrics:\n     - metric name:\n         usage: GAUGE, LABEL, COUNTER, MAPPEDMETRIC or DURATION\n         description: a human readable description\n</code></pre>"},{"location":"setting-up/client/postgresql.html#example","title":"Example","text":"<pre><code>pg_postmaster_uptime:\n   query: \"select extract(epoch from current_timestamp - pg_postmaster_start_time()) as seconds\"\n   master: true\n   metrics:\n     - seconds:\n         usage: \"GAUGE\"\n         description: \"Service uptime\"\n</code></pre> <p>Check the see also section for a more detailed description on MySQL custom queries with more examples about how to use custom queries in dashboards.</p> <p>See also</p> <ul> <li><code>pmm-admin</code> man page for <code>pmm-admin add postgresql</code></li> <li>Configuring Percona Repositories with percona-release</li> <li>Percona Blog \u2013 Running Custom MySQL Queries in Percona Monitoring and Management</li> </ul>"},{"location":"setting-up/client/proxysql.html","title":"ProxySQL","text":"<p>Use the <code>proxysql</code> alias to enable ProxySQL performance metrics monitoring.</p>"},{"location":"setting-up/client/proxysql.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <p>where <code>username</code> and <code>password</code> are credentials for the administration interface of the monitored ProxySQL instance.  You should configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL</p> <p>Additionally, two positional arguments can be appended to the command line flags: a service name to be used by PMM, and a service address. If not specified, they are substituted automatically as <code>&lt;node&gt;-proxysql</code> and <code>127.0.0.1:6032</code>.</p> <p>The output of this command may look as follows:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <pre><code>ProxySQL Service added.\nService ID  : /service_id/f69df379-6584-4db5-a896-f35ae8c97573\nService name: ubuntu-proxysql\n</code></pre> <p>Beside positional arguments shown above you can specify service name and service address with the following flags: <code>--service-name</code>, and <code>--host</code> (the hostname or IP address of the service) and <code>--port</code> (the port number of the service), or <code>--socket</code> (the UNIX socket path). If both flag and positional argument are present, flag gains higher priority. Here is the previous example modified to use these flags for both host/port or socket connections:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=pmm --service-name=my-new-proxysql --host=127.0.0.1 --port=6032\npmm-admin add proxysql --username=pmm --password=pmm --service-name=my-new-proxysql --socket=/tmp/proxysql_admin.sock\n</code></pre>"},{"location":"setting-up/client/remote.html","title":"Remote instances","text":""},{"location":"setting-up/client/remote.html#recommended-settings","title":"Recommended settings","text":"<p>When monitoring remote instances including RDS and Google instances, network latency might affect the scrape process and throw timeout errors. For this reason, it is recommended to lower the metrics resolution.</p> <p>Starting with PMM 2.18, the scrape timeout has been updated according to the following rules:</p> <ul> <li>For resolutions &lt;= 2 seconds, scrape timeout is 1 second.</li> <li>For resolutions &lt;= 10 seconds, timeout is set to resolution minus 1 second. For example, for 10 second resolution, timeout will be set at 9 seconds.</li> <li>For lower resolutions (values &gt; 10 seconds), the scrape timeout is set to 90% of the resolution time. For example, for 60 second resolution, the scrape timeout will be set to 54 seconds.</li> </ul>"},{"location":"setting-up/client/remote.html#how-to-check-for-scrape-timeouts","title":"How to check for scrape timeouts","text":"<p>Sometimes it is hard to check if you are using the correct values to scrape or if there some other reason why there is no data in a dashboard even when the instance has been added correctly and the agent is running.</p> <p>One additional step you can do is to check for scrape target statuses. Browse to <code>http://&lt;your-pmm-server-address&gt;/prometheus/targets</code> and then click on the Unhealthy button.</p> <p></p> <p>The page will show only agents having issues while scrapping and the scrape result including the error messages.</p> <p></p> <p>In the example here, there is a message that says: context deadline exceeded and the scrape duration column says the scrape took 10 seconds; this means that the exporter didn\u2019t respond in the 10 seconds the scrape process was allowed to run due to the configured metric resolutions and their timeouts.</p> <p>In this case, we can lower the metric resolutions increasing these values as shown in the image below.</p> <p></p>"},{"location":"setting-up/server/index.html","title":"Set up PMM Server","text":"<ol> <li> <p>Check system requirements.</p> <p>Disk</p> <p>Approximately 1 GB of storage per monitored database node with data retention set to one week. By default, retention is 30 days.</p> <p>Tip</p> <p>Disable table statistics to decrease the VictoriaMetrics database size.</p> <p>Memory</p> <p>A minimum of 2 GB per monitored database node. The increase in memory usage is not proportional to the number of nodes. For example, data from 20 nodes should be easily handled with 16 GB.</p> <p>Architecture</p> <p>Your CPU must support the <code>SSE4.2</code> instruction set, a requirement of ClickHouse, a third-party column-oriented database used by Query Analytics. If your CPU is lacking this instruction set you won\u2019t be able to use Query Analytics.  Additionally, since PMM 2.38.0, your CPU and any virtualization layer in use must support x86-64-v2 or your container may not start.   </p> </li> <li> <p>Configure your network.</p> </li> <li> <p>Decide how you want to run PMM Server. Choose from:</p> <ul> <li>Docker;</li> <li>Podman;</li> <li>Helm;</li> <li>Virtual appliance;</li> <li>Amazon AWS;</li> <li>Use the easy install script.</li> </ul> </li> <li> <p>Authenticating using API keys.</p> <p>While adding clients to the PMM server, you use the <code>admin</code> user. However, if you change the password for the admin user from the PMM UI, then the clients will not be able to access PMM. Also, due to multiple unsuccessful login attempts Grafana will lock out the <code>admin</code> user. The solution is to use API key for authentication. You can use API keys as a replacement for basic authentication.</p> </li> </ol>"},{"location":"setting-up/server/aws.html","title":"AWS Marketplace","text":"<p>You can run an instance of PMM Server hosted at AWS Marketplace.</p> <p>Assuming that you have an AWS (Amazon Web Services) account, locate Percona Monitoring and Management Server in AWS Marketplace or use this link.</p> <p></p> <p>Selecting a region and instance type in the Pricing Information section will give you an estimate of the costs involved. This is only an indication of costs. You will choose regions and instance types in later steps.</p> <p>Percona Monitoring and Management Server is provided at no cost, but you may need to pay for infrastructure costs.</p> <p>Disk space consumed by PMM Server depends on the number of hosts being monitored. Although each environment will be unique, you can consider the data consumption figures for the PMM Demo web site which consumes approximately 230 MB per host per day, or approximately 6.9 GB per host at the default 30 day retention period.</p> <p>For more information, see our blog post How much disk space should I allocate for Percona Monitoring and Management?.</p> <ol> <li> <p>Click Continue to Subscribe.</p> </li> <li> <p>Subscribe to this software: Check the terms and conditions and click Continue to Configuration.</p> </li> <li> <p>Configure this software:</p> <ol> <li>Select a value for Software Version. (The latest is 2.44.0.)</li> <li>Select a region. (You can change this in the next step.)</li> <li>Click Continue to Launch.</li> </ol> </li> <li> <p>Launch this software:</p> <ol> <li> <p>Choose Action: Select a launch option. Launch from Website is a quick way to make your instance ready. For more control, choose Launch through EC2.</p> </li> <li> <p>EC2 Instance Type: Select an instance type.</p> </li> <li> <p>VPC Settings: Choose or create a VPC (virtual private cloud).</p> </li> <li> <p>Subnet Settings: Choose or create a subnet.</p> </li> <li> <p>Security Group Settings: Choose a security group or click *Create New Based On Seller Settings</p> </li> <li> <p>Key Pair Settings: Choose or create a key pair.</p> </li> <li> <p>Click Launch.</p> </li> </ol> </li> </ol>"},{"location":"setting-up/server/aws.html#limiting-access-to-the-instance-security-group-and-a-key-pair","title":"Limiting Access to the instance: security group and a key pair","text":"<p>In the Security Group section, which acts like a firewall, you may use the preselected option <code>Create new based on seller settings</code> to create a security group with recommended settings. In the Key Pair select an already set up EC2 key pair to limit access to your instance.</p> <p></p> <p>Important</p> <p>The security group should allow communication via the the following ports: 22, 80, and 443. PMM should also be able to access port 3306 on the RDS that uses the instance.</p> <p></p>"},{"location":"setting-up/server/aws.html#applying-settings","title":"Applying settings","text":"<p>Scroll up to the top of the page to view your settings. Then, click the Launch with 1 click button to continue and adjust your settings in the EC2 console.</p> <p>Your instance settings are summarized in a special area. Click the Launch with 1 click button to continue.</p> <p></p> <p>The Launch with 1 click button may alternatively be titled as Accept Software Terms &amp; Launch with 1-Click.</p>"},{"location":"setting-up/server/aws.html#adjusting-instance-settings-in-the-ec2-console","title":"Adjusting instance settings in the EC2 Console","text":"<p>Your clicking the Launch with 1 click button, deploys your instance. To continue setting up your instance, run the EC2 console. It is available as a link at the top of the page that opens after you click the Launch with 1 click button.</p> <p>Your instance appears in the EC2 console in a table that lists all instances available to you. When a new instance is only created, it has no name. Make sure that you give it a name to distinguish it from other instances managed via the EC2 console.</p> <p></p>"},{"location":"setting-up/server/aws.html#running-the-instance","title":"Running the instance","text":"<p>After you add your new instance ,it will take some time to initialize it. When the AWS console reports that the instance is now in a running state, you may continue with configuration of PMM Server.</p> <p>When started the next time after rebooting, your instance may acquire another IP address. You may choose to set up an elastic IP to avoid this problem.</p> <p>With your instance selected, open its IP address in a web browser. The IP address appears in the IPv4 Public IP column or as value of the Public IP field at the top of the Properties panel.</p> <p></p> <p>To run the instance, copy and paste its public IP address into the location bar of your browser. In the Percona Monitoring and Management welcome page that opens, enter the instance ID.</p> <p></p> <p>You can copy the instance ID from the Properties panel of your instance, select the Description tab back in the EC2 console. Click the Copy button next to the Instance ID field. This button appears as soon as you hover the cursor of your mouse over the ID.</p> <p>Hover the cursor over the instance ID for the Copy button to appear.</p> <p></p> <p>Paste the instance in the Instance ID field of the Percona Monitoring and Management welcome page and click Submit.</p> <p>PMM Server provides user access control, and therefore you will need user credentials to access it:</p> <p></p> <ul> <li>Default user name: <code>admin</code></li> <li>Default password: <code>admin</code></li> </ul> <p>You will be prompted to change the default password every time you log in.</p> <p>The PMM Server is now ready and the home page opens.</p> <p></p> <p>You are creating a username and password that will be used for two purposes:</p> <ol> <li> <p>authentication as a user to PMM - the credentials to log in to PMM.</p> </li> <li> <p>authentication between PMM Server and PMM Clients - you will re-use these credentials on another host when configuring PMM Client for the first time on a server, for example (DO NOT RUN ON THIS PMM SERVER YOU JUST CREATED):</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@&lt;IP Address&gt;:443\n</code></pre> <p>For instructions about how to access your instances by using an SSH client, see Connecting to Your Linux Instance Using SSH</p> <p>Make sure to replace the user name <code>ec2-user</code> used in this document with <code>admin</code>.</p> </li> </ol>"},{"location":"setting-up/server/aws.html#resizing-the-ebs-volume","title":"Resizing the EBS Volume","text":"<p>Your AWS instance comes with a predefined size which can become a limitation. To make more disk space available to your instance, you need to increase the size of the EBS volume as needed and then your instance will reconfigure itself to use the new size.</p> <p>The procedure of resizing EBS volumes is described in the Amazon documentation: Modifying the Size, IOPS, or Type of an EBS Volume on Linux.</p> <p>After the EBS volume is updated, PMM Server instance will auto-detect changes in approximately 5 minutes or less and will reconfigure itself for the updated conditions.</p>"},{"location":"setting-up/server/aws.html#upgrading-pmm-server-on-aws","title":"Upgrading PMM Server on AWS","text":""},{"location":"setting-up/server/aws.html#change-public-ip-address","title":"Change Public IP address","text":"<p>To assign a public IP address for an Amazon EC2 instance, follow these steps:</p> <ol> <li> <p>Allocate Elastic IP address</p> <p></p> </li> <li> <p>Associate Elastic IP address with a Network interface ID of your EC2 instance</p> <p>If you associate an Elastic IP address to an instance that already has an Elastic IP address associated, this previously associated Elastic IP address will be disassociated but still allocated to your account.</p> <p></p> </li> </ol>"},{"location":"setting-up/server/aws.html#upgrading-ec2-instance-class","title":"Upgrading EC2 instance class","text":"<p>Upgrading to a larger EC2 instance class is supported by PMM provided you follow the instructions from the AWS manual. The PMM AMI image uses a distinct EBS volume for the PMM data volume which permits independent resizing of the EC2 instance without impacting the EBS volume.</p> <ol> <li> <p>Open the Amazon EC2 console.</p> </li> <li> <p>In the navigation pane, choose PMM Server Instances.</p> </li> <li> <p>Select the instance and choose Actions, Instance state, Stop instance.</p> </li> <li> <p>In the Change instance type dialog box, select the instance type that you want.</p> <p></p> </li> <li> <p>Choose Apply to accept the new settings and start the stopped instance.</p> </li> </ol>"},{"location":"setting-up/server/aws.html#expanding-the-pmm-data-ebs-volume","title":"Expanding the PMM Data EBS Volume","text":"<p>The PMM data volume is mounted as an XFS formatted volume on top of an LVM volume. There are two ways to increase this volume size:</p> <ol> <li> <p>Add a new disk via EC2 console or API, and expand the LVM volume to include the new disk volume.</p> </li> <li> <p>Expand existing EBS volume and grow the LVM volume.</p> </li> </ol>"},{"location":"setting-up/server/aws.html#expand-existing-ebs-volume","title":"Expand existing EBS volume","text":"<p>To expand the existing EBS volume for increased capacity, follow these steps.</p> <ol> <li> <p>Expand the disk from AWS Console/CLI to the desired capacity.</p> </li> <li> <p>Login to the PMM EC2 instance and verify that the disk capacity has increased. For example, if you have expanded your disk from 16G to 32G, <code>dmesg</code> output should look like below:</p> <pre><code>[  535.994494] xvdb: detected capacity change from 17179869184 to 34359738368\n</code></pre> </li> <li> <p>You can check information about volume groups and logical volumes with the <code>vgs</code> and <code>lvs</code> commands:</p> <pre><code>vgs\n</code></pre> <pre><code>VG     #PV #LV #SN Attr   VSize  VFree\nDataVG   1   2   0 wz--n- &lt;16.00g    0\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.74\nThinPool DataVG twi-aotz--  15.96g 1.39  1.29\n</code></pre> </li> <li> <p>Now we can use the <code>lsblk</code> command to see that our disk size has been identified by the kernel correctly, but LVM2 is not yet aware of the new size. We can use <code>pvresize</code> to make sure the PV device reflects the new size. Once <code>pvresize</code> is executed, we can see that the VG has the new free space available.</p> <pre><code>lsblk | grep xvdb\n</code></pre> <pre><code>xvdb                      202:16 0 32G 0 disk\n</code></pre> <pre><code>pvscan\n</code></pre> <pre><code>PV /dev/xvdb   VG DataVG    lvm2 [&lt;16.00 GiB / 0    free]\nTotal: 1 [&lt;16.00 GiB] / in use: 1 [&lt;16.00 GiB] / in no VG: 0 [0   ]\n</code></pre> <pre><code>pvresize /dev/xvdb\n</code></pre> <pre><code>Physical volume \"/dev/xvdb\" changed\n1 physical volume(s) resized / 0 physical volume(s) not resized\n</code></pre> <pre><code>pvs\n</code></pre> <pre><code>PV         VG     Fmt  Attr PSize   PFree\n/dev/xvdb  DataVG lvm2 a--  &lt;32.00g 16.00g\n</code></pre> </li> <li> <p>We then extend our logical volume. Since the PMM image uses thin provisioning, we need to extend both the pool and the volume:</p> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  15.96g                 1.42   1.32\n</code></pre> <pre><code>lvextend /dev/mapper/DataVG-ThinPool -l 100%VG\n</code></pre> <pre><code>Size of logical volume DataVG/ThinPool_tdata changed from 16.00 GiB (4096 extents) to 31.96 GiB (8183 extents).\nLogical volume DataVG/ThinPool_tdata successfully resized.\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> </li> <li> <p>Once the pool and volumes have been extended, we need to now extend the thin volume to consume the newly available space. In this example we\u2019ve grown available space to almost 32GB, and already consumed 12GB, so we\u2019re extending an additional 19GB:</p> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> <pre><code>lvextend /dev/mapper/DataVG-DataLV -L +19G\n</code></pre> <pre><code>Size of logical volume DataVG/DataLV changed from &lt;12.80 GiB (3276 extents) to &lt;31.80 GiB (8140 extents).\nLogical volume DataVG/DataLV successfully resized.\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;31.80g ThinPool        0.71\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> </li> <li> <p>We then expand the XFS file system to reflect the new size using <code>xfs_growfs</code>, and confirm the file system is accurate using the <code>df</code> command.</p> <pre><code>df -h /srv\n</code></pre> <pre><code>Filesystem                  Size Used Avail Use% Mounted on\n/dev/mapper/DataVG-DataLV    13G 249M   13G   2% /srv\n</code></pre> <pre><code>xfs_growfs /srv\n</code></pre> <pre><code>meta-data=/dev/mapper/DataVG-DataLV isize=512    agcount=103, agsize=32752 blks\n         =                          sectsz=512   attr=2, projid32bit=1\n         =                          crc=1        finobt=0 spinodes=0\ndata     =                          bsize=4096   blocks=3354624, imaxpct=25\n         =                          sunit=16     swidth=16 blks\nnaming   =version 2                 bsize=4096   ascii-ci=0 ftype=1\nlog      =internal                  bsize=4096   blocks=768, version=2\n         =                          sectsz=512   sunit=16 blks, lazy-count=1\nrealtime =none                      extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 3354624 to 8335360\n</code></pre> <pre><code>df -h /srv\n</code></pre> <pre><code>Filesystem                 Size Used Avail Use% Mounted on\n/dev/mapper/DataVG-DataLV   32G 254M   32G   1% /srv\n</code></pre> </li> </ol>"},{"location":"setting-up/server/aws.html#expand-the-amazon-ebs-root-volume","title":"Expand the Amazon EBS root volume","text":"<ol> <li> <p>Expand the disk from AWS Console/CLI to the desired capacity.</p> </li> <li> <p>Login to the PMM EC2 instance and verify that the disk capacity has increased. For example, if you have expanded disk from 8G to 10G, <code>dmesg</code> output should look like below:</p> <pre><code># dmesg | grep \"capacity change\"\n[63175.044762] nvme0n1: detected capacity change from 8589934592 to 10737418240\n</code></pre> </li> <li> <p>Use the <code>lsblk</code> command to see that our disk size has been identified by the kernel correctly, but LVM2 is not yet aware of the new size.</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0     8G  0 part /\n...\n</code></pre> </li> <li> <p>For volumes that have a partition, such as the root volume shown in the previous step, use the <code>growpart</code> command to extend the partition.</p> <pre><code># growpart /dev/nvme0n1 1\nCHANGED: partition=1 start=2048 old: size=16775168 end=16777216 new: size=20969439 end=20971487\n</code></pre> </li> <li> <p>To verify that the partition reflects the increased volume size, use the <code>lsblk</code> command again.</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0    10G  0 part /\n...\n</code></pre> </li> <li> <p>Extend the XFS file system on the root volume by <code>xfs_growfs</code> command. I</p> <pre><code># xfs_growfs -d /\nmeta-data=/dev/nvme0n1p1         isize=512    agcount=4, agsize=524224 blks\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0 spinodes=0\ndata     =                       bsize=4096   blocks=2096896, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal               bsize=4096   blocks=2560, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 2096896 to 2621120\n</code></pre> </li> <li> <p>Verify that file system reflects the increased volume size</p> <pre><code># df -hT /\nFilesystem     Type  Size  Used Avail Use% Mounted on\n/dev/nvme0n1p1 xfs    10G  5,6G  4,5G  56% /\n</code></pre> </li> </ol>"},{"location":"setting-up/server/aws.html#backup-pmm-server","title":"Backup PMM Server","text":"<p>All data are stored in the <code>/srv</code> partition, so it\u2019s enough to back the PMM data volume. You can create a point-in-time snapshot of the volume and use it for data backup.</p> <p>The procedure of creating a snapshot is described in the Amazon documentation: Create Amazon EBS snapshots</p> <p></p>"},{"location":"setting-up/server/aws.html#restore-pmm-server-from-a-backup","title":"Restore PMM Server from a backup","text":"<ol> <li> <p>Create a new volume by using the latest snapshot of the PMM data volume.</p> <p></p> </li> <li> <p>Stop the PMM Server instance.</p> </li> <li> <p>Detach the current PMM data volume.</p> <p></p> </li> <li> <p>Attach the new volume.</p> <p></p> </li> <li> <p>Start the PMM Server instance.</p> </li> </ol>"},{"location":"setting-up/server/aws.html#remove-pmm-server","title":"Remove PMM Server","text":"<ol> <li> <p>Find the instance in the EC2 Console</p> <p></p> </li> <li> <p>Select \u201cInstance state\u201d menu and \u201cTerminate instance\u201d</p> <p></p> </li> <li> <p>Confirm termination operation</p> <p></p> </li> </ol> <p>See also</p> <ul> <li>Improving Percona Monitoring and Management EC2 Instance Resilience Using CloudWatch Alarm Actions </li> <li>Simplify the Use of ENV Variables in Percona Monitoring and Management AMI</li> </ul>"},{"location":"setting-up/server/docker.html","title":"Docker","text":"<p>How to run PMM Server with Docker based on our Docker image.</p> <p>The tags used here are for the current release. Other tags are available.</p> <p>See also</p> <p>Easy-install script</p>"},{"location":"setting-up/server/docker.html#before-you-start","title":"Before you start","text":"<ul> <li>Install Docker 1.12.6 or higher.</li> <li>For PMM 2.38.0 or greater, ensure your CPU (and any virtualization layer you may be using) supports <code>x86-64-v2</code></li> </ul>"},{"location":"setting-up/server/docker.html#run","title":"Run","text":"<p>Summary</p> <ul> <li>Pull the Docker image.</li> <li>Copy it to create a persistent data container.</li> <li>Run the image.</li> <li>Open the PMM UI in a browser.</li> </ul> <p>You can store data from your PMM in:</p> <ol> <li>Docker volume (Preffered method)</li> <li>Data container</li> <li>Host directory</li> </ol>"},{"location":"setting-up/server/docker.html#run-docker-with-volume","title":"Run Docker with volume","text":"<ol> <li> <p>Pull the image.</p> <pre><code>docker pull percona/pmm-server:2\n</code></pre> </li> <li> <p>Create a volume:</p> <pre><code>docker volume create pmm-data\n</code></pre> </li> <li> <p>Run the image:</p> <pre><code>docker run --detach --restart always \\\n--publish 443:443 \\\n-v pmm-data:/srv \\\n--name pmm-server \\\npercona/pmm-server:2\n</code></pre> </li> <li> <p>Change the password for the default <code>admin</code> user.</p> <ul> <li>For PMM versions 2.27.0 and later:</li> </ul> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> <ul> <li>For PMM versions prior to 2.27.0:</li> </ul> <pre><code>docker exec -t pmm-server bash -c 'grafana-cli --homepath /usr/share/grafana --configOverrides cfg:default.paths.data=/srv/grafana admin reset-admin-password newpass'\n</code></pre> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. (If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol>"},{"location":"setting-up/server/docker.html#run-docker-with-data-container","title":"Run Docker with data container","text":"<ol> <li> <p>Create a persistent data container.</p> <pre><code>docker create --volume /srv \\\n--name pmm-data \\\npercona/pmm-server:2 /bin/true\n</code></pre> <p>Important</p> <p>PMM Server expects the data volume to be <code>/srv</code>. Using any other value will result in data loss when upgrading.</p> <p>To check server and data container mount points:</p> <pre><code>docker inspect pmm-data | grep Destination &amp;&amp; \\\ndocker inspect pmm-server | grep Destination\n</code></pre> </li> <li> <p>Run the image.</p> <pre><code>docker run --detach --restart always \\\n--publish 443:443 \\\n--volumes-from pmm-data \\\n--name pmm-server \\\npercona/pmm-server:2\n</code></pre> </li> <li> <p>Change the password for the default <code>admin</code> user.</p> <ul> <li>For PMM versions 2.27.0 and later:</li> </ul> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> <ul> <li> <p>For PMM versions prior to 2.27.0:</p> <pre><code>docker exec -t pmm-server bash -c 'grafana-cli --homepath /usr/share/grafana --configOverrides cfg:default.paths.data=/srv/grafana admin reset-admin-password newpass'\n</code></pre> </li> </ul> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. (If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol>"},{"location":"setting-up/server/docker.html#run-docker-with-the-host-directory","title":"Run Docker with the host directory","text":"<p>Availability</p> <p>This feature is available starting with PMM 2.29.0.</p> <ol> <li> <p>Pull the image.</p> <pre><code>docker pull percona/pmm-server:2\n</code></pre> </li> <li> <p>Run the image.</p> <p><pre><code>export DATA_DIR=$HOME/srv\ndocker run -v $DATA_DIR/srv:/srv -d --restart always --publish 80:80 --publish 443:443 --name pmm-server percona/pmm-server:2\n</code></pre> <code>DATA_DIR</code> is a directory where you want to store the state for PMM.</p> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. (If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol>"},{"location":"setting-up/server/docker.html#migrate-from-data-container-to-host-directoryvolume","title":"Migrate from data container to host directory/volume","text":"<p>To migrate your PMM from data container to host directory or volume run the following command: <pre><code>docker cp &lt;containerId&gt;:/srv /target/host/directory\n</code></pre></p>"},{"location":"setting-up/server/docker.html#backup","title":"Backup","text":"<p>Summary</p> <ul> <li>Stop and rename the <code>pmm-server</code> container.</li> <li>Take a local copy of the <code>pmm-data</code> container\u2019s <code>/srv</code> directory.</li> </ul> <p>Important</p> <p>Grafana plugins have been moved to the data volume <code>/srv</code> since the 2.23.0 version. So if you are upgrading PMM from any version before 2.23.0 and have installed additional plugins then plugins should be installed again after the upgrade.</p> <p>To check used grafana plugins:</p> <pre><code>docker exec -it pmm-server ls /var/lib/grafana/plugins\n</code></pre> <ol> <li> <p>Stop the container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Move the image.</p> <pre><code>docker rename pmm-server pmm-server-backup\n</code></pre> </li> <li> <p>Create a subdirectory (e.g., <code>pmm-data-backup</code>) and move to it.</p> <pre><code>mkdir pmm-data-backup &amp;&amp; cd pmm-data-backup\n</code></pre> </li> <li> <p>Backup the data.</p> <pre><code>docker cp pmm-data:/srv .\n</code></pre> </li> </ol>"},{"location":"setting-up/server/docker.html#upgrade","title":"Upgrade","text":"<p>Summary</p> <ul> <li>Stop the running container.</li> <li>Backup (rename) the container and copy data.</li> <li>Pull the latest Docker image.</li> <li>Run it.</li> </ul> <p>Important</p> <p>Downgrades are not possible. To go back to using a previous version you must have created a backup of it before upgrading.</p> <p>Tip</p> <p>To see what release you are running, use the PMM Upgrade panel on the Home Dashboard, or run:</p> <pre><code>docker exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> <p>(If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> <ol> <li> <p>Stop the container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Perform a backup.</p> </li> <li> <p>Pull the latest image.</p> <pre><code>docker pull percona/pmm-server:2\n</code></pre> </li> <li> <p>Rename the original container</p> <pre><code>docker rename pmm-server pmm-server-old\n</code></pre> </li> <li> <p>Run it.</p> <pre><code>docker run \\\n--detach \\\n--restart always \\\n--publish 443:443 \\\n--volumes-from pmm-data \\\n--name pmm-server \\\npercona/pmm-server:2\n</code></pre> </li> </ol>"},{"location":"setting-up/server/docker.html#restore","title":"Restore","text":"<p>Summary</p> <ul> <li>Stop and remove the container.</li> <li>Restore (rename) the backup container.</li> <li>Restore saved data to the data container.</li> <li>Restore permissions to the data.</li> </ul> <p>Important</p> <p>You must have a backup to restore from.</p> <ol> <li> <p>Stop the container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove it.</p> <pre><code>docker rm pmm-server\n</code></pre> </li> <li> <p>Revert to the saved image.</p> <pre><code>docker rename pmm-server-backup pmm-server\n</code></pre> </li> <li> <p>Change directory to the backup directory (e.g. <code>pmm-data-backup</code>).</p> </li> <li> <p>Remove Victoria Metrics data folder.</p> <pre><code>docker run --rm --volumes-from pmm-data -it percona/pmm-server:2 rm -r /srv/victoriametrics/data\n</code></pre> </li> <li> <p>Copy the data.</p> <pre><code>docker cp srv pmm-data:/\n</code></pre> </li> <li> <p>Restore permissions.</p> <pre><code>docker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R root:root /srv &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R pmm:pmm /srv/alertmanager &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R root:pmm /srv/clickhouse &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R grafana:grafana /srv/grafana &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R pmm:pmm /srv/logs &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R postgres:postgres /srv/postgres14 &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R pmm:pmm /srv/prometheus &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R pmm:pmm /srv/victoriametrics &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it percona/pmm-server:2 chown -R postgres:postgres /srv/logs/postgresql14.log\n</code></pre> </li> <li> <p>Start the image.</p> <pre><code>docker start pmm-server\n</code></pre> </li> </ol>"},{"location":"setting-up/server/docker.html#remove","title":"Remove","text":"<p>Summary</p> <ul> <li>Stop the container.</li> <li>Remove (delete) both the server and data containers.</li> <li>Remove (delete) both images.</li> </ul> <p>Caution</p> <p>These steps delete the PMM Server Docker image and any accumulated PMM metrics data.</p> <ol> <li> <p>Stop pmm-server container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove containers.</p> <pre><code>docker rm pmm-server pmm-data\n</code></pre> </li> <li> <p>Remove the image.</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-server\" | awk {'print $3'})\n</code></pre> </li> </ol>"},{"location":"setting-up/server/docker.html#environment-variables","title":"Environment variables","text":"<p>Use the following Docker container environment variables (with <code>-e var=value</code>) to set PMM Server parameters.</p> Variable  \u00a0 \u00a0 \u00a0 \u00a0 Description <code>DISABLE_UPDATES</code> Disables a periodic check for new PMM versions as well as ability to apply upgrades using the UI <code>DISABLE_TELEMETRY</code> Disable built-in telemetry and disable STT if telemetry is disabled. <code>METRICS_RESOLUTION</code> High metrics resolution in seconds. <code>METRICS_RESOLUTION_HR</code> High metrics resolution (same as above). <code>METRICS_RESOLUTION_MR</code> Medium metrics resolution in seconds. <code>METRICS_RESOLUTION_LR</code> Low metrics resolution in seconds. <code>DATA_RETENTION</code> The number of days to keep time-series data. N.B. This must be set in a format supported by <code>time.ParseDuration</code>  and represent the complete number of days.  The supported units are <code>ns</code>, <code>us</code> (or <code>\u00b5s</code>), <code>ms</code>, <code>s</code>, <code>m</code>, and <code>h</code>.  The value must be a multiple of 24, e.g., for 90 days 2160h (90 * 24). <code>ENABLE_VM_CACHE</code> Enable cache in VM. <code>DISABLE_ALERTING</code> Disables built-in Percona Alerting, which is enabled by default. <code>ENABLE_AZUREDISCOVER</code> Enable support for discovery of Azure databases. <code>DISABLE_BACKUP_MANAGEMENT</code> Disables Backup Management, which is enabled by default. <code>ENABLE_DBAAS</code> Enable DBaaS features. <code>PMM_DEBUG</code> Enables a more verbose log level. <code>PMM_TRACE</code> Enables a more verbose log level including trace-back information. <code>PMM_PUBLIC_ADDRESS</code> External IP address or the DNS name on which PMM server is running. <p>The following variables are also supported but values passed are not verified by PMM. If any other variable is found, it will be considered invalid and the server won\u2019t start.</p> Variable Description <code>_</code>, <code>HOME</code>, <code>HOSTNAME</code>, <code>LANG</code>, <code>PATH</code>, <code>PWD</code>, <code>SHLVL</code>, <code>TERM</code> Default environment variables. <code>GF_*</code> Grafana environment variables. <code>VM_*</code> VictoriaMetrics\u2019 environment variables. Note that environment variables inherit their names from the command line flags. To find out which variables are available to you, see the full list of CLI command flags. <p>| <code>SUPERVISOR_</code>                                                   | <code>supervisord</code> environment variables. | <code>KUBERNETES_</code>                                                   | Kubernetes environment variables. | <code>MONITORING_</code>                                                   | Kubernetes monitoring environment variables. | <code>PERCONA_TEST_</code>                                                 | Unknown variable but won\u2019t prevent the server starting. | <code>PERCONA_TEST_DBAAS</code>                                            | Deprecated. Use <code>ENABLE_DBAAS</code>.</p>"},{"location":"setting-up/server/docker.html#preview-environment-variables","title":"Preview environment variables","text":"<p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production.</p> Variable Description <code>PERCONA_TEST_SAAS_HOST</code> SaaS server hostname. <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> Name of the host and port of the external ClickHouse database instance. <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> Database name of the external ClickHouse database instance. <code>\u200b\u200bPERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> The maximum number of threads in the current connection thread pool. This value cannot be bigger than max_thread_pool_size. <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> The number of rows to load from tables in one block for this connection."},{"location":"setting-up/server/docker.html#tips","title":"Tips","text":"<ul> <li> <p>To Disable the Home Dashboard PMM Upgrade panel you can either add <code>-e DISABLE_UPDATES=true</code> to the <code>docker run</code> command (for the life of the container) or navigate to PMM \u2192 PMM Settings \u2192 Advanced Settings and disable \u201cCheck for Updates\u201d (can be turned back on by any admin in the UI).</p> </li> <li> <p>Eliminate browser certificate warnings by configuring a trusted certificate.</p> </li> <li> <p>You can optionally enable an (insecure) HTTP connection by adding <code>--publish 80:80</code> to the <code>docker run</code> command. However, running PMM insecure is not recommended. You should also note that PMM Client requires TLS to communicate with the server, only working on a secure port.</p> </li> </ul>"},{"location":"setting-up/server/docker.html#isolated-hosts","title":"Isolated hosts","text":"<p>If the host where you will run PMM Server has no internet connection, you can download the Docker image on a separate (internet-connected) host and securely copy it.</p> <ol> <li> <p>On an internet-connected host, download the Docker image and its checksum file.</p> <pre><code>wget https://downloads.percona.com/downloads/pmm2/2.44.0/docker/pmm-server-2.44.0.docker\nwget https://downloads.percona.com/downloads/pmm2/2.44.0/docker/pmm-server-2.44.0.sha256sum\n</code></pre> </li> <li> <p>Copy both files to where you will run PMM Server.</p> </li> <li> <p>Open a terminal on the PMM Server host.</p> </li> <li> <p>(Optional) Check the Docker image file integrity.</p> <pre><code>shasum -ca 256 pmm-server-2.44.0.sha256sum\n</code></pre> </li> <li> <p>Load the image.</p> <pre><code>docker load -i pmm-server-2.44.0.docker\n</code></pre> </li> <li> <p>Run the container as if your image is already pulled using your desired method for a storage volume (you can step over any docker pull commands as the image has been pre-staged).</p> </li> </ol>"},{"location":"setting-up/server/easy-install.html","title":"Easy-install script","text":"<p>Caution</p> <p>You can download and check <code>get-pmm.sh</code> before running it from our github:</p>"},{"location":"setting-up/server/easy-install.html#linux-or-macos","title":"Linux or macOS","text":"<p>Using <code>curl</code>: <pre><code>curl -fsSL https://www.percona.com/get/pmm | /bin/bash\n</code></pre></p> <p>Using <code>wget</code>:  <pre><code>wget -O - https://www.percona.com/get/pmm | /bin/bash\n</code></pre></p> <p>This script:</p> <ul> <li>Installs Docker if it is not already installed on your system.</li> <li>Stops and renames any currently running PMM Server Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old pmm-server container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Server Docker image.</li> <li>Can run in Interactive mode to change the default settings: <pre><code>curl -fsSLO https://www.percona.com/get/pmm (or wget https://www.percona.com/get/pmm)\nchmod +x pmm\n./pmm --interactive\n</code></pre></li> </ul>"},{"location":"setting-up/server/helm.html","title":"Helm","text":"<p>Helm is the package manager for Kubernetes. Percona Helm charts can be found in percona/percona-helm-charts repository on Github.</p>"},{"location":"setting-up/server/helm.html#before-you-start","title":"Before you start","text":"<ul> <li>Install Helm following its official installation instructions.</li> <li>Kubernetes cluster that Helm supports</li> </ul> <p>Helm v3 is needed to run the following steps.</p> <p>Refer to Kubernetes Supported versions and Helm Version Support Policy to find the supported versions.</p> <p>PMM should be platform-agnostic, but it requires escalated privileges inside a container. It is necessary to have a <code>root</code> user inside the PMM container. Thus, PMM would not work for Kubernetes Platforms such as OpenShift or others that have hardened Security Context Constraints, for example:</p> <ul> <li>Security context constraints (SCCs) </li> <li>Managing security context constraints</li> </ul> <p>Kubernetes platforms offer a different set of capabilities. To use PMM in production, you would need backups and, thus storage driver that supports snapshots. Consult your provider for Kubernetes and Cloud storage capabilities.</p>"},{"location":"setting-up/server/helm.html#locality-and-availability","title":"Locality and Availability","text":"<p>You should not run the PMM monitoring server along with the monitored database clusters and services on the same system.</p> <p>Please ensure proper locality either by physically separating workloads in Kubernetes clusters or running separate Kubernetes clusters for the databases and monitoring workloads.</p> <p>You can physically separate workloads by properly configuring Kubernetes nodes, affinity rules, label selections, etc.</p> <p>Also, ensure that the Kubernetes cluster has high availability so that in case of a node failure, the monitoring service will be running and capturing the required data.</p>"},{"location":"setting-up/server/helm.html#use-helm-to-install-pmm-server-on-kubernetes-clusters","title":"Use Helm to install PMM server on Kubernetes clusters","text":"<p>Availability</p> <p>This feature is available starting with PMM 2.29.0.</p> <p>Summary</p> <ul> <li>Setup PMM admin password</li> <li>Install</li> <li>Configuration parameters</li> <li>PMM environment variables</li> <li>PMM SSL certificates</li> <li>Backup</li> <li>Upgrade</li> <li>Restore</li> <li>Uninstall</li> </ul>"},{"location":"setting-up/server/helm.html#setup-pmm-admin-password","title":"Setup PMM admin password","text":"<p>Create Kubernetes secret with PMM admin password: <pre><code>cat &lt;&lt;EOF | kubectl create -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: pmm-secret\n  labels:\n    app.kubernetes.io/name: pmm\ntype: Opaque\ndata:\n# base64 encoded password\n# encode some password: `echo -n \"admin\" | base64`\n  PMM_ADMIN_PASSWORD: YWRtaW4=\nEOF\n</code></pre></p> <p>To get admin password execute:</p> <pre><code>kubectl get secret pmm-secret -o jsonpath='{.data.PMM_ADMIN_PASSWORD}' | base64 --decode\n</code></pre>"},{"location":"setting-up/server/helm.html#install","title":"Install","text":"<p>To install the chart with the release name <code>pmm</code>:</p> <p><pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\nhelm install pmm \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\npercona/pmm\n</code></pre> The command deploys PMM on the Kubernetes cluster in the default configuration and specified secret. The Parameters section lists the parameters that can be configured during installation.</p> <pre><code>helm uninstall pmm\n</code></pre> <p>Tip</p> <p>List all releases using <code>helm list</code>.</p>"},{"location":"setting-up/server/helm.html#parameters","title":"Parameters","text":"<p>The list of Parameters is subject to change from release to release. Check the Parameters section of the PMM Helm Chart.</p> <p>Tip</p> <p>You can list the default parameters values.yaml or get them from chart definition: <code>helm show values percona/pmm</code></p> <p>Specify each parameter using the <code>--set key=value[,key=value]</code> or <code>--set-string key=value[,key=value]</code> arguments to <code>helm install</code>. For example,</p> <pre><code>helm install pmm \\\n--set secret.create=false --set secret.name=pmm-secret \\\n--set-string pmmEnv.DISABLE_UPDATES=\"1\" \\\n--set service.type=\"NodePort\" \\\n--set storage.storageClassName=\"linode-block-storage-retain\" \\\n    percona/pmm\n</code></pre> <p>The command above installs PMM, configuring the service network type as <code>NodePort</code> and setting the storage class to <code>linode-block-storage-retain</code> for persistent storage on LKE.```</p> <pre><code>helm uninstall pmm\n</code></pre> <p>Important</p> <p>Once this chart is deployed, it is impossible to change the application\u2019s access credentials, such as password, using Helm. To change these application credentials after deployment, delete any persistent volumes (PVs) used by the chart and re-deploy it, or use the application\u2019s built-in administrative tools (if available)</p> <p>Alternatively, a YAML file that specifies the values for the above parameters can be provided while installing the chart. For example:</p> <pre><code>helm show values percona/pmm &gt; values.yaml\n\n#change needed parameters in values.yaml, you need `yq` tool pre-installed\nyq -i e '.secret.create |= false' values.yaml\n\nhelm install pmm -f values.yaml percona/pmm\n</code></pre>"},{"location":"setting-up/server/helm.html#pmm-environment-variables","title":"PMM environment variables","text":"<p>In case you want to add extra environment variables (useful for advanced operations like custom init scripts), you can use the <code>pmmEnv</code> property.</p> <pre><code>pmmEnv:\n  DISABLE_UPDATES: \"1\"\n</code></pre>"},{"location":"setting-up/server/helm.html#pmm-ssl-certificates","title":"PMM SSL certificates","text":"<p>PMM ships with self signed SSL certificates to provide secure connection between client and server (check here).</p> <p>You will see the warning when connecting to PMM. To further increase security, you should provide your certificates and add values of credentials to the fields of the <code>cert</code> section:</p> <pre><code>certs:\n  name: pmm-certs\n  files:\n    certificate.crt: &lt;content&gt;\n    certificate.key: &lt;content&gt;\n    ca-certs.pem: &lt;content&gt;\n    dhparam.pem: &lt;content&gt;\n</code></pre> <p>Another approach to set up TLS certificates is to use the Ingress controller, see TLS. PMM helm chart supports Ingress. See PMM network configuration.</p>"},{"location":"setting-up/server/helm.html#backup","title":"Backup","text":"<p>PMM helm chart uses PersistentVolume and PersistentVolumeClaim to allocate storage in the Kubernetes cluster.</p> <p>Volumes could be pre-provisioned and dynamic. PMM chart supports both and exposes it through PMM storage configuration.</p> <p>Backups for the PMM server currently support only storage layer backups and thus require StorageClass and VolumeSnapshotClass.</p> <p>Validate the correct configuration by using these commands: <pre><code>kubectl get sc\nkubectl get volumesnapshotclass\n</code></pre></p> <p>Storage</p> <p>Storage configuration is Hardware and Cloud specific. There could be additional costs associated with Volume Snapshots. Check the documentation for your Cloud or for your Kubernetes cluster.</p> <p>Before taking a VolumeSnapshot, stop the PMM server. In this step, we will stop PMM (scale to 0 pods), take a snapshot, wait until the snapshot completes, then start PMM server (scale to 1 pod): <pre><code>kubectl scale statefulset pmm --replicas=0\nkubectl wait --for=jsonpath='{.status.replicas}'=0 statefulset pmm\n\ncat &lt;&lt;EOF | kubectl create -f -\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: before-v2.34.0-upgrade\n  labels:\n    app.kubernetes.io/name: pmm\nspec:\n  volumeSnapshotClassName: csi-hostpath-snapclass\n  source:\n    persistentVolumeClaimName: pmm-storage-pmm-0\nEOF\n\nkubectl wait --for=jsonpath='{.status.readyToUse}'=true VolumeSnapshot/before-v2.34.0-upgrade\nkubectl scale statefulset pmm --replicas=1\n</code></pre></p> <p>Output: <pre><code>statefulset.apps/pmm scaled\nstatefulset.apps/pmm condition met\nvolumesnapshot.snapshot.storage.k8s.io/before-v2.34.0-upgrade created\nvolumesnapshot.snapshot.storage.k8s.io/before-v2.34.0-upgrade condition met\nstatefulset.apps/pmm scaled\n</code></pre></p> <p>PMM scale</p> <p>Only one replica set is currently supported.</p> <p>You can view available snapshots by executing the following command: <pre><code>kubectl get volumesnapshot\n</code></pre></p>"},{"location":"setting-up/server/helm.html#upgrades","title":"Upgrades","text":"<p>Percona will release a new chart updating its containers if a new version of the main container is available, there are any significant changes, or critical vulnerabilities exist.</p> <p>By default the UI update feature is disabled and should not be enabled. Do not modify that parameter when customizing the <code>values.yaml</code> file:</p> <pre><code>pmmEnv:\n  DISABLE_UPDATES: \"1\"\n</code></pre> <p>Before updating the helm chart, it is recommended to pre-pull the image on the node where PMM is running, as the PMM images could be large and could take time to download.</p> <p>Update PMM as follows:</p> <pre><code>helm repo update percona\nhelm upgrade pmm -f values.yaml percona/pmm\n</code></pre> <p>This will check updates in the repo and upgrade deployment if the updates are available.</p>"},{"location":"setting-up/server/helm.html#restore","title":"Restore","text":"<p>The version of the PMM server should be greater than or equal to the version in a snapshot. To restore from the snapshot, delete the old deployment first: <pre><code>helm uninstall pmm\n</code></pre></p> <p>And then use snapshot configuration to start the PMM server again with the correct version and correct storage configuration: <pre><code>helm install pmm \\\n--set image.tag=\"2.34.0\" \\\n--set storage.name=\"pmm-storage-old\" \\\n--set storage.dataSource.name=\"before-v2.34.0-upgrade\" \\\n--set storage.dataSource.kind=\"VolumeSnapshot\" \\\n--set storage.dataSource.apiGroup=\"snapshot.storage.k8s.io\" \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\npercona/pmm\n</code></pre></p> <p>Here, we created a new <code>pmm-storage-old</code> PVC with data from the snapshot. So, there are a couple of PV and PVCs available in a cluster.</p> <pre><code>$ kubectl get pvc\nNAME                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\npmm-storage-old-pmm-0   Bound    pvc-70e5d2eb-570f-4087-9515-edf2f051666d   10Gi       RWO            csi-hostpath-sc   3s\npmm-storage-pmm-0       Bound    pvc-9dbd9160-e4c5-47a7-bd90-bff36fc1463e   10Gi       RWO            csi-hostpath-sc   89m\n\n$ kubectl get pv\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                           STORAGECLASS      REASON   AGE\npvc-70e5d2eb-570f-4087-9515-edf2f051666d   10Gi       RWO            Delete           Bound    default/pmm-storage-old-pmm-0   csi-hostpath-sc            4m50s\npvc-9dbd9160-e4c5-47a7-bd90-bff36fc1463e   10Gi       RWO            Delete           Bound    default/pmm-storage-pmm-0       csi-hostpath-sc            93m\n</code></pre> <p>Delete unneeded PVC when you are sure you don\u2019t need them.</p>"},{"location":"setting-up/server/helm.html#uninstall","title":"Uninstall","text":"<p>To uninstall <code>pmm</code> deployment:</p> <pre><code>helm uninstall pmm\n</code></pre> <p>This command takes a release name and uninstalls the release.</p> <p>It removes all resources associated with the last release of the chart as well as the release history.</p> <p>Helm will not delete PVC, PV, and any snapshots. Those need to be deleted manually.</p> <p>Also, delete PMM <code>Secret</code> if no longer required: <pre><code>kubectl delete secret pmm-secret\n</code></pre></p>"},{"location":"setting-up/server/network.html","title":"Network","text":""},{"location":"setting-up/server/network.html#ports","title":"Ports","text":"<p>This is a list of ports used by the various components of PMM.</p> <p>For PMM to work correctly, your system\u2019s firewall should allow TCP traffic on these ports (UDP is not needed).</p> <p>Ports to expose:</p> PMM component TCP port Direction Description PMM Server 80 both HTTP server, used for gRPC over HTTP and web interface (insecure, use with caution). PMM Server 443 both HTTPS server, used for gRPC over HTTPS and web interface (secure, use of SSL certificates is highly encouraged). <p>Other ports:</p> PMM component TCP port Direction Description PMM Server 7771 both gRPC, used for communication between <code>pmm-agent</code>, <code>pmm-admin</code>. PMM Server 7772 out HTTP1 server, used for older links like <code>logs.zip</code>. PMM Server 7773 out Debugging. <code>pmm-agent</code> 7777 out Default <code>pmm-agent</code> listen port. <code>vm-agent</code> 8428 both VictoriaMetrics port. <code>pmm-agent</code> 42000 - 51999 in Default range for <code>pmm-agent</code> connected agents. <p>Important</p> <p>Depending on your architecture other ports may also need to be exposed. - For <code>pmm-agent</code>, the default listen port is 7777. - The default port range for <code>pmm-agent</code> is large by default to accomodate any architecture size but it can be modified using the <code>--ports-min</code> and <code>--ports-max</code> flags, or modifying the configuration file. In network constraint environments, the range can be reduced to a minimum by allocating at least one port per agent monitored. Learn more about available settings for <code>pmm-agent</code> in Percona PMM-Agent documentation.</p>"},{"location":"setting-up/server/network.html#network-configuration-for-locked-down-environments","title":"Network configuration for locked-down environments","text":"<p>For computers in a locked-down corporate environment without direct access to the Internet, make sure to enable access to Percona Platform services following the instructions in the Percona Platform documentation.</p>"},{"location":"setting-up/server/podman.html","title":"Podman","text":"<p>How to run PMM Server with Podman on our Docker image</p> <p>The tags used here are for the current release (PMM 2.33.0). Other tags are available.</p> <p>See also</p> <p>Docker</p> <p>Podman is an open-source project available on most Linux platforms and resides on GitHub. Podman is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers and container images on your Linux System. </p> <p>Non-privileged users could run containers under the control of Podman.</p> <p>It could be just aliased (<code>alias docker=podman</code>) with docker and work with the same way. All instructions from Docker section also apply here.</p> <p>Percona recommends running PMM as a non-privileged user and running it as part of the SystemD service provided. SystemD service ensures that the service is running and maintains logs and other management features (start, stop, etc.).</p>"},{"location":"setting-up/server/podman.html#before-you-start","title":"Before you start","text":"<ul> <li>Install Podman.</li> <li>Configure rootless  Podman.</li> </ul>"},{"location":"setting-up/server/podman.html#run-as-non-privileged-user-to-start-pmm","title":"Run as non-privileged user to start PMM","text":"<p>Availability</p> <p>This feature is available starting with PMM 2.29.0.</p> <p>Summary</p> <ul> <li>Install.</li> <li>Configure.</li> <li>Enable and Start.</li> <li>Open the PMM UI in a browser.</li> </ul> <ol> <li> <p>Install.</p> <p>Create <code>~/.config/systemd/user/pmm-server.service</code> file:</p> <pre><code>mkdir -p ~/.config/systemd/user/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/systemd/user/pmm-server.service\n[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n\n[Service]\nType=simple\n\n# set environment for this unit\nEnvironment=PMM_PUBLIC_PORT=8443\nEnvironment=PMM_VOLUME_NAME=%N\nEnvironment=PMM_TAG=2.33.0\nEnvironment=PMM_IMAGE=docker.io/percona/pmm-server\nEnvironment=PMM_ENV_FILE=%h/.config/pmm-server/pmm-server.env\n\n# optional env file that could override previous env settings for this unit\nEnvironmentFile=-%h/.config/pmm-server/env\n\nExecStart=/usr/bin/podman run --rm --replace=true --name=%N -p ${PMM_PUBLIC_PORT}:443/tcp --ulimit=host --volume=${PMM_VOLUME_NAME}:/srv --env-file=${PMM_ENV_FILE} --health-cmd=none --health-interval=disable ${PMM_IMAGE}:${PMM_TAG}\nExecStop=/usr/bin/podman stop -t 10 %N\nRestart=on-failure\nRestartSec=20\n\n[Install]\nAlias=%N\nWantedBy=default.target\n\nEOF\n</code></pre> <p>Create <code>~/.config/pmm-server/pmm-server.env</code> file:</p> <pre><code>mkdir -p ~/.config/pmm-server/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/pmm-server/pmm-server.env\n# env file passed to the container\n# full list of environment variables:\n# https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/docker.html#environment-variables\n\n# keep updates disabled\n# do image replacement instead (update the tag and restart the service)\nDISABLE_UPDATES=1\n\n# Enable DBaaS feature\n#ENABLE_DBAAS=1\nEOF\n</code></pre> </li> <li> <p>Configure.</p> <p>There are 2 configuration files: 1.  <code>~/.config/pmm-server/pmm-server.env</code> defines environment variables for PMM Server (PMM parameters like DBaaS feature and etc) 2.  <code>~/.config/pmm-server/env</code> defines environment variables for SystemD service (image tags, repo and etc)</p> <p>SystemD service passes the environment parameters from the <code>pmm-server.env</code>file (in <code>~/.config/pmm-server/pmm-server.env</code>) to PMM. For more information about container environment variables, check Docker Environment.</p> <p>SystemD service uses some environment variables that could be customized if needed:</p> <pre><code>Environment=PMM_PUBLIC_PORT=8443\nEnvironment=PMM_VOLUME_NAME=%N\nEnvironment=PMM_TAG=2.33.0\nEnvironment=PMM_IMAGE=docker.io/percona/pmm-server\n</code></pre> <p>You can override the environment variables by defining them in the file  <code>~/.config/pmm-server/env</code>. For example, to override the path to a custom registry <code>~/.config/pmm-server/env</code>:</p> <pre><code>mkdir -p ~/.config/pmm-server/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/pmm-server/env\nPMM_TAG=2.31.0\nPMM_IMAGE=docker.io/percona/pmm-server\nPMM_PUBLIC_PORT=8443\nEOF\n</code></pre> <p>Important</p> <p>Ensure that you modify PMM_TAG in <code>~/.config/pmm-server/env</code> and update it regularly as Percona cannot update it. It needs to be done by you.</p> </li> <li> <p>Enable and Start.</p> <pre><code>systemctl --user enable --now pmm-server\n</code></pre> </li> <li> <p>Visit <code>https://localhost:8443</code> to see the PMM user interface in a web browser. (If you are accessing host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol> <pre><code>#first pull can take time\nsleep 80\ntimeout 60 podman wait --condition=running pmm-server\n</code></pre>"},{"location":"setting-up/server/podman.html#backup","title":"Backup","text":"<p>Summary</p> <ul> <li>Stop PMM server.</li> <li>Backup the data.</li> </ul> <p>Important</p> <p>Grafana plugins have been moved to the data volume <code>/srv</code> since the 2.23.0 version. So if you are upgrading PMM from any version before 2.23.0 and have installed additional plugins then plugins should be installed again after the upgrade. To check used grafana plugins: <code>podman exec -it pmm-server ls /var/lib/grafana/plugins</code></p> <ol> <li> <p>Stop PMM server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Backup the data.</p> <p> <pre><code>podman wait --condition=stopped pmm-server || true\nsleep 30\n</code></pre> </p> <pre><code>podman volume export pmm-server --output pmm-server-backup.tar\n</code></pre> <p>Important</p> <p>If you changed the default name to <code>PMM_VOLUME_NAME</code> environment variable, use that name after <code>export</code> instead of <code>pmm-server</code> (which is the default volume name).</p> </li> </ol>"},{"location":"setting-up/server/podman.html#upgrade","title":"Upgrade","text":"<p>Summary</p> <ul> <li>Perform a backup.</li> <li>Update PMM tag.</li> <li>Pre-pull image.</li> <li>Run it.</li> </ul> <p>Important</p> <p>You cannot downgrade. To go to a previous version, you must create a backup before upgrading.</p> <p>Tip</p> <p>To see the current release running on your system, use the PMM Upgrade panel on the Home Dashboard, or run:</p> <pre><code>podman exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> <p>(If you are accessing the podman host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> <ol> <li> <p>Perform a backup.</p> </li> <li> <p>Update PMM tag.</p> <p>Edit <code>~/.config/pmm-server/env</code> and create/update with a new tag from latest release:</p> <pre><code>sed -i \"s/PMM_TAG=.*/PMM_TAG=2.33.0/g\" ~/.config/pmm-server/env\n</code></pre> </li> <li> <p>Pre-pull image for faster restart.</p> <p> <pre><code>sed -i \"s/PMM_TAG=.*/PMM_TAG=2.33.0-rc/g\" ~/.config/pmm-server/env\nsed -i \"s|PMM_IMAGE=.*|PMM_IMAGE=docker.io/perconalab/pmm-server|g\" ~/.config/pmm-server/env\n</code></pre> </p> <pre><code>source ~/.config/pmm-server/env\npodman pull ${PMM_IMAGE}:${PMM_TAG}\n</code></pre> </li> <li> <p>Run PMM.</p> <pre><code>systemctl --user restart pmm-server\n</code></pre> </li> </ol> <pre><code>sleep 30\ntimeout 60 podman wait --condition=running pmm-server\n</code></pre>"},{"location":"setting-up/server/podman.html#restore","title":"Restore","text":"<p>Summary</p> <ul> <li>Stop PMM server.</li> <li>Run PMM on the previous image.</li> <li>Restore the volume.</li> <li>Start PMM Server.</li> </ul> <p>Important</p> <p>You must have a backup to restore from. You need to perform restore only if you have issues with upgrade or with the data.</p> <ol> <li> <p>Stop PMM server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Run PMM on the previous image.</p> <p>Edit <code>~/.config/pmm-server/env</code> file:</p> <pre><code>sed -i \"s/PMM_TAG=.*/PMM_TAG=2.31.0/g\" ~/.config/pmm-server/env\n</code></pre> <p>Important</p> <p>X.Y.Z (2.31.0) is the version you used before upgrade and you made Backup with it</p> </li> <li> <p>Restore the volume.</p> <pre><code>podman volume import pmm-server pmm-server-backup.tar\n</code></pre> </li> <li> <p>Start PMM Server.</p> <pre><code>systemctl --user start pmm-server\n</code></pre> <p> sleep 30 timeout 60 podman wait \u2013condition=running pmm-server ``` </p> </li> </ol>"},{"location":"setting-up/server/podman.html#remove","title":"Remove","text":"<p>Summary</p> <ul> <li>Stop PMM server.</li> <li>Remove (delete) volume.</li> <li>Remove (delete) images.</li> </ul> <p>Caution</p> <p>These steps delete the PMM Server Docker image and the associated PMM metrics data.</p> <ol> <li> <p>Stop PMM server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Remove volume.</p> <p> <pre><code>#wait for container to stop\npodman wait --condition=stopped pmm-server || true\nsleep 10\n</code></pre> </p> <pre><code>podman volume rm --force pmm-server\n</code></pre> </li> <li> <p>Remove the PMM images.</p> <pre><code>podman rmi $(podman images | grep \"pmm-server\" | awk {'print $3'})\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html","title":"Virtual Appliance","text":"<p>How to run PMM Server as a virtual machine.</p> <p>Summary</p> <ul> <li>Download and verify the latest OVF file.</li> <li>Import it.</li> <li>Reconfigure network.</li> <li>Start the VM and get IP.</li> <li>Log into PMM UI.</li> <li>(Optional) Change VM root password.</li> <li>(Optional) Set up SSH.</li> <li>(Optional) Set up static IP.</li> </ul> <p>Most steps can be done with either a user interface or on the command line, but some steps can only be done in one or the other. Sections are labelled UI for user interface or CLI for command line instructions.</p>"},{"location":"setting-up/server/virtual-appliance.html#terminology","title":"Terminology","text":"<ul> <li>Host is the desktop or server machine running the hypervisor.</li> <li>Hypervisor is software (e.g. VirtualBox, VMware) that runs the guest OS as a virtual machine.</li> <li>Guest is the CentOS virtual machine that runs PMM Server.</li> </ul>"},{"location":"setting-up/server/virtual-appliance.html#ova-file-details","title":"OVA file details","text":"Item Value Download page https://www.percona.com/downloads/pmm2/2.44.0/ova File name <code>pmm-server-2.44.0.ova</code> VM name <code>PMM2-Server-2024-12-13-N</code> (<code>N</code>=build number)"},{"location":"setting-up/server/virtual-appliance.html#vm-specifications","title":"VM specifications","text":"Component Value OS Oracle Linux 9 (64-bit) CPU 1 Base memory 4096 MB Disks LVM, 2 physical volumes Disk 1 (<code>sda</code>) VMDK (SCSI, 40 GB) Disk 2 (<code>sdb</code>) VMDK (SCSI, 400 GB)"},{"location":"setting-up/server/virtual-appliance.html#users","title":"Users","text":"Default Username Default password <code>root</code> <code>percona</code> <code>admin</code> <code>admin</code>"},{"location":"setting-up/server/virtual-appliance.html#download","title":"Download","text":""},{"location":"setting-up/server/virtual-appliance.html#ui","title":"UI","text":"<ol> <li>Open a web browser.</li> <li>Visit the PMM Server download page.</li> <li>Choose a Version or use the default (the latest).</li> <li>Click the link for <code>pmm-server-2.44.0.ova</code> to download it. Note where your browser saves it.</li> <li>Right-click the link for <code>pmm-server-2.44.0.sha256sum</code> and save it in the same place as the <code>.ova</code> file.</li> <li>(Optional) Verify.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cli","title":"CLI","text":"<p>Download the latest PMM Server OVA and checksum files.</p> <pre><code>wget https://www.percona.com/downloads/pmm2/2.44.0/ova/pmm-server-2.44.0.ova\nwget https://www.percona.com/downloads/pmm2/2.44.0/ova/pmm-server-2.44.0.sha256sum\n</code></pre>"},{"location":"setting-up/server/virtual-appliance.html#verify","title":"Verify","text":""},{"location":"setting-up/server/virtual-appliance.html#cli_1","title":"CLI","text":"<p>Verify the checksum of the downloaded .ova file.</p> <pre><code>shasum -ca 256 pmm-server-2.44.0.sha256sum\n</code></pre>"},{"location":"setting-up/server/virtual-appliance.html#vmware","title":"VMware","text":""},{"location":"setting-up/server/virtual-appliance.html#import","title":"Import","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_1","title":"UI","text":"<ol> <li>Select File \u2192 Import.</li> <li>Click Choose file\u2026.</li> <li>Navigate to the downloaded <code>.ova</code> file and select it.</li> <li>Click Open.</li> <li>Click Continue.</li> <li> <p>In the Save as dialog:</p> <p>a. (Optional) Change the directory or file name.</p> <p>b. Click Save.</p> </li> <li> <p>Choose one of:</p> <ul> <li>(Optional) Click Finish. This starts the virtual machine.</li> <li>(Recommended) Click Customize Settings. This opens the VM\u2019s settings page without starting the machine.</li> </ul> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cli_2","title":"CLI","text":"<ol> <li>Install <code>ovftool</code>. (You need to register.)</li> <li> <p>Import and convert the OVA file. (<code>ovftool</code> can\u2019t change CPU or memory settings during import, but it can set the default interface.)</p> <p>Choose one of:</p> <ul> <li> <p>Download and import the OVA file.</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=Wi-Fi \\\nhttps://www.percona.com/downloads/pmm2/2.44.0/ova/pmm-server-2.44.0.ova \\\npmm-server-2.44.0.vmx\n</code></pre> </li> <li> <p>Import an already-downloaded OVA file.</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=WiFi \\\npmm-server-2.44.0.ova \\\npmm-server.vmx\n</code></pre> </li> </ul> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#reconfigure-interface","title":"Reconfigure interface","text":"<p>When using the command line, the interface is remapped during import.</p>"},{"location":"setting-up/server/virtual-appliance.html#ui_2","title":"UI","text":"<ol> <li>If started, shut down the virtual machine.</li> <li>In the VMware main window, select the imported virtual machine.</li> <li>Click Virtual Machine \u2192 Settings\u2026.</li> <li>Click Network Adapter.</li> <li>In the Bridged Networking section, select Autodetect.</li> <li>Close the settings window.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#start-guest-and-get-ip-address","title":"Start guest and get IP address","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_3","title":"UI","text":"<ol> <li>In the VMware main window, select the imported virtual machine.</li> <li>Click the play button  or select Virtual Machine \u2192 Start Up.</li> <li>When the instance has been booted, note the IP address in the guest console.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cliui","title":"CLI/UI","text":"<ol> <li> <p>Start the virtual machine in GUI mode. (There\u2019s no way to redirect a VMware VM\u2019s console to the host.)</p> <pre><code>vmrun -gu root -gp percona start \\\npmm-server.vmx gui\n</code></pre> </li> <li> <p>When the instance has been booted, note the IP address in the guest console.</p> </li> <li> <p>(Optional) Stop and restart the instance in headless mode.</p> <pre><code>vmrun stop pmm-server.vmx\nvmrun -gu root -gp percona start \\\npmm-server.vmx nogui\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#virtualbox","title":"VirtualBox","text":""},{"location":"setting-up/server/virtual-appliance.html#import_1","title":"Import","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_4","title":"UI","text":"<ol> <li>Select File \u2192 Import appliance\u2026.</li> <li>In the File field, type the path to the downloaded <code>.ova</code> file, or click the folder icon to navigate and open it.</li> <li>Click Continue.</li> <li>On the Appliance settings page, review the settings and click Import.</li> <li>Click Start.</li> <li>When the guest has booted, note the IP address in the guest console.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cli_3","title":"CLI","text":"<ol> <li> <p>Open a terminal and change the directory to where the downloaded <code>.ova</code> file is.</p> </li> <li> <p>(Optional) Do a \u2018dry run\u2019 import to see what values will be used.</p> <pre><code>VBoxManage import pmm-server-2.44.0.ova --dry-run\n</code></pre> </li> <li> <p>Import the image.     Choose one of:</p> <ul> <li> <p>With the default settings.</p> <pre><code>VBoxManage import pmm-server-2.44.0.ova\n</code></pre> </li> <li> <p>With custom settings (in this example, Name: \u201cPMM Server\u201d, CPUs: 2, RAM: 8192 MB).</p> <pre><code>VBoxManage import --vsys 0 --vmname \"PMM Server\" \\\n--cpus 2 --memory 8192 pmm-server-2.44.0.ova\n</code></pre> </li> </ul> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#interface","title":"Interface","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_5","title":"UI","text":"<ol> <li>Click Settings.</li> <li>Click Network.</li> <li>In the Adapter 1 field, click Attached to and change to Bridged Adapter.</li> <li>In the Name field, select your host\u2019s active network interface (e.g. <code>en0: Wi-Fi (Wireless)</code>).</li> <li>Click OK.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cli_4","title":"CLI","text":"<ol> <li> <p>Show the list of available bridge interfaces.</p> <pre><code>VBoxManage list bridgedifs\n</code></pre> </li> <li> <p>Find the name of the active interface you want to bridge to (one with Status: Up and a valid IP address). Example: <code>en0: Wi-Fi (Wireless)</code></p> </li> <li> <p>Bridge the virtual machine\u2019s first interface (<code>nic1</code>) to the host\u2019s <code>en0</code> ethernet adapter.</p> <pre><code>VBoxManage modifyvm 'PMM Server' \\\n--nic1 bridged --bridgeadapter1 'en0: Wi-Fi (Wireless)'\n</code></pre> </li> <li> <p>Redirect the console output into a host file.</p> <pre><code>VBoxManage modifyvm 'PMM Server' \\\n--uart1 0x3F8 4 --uartmode1 file /tmp/pmm-server-console.log\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#get-ip","title":"Get IP","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_6","title":"UI","text":"<ol> <li>Select the PMM Server virtual machine in the list.</li> <li>Click Start.</li> <li>When the guest has booted, note the IP address in the guest console.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#cli_5","title":"CLI","text":"<ol> <li> <p>Start the guest.</p> <pre><code>VBoxManage startvm --type headless 'PMM Server'\n</code></pre> </li> <li> <p>(Optional) Watch the log file.</p> <pre><code>tail -f /tmp/pmm-server-console.log\n</code></pre> </li> <li> <p>Wait for one minute for the server to boot up.</p> </li> <li> <p>Choose one of:</p> <ul> <li>Read the IP address from the tailed log file.</li> <li> <p>Extract the IP address from the log file.</p> <pre><code>grep -e \"^IP:\" /tmp/pmm-server-console.log | cut -f2 -d' '\n</code></pre> </li> </ul> </li> <li> <p>(Optional) Stop the guest:</p> <pre><code>VBoxManage controlvm \"PMM Server\" poweroff\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#log-into-user-interface","title":"Log into user interface","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_7","title":"UI","text":"<ol> <li> <p>Open a web browser and visit the guest IP address.</p> </li> <li> <p>The PMM login screen appears.</p> </li> <li> <p>Enter the default username and password in the relevant fields and click Log in.</p> <ul> <li> <p>username: <code>admin</code></p> </li> <li> <p>password: <code>admin</code></p> </li> </ul> </li> <li> <p>(Recommended) Follow the prompts to change the default password.</p> </li> </ol> <p>You also can change the default password through SSH by using the <code>change-admin-password</code> command.</p> <ol> <li>The PMM Home Dashboard appears.</li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#optional-change-root-password","title":"(Optional) Change root password","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_8","title":"UI","text":"<ol> <li> <p>Start the virtual machine in GUI mode.</p> </li> <li> <p>Log in with the default superuser credentials:</p> <ul> <li> <p>Username: <code>root</code></p> </li> <li> <p>Password: <code>percona</code></p> </li> </ul> </li> <li> <p>Follow the prompts to change the password.</p> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#optional-set-up-ssh","title":"(Optional) Set up SSH","text":""},{"location":"setting-up/server/virtual-appliance.html#uicli","title":"UI/CLI","text":"<ol> <li> <p>Create a key pair for the <code>admin</code> user.</p> <pre><code>ssh-keygen -f admin\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM \u2192 PMM Settings \u2192 SSH Key.</p> </li> <li> <p>Copy and paste the contents of the <code>admin.pub</code> file into the SSH Key field.</p> </li> <li> <p>Click Apply SSH Key. (This copies the public key to <code>/home/admin/.ssh/authorized_keys</code> in the guest).</p> </li> <li> <p>Log in via SSH (<code>N.N.N.N</code> is the guest IP address).</p> <pre><code>ssh -i admin admin@N.N.N.N\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#optional-set-up-static-ip","title":"(Optional) Set up static IP","text":"<p>When the guest OS starts, it will get an IP address from the hypervisor\u2019s DHCP server. This IP can change each time the guest OS is restarted. Setting a static IP for the guest OS avoids having to check the IP address whenever the guest is restarted.</p>"},{"location":"setting-up/server/virtual-appliance.html#cli_6","title":"CLI","text":"<ol> <li> <p>Start the virtual machine in non-headless (GUI) mode.</p> </li> <li> <p>Log in as <code>root</code>.</p> </li> <li> <p>Edit <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code></p> </li> <li> <p>Change the value of <code>BOOTPROTO</code>:</p> <pre><code>BOOTPROTO=none\n</code></pre> </li> <li> <p>Add these values:</p> <pre><code>IPADDR=192.168.1.123 # replace with the desired static IP address\nNETMASK=255.255.255.0 # replace with the netmask for your IP address\nGATEWAY=192.168.1.1 # replace with the network gateway for your IP address\nPEERDNS=no\nDNS1=192.168.1.53 # replace with your DNS server IP\n</code></pre> </li> <li> <p>Restart the interface.</p> <pre><code>ifdown eth0 &amp;&amp; ifup eth0\n</code></pre> </li> <li> <p>Check the IP.</p> <p><pre><code>ip addr show eth0\n</code></pre> 8. Preserve the network configuration across reboots.</p> <pre><code>echo \"network: {config: disabled}\" &gt; /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n</code></pre> </li> </ol>"},{"location":"setting-up/server/virtual-appliance.html#remove","title":"Remove","text":""},{"location":"setting-up/server/virtual-appliance.html#ui_9","title":"UI","text":"<ol> <li> <p>Stop the virtual machine: select Close \u2192 Power Off.</p> </li> <li> <p>Remove the virtual machine: select Remove \u2192 Delete all files.</p> </li> </ol>"}]}