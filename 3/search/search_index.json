{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About PMM","text":"<p> Info: This is the documentation for the latest release, PMM 3.0.0 Beta. See the Release Notes for details.</p> <p>Percona Monitoring and Management (PMM) is an open source database observability, monitoring, and management tool for use with MySQL, PostgreSQL, MongoDB, and the servers on which they run. It enables you to view node- to single-query performance metrics for all of your databases in a single place. </p> <ul> <li>PMM is designed to facilitate seamless access to comprehensive performance metrics for all the nodes and queries associated with your databases via a user-friendly interface.</li> <li>PMM is highly versatile and can be deployed behind a firewall, on the cloud, or across hybrid platforms. </li> <li>It is a complete package comprising in-house and third-party components and tools for all your monitoring requirements.</li> <li>To set up basic PMM, you just need to install a server and a client on each system you intend to monitor.</li> </ul> <p>Would you like to see a preview of our Home page? Take a look at our free, live demo.</p> <p></p>"},{"location":"index.html#discover","title":"Discover","text":"<p>Discover how PMM can help you monitor your systems and make informed decisions.</p> <p>Discover PMM </p>"},{"location":"index.html#install","title":"Install","text":"<p>Ready to dive into PMM? Follow our simple, step-by-step installation instructions to get started in no time!</p> <p>Quickstart guide </p>"},{"location":"index.html#configure","title":"Configure","text":"<p>Are you ready to begin configuring PMM  but need help figuring out how to begin? Let\u2019s dive in together.</p> <p>Configure PMM </p>"},{"location":"index.html#resources","title":"Resources","text":"<p>Looking for reliable and easy-to-use resources to tackle your daily challenges with database monitoring and management?</p> <p>Additional resources </p>"},{"location":"index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"quickstart.html","title":"Get started with PMM","text":"<p>To get up and running with Percona Monitoring and Management (PMM) in no time, install PMM on Bare Metal/Virtual using the Easy-install script for Docker.</p> <p>This is the simplest and most efficient way to install PMM.</p> Alternative installation options <p>For alternative setups, explore the additional installation options detailed in the Setting up chapter:</p> <ul> <li>Deploy on Podman</li> <li>Deploy based on a Docker image</li> <li>Deploy on Virtual Appliance</li> <li>Deploy on Kubernetes via Helm</li> <li>Run a PMM instance hosted at AWS Marketplace</li> </ul>"},{"location":"quickstart.html#prerequisites","title":"Prerequisites","text":"<p>Before you start installing PMM, verify that your system meets the compatibility requirements.</p> Verify system compatibility <ul> <li>Disk: Approximately 1 GB of storage per monitored database node with data retention set to one week. By default, retention is 30 days.</li> <li>Memory: A minimum of 2 GB per monitored database node. The increase in memory usage is not proportional to the number of nodes. For example, the data from 20 nodes should be easily handled with 16 GB.</li> <li>Ports: Your system\u2019s firewall should allow TCP traffic on port 443.</li> </ul>"},{"location":"quickstart.html#install-pmm","title":"Install PMM","text":"<p>The Easy-install script only runs on Linux-compatible systems. To use it, run the command with <code>sudo</code> privileges or as <code>root</code>:</p> <ol> <li> <p>Download and install PMM using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>curl -fsSL https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash\n</code></pre> <pre><code>wget -qO - https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash    \n</code></pre> </li> <li> <p>After the installation is complete, log into PMM with the default <code>admin:admin</code> credentials.</p> </li> </ol> What\u2019s happening under the hood? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not installed on your system.</li> <li>Stops and renames any currently running PMM Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old <code>pmm-server</code> container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Docker image.</li> </ul>"},{"location":"quickstart.html#connect-database","title":"Connect database","text":"<p>Once PMM is set up, choose the database or the application that you want it to monitor:</p>  MySQL PostgreSQL MongoDB ProxySQL HAProxy <p>To connect a self-hosted MySQL database:</p> <ol> <li> <p>Create database account for PMM using the following command example. This creates a database user with name <code>pmm</code>, password <code>&lt;your_password&gt;</code>, and the necessary permissions:</p> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY '&lt;your_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:    </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install the Percona Release Tool.  If this is already, make sure to update it to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version.</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MySQL database using Performance Schema:  </p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> Alternative database connection workflows <p>While the default instructions above focus on connecting a self-hosted MySQL database, PMM offers the flexibility to connect to various MySQL databases, including AWS RDS, Azure MySQL or Google Cloud MySQL. </p> <p>The PMM Client installation also comes with options: in addition to the installation via Package Manager described above, you can also install it as a Docker container or as a binary package. Explore alternative PMM Client installation options for more information.</p> <p>Additionally, if direct access to the database node isn\u2019t available, opt to Add remote instance via User Interface instead. </p> <p>To connect a PostgreSQL database: </p> <ol> <li> <p>Create a PMM-specific user for monitoring:</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '&lt;your_password&gt;';\n</code></pre> </li> <li> <p>Ensure that PMM can log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If  not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> </li> <li> <p>Set up the <code>pg_stat_monitor</code> database extension and configure your database server accordingly. </p> <p>If you need to use the <code>pg_stat_statements</code> extension instead, see Adding a PostgreSQL database and the <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Set or change the value for <code>shared_preload_library</code> in your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> </li> <li> <p>Set up configuration values in your <code>postgresql.conf</code> file:</p> <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre> </li> <li> <p>In a <code>psql</code> session, run the following command to create the view where you can access the collected statistics. We recommend that you create the extension for the <code>postgres</code> database so that you can receive access to statistics from each database.</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:  </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the PostgreSQL database:</p> <pre><code>pmm-admin add postgresql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions and advanced installation options, see Adding a PostgreSQL database.</p> <p>To connect a MongoDB database:</p> <ol> <li> <p>Run the following command in <code>mongo</code> shell to create a role with the monitoring permissions: </p> <pre><code>db.createRole({\n    \"role\":\"explainRole\",\n    \"privileges\":[\n        {\n            \"resource\":{\n                \"db\":\"\",\n                \"collection\":\"\"\n            },\n            \"actions\":[\n                \"collStats\",\n                \"dbHash\",\n                \"dbStats\",\n                \"find\",\n                \"listIndexes\",\n                \"listCollections\"\n            ]\n        }\n    ],\n    \"roles\":[]\n})\n</code></pre> </li> <li> <p>Create a user and grant it the role created above:</p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\":\"pmm\",\n    \"pwd\":\"&lt;your_password&gt;\",\n    \"roles\":[\n        {\n            \"role\":\"explainRole\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"clusterMonitor\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"read\",\n            \"db\":\"local\"\n        }\n    ]\n})\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MongoDB database:</p> <pre><code>pmm-admin add mongodb --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Adding a MongoDB database for monitoring.</p> <p>To connect a ProxySQL service:</p> <ol> <li> <p>Configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL.</p> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the ProxySQL service:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Enable ProxySQL performance metrics monitoring.</p> <p>To connect an HAProxy service:</p> <ol> <li>Set up an HAproxy instance. </li> <li>Add the instance to PMM (default address is http://localhost:8404/metrics), and use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node: </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Run the command below, specifying the `listen-port`` as the port number where HAProxy is running. (This flag is mandatory.)</p> <pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> </li> </ol> <p>For detailed instructions and more information on the command arguments, see the HAProxy topic.</p>"},{"location":"quickstart.html#check-database-monitoring-results","title":"Check database monitoring results","text":"<p>After installing PMM and connecting the database, go to the database\u2019s Instance Summary dashboard. This shows essential information about your database performance and an overview of your environment.</p> <p>For more information, see PMM Dashboards.</p>"},{"location":"quickstart.html#next-steps","title":"Next steps","text":"<ul> <li>Configure PMM via the interface</li> <li>Manage users in PMM</li> <li>Set up roles and permissions</li> <li>Back up and restore data in PMM</li> </ul>"},{"location":"quickstart.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p> <p></p>"},{"location":"trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"advisors/advisors-details.html","title":"Advisors details","text":""},{"location":"advisors/advisors-details.html#list-of-database-advisors","title":"List of database Advisors","text":"<p>Percona Monitoring and Management (PMM) offers four categories of database Advisors to help you improve database performance: Configuration, Performance, Query and Security Advisors.</p> <p>Each Advisor includes a set of automated checks, which investigate a specific range of possible issues and areas of improvement: security threats, non-compliance issues, performance degradation, query and index optimization strategies etc.</p> <p>This page presents the complete list of database Advisors along with the corresponding subscription tier for which they are available.</p> <p>You can also access this list through the Advisor checks for PMM section in the Percona Portal documentation, as the Advisors are hosted on the Percona Platform. PMM Server automatically downloads them from this source when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both options are enabled by default.</p>"},{"location":"advisors/advisors-details.html#configuration-advisors","title":"Configuration Advisors","text":"Advisor Name Description Subscription Database Technology Version Configuration Notifies of newly released database versions to streamline database maintenance and ensure the most up-to-date performance. All Users MySQL, MongoDB, PostgreSQL Generic Configuration Provides basic recommendations for improving your database configuration. All Users MySQL, MongoDB, PostgreSQL Resources Configuration Watches your database and gives you recommendations for efficient management of resources like binaries architecture, CPU number versus DB Configuration, etc. All Users MySQL, MongoDB Connection Configuration Provides recommendations on configuring database connection parameters for improving database performance. Customers only MySQL, MongoDB, PostgreSQL Replication Configuration Provides recommendations for scalable replication in database clusters. Customers only MySQL, MongoDB InnoDB Configuration Advises on configuring InnoDB optimization for high performance. Customers only MySQL Vacuum Configuration Provides recommendations on optimizing Vacuum operations. Customers only PostgreSQL"},{"location":"advisors/advisors-details.html#performance-advisors","title":"Performance Advisors","text":"Advisor Name Description Subscription Database Technology Generic Performance Provides basic database configuration recommendations for high-performance query execution. All Users MongoDB, PostgreSQL Vacuum Performance Helps improve the efficiency and execution speed of database Vacuum commands. Customers only PostgreSQL Replication Performance Checks efficient replication usage of your database. Customers only MongoDB, PostgreSQL"},{"location":"advisors/advisors-details.html#security-advisors","title":"Security Advisors","text":"Advisor Name Description Subscription Database Technology CVE Security Informs you of any database versions affected by CVE. All Users MongoDB, PostgreSQL Configuration Security Checks your database configuration to ensure that security best practices are correctly implemented. All Users MySQL, MongoDB, PostgreSQL Authentication Security Ensures that all database authentication parameters are configured securely. Customers only MySQL, MongoDB, PostgreSQL Replication Security Helps safeguard data replication by assessing security risks and providing recommendations for improving protection. Customers only MySQL Connection Security Helps identify security issues on network connections and provides recommendations for enhancing security. Customers only MySQL, MongoDB"},{"location":"advisors/advisors-details.html#query-advisors","title":"Query Advisors","text":"Advisor Name Description Subscription Database Technology Index Query Provides query and index optimization strategies for peak database performance. Customers only MySQL, MongoDB, PostgreSQL Schema Design Query Helps create efficient database schemas by analyzing queries and offering suggestions for optimization. All Users MySQL"},{"location":"advisors/advisors-details.html#list-of-checks","title":"List of checks","text":"<p>Every Advisor consists of one or more Advisor checks.  We have listed the checks and their details here.</p>"},{"location":"advisors/advisors-details.html#mongodb","title":"MongoDB","text":"Advisor Check Name Description Summary Connection Configuration mongodb_connection_sudden_spike Warns about any significant increase in the number of connections exceeding 50% of the recent or typical connection count. MongoDB Sudden Increase in Connection Count Connection Configuration mongodb_connections Returns the current number of connections as an informational notice when connection counts exceed 5000. MongoDB High Connections Generic Configuration mongo_cache_size Warns when Mongo wiredtiger cache size is greater than the default 50%. Mongo Storage Cache Generic Configuration mongodb_active_vs_available_connections Warns if the ratio between active and available connections is higher than 75%. MongoDB Active vs Available Connections Generic Configuration mongodb_journal Warns if the journal is disabled. MongoDB Journal Generic Configuration mongodb_loglevel Warns if MongoDB is not using the default Log level. MongoDB Non-Default Log Level Generic Configuration mongodb_read_tickets Warns if MongoDB is using more than 128 read tickets. MongoDB Read Tickets Generic Configuration mongodb_write_tickets Warns if MongoDB is using more than 128 write tickets. MongoDB Write Tickets Generic Configuration mongodb_write_tickets_runtime Warns if MongoDB is using more than 128 write tickets during runtime. MongoDB - Configuration Write Ticket Check Replication Configuration mongodb_psa_architecture_check Raises an error if the replicaSet is utilizing a PSA (Primary-Secondary-Arbiter) architecture. MongoDB PSA Architecture Replication Configuration mongodb_replicaset_topology Warns if the Replica Set has less than three data-bearing nodes. MongoDB Replica Set Topology Resources Configuration mongodb_collection_fragmented Warns if the storage size exceeds the data size of a collection, indicating potential fragmentation. This suggests the need for compaction or an initial sync to reclaim disk space. MongoDB Collections Fragmented Resources Configuration mongodb_cpucores Warns if the number of CPU cores does not meet the minimum recommended requirements according to best practices. MongoDB CPU Cores Resources Configuration mongodb_dbpath_mount Warns if dbpath does not have a dedicated mount point. MongoDB - Separate Mount Point Other Than \u201c/\u201d Partition for dbpath. Resources Configuration mongodb_fcv_check Warns if there is a mismatch between the MongoDB version and the internal FCV (Feature Compatibility Version) parameter setting. MongoDB - FCV Mismatch Resources Configuration mongodb_maxsessions Warns if MongoDB is configured with a maxSessions value other than the default value of 1000000. MongoDB maxSessions Resources Configuration mongodb_swap_allocation Warns if there is no swap memory allocated to your instance. MongoDB - Allocate Swap Memory Resources Configuration mongodb_taskexecutor Warns if the count of MongoDB TaskExecutorPoolSize exceeds the number of available CPU cores. MongoDB TaskExecutorPoolSize High Resources Configuration mongodb_xfs_ftype Warns if dbpath is not using the XFS filesystem type. MongoDB - XFS Version Configuration mongodb_EOL Raises an error or a warning if your current PSMDB or MongoDB version has reached or is nearing its End-of-Life (EOL) status. MongoDB Version EOL Version Configuration mongodb_unsupported_version Raises an error if your current PSMDB or MongoDB version is not supported. MongoDB Unsupported Version Version Configuration mongodb_version Provides information on current MongoDB or Percona Server for MongoDB versions used in your environment. It also offers details on other available minor or major versions that you may consider for upgrades. MongoDB Version Check Generic Performance mongodb_multiple_services Warns if multiple mongod services are detected running on a single node. MongoDB - Multiple mongod Services Replication Performance mongodb_chunk_imbalance Warns if the distribution of chunks across shards is imbalanced. MongoDB Sharding - Chunk Imbalance Across Shards Replication Performance mongodb_oplog_size_recommendation Warns if the oplog window is below a 24-hour period and provides a recommended oplog size based on your instance. MongoDB - Oplog Recovery Window is Low Replication Performance mongodb_replication_lag Warns if the replica set member lags behind the primary by more than 10 seconds. MongoDB Replication Lag Index Query mongodb_shard_collection_inconsistent_indexes Warns if there are inconsistent indexes across shards for sharded collections. Missing or inconsistent indexes across shards can have a negative impact on performance. MongoDB Sharding - Inconsistent Indexes Across Shards Index Query mongodb_unused_index Warns if there are unused indexes on any database collection in your instance. This requires enabling the \u201cindexStats\u201d collector. MongoDB - Unused Indexes Authentication Security mongodb_auth Warns if MongoDB authentication is disabled. MongoDB Authentication Authentication Security mongodb_localhost_auth_bypass Warns if MongoDB localhost bypass is enabled. MongoDB localhost authentication bypass enabled Configuration Security mongodb_authmech_scramsha256 Warns if MongoDB is not using the default SHA-256 hashing function as its SCRAM authentication method. MongoDB Security AuthMech Check Connection Security mongodb_bindip Warns if the MongoDB network binding is not set as Recommended. MonogDB IP Bindings CVE Security mongodb_cve_version Shows an error if MongoDB or Percona Server for MongoDB version is older than the latest version containing CVE (Common Vulnerabilities and Exposures) fixes. MongoDB CVE Version"},{"location":"advisors/advisors-details.html#mysql","title":"MySQL","text":"Advisor Check Name Description Summary Connection Configuration mysql_configuration_max_connections_usage Checks the MySQL max_connections configuration option to ensure maximum utilization is achieved. Check Max Connections Usage Generic Configuration mysql_automatic_sp_privileges_enabled Checks if the automatic_sp_privileges configuration is ON. Checks if automatic_sp_privileges configuration is ON. Generic Configuration mysql_config_binlog_retention_period Checks whether binlogs are being rotated too frequently, which is not recommended, except in very specific cases. Binlogs Retention Check Generic Configuration mysql_config_binlog_row_image Advises when to set binlog_row_image=FULL. Binlogs Raw Image is Not Set to FULL Generic Configuration mysql_config_binlogs_checksummed Advises when to set binlog_checksum=CRC32 to improve consistency and reliability. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_general_log Checks whether the general log is enabled. General Log is Enabled Generic Configuration mysql_config_log_bin Checks whether the binlog is enabled or disabled. Binary Log is disabled Generic Configuration mysql_config_sql_mode Checks whether the server has specific values configured in sql_mode to ensure maximum data integrity. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_tmp_table_size_limit Checks whether the size of temporary tables exceeds the size of heap tables. Temp Table Size is Larger Than Heap Table Size Generic Configuration mysql_configuration_log_verbosity Checks whether warnings are being printed on the log. Check Log Verbosity Generic Configuration mysql_test_database Notifies if there are database named \u2018test\u2019 or \u2018test_%\u2019. MySQL Test Database Generic Configuration mysql_timezone Verifies whether the time zone is correctly loaded. MySQL configuration check InnoDB Configuration innodb_redo_logs_not_sized_correctly Reviews the InnoDB redo log size and provides suggestions if it is configured too low. InnoDB Redo Log Size is Not Configured Correctly. InnoDB Configuration mysql_ahi_efficiency_performance_basic_check Checks the efficiency and effectiveness of InnoDB\u2019s Adaptive Hash Index (AHI). InnoDB Adaptive Hash Index (AHI) Efficiency InnoDB Configuration mysql_config_innodb_redolog_disabled Warns when the MySQL InnoDB Redo log is set to OFF, which poses a significant security risk and compromises data integrity. The MySQL InnoDB Redo log is a crucial component for maintaining the ACID (Atomicity, Consistency, Isolation, Durability) properties in MySQL databases. Redo Log is Disabled in This Instance InnoDB Configuration mysql_configuration_innodb_file_format Verifies whether InnoDB is configured with the recommended file format. MySQL InnoDB File Format InnoDB Configuration mysql_configuration_innodb_file_maxlimit Checks whether InnoDB is configured with the recommended auto-extend settings. InnoDB Tablespace Size Has a Maximum Limit. InnoDB Configuration mysql_configuration_innodb_file_per_table_not_enabled Warns when innodb_file_per_table is not enabled. innodb_file_per_table Not Enabled InnoDB Configuration mysql_configuration_innodb_flush_method Checks whether InnoDB is configured with the recommended flush method. MySQL InnoDB Flush Method InnoDB Configuration mysql_configuration_innodb_strict_mode Warns about password lifetime. InnoDB strict mode Replication Configuration mysql_config_relay_log_purge Identifies whether a replica node has relay-logs purge set. Automatic Relay Log Purging is OFF Replication Configuration mysql_config_replication_bp1 Identifies whether a replica node is in read-only mode and if checksum is enabled. Checks Basic Best Practices When Setting Replica Node. Replication Configuration mysql_config_slave_parallel_workers Identifies whether replication is single-threaded. Replication is Single-Threaded Replication Configuration mysql_config_sync_binlog Checks whether the binlog is synchronized before a transaction is committed. Sync Binlog Disabled Replication Configuration mysql_log_replica_updates Checks if a replica is safely logging replicated transactions. MySQL Configuration Check Replication Configuration replica_running_skipping_errors_or_idempotent_mode Reviews replication status to check if it is configured to skip errors or if the slave_exec_mode is set to be idempotent. Replica is skipping errors or slave_exec_mode is Idempotent. Resources Configuration mysql_32binary_on_64system Notifies if version_compile_machine equals i686. Check if Binaries are 32 Bits Version Configuration mysql_unsupported_version_check Warns against an unsupported Mysql version. Checks Mysql Version Version Configuration mysql_version Warns if MySQL, Percona Server for MySQL, or MariaDB version is not the latest available one. MySQL Version Version Configuration mysql_version_eol_57 Checks if the server version is EOL. End Of Life Server Version (5.7). Index Query mysql_performance_temp_ondisk_table_high Warns if there are too many on-disk temporary tables being created due to unoptimized query execution. Too Many on Disk Temporary Tables Index Query mysql_tables_without_pk Checks tables without primary keys. MySQL check for a table without Primary Key Schema Design Query mysql_indexes_larger Check all the tables to see if any have indexes larger than data. This indicates a sub-optimal schema and should be reviewed. Tables With Index Sizes Larger Than Data Authentication Security mysql_automatic_expired_password Warns if the MySQL parameter for automatic password expiry is not active. MySQL Automatic User Expired Password Authentication Security mysql_security_anonymous_user Verifies if anonymous users are present, as this would contradict security best practices. Anonymous User (You Must Remove Any Anonymous User) Authentication Security mysql_security_open_to_world_host Checks whether host definitions are set as \u2018%\u2019 since this is overly permissive and could pose security risks. UserS Have Host Definition \u2018%\u2019 Which is Too Open Authentication Security mysql_security_root_not_local Checks whether the root user has a host definition that is not set to 127.0.0.1 or localhost. Root User Can Connect From Non-local Location Authentication Security mysql_security_user_ssl Reports users who are not using a secure SSL protocol to connect. Users Not Using Secure SSL Authentication Security mysql_security_user_super_not_local Reports users with super privileges who are not connecting from the local host or the host is not fully restricted (e.g., 192.168.%). Users have Super privileges With Remote and Too Open Access Authentication Security mysql_security_user_without_password Reports users without passwords. Users Without Password Configuration Security mysql_config_local_infile Checks if the \u201cLOAD DATA INFILE\u201d functionality is active. Load Data in File Active Configuration Security mysql_configuration_secure_file_priv_empty Warns when  secure_file_priv is empty as this enables users with FILE privilege to create files at any location where MySQL server has Write permission. secure_file_priv is Empty Configuration Security mysql_password_expiry Checks if MySQL user passwords are expired or expiring within the next 30 days. Check MySQL User Password Expiry Configuration Security mysql_require_secure_transport Checks the status of mysql_secure_transport_only. MySQL configuration check Configuration Security mysql_security_password_lifetime Warns about password lifetime. InnoDB Password Lifetime Configuration Security mysql_security_password_policy Checks for password policy. MySQL Security Check for Password Connection Security mysql_private_networks_only Notifies about MySQL accounts that are allowed to connect from public networks. MySQL Users With Granted Public Networks Access Replication Security mysql_replication_grants Checks if replication is configured on a node without user grants. MySQL Security Check for Replication User Replication Security mysql_security_replication_grants_mixed Checks if replication privileges are mixed with more elevated privileges. Replication Privileges"},{"location":"advisors/advisors-details.html#postgresql","title":"PostgreSQL","text":"Advisor Check Name Description Connection Configuration postgresql_max_connections_1 Notifies if the max_connections configuration option is set to a high value (above 300). PostgreSQL doesn\u2019t cope well with having many connections even if they are idle. The recommended value is below 300. Generic Configuration postgresql_archiver_failing_1 Verifies if the archiver has failed. Generic Configuration postgresql_fsync_1 Returns an error if the fsync configuration option is set to OFF, as this can lead to database corruptions. Generic Configuration postgresql_log_checkpoints_1 Notifies if the log_checkpoints configuration option is not enabled. It is recommended to enable the logging of checkpoint information, as that provides a lot of useful information with almost no drawbacks. Generic Configuration postgresql_logging_recommendation_checks Verifies whether the recommended minimum logging features are enabled. Generic Configuration postgresql_wal_retention_check Checks if there are too many WAL files retained in the WAL directory. Vacuum Configuration postgresql_log_autovacuum_min_duration_1 Notifies if the log_autovacuum_min_duration configuration option is set to -1 (disabled). It is recommended to enable the logging of autovacuum run information, as it provides a lot of useful information with almost no drawbacks. Vacuum Configuration postgresql_table_autovac_settings Returns tables where autovacuum parameters are specified along with the corresponding autovacuum settings. Vacuum Configuration postgresql_txid_wraparound_approaching Verifies the age of databases and alerts if the transaction ID wraparound issue is nearing. Vacuum Configuration postgresql_vacuum_sanity_check This performs a quick check of some vacuum parameters. Version Configuration postgresql_eol_check Checks if the currently installed PostgreSQL version has reached its EOL and is no longer supported. Version Configuration postgresql_extension_check Lists outdated extensions with newer versions available. Version Configuration postgresql_unsupported_check Verifies if the currently installed version is supported by Percona. Version Configuration postgresql_version_check Checks if the currently installed version is outdated for its release level. Generic Performance postgresql_cache_hit_ratio_1 Checks the hit ratio of one or more databases and raises a complaint when they are too low. Generic Performance postgresql_config_changes_need_restart_1 Warns if there are any settings or configurations that have been changed and require a server restart or reload. Generic Performance postgresql_tmpfiles_check Reports the number of temporary files and the number of bytes written to disk since the last statistics reset. Replication Performance postgresql_stale_replication_slot_1 Warns if there is a stale replication slot. Stale replication slots will lead to WAL file accumulation and can result in a database server outage. Vacuum Performance postgresql_table_bloat_bytes Verifies the size of the table bloat in bytes across all databases and raises alerts accordingly. Vacuum Performance postgresql_table_bloat_in_percentage Verifies the size of the table bloat in the percentage of the total table size and alerts accordingly. Index Query postgresql_number_of_index_check Lists relations with more than ten indexes. Index Query postgresql_sequential_scan_check Checks for tables with excessive sequential scans. Index Query postgresql_unused_index_check Lists relations with indexes that have not been used since the statistics were last reset. Authentication Security postgresql_super_role Notifies if there are users with Superuser role. Configuration Security postgresql_expiring_passwd_check Checks for passwords that are expiring and displays the time left before they expire. CVE Security postgresql_cve_check Checks if the currently installed version has reported security vulnerabilities."},{"location":"advisors/advisors-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"advisors/advisors.html","title":"Advisors","text":"<p>Percona Advisors provide automated insights and recommendations within Percona Monitoring and Management. These proactive insights help you uncover problems before they become larger issues: security risks, misconfigurations, poor performance, etc.</p> <p>Advisors are grouped by category: Security, Configuration, Performance and Query. Each Advisor category offers a set of automated checks, which investigate a specific range of possible issues. The list of Advisor checks available for your instance depends on whether your instance is connected to Percona Platform, and on your current subscription plan.</p>"},{"location":"advisors/advisors.html#prerequisites-for-accessing-advisor-checks","title":"Prerequisites for accessing Advisor checks","text":"<p>All checks are hosted on Percona Platform. PMM Server automatically downloads them from here when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both these options are enabled by default.</p>"},{"location":"advisors/advisors.html#highest-security-for-your-databases","title":"Highest security for your databases","text":"<p>Percona Platform communicates with PMM via secure channels, using the highest standards for privacy and security. Before downloading and running Advisor checks on your database, PMM verifies the content and integrity of all Advisor checks to confirm that every component originated from Percona Platform and that no one has altered them since the checks were digitally signed.</p>"},{"location":"advisors/advisors.html#advisor-check-tiers-and-platform-entitlements","title":"Advisor check tiers and Platform entitlements","text":"<p>Depending on the entitlements available for your Percona Account, the set of Advisor checks that PMM can download from the Percona Platform differs in terms of complexity and functionality.</p> <p>If your PMM instance is not connected to Percona Platform, PMM can only use the default Advisor checks. As soon as you connect your PMM instance to Percona Platform, has access to additional checks, available only for registered PMM instances.</p> <p>If you are a Percona customer with a Percona Customer Portal account, you also get access to Standard/Premium Advisor checks, which offer more advanced database health information.</p> <p>To see the complete list of available checks, see the Advisor Checks for PMM topic in the Percona Platform documentation.</p>"},{"location":"advisors/advisors.html#enabledisable","title":"Enable/Disable","text":"<p>To download the checks available for your Percona Account, the Advisors and Telemetry options have to be enabled under  Configuration  &gt; Settings &gt; Advanced Settings.</p> <p>These options are enabled by default so that PMM can run automatic Advisor checks in the background. However, you can disable them at any time if you do not need to check the health and performance of your connected databases.</p>"},{"location":"advisors/advisors.html#automatic-checks","title":"Automatic checks","text":"<p>Advisor checks can be executed manually or automatically. By default, PMM runs all the checks available for your PMM instances every 24 hours.</p>"},{"location":"advisors/advisors.html#change-run-interval-for-automatic-advisors","title":"Change run interval for automatic advisors","text":"<p>You can change the standard 24-hour interval to a custom frequency for each Advisor check:</p> <ul> <li>Rare interval - 78 hours</li> <li>Standard interval (default) - 24 hours</li> <li>Frequent interval - 4 hours</li> </ul> <p>To change the frequency of an automatic check:</p> <ol> <li>Click   Advisors.</li> <li>Select the Advisor tab that contains the check for which you want to change the frequency.</li> <li> <p>Expand the relevant Advisor and scroll through the list to find your check. Alternatively, use the Filter section at the top of the table to search checks by Name, Description, Status, or Interval.</p> <p>Tip</p> <p>If you need to share filtered Advisor results with your team members, send them the PMM URL. This saves your search criteria and results.</p> <ol> <li>Click the  Interval icon in the Actions column, next to the check you want to update.</li> <li>Chose an interval and click Save.</li> </ol> </li> </ol>"},{"location":"advisors/advisors.html#manual-checks","title":"Manual checks","text":"<p>In addition to the automatic checks that run every 24 hours, you can also run checks manually, for ad-hoc assessments of your database health and performance.</p> <p>To run checks manually:</p> <ol> <li>Click   Advisors on the main menu.</li> <li>Select the Advisor tab that contains the checks which you want to run manually.</li> <li>Click Run checks to run all the available checks for this Advisor group, or expand an Advisor and click Run next to each check that you want to run individually. </li> </ol>"},{"location":"advisors/advisors.html#advisor-checks-results","title":"Advisor checks results","text":"<p>The results are sent to PMM Server where you can review any failed checks on the Home dashboard. The summary count of failed checks is classified as:</p> <ul> <li>Critical, which also includes checks tagged as Alert and Emergency</li> <li>Error</li> <li>Warning</li> <li>Notice, which also includes checks tagged as Info and Debug</li> </ul> <p></p> <p>To see more details about the available checks and any checks that failed, click the   Advisors icon on the main menu.</p> <p>Check results data always remains on the PMM Server. This is not related to anonymous data sent for Telemetry purposes.</p>"},{"location":"advisors/advisors.html#create-your-own-advisors","title":"Create your own Advisors","text":"<p>PMM Advisors offer a set of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>Developers can create custom checks to cover additional use cases, relevant to specific database infrastructure. For more information, see Develop Advisor checks.</p> <p></p>"},{"location":"advisors/advisors.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"advisors/develop_advisor_checks.html","title":"Developing Advisor checks","text":"<p>PMM offers sets of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>As a developer, you can create custom checks to cover additional use cases, relevant to your specific database infrastructure.</p>"},{"location":"advisors/develop_advisor_checks.html#check-components","title":"Check components","text":"<p>A check is a combination of:</p> <ul> <li>A query for extracting data from the database.</li> <li>Python script for converting extracted data into check results. This is actually a Starlark script, which is a Python dialect that adds more imperative features than Python. The script\u2019s execution environment is sandboxed, and no I/O can be done from it.</li> </ul> <p>All checks are self-contained in the first phase, as well as in most of the planned phases.</p> <p>This means that extracted data is processed on the PMM side and not sent back to Percona Platform.</p>"},{"location":"advisors/develop_advisor_checks.html#backend","title":"Backend","text":"<p>At the backend, pmm-managed does the following:</p> <ol> <li>pmm-managed checks that the installation is opted-in for checks.</li> <li>pmm-managed downloads files with checks from Percona Platform.</li> <li>pmm-managed verifies file signatures using a list of hard-coded public keys. At least one signature should be correct.</li> <li>pmm-managed sends queries to pmm-agent and gathers results.</li> <li>pmm-managed executes check scripts that produce alert information.</li> <li>pmm-managed sends alerts to Alertmanager.</li> <li>Due to Alertmanager design, pmm-managed has to send and re-send alerts to it much more often than the frequency with which checks are executed. This expected behavior is not important for using checks but is important for understanding how checks work.</li> <li>Currently, Prometheus is not involved.</li> </ol> <p></p>"},{"location":"advisors/develop_advisor_checks.html#frontend","title":"Frontend","text":"<p>PMM uses Alertmanager API to get information about failed checks and show them on the UI:</p> <p></p>"},{"location":"advisors/develop_advisor_checks.html#format-for-checks","title":"Format for checks","text":"<p>Advisor checks use the following format:</p> Checks Format <pre><code>---\nchecks:\n  - version: 2\n    name: exampleV2\n    summary: Check format V2\n    description: Checks something important\n    interval: standard\n    family: MYSQL\n    category: configuration ## Deprecated since PMM 2.36\n    advisor: dev            ## Required since PMM 2.36\n    queries:\n      - type: MYSQL_SHOW\n        query: VARIABLES\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n        parameters:\n          lookback: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          range: 15m\n          step: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          lookback: 5m\n          range: 15m\n          step: 5m\n\n    script: |\n      def check_context(docs, context):\n          # `docs` is a frozen (deeply immutable) list where each item represents single query results. Order of results\n          # matches order of queries in check file. Each query result is list of dicts where each item where each dict\n          # represents a single document in result set.\n          #\n          # `context` is a dict with additional functions.\n          #\n          # Global `print` and `fail` functions are available.\n          #\n          # `check_context` function is expected to return a list of dicts that are then converted to alerts;\n          # in particular, that list can be empty.\n          # Any other value (for example, string) is treated as a script execution failure\n          # (Starlark does not support Python exceptions);\n          # it is recommended to use global function `fail` for that instead.\n\n          results = []\n\n          for row in docs[0]:\n              name, value = row[\"Variable_name\"], row[\"Value\"]\n              if name == \"version\":\n                  results.append({\n                      \"summary\": \"MySQL has version {}\".format(value),\n                      \"description\": \"Current version is {}\".format(value),\n                      \"read_more_url\": \"\",\n                      \"severity\": \"warning\",\n                      \"labels\": {},\n                  })\n\n          uptimeNow = int(int(docs[1][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime {} min\".format(uptimeNow),\n              \"description\": \"Current uptime is {} min\".format(uptimeNow),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          uptimeFiveMinAgo = int(int(docs[2][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime 5 min ago was {} min\".format(uptimeFiveMinAgo),\n              \"description\": \"5 min ago uptime was {} min\".format(uptimeFiveMinAgo),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[3][0][\"values\"]:\n            dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Node has load average for last 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[4][0][\"values\"]:\n              dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Five minutes ago node had load average for 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          return results\n</code></pre>"},{"location":"advisors/develop_advisor_checks.html#checks-script","title":"Checks script","text":"<p>The check script assumes that there is a function with <code>check_context</code>, that accepts a list where each item represents the result of a single query specified in the check. Each result itself is a list of docs containing returned rows for SQL databases and documents for MongoDB. It returns zero, one, or several check results that are then converted to alerts.</p>"},{"location":"advisors/develop_advisor_checks.html#check-severity-levels","title":"Check severity levels","text":"<p>You can label your advisor checks with one of the following available severity levels: Emergency, Alert, Critical, Error, Warning, Notice, Info, Debug. PMM groups failed checks by their severity, and displays them under Advisors Checks &gt; Failed Checks.</p>"},{"location":"advisors/develop_advisor_checks.html#check-fields","title":"Check fields","text":"<p>Checks can include the following fields:</p> <ul> <li>Version (integer, required): defines what other properties are expected, what types are supported, what is expected from the script and what it can expect from the execution environment, etc.</li> <li>Name (string, required): defines machine-readable name (ID).</li> <li>Summary (string, required): defines short human-readable description.</li> <li>Description (string, required): defines long human-readable description.</li> <li>Family (string, required): specifies one of the supported database families: MYSQL, POSTGRESQL, MONGODB. This field is only available for Advisor checks v.2.</li> <li>Advisor (string, required): specifies the advisor to which this check belongs. For local environments, specify dev.</li> <li>Interval (string/enum, optional): defines running interval. Can be one of the predefined intervals in the UI: Standard, Frequent, Rare.</li> <li>Queries (array, required): contains items that specify queries.<ul> <li>Type (string/enum, required): defines the query type. Check the list of available types in the table below.</li> <li>Query (string, can be absent if the type defines the whole query by itself): The query is executed on the PMM Client side and can contain multiple queries specific to the target DBMS.</li> <li>Parameters (key-value, can be absent if query doesn\u2019t have required parameters)</li> </ul> </li> <li>Script (string, required): contains a small Starlark script that processes query results, and returns check results. It is executed on the PMM Server side.</li> </ul>"},{"location":"advisors/develop_advisor_checks.html#query-types","title":"Query types","text":"<p>Expand the table below for the list of checks types that you can use to define your query type and the PMM Service type for which the check will run.</p> Check Types table Check type Description \u201cquery\u201d required (must be empty if \u201cNo\u201d) MYSQL_SHOW Executes \u2018SHOW \u2026\u2019 clause against MySQL database. Yes MYSQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against MySQL database. Yes POSTGRESQL_SHOW Executes \u2018SHOW ALL\u2019 command against PosgreSQL database. No POSTGRESQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against PosgreSQL database. Yes MONGODB_GETPARAMETER Executes db.adminCommand( { getParameter: \u201c*\u201d } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getParameter No MONGODB_BUILDINFO Executes db.adminCommand( { buildInfo:  1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see buildInfo No MONGODB_GETCMDLINEOPTS Executes db.adminCommand( { getCmdLineOpts: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getCmdLineOpts No MONGODB_REPLSETGETSTATUS Executes db.adminCommand( { replSetGetStatus: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see  replSetGetStatus No MONGODB_GETDIAGNOSTICDATA Executes db.adminCommand( { getDiagnosticData: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see MongoDB Performance No METRICS_INSTANT Executes instant MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about instant queries, check out the Prometheus docs. Yes METRICS_RANGE Executes range MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about range queries, check out the Prometheus docs. Yes CLICKHOUSE_SELECT Executes \u2018SELECT \u2026\u2019 statements against PMM\u2019s Query Analytics Clickhouse database. Queries can use the  {{.ServiceName}} and {{.ServiceID}}   placeholders in query string. They match the target service name and service ID respectively. Yes"},{"location":"advisors/develop_advisor_checks.html#query-parameters","title":"Query parameters","text":"<ul> <li><code>METRICS_INSTANT</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> </ul> </li> <li><code>METRICS_RANGE</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> <li>range (duration, required): specifies time window of the query. This parameter is equal to Prometheus API.</li> <li>step (duration, required): query resolution. This parameter is equal to Prometheus API.</li> </ul> </li> <li><code>POSTGRESQL_SELECT</code><ul> <li>all_dbs (boolean, optional): execute query on all available databases in PostgreSQL instance. If this parameter is not specified, then query executed on the default database (the one that was specified when service was added to PMM).</li> </ul> </li> </ul>"},{"location":"advisors/develop_advisor_checks.html#develop-checks","title":"Develop checks","text":"<p>Development / Debugging Only</p> <p>Note that check development in PMM is currently for debugging only and NOT for production use!  Future releases plan to include the option to run custom local checks in addition to hosted Percona Platform checks.</p> <p>To develop custom checks for PMM:</p> <ol> <li>Install the latest PMM Server and PMM Client builds following the installation instructions.</li> <li> <p>Run PMM Server with special environment variables:</p> <ul> <li><code>PERCONA_TEST_CHECKS_FILE=/srv/custom-checks.yml</code> to use checks from the local files instead of downloading them from Percona Platform.</li> <li><code>PERCONA_TEST_CHECKS_DISABLE_START_DELAY=true</code> to disable the default check execution start delay. This is currently set to one minute, so that checks run upon system start.</li> <li><code>PERCONA_TEST_CHECKS_RESEND_INTERVAL=2s</code> to define the frequency for sending the SA-based alerts to Alertmanager.</li> </ul> <pre><code>docker run -p 80:80 -p 443:443 --name pmm-server \\\n-e PERCONA_TEST_CHECKS_FILE=/srv/custom-checks.yml \\\n-e PERCONA_TEST_CHECKS_DISABLE_START_DELAY=true \\\n-e PERCONA_TEST_CHECKS_RESEND_INTERVAL=2s \\\nperconalab/pmm-server:3-dev-container\n</code></pre> </li> <li> <p>Log into Grafana with credentials admin/admin.</p> </li> <li> <p>Go to PMM Configuration &gt; Settings &gt; Advanced Settings and make sure the Advisors option is enabled.</p> </li> <li> <p>Create <code>/srv/custom-checks.yml</code> inside the <code>pmm-server</code> container with the content of your check. Specify dev advisor in your check.</p> </li> <li> <p>The checks will run according to the time interval defined on the UI. You can see the result of running the check on the home dashboard:</p> <p></p> </li> <li> <p>Click on the number of failed checks to open the Failed Checks dashboard:</p> <p></p> </li> <li> <p>Check out pmm-managed logs:     <pre><code>docker exec -it pmm-server supervisorctl tail -f pmm-managed\n</code></pre></p> </li> </ol>"},{"location":"advisors/develop_advisor_checks.html#troubleshooting-and-tips","title":"Troubleshooting and tips","text":"<ul> <li>in Debug mode, PMM generates a lot of redundant information in the log files, information that is not useful for developing checks.  If debug logging is enabled, you can disable it with the following environment variable: <code>PMM_DEBUG=0</code>.</li> <li>All logs from checks subsystem has <code>component=checks</code> tag, so you can just filter <code>pmm-managed</code> logs with grep.</li> <li>Local check file should always be linked to fake dev advisor: <code>advisor: dev</code>. If PMM does not display the Development tab on the Advisors page, make sure that you specify dev advisor in the check file.</li> <li>If this still doesn\u2019t display the Development tab, probably PMM could not load your file due to formatting issues. Check pmm-managed logs for details.</li> <li>There are to ways to reload the check file:</li> <li>Click <code>Run check</code> button (but it\u2019s unavailable if you don\u2019t have any tabs on advisors page and most likely that is the case during development)</li> <li>Reload managed: <code>supervisorctl restart pmm-managed</code> (execute inside PMM Server)</li> </ul>"},{"location":"advisors/develop_advisor_checks.html#submit-feedback","title":"Submit feedback","text":"<p>We welcome your feedback on the current process for developing and debugging checks. Send us your comments over Slack or post a question on the Percona Forums.</p> <p></p>"},{"location":"advisors/develop_advisor_checks.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/index.html","title":"About Percona Alerting","text":"<p>Alerting notifies of important or unusual activity in your database environments so that you can identify and resolve problems quickly. When something needs your attention, Percona Alerting can be configured to automatically send you a notification through your specified contact points.</p> <p>Percona Alerting is enabled by default in the PMM Settings. This feature adds the Alert rule templates option on the main menu and alert template options on the Alerting page.</p> <p>These options enable you to create alerts based on a set of Percona-supplied templates with common events and expressions for alerting. </p>"},{"location":"alert/index.html#alert-types","title":"Alert types","text":"<p>Percona Alerting is powered by Grafana infrastructure. It leverages Grafana\u2019s advanced alerting capabilities and provides pre-configured Alert Rule Templates that simplify creating powerful alerting rules.</p> <p>Depending on the datasources that you want to query, and the complexity of your required evaluation criteria, Percona Alerting enables you to create the following types of alerts:</p> <ul> <li>Percona templated alerts: alerts based on a set of Percona-supplied templates with common events and expressions for alerting. If you need custom expressions on which to base your alert rules, you can also create your own templates.</li> <li>Grafana managed alerts: alerts that handle complex conditions and can span multiple different data sources like SQL, Prometheus, InfluxDB, etc. These alerts are stored and executed by Grafana.</li> </ul> <p></p>"},{"location":"alert/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/alert_rules.html","title":"Alert rules and alert templates","text":"<p>Alert rules describe the circumstances under which you want to be alerted. The evaluation criteria that you define determine whether an alert will fire. </p> <p>An alert rule consists of one or more queries and expressions, a condition, the frequency of evaluation, and the duration over which the condition is met. For example, you might configure an alert to fire and trigger a notification when MongoDB is down.</p> <p></p> <p>An alert rule can be in three possible states:</p> <ul> <li>Normal: Everything is working correctly and the conditions specified in the rule has not been met. This is the default state for newly created rules.</li> <li>Pending: The conditions specified in the alert rule has been met, but for a time that is less than the configured duration.</li> <li>Firing: Both the conditions and the duration specified in the alert rule have both been met.</li> </ul> <p>It takes at least one evaluation cycle for an alert rule to transition from one state to another (e.g., from <code>Normal</code> to <code>Pending</code>).</p>"},{"location":"alert/alert_rules.html#alert-rules-templates","title":"Alert rules templates","text":"<p>PMM provides a set of Alert Rule templates with common events and expressions for alerting. These templates can be used as a basis for creating Alert Rules. You can also create your own templates if you need custom expressions.</p> <p>You can check the alert templates available for your account under Alerting &gt; Alert rule templates tab. PMM lists here the following types of templates:</p> <ul> <li>Built-in templates, available out-of-the-box with PMM.</li> <li>Templates downloaded from Percona Platform.</li> <li>Custom templates created or uploaded on the Alerting page &gt; Alert Templates tab. You can also store your custom template files in your <code>/srv/alerting/templates</code> directory and PMM will load them during startup.</li> </ul>"},{"location":"alert/alert_rules.html#accessing-alert-templates","title":"Accessing alert templates","text":"<p>To check the alert templates for your PMM instance, go to PMM &gt; Alerting &gt; Alert Rule Templates tab.</p> <p>To check the full list of available PMM templates, see the List of available alert templates topic</p>"},{"location":"alert/alert_rules.html#create-alert-rules-from-alert-rule-templates","title":"Create alert rules from alert rule templates","text":"<p>This section focuses on creating an alert rule based on PMM templates. For information on working with the other alert types, check the Grafana documentation on Grafana Labs.</p>"},{"location":"alert/alert_rules.html#provision-alert-resources","title":"Provision alert resources","text":"<p>Before creating PMM alert rules, configure the required alert resources:</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced Settings and ensure that the Percona Alerting option is enabled. When this is disabled, the Alerting page displays only Grafana-managed alert rules. This means that you will not be able to create alerts based on PMM templates.</li> <li>Go to Dashboards and check the folders available for storing alert rules. If none of the available folders are relevant for your future alert rules, click New &gt; New Folder and create a custom one.</li> <li>Go to Alerting &gt; Alert rule templates and check the default PMM templates. If none of the templates include a relevant expression for the type of alerts that you want to create, click Add template to create a custom template instead.</li> </ol>"},{"location":"alert/alert_rules.html#configure-alert-templates","title":"Configure alert templates","text":"<p>Alerts templates are YAML files that provide the source framework for alert rules. Alert templates contain general template details and an alert expression defined in MetricsQL. This query language is backward compatible with PromQL.</p>"},{"location":"alert/alert_rules.html#create-custom-templates","title":"Create custom templates","text":"<p>If none of the default PMM templates contain a relevant expression for the alert rule that you need, you can create a custom template instead.</p> <p>You can base multiple alert rules on the same template. For example, you can create a <code>pmm_node_high_cpu_load</code> template that can be used as the source for alert rules for production versus staging, warning versus critical, etc.</p>"},{"location":"alert/alert_rules.html#template-format","title":"Template format","text":"<p>When creating custom templates, make sure to use the required template format below:</p> <ul> <li>name (required): uniquely identifies template. Spaces and special characters are not allowed.</li> <li>version (required): defines the template format version.</li> <li>summary (required): a template description.</li> <li>expr (required): a MetricsQL query string with parameter placeholders.</li> <li>params: contains parameter definitions required for the query. Each parameter has a name, type, and summary. It also may have a unit, available range, and default value.<ul> <li>name (required): the name of the parameter. Spaces and special characters are not allowed.</li> <li>summary (required): a short description of what this parameter represents.</li> <li>unit (optional): PMM currently supports either s (seconds) or % (percentage).</li> <li>type (required): PMM currently supports the <code>float</code> type. <code>string</code>, <code>bool</code>, and other types will be available in a future release.</li> <li>range (optional): defines the boundaries for the value of a  float parameter</li> </ul> </li> <li>value (optional): default parameter value. Value strings must not include any of these special characters: <code>&lt; &gt; ! @ # $ % ^ &amp; * ( ) _ / \\ ' + - = (space)</code></li> <li>for (required): specifies the duration of time that the expression must be met before the alert will be fired</li> <li>severity (required): specifies default alert severity level</li> <li> <p>labels (optional): are additional labels to be added to generated alerts</p> </li> <li> <p>annotations (optional): are additional annotations to be added to generated alerts.</p> </li> </ul> Template example <pre><code>---\ntemplates:\n  - name: pmm_node_high_cpu_load\n    version: 1\n    summary: Node high CPU load\n    expr: |-\n      (1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])))\n      * 100\n      &gt; bool [[ .threshold ]]\n    params:\n      - name: threshold\n        summary: A percentage from configured maximum\n        unit: \"%\"\n        type: float\n        range: [0, 100]\n        value: 80\n    for: 5m\n    severity: warning\n    annotations:\n      summary: Node high CPU load ({{ $labels.node_name }})\n      description: |-\n        {{ $labels.node_name }} CPU load is more than [[ .threshold ]]%.\n</code></pre>"},{"location":"alert/alert_rules.html#test-alert-expressions","title":"Test alert expressions","text":"<p>If you want to create custom templates, you can test the MetricsQL expressions for your custom template in the Explore section of PMM. Here you can also query any PMM internal database.</p> <p>To test expressions for custom templates:</p> <ol> <li>On the main menu in PMM, choose Explore &gt; Metrics.</li> <li>Enter your expression in the Metrics field and click Run query.</li> </ol> <p>For example, to check the CPU usage, Go to Explore &gt; Metrics in your PMM dashboard and run the query expression below: <pre><code>(1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100\n</code></pre> </p> <p>Note that to paste the query above, Explore must be in <code>Code</code> mode, and not in <code>Builder</code> mode.</p>"},{"location":"alert/alert_rules.html#add-an-alert-rule-based-on-a-template","title":"Add an alert rule based on a template","text":"<p>After provisioning the resources required for creating Percona templated alerts, you are now ready to create your alert rule based on a Percona template. </p> <p>If you want to learn about creating Grafana alerts instead, check out Grafana\u2019s documentation:</p> <ol> <li>Go to Alerting &gt; Alert Rules, and click New alert rule from template.</li> <li>On the Create alert rule from template page, choose the template on which you want to base the new alert rule. This automatically populates the Name, Duration, and Severity fields with information from the template. You can change these values if you want to override the default specifications in the template.</li> <li>From the Folder drop-down menu, select the location where you want to store the rule.</li> <li> <p>In the Filters section, specify if you want the alert rule to apply only to specific services or nodes. For example: <code>service_name=ps5.7</code>. When creating alert rule filters, consider the following:</p> <ul> <li>Filters use conjunction semantics. This means that if you add more than one filter, PMM will combine their conditions to search for matches: filter 1 AND filter 2 AND filter 3.</li> <li>Label must be an exact match. You can find a complete list of labels using the  Explore menu in PMM.</li> </ul> </li> <li> <p>Click Save and Exit to close the page and go to the Alert Rules tab where you can review, edit and silence your new alert.</p> </li> </ol> <p></p>"},{"location":"alert/alert_rules.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/contact_points.html","title":"Contact points","text":"<p>Contact points specify where Percona Alerting should deliver notifications for alerts. PMM can be configured via a Notification policy to send a notification to specified contact points whenever an alert is fired.</p> <p>Depending on the severity of an alert, you might want to send different alert notifications to different channels. For example, you can deliver common notifications via a Slack channel, but send an email notification for potentially critical issues.  </p> <p>Percona Alerting uses email as the default contact point but you can choose from a variety of other contact points, including Slack, Webhooks, PagerDuty, and more.</p> <p>Before Percona Alerting can send out email notifications via email contact points, you will need to:</p> <ol> <li>Configure Email (SMTP) server settings.</li> <li>Configure a contact point to define the email delivery options</li> </ol> <p>Contact points with invalid settings show a No Attempts status under  Alerting &gt; Contact points.</p>"},{"location":"alert/contact_points.html#configure-email-smtp-server-settings","title":"Configure Email (SMTP) server settings","text":"<p>To use SMTP with a PMM Docker installation:</p> <ol> <li> <p>Create an <code>.env</code> file and populate it with your SMTP credentials (and other environment variables) as follows:</p> <p><pre><code>GF_SMTP_ENABLED=true  \nGF_SMTP_HOST=smtp.gmail.com:587\nGF_SMTP_USER=email@domain.com\nGF_SMTP_PASSWORD=&lt;YOUR_SMTP_PASSWORD&gt;\nGF_SMTP_SKIP_VERIFY=false\nGF_SMTP_FROM_ADDRESS=email@domain.com\nGF_SMTP_FROM_NAME=Percona Alerting\n</code></pre> Below is a summary of each environment variable above: </p> <ul> <li><code>GF_SMTP_ENABLED</code>: When true, enables Grafana to send emails.</li> <li><code>GF_SMTP_HOST</code>: Host address of your SMTP server.</li> <li><code>GF_SMTP_USER</code>: Username for SMTP authentication.</li> <li><code>GF_SMTP_PASSWORD</code>: Password for SMTP authentication</li> <li><code>GF_SMTP_SKIP_VERIFY</code>: When true, verifies SSL for the SMTP server.</li> <li><code>GF_SMTP_FROM_ADDRESS</code>: Email address to be used when sending out emails.</li> <li><code>GF_SMTP_FROM_NAME</code>: Name to be used when sending out emails.</li> </ul> <p>NB: If you are using your Gmail\u2019s SMTP credentials as shown above, you will have to generate an app password and fill it in as the value of your $GF_SMTP_PASSWORD variable. 2. Pass in the <code>.env</code> file to Docker run using the <code>--env-file</code> flag: <pre><code>docker run --env-file=.env -p 443:443 -p 80:80 perconalab/pmm-server:3.0.0-beta\n</code></pre> This command starts a docker container and will keep running as long as the container is also running. Stopping the command (e.g with Ctrl+C) will stop the container hence, subsequent commands should be run in a new terminal.</p> </li> </ol>"},{"location":"alert/contact_points.html#restore-smtp-settings-following-an-upgrade","title":"Restore SMTP settings following an upgrade","text":"<p>If you configured PMM to use SMTP settings via environment variables, you do not need to do anything after an upgrade as your settings will be transferred.</p>"},{"location":"alert/contact_points.html#configure-an-email-contact-point","title":"Configure an Email contact point","text":"<p>After configuring the SMTP settings, specify email delivery options for an Email contact point:</p> <ol> <li>Go to Alerting &gt; Contact points.</li> <li>Click the edit button next to the grafana-default-email to update PMM\u2019s default Email contact point, or click Add contact point to create a custom one.</li> <li>Enter a contact point name, and add the email addresses for the recipients of the email notifications.</li> <li>Expand Optional Email settings and fill in any other relevant settings:<ul> <li>Enable the Single email option to send a single email to the recipients containing alerts that are firing. For example, if an alert fires for three nodes, this would send only one email listing all three alerts.</li> <li>Add an optional message to include with the email notifications.</li> <li>Edit the email subject for the notifications. The default subject line uses the following format FIRING: number of alerts firing for the alert rule.</li> </ul> </li> <li>If you do not want to be notified when an alert resolves, expand Notification settings, and tick the Disable Resolved Message checkbox.</li> <li>If you want your contact point to notify via multiple channels, for example, both via Email and Teams, click New contact point type and fill out additional contact point type details.</li> <li>Click the Test button to send a test email and make sure your contact point works as expected.     </li> <li>Click the Save contact point button at the bottom of the page. The contact point is now listed under Alerting &gt; Contact points.</li> </ol>"},{"location":"alert/contact_points.html#create-additional-contact-points","title":"Create additional contact points","text":"<p>In addition to Email contact points, you can add a variety of other contact points, including Slack, email, webhooks, PagerDuty, and more.</p> <p>Follow the steps above to create additional contact points. Different contact points require different configuration information. For example, for Slack, PMM requires the recipient information, the API token and the webhook URL, which you can get from your Slack administrator.</p>"},{"location":"alert/contact_points.html#notification-policies","title":"Notification policies","text":"<p>Notification policies determine how notifications (triggered by alerts) are routed to contact points by defining where, when, and how to send notifications.</p> <p>For example, you might specify a limit for the number of times a notification is sent during a certain period. This helps ensure that you don\u2019t spam your Slack channel with too many notifications about the same issue.</p>"},{"location":"alert/contact_points.html#root-notification-policy","title":"Root notification policy","text":"<p>Percona Alerting comes pre-configured with a Notification Root Policy, which is the default notification policy. It uses the grafana-default-email contact point and is applied to all alerts that don\u2019t have a custom notification policy assigned to them.</p>"},{"location":"alert/contact_points.html#how-matching-works","title":"How matching works","text":"<p>Policies can have one or more child policies. An alert matches if the alert\u2019s labels match all the Matching Labels specified on the policy.</p> <p>Alerts that don\u2019t match any specific policies are handled by the root policy. The root policy also handles any alert rules for which the assigned custom notification policy has been deleted, to ensure notifications for existing alerts continue to be delivered.</p>"},{"location":"alert/contact_points.html#edit-the-root-notification-policy","title":"Edit the root notification policy","text":"<p>To edit the root notification policy:</p> <ol> <li>Go to  Alerting &gt; Notification policies tab.</li> <li>Click the ellipsis botton next to the root policy box and select the Edit option.</li> <li>Choose whether to keep the default Email contact point, select a new available contact point or create a new one.</li> <li>In the Group by field, specify how alert rules should be processed into notifications. If multiple alerts are matched for this policy, they will be grouped based on the labels you specify, and a notification will be sent per group.</li> <li>Expand the Timing options section and specify how notification wait times should be processed. These are short pauses the system can take to efficiently process multiple sets of alerts for notifications:<ul> <li>Group wait: The default is to wait 30 seconds to buffer alerts of the same group before sending a notification initially.</li> <li>Group interval: The default is to wait five minutes before sending a batch of new alerts after the first notification was sent.</li> <li>Repeat interval: The default is to wait four hours before resending an alert.</li> </ul> </li> <li>Click Save to save your changes.</li> </ol>"},{"location":"alert/contact_points.html#create-a-new-notification-policy","title":"Create a new notification policy","text":"<p>To create a new notification policy:</p> <ol> <li> <p>Go to  Alerting &gt; Notification policies tab. </p> </li> <li> <p>Click New nested policy.</p> </li> <li>The Matching labels section defines the rules for matching alert labels. The matching label is a combination of label name, operator and label value, where the label name is any valid label in your environment. For example:  <code>node_name</code>, <code>cluster</code>, etc. A policy will match an alert if the alert\u2019s labels match all the matching labels specified on the policy. If there are no matchers, the policy will handle all the alert instances. For example, you could add a node_name=pmm-server matcher to send out notifications only for this node.</li> <li>Select an existing contact point for the policy.</li> <li>Enable Continue matching subsequent sibling nodes to continue matching subsequent siblings of the policy after an alert matched the parent policy. This can be useful, for example, when you want to send notifications to a catch-all contact point as well as to one of more specific contact points handled by subsequent policies.</li> <li>Toggle Override grouping if you do not want to use root policy grouping.</li> <li>Toggle Override general timings to specify how often you want to wait until the initial notification is sent for a new group. When this is disabled, PMM uses root policy group timings instead.</li> <li> <p>Add a mute timing if you want to mute notifications or this policy for a specific, regular interval. For example, you can create a mute to suppress trivial notifications during weekends.  Mute timings are different from silences in the sense that they are recurring, while silences have a fixed start and end time.</p> <p>Important</p> <p>Time specified in mute timing must be in UTC and military format i.e. 14:00 not 2:00 PM.</p> </li> </ol> <p></p>"},{"location":"alert/contact_points.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/disable_alerts.html","title":"Disable Percona Alerting","text":"<p>Percona Alerting is enabled by default in the PMM Settings. This feature adds the Percona templated alerts option on the Alerting menu.</p> <p>If for some reason you want to disable PMM Alert templates and keep only Grafana-managed alerts:</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced settings.</li> <li>Disable the Alerting option. The Alerting menu will now display only Grafana-managed alert rules.</li> </ol> <p></p>"},{"location":"alert/disable_alerts.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/silence_alerts.html","title":"Silence alerts","text":"<p>Create a silence when you want to suppress/stop alerts and their associated notifications for a very specific amount of time.  Silences default to today\u2019s current date and have a default duration of two hours.</p> <p>You can also schedule a silence for a future date and time. This is referred to as a <code>Pending</code> silence, which can be observed on the Silences page.</p> <p>During a silence, PMM continues to track metrics but does not trigger alerts or send notifications to any specified contact points. Once the silence expires alerts and notifications will resume.</p> <p>Silenced alerts are still recorded under Alerting &gt; Fired Alerts so that you can review them later. Silenced alerts show up as Surpressed and are disabled for as long as it\u2019s specified in the Silence Duration, or until you remove a silence.</p>"},{"location":"alert/silence_alerts.html#using-silences","title":"Using silences","text":"<p>You can silence an alert by creating a silence from the Silences page.  Here you define labels that match the alert that you want to silence.</p> <p>To create a new silence:</p> <ol> <li>Click the Create silence button.</li> <li>Select the start and end date to indicate when the silence should go into effect and expire.</li> <li>Optionally, update the duration to alter the time for the end of silence in the previous step to correspond to the start plus the duration.</li> <li>Enter one or more matching labels by filling out the Name and Value fields. Matchers determine which rules the silence will apply to. Note that all labels specified here must be matched by an alert for it to be silenced.</li> <li>Enter any additional comments you would like about this silence - by default, the date the silence was created is placed here.</li> <li>Review the affected alert instances that will be silenced.</li> <li>Click Save silece.</li> </ol> <p>For more information on working with silences, see About alerting silences in the Grafana documentation.</p>"},{"location":"alert/silence_alerts.html#alerting-compatibility","title":"Alerting compatibility","text":""},{"location":"alert/silence_alerts.html#template-compatibility-with-pmm-2","title":"Template compatibility with PMM 2","text":"<p>After upgrading from the latest PMM 2 version to PMM 3, you will find all your alert templates under Alerting &gt; Alert rule templates.</p> <p>If you have any templates available in the  <code>/srv/ia/templates</code> folder, make sure to transfer them to <code>/srv/alerting/templates</code> as PMM 3 will look for custom templates in this location.</p>"},{"location":"alert/silence_alerts.html#template-compatibility-with-other-alerting-tools","title":"Template compatibility with other alerting tools","text":"<p>If you have existing YAML alert templates that you want to leverage in Percona Alerting:</p> <ol> <li>Go to Alerting &gt; Alert rule templates tab and click Add template at the top right-hand side of the table.</li> <li>Upload a local .yaml file that contains the definition of one or more alert templates then click Add. Alert templates added in bulk will be displayed individually on Alert rule templates page.</li> </ol>"},{"location":"alert/silence_alerts.html#script-commands","title":"Script commands","text":"<p>The default command for migrating rules is: <pre><code>python3 ia_migration.py -u admin -p admin\n</code></pre> To see all the available options, check the scrip help using <code>ia_migration.py -h</code></p>"},{"location":"alert/silence_alerts.html#script-prerequisites","title":"Script prerequisites","text":"<ul> <li>Python version 3.x, which you can download from Python Downloads centre.</li> <li>Requests library, which you can install with the following command: <code>pip3 install requests</code>.</li> </ul> <p>Important</p> <p>The script sets all migrated alert rules to Active. Make sure to silence any alerts that should not be firing.</p> <p>For more information about the script and advanced migration options, check out the help information embedded in the script.</p> <p></p>"},{"location":"alert/silence_alerts.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"alert/templates_list.html","title":"List of available alert templates","text":"<p>The table below lists all the alert templates available in Percona Monitoring and Management (PMM). </p> <p>This list includes both built-in templates (accessible to all PMM users), and customer-only templates.</p> <p>To access the customer-only templates, you must be a Percona customer and connect PMM to Percona Platform using a Percona Account.</p> Template name Description Availability Database technology Node high CPU load Monitors node CPU usage and alerts when it surpasses 80% (default threshold). Provides details about specific nodes experiencing high CPU load, indicating potential performance issues or scaling needs. All users MySQL, MongoDB, PostgreSQL Memory available less than a threshold Tracks available memory on nodes and alerts when free memory drops below 20% (default threshold). Helps prevent system instability due to memory constraints. All users MySQL, MongoDB, PostgreSQL Node high swap filling up Monitors node swap usage and alerts when it exceeds 80% (default threshold). Indicates potential memory pressure and performance degradation, allowing for timely intervention. All users MySQL, MongoDB, PostgreSQL PMM agent down Monitors PMM Agent status and alerts when an agent becomes unreachable, indicating potential host or agent issues. All users MySQL, MongoDB, PostgreSQL, ProxySQL Backup failed [Technical Preview] Monitors backup processes and alerts on failures, providing details about the failed backup artifact and service. Helps maintain data safety and recovery readiness. This template is currently in Technical Preview status and should be used for testing purposes only as it is subject to change. All users MySQL, MongoDB, PostgreSQL, ProxySQL MongoDB down Detects when a MongoDB instance becomes unavailable, enabling rapid response to maintain database accessibility. All users MongoDB Memory used by MongoDB connections Tracks MongoDB connection memory usage and alerts when it exceeds configurable thresholds. Helps identify and address potential performance issues caused by high memory consumption. All users MongoDB Memory used by MongoDB Monitors overall MongoDB memory usage and alerts when it exceeds 80% of total system memory. Provides details about specific MongoDB services and nodes experiencing high memory consumption, aiding in resource optimization. All users MongoDB MongoDB restarted Detects recent MongoDB restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Facilitates investigation of unexpected downtime and potential issues. All users MongoDB MongoDB DBPath disk space utilization Monitors disk space usage in MongoDB\u2019s data directory and alerts when it exceeds set thresholds. Helps prevent storage-related issues and ensures adequate space for database operations. Customer-only MongoDB MongoDB host SSL certificate expiry Tracks SSL certificate expiration dates for MongoDB hosts and alerts when certificates are approaching expiry. Enables timely certificate renewal to maintain secure connections. Customer-only MongoDB MongoDB oplog window Monitors the oplog window size and alerts when it falls below the recommended threshold (typically 24-48 hours). Ensures sufficient time for secondary nodes to replicate data and maintain cluster consistency. Customer-only MongoDB MongoDB read tickets Tracks read ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Helps optimize read performance and identify potential bottlenecks. Customer-only MongoDB MongoDB replication lag is high Monitors replication lag and alerts when it exceeds acceptable thresholds. Crucial for maintaining data consistency across replicas and identifying synchronization issues. Customer-only MongoDB MongoDB ReplicaSet has no primary Detects when a replica set loses its primary node and alerts users. Indicates that the cluster is in read-only mode, potentially affecting write operations and overall database functionality. Customer-only MongoDB MongoDB member is in unusual state Identifies and alerts when replica set members enter unusual states such as Recovering, Startup, or Rollback. Helps maintain cluster health and performance by enabling quick intervention. Customer-only MongoDB MongoDB write tickets Monitors write ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Aids in optimizing write performance and identifying potential bottlenecks. Customer-only MongoDB MySQL down Monitors MySQL instance availability and alerts when any MySQL service becomes unreachable. Enables quick response to maintain database services. All users MySQL MySQL replication running IO Tracks MySQL replication I/O thread status and alerts if it stops running on a replica. Crucial for ensuring data is being received from the primary server. All users MySQL MySQL replication running SQL Monitors MySQL replication SQL thread status and alerts if it stops running on a replica. Essential for verifying that received data is being applied correctly to maintain data consistency. All users MySQL MySQL restarted Detects recent MySQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. All users MySQL MySQL connections in use Tracks MySQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to connection overload. All users MySQL PostgreSQL down Detects when PostgreSQL instances become unavailable, enabling quick response to maintain database services. Provides details about affected services and nodes. All users PostgreSQL PostgreSQL restarted Identifies recent PostgreSQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. All users PostgreSQL PostgreSQL connections in use Monitors PostgreSQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to excessive connections. All users PostgreSQL PostgreSQL index bloat is high Detects excessive index bloat and alerts users. Helps identify performance degradation due to bloated indexes, enabling timely maintenance to improve query performance. Customer-only PostgreSQL PostgreSQL high number of dead tuples Monitors the accumulation of dead tuples in relations and alerts when they exceed set thresholds. Indicates potential issues with vacuum settings and helps optimize storage and query performance. Customer-only PostgreSQL PostgreSQL has a high number of statement timeouts Tracks and alerts on frequent query cancellations due to statement timeouts. Helps identify various issues such as high load, poorly written queries, or inadequate resource allocation. Customer-only PostgreSQL PostgreSQL table bloat is high Detects excessive table bloat and alerts users. Indicates a need to adjust vacuum settings for specific relations or globally, helping to maintain optimal query performance and storage efficiency. Customer-only PostgreSQL PostgreSQL high rate of transaction rollbacks Monitors the ratio of transaction rollbacks to commits and alerts on high rates. Helps identify potential application or database issues leading to frequent transaction failures. Customer-only PostgreSQL PostgreSQL tables not auto analyzed Identifies tables that are not being auto-analyzed and alerts users. Crucial for maintaining accurate statistics and generating proper query execution plans. Customer-only PostgreSQL PostgreSQL tables not auto vacuumed Detects tables that are not being auto-vacuumed and alerts users. Essential for managing bloat, optimizing storage, and maintaining overall database health. Customer-only PostgreSQL PostgreSQL unused replication slot Identifies and alerts on unused replication slots. Helps prevent excessive WAL retention and potential disk space issues, especially when replicas are offline. Customer-only PostgreSQL ProxySQL server status Tracks ProxySQL server status and alerts when a server\u2019s status becomes OFFLINE_SOFT (3) or OFFLINE_HARD (4). Provides details about the server\u2019s endpoint, hostgroup, and associated ProxySQL service. Crucial for maintaining high availability and preventing service disruptions. All users ProxySQL <p></p>"},{"location":"alert/templates_list.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"annotate/index.html","title":"PMM annotation","text":"<p>Alerting notifies of important or unusual activity in your database environments so that you can identify and resolve problems quickly. When something needs your attention, PMM automatically sends you an alert through your specified contact points. </p> <p></p>"},{"location":"annotate/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"api/index.html","title":"About PMM API","text":"<p>PMM Server lets you visually interact with API resources representing all objects within PMM. You can browse the API using the Swagger UI, accessible at the <code>/swagger/</code> endpoint URL:</p> <p></p> <p>Clicking an object lets you examine objects and execute requests on them:</p> <p></p> <p>The objects visible are nodes, services, and agents:</p> <ul> <li> <p>A Node represents a bare metal server, a virtual machine, a Docker container, or a more specific type such as an Amazon RDS Node. A node runs zero or more Services and Agents, and has zero or more Agents providing insights for it.</p> </li> <li> <p>A Service represents something useful running on the Node: Amazon Aurora MySQL, MySQL, MongoDB, etc. It runs on zero (Amazon Aurora Serverless), single (MySQL), or several (Percona XtraDB Cluster) Nodes. It also has zero or more Agents providing insights for it.</p> </li> <li> <p>An Agent represents something that runs on the Node which is not useful in itself, but instead provides insights (metrics, query performance data, etc.) about Nodes and/or Services. An agent always runs on the single Node (except External Exporters), and provides insights for zero or more Services and Nodes.</p> </li> </ul> <p>Nodes, Services, and Agents have Types which define specific their properties, and their specific logic.</p> <p>Nodes and Services are inherently external. We don\u2019t manage their creation or deletion, but rather maintain a list of them within PMM Server by adding them to or removing them from the inventory. The majority of Agents are initiated and halted by pmm-agent, with one exception being the External Exporter Type, which is initiated externally.</p>"},{"location":"api/index.html#service-accounts-and-authentication","title":"Service accounts and authentication","text":"<p>For information about controlling access to the PMM Server components and resources, see the Authentication with service accounts topic.</p> <p></p>"},{"location":"api/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"api/authentication.html","title":"Service accounts authentication","text":"<p>Deprecation notice</p> <p>Starting with version 3, PMM no longer uses API keys as the primary method for controlling access to the PMM Server components and resources. Instead, PMM is now leveraging Grafana service accounts, which have limited scopes and offer enhanced security compared to API keys.</p>"},{"location":"api/authentication.html#automatic-migration-of-api-keys","title":"Automatic migration of API keys","text":"<p>When you install PMM v3.x, any existing API keys will be seamlessly converted to service accounts with corresponding service tokens.</p> <p>Service accounts in PMM provide a secure and efficient way to manage access to the PMM Server and its resources. They serve as a replacement for the basic authentication and API keys used in previous versions of PMM (v.2 and earlier).</p> <p>With service accounts, you can:</p> <ul> <li>control access to PMM Server components and resources.</li> <li>define granular permissions for various actions.</li> <li>create and manage multiple access tokens for a single service account.</li> </ul> <p>Creating multiple tokens for the same service account is beneficial in the following scenarios:</p> <ul> <li>when multiple applications require the same permissions but need to be audited or managed separately. By assigning each application its own token, you can track and control their actions individually.</li> <li>when a token becomes compromised and needs to be replaced. Instead of revoking the entire service account, you can rotate or replace the affected token without disrupting other applications using the same service account.</li> <li>when you want to implement token lifecycle management. You can set expiration dates for individual tokens, ensuring that they are regularly rotated and reducing the risk of unauthorized access.</li> </ul>"},{"location":"api/authentication.html#service-account-name-management","title":"Service Account name management","text":"<p>To prevent node registration failures, PMM automatically manages service account names that exceed 200 characters using a <code>{prefix}_{hash}</code> pattern. For example, a very long service account name will be automatically shortened while maintaining uniqueness:</p> <ul> <li>original: <code>very_long_mysql_database_server_in_production_environment_with_specific_location_details...</code></li> <li>shortened: <code>very_long_mysql_database_server_in_prod_4a7b3f9d</code></li> </ul>"},{"location":"api/authentication.html#generate-a-service-account-and-token","title":"Generate a service account and token","text":"<p>PMM uses Grafana service account tokens for authentication. These tokens are randomly generated strings that serve as alternatives to API keys or basic authentication passwords.</p> <p>Here\u2019s how to generate a service account token:</p> <ol> <li>Log into PMM.</li> <li>From the side menu, click Administration &gt; Users and access.</li> <li>Click on the Service accounts card.</li> <li>Click Add service account. Specify a unique name for your service account, select a role from the drop-down menu, and click Create to display your newly created service account.</li> <li>Click Add service account token.</li> <li>In the pop-up dialog, provide a name for the new service token, or leave the field empty to generate an automatic name.</li> <li>Optionally, set an expiration date for the service account token. PMM cannot automatically rotate expired tokens, which means and you will need to manually update the PMM-agent configuration file with a new service account token. Permanent tokens, on the other hand, remain valid indefinitely unless specifically revoked.</li> <li>Click Generate Token. A pop-up window will display the new token, which usually has a glsa_ prefix.</li> <li>Copy your service token to the clipboard and store it securely. Now you can use your new service token for authentication in PMM API calls or in your pmm-agent configuration.</li> </ol>"},{"location":"api/authentication.html#authenticate","title":"Authenticate","text":"<p>You can authenticate your request using the HTTPS header.</p> <p>Important</p> <p>Use the <code>-k</code> or <code>--insecure</code> parameter to force cURL to ignore invalid and self-signed SSL certificate errors. The option will skip the SSL verification process, and you can bypass any SSL errors while still having SSL-encrypted communication. However, using the <code>--insecure</code>  parameter is not recommended. Although the data transfer is encrypted, it is not entirely secure. For enhanced security of your PMM installation, you need valid SSL certificates. For information on validating SSL certificates, refer to: SSL certificates.</p> <pre><code>curl -H \"Authorization: Bearer &lt;service_token&gt;\" https://127.0.0.1/v1/version\n</code></pre>"},{"location":"api/authentication.html#use-a-service-token-in-basic-authentication","title":"Use a service token in basic authentication","text":"<p>You can include the service token as a query parameter in a REST API call using the following format. Replace YOUR_SERVICE_TOKEN with the actual service token you obtained in step 12.</p> <p>Example <pre><code>curl -X GET https://service_token:SERVICE_TOKEN@localhost/v1/version\n</code></pre></p>"},{"location":"api/authentication.html#use-a-service-token-in-bearer-authentication-http-header","title":"Use a service token in Bearer authentication (HTTP header)","text":"<p>You can also include the service token in the header of an HTTP request for authentication. To do this, replace <code>SERVICE_TOKEN</code> with the actual service token you obtained in step 12.</p> <p>Example <pre><code>curl -X GET -H 'Authorization: Bearer SERVICE_TOKEN' \\\n  -H 'Content-Type: application/json' https://127.0.0.1/v1/version\n</code></pre></p> <p></p>"},{"location":"api/authentication.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/index.html","title":"Back up and restore","text":"<p>Losing your data can destroy your business. This is why backing up data is critical for all database operations. Even more important than backing up data, is the ability to restore it in the event of data loss. PMM enables you to do all this with zero downtime and minimal performance impact.</p> <ul> <li>MongoDB (Generally Available)</li> <li>MySQL (in Technical Preview)</li> </ul> <p>Enable the Backup Management option in PMM\u2019s Advanced Settings to activate the Backup page from where you can: </p> <ul> <li>Create and restore MongoDB and MySQL backups </li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"backup/index.html#supported-setups","title":"Supported setups","text":"<p>For MySQL databases, you can create and restore on-demand and scheduled physical backups. For MongoDB, you can create and restore physical, logical and Point-in-Time-Recovery (PITR) backups, both on-demand and scheduled.</p>"},{"location":"backup/index.html#sharded-mongodb-cluster-configurations","title":"Sharded MongoDB cluster configurations","text":"<p>PMM 3 supports creating backups of sharded MongoDB clusters. However, the restoring process is not handled end-to-end, and requires you to manually restore the artifacts using the CLI in Percona Backup for MongoDB.</p>"},{"location":"backup/index.html#start-here","title":"Start here","text":"<p>To learn how to create and restore backups, check out subtopics below:</p> <ul> <li>Prepare a storage location</li> <li> MongoDB  backups</li> <li> MySQL backups </li> </ul> Additional resources <p>Here are some external resources for learning more about databases backups:</p> <ul> <li>Amazon Web Services S3</li> <li>Percona Backup for MongoDB</li> <li>PERCONA_QPRESS</li> <li>PERCONA_XBCLOUD</li> <li>PERCONA_XBSTREAM</li> <li>PERCONA_XTRABACKUP</li> <li>oplog slices</li> <li>Percona Server for MongoDB</li> <li>MongoDB Replication</li> </ul> <p></p>"},{"location":"backup/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/delete_a_backup.html","title":"Delete a backup","text":"<p>You can only delete backup artifacts stored on Amazon S3-compatible. Local backups must be removed manually.</p> <p>To delete a backup:</p> <ol> <li>Go to   Backup &gt; All Backups and find the row with the backup you want to delete.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  &gt; Delete backup.</li> <li>In the Delete backup artifact dialog box, enable Delete from storage if you also want to delete the actual backup content besides just the backup register.</li> <li>Click Delete.</li> </ol> <p></p>"},{"location":"backup/delete_a_backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/edit_scheduled.html","title":"Edit a scheduled backup","text":"<p>To edit a scheduled backup:</p> <ol> <li>Go to Backup &gt; Scheduled Backup Jobs.</li> <li>In the Actions column:<ul> <li>Click the switch  to enable or disable the backup.</li> <li>Click  to edit, delete or create a (by default, disabled) copy of the backup schedule.</li> </ul> </li> </ol> <p></p> <p></p>"},{"location":"backup/edit_scheduled.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/prepare_storage_location.html","title":"Prepare a storage location","text":"<p>Prepare a storage location as a backup destination for creating and storing your backup artifacts.</p> <p>PMM supports the following types of storage:</p> <ul> <li>Amazon S3-compatible: enables you to use not only AWS S3, but also other storage solutions that support S3 API, like min.io.</li> <li>Local storage: currently only available for MongoDB backups.</li> </ul>"},{"location":"backup/prepare_storage_location.html#prepare-a-location-for-local-backups","title":"Prepare a location for local backups","text":"<p>If you prefer storing your MongoDB backup artifacts on a remote filesystem, make sure that you\u2019ve mounted the remote folder to all the mongoDB nodes on the same path, and that PBM tool has Write permissions on the path you define.</p> <p>For more information, see the Percona Backup for MongoDB (PBM) documentation.</p>"},{"location":"backup/prepare_storage_location.html#prepare-a-location-for-s3-compatible-storage","title":"Prepare a location for S3-compatible storage","text":"<p>If you want to store backup artifacts in S3-compatible storage, you can use Amazon S3, Min.io or any other storage solution with S3-compatible API.</p> <p>Before creating a cloud storage location for our future backups, make sure you have your S3-compatible storage ready. In addition to bucket location details, you will also need to ensure proper S3 permissions.</p> <p>The general minimum permissions are LIST/PUT/GET/DELETE. A sample IAM policy is:</p> <pre><code>    ```json\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:ListBucket\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing\"\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:PutObject\",\n                    \"s3:PutObjectAcl\",\n                    \"s3:GetObject\",\n                    \"s3:GetObjectAcl\",\n                    \"s3:DeleteObject\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing/*\"\n            }\n        ]\n    }\n    ```\n</code></pre>"},{"location":"backup/prepare_storage_location.html#create-the-storage-location","title":"Create the storage location","text":"<ol> <li> <p>Go to Backup &gt; Storage Locations:</p> <p></p> </li> <li> <p>Click Add storage location and fill in a name and description for this new location.</p> </li> <li> <p>Choose the type of storage location you are creating:</p> <ul> <li>S3: Specify the S3-compatible backup location endpoint (URL), bucket name, and connection details. </li> <li>Local Client: specify the path on your local client for files to be backed up to.</li> </ul> </li> <li> <p>Optionally, for S3-compatible storages, you can click Test to check the connection.</p> </li> <li> <p>Click Add to create the location.</p> </li> </ol>"},{"location":"backup/prepare_storage_location.html#specific-target-directories-for-backups","title":"Specific target directories for backups","text":"<p>During backup creation, PMM enables you to set a specific folder within the local or S3-compatible location that you prepared following the instructions above. Organizing backups in folders not only makes it easier to group backups for an entire cluster, but also improves PMM-PBM (Percona Backup for MongoDB) integration workflows. </p> <p>The Folder field on the Create Backup pages is automatically populated with the value of the cluster label. You can change this default folder from PMM\u2019s Advanced Settings, but make sure you understand how your custom folder will impact PBM integration workflows.</p> <p></p>"},{"location":"backup/prepare_storage_location.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/backup_mongo.html","title":"Supported setups for MongoDB backups","text":"<p>PMM supports the following actions for MongoDB backups: </p>"},{"location":"backup/mongodb-backup/backup_mongo.html#replica-set-setups","title":"Replica set setups","text":"<ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating and restoring Logical snapshot backups</li> <li>Creating and restoring Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage. Restoring logical PITR backups from S3-compatible object storage.</li> </ul>"},{"location":"backup/mongodb-backup/backup_mongo.html#sharded-clusters","title":"Sharded clusters","text":"<p>PMM 3 supports backing up sharded clusters. However, restoring for sharded cluster configurations is only supported from the CLI, and is handled via Percona Backup for MongoDB.</p> <ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating Logical snapshot backups</li> <li>Creating Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage</li> </ul> <p>For a detailed overview of the supported setups for MongoDB, check out the Support matrix.</p> <p></p>"},{"location":"backup/mongodb-backup/backup_mongo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html","title":"Create MongoDB PITR backups","text":"<p>Point-in-Time Recovery (PITR) restores databases up to a specific moment in time. PITR includes restoring the data from a backup snapshot and replaying all events that occurred to this data up to a specified moment from oplog slices.</p> <p>Point-in-Time Recovery helps you prevent data loss during a disaster such as crashed database, accidental data deletion or drop of tables, or unwanted update of multiple fields instead of a single one.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#compatibility-with-percona-backup-for-mongodb","title":"Compatibility with Percona Backup for MongoDB","text":"<p>PMM introduced the option to create PITR Backups for MongoDB in version 2.23, as part of the larger Backup Management feature. This implementation in PMM uses Percona Backup for MongoDB (pbm) behind the scenes.</p> <p>Percona Backup for MongoDB is a distributed, low-impact solution for achieving consistent backups of MongoDB sharded clusters and replica sets. Restoring PITR backups is available for backups based on pbm \u2264 2.0.1. To restore PITR backups, make sure you have pbm \u2265 2.0.1 installed.</p> <p>Percona Backup for MongoDB supports Percona Server for MongoDB and MongoDB Community \u2264 3.6, with MongoDB Replication enabled. For more information, see the Percona Backup for MongoDB documentation.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#how-does-it-work","title":"How does it work?","text":"<p>When point-in-time recovery (PITR) is enabled, pbm-agent periodically saves consecutive slices of the oplog.</p> <p>To start saving oplog, PBM requires a backup snapshot. Such snapshots are created when you activate a PITR-scheduled task in PMM.</p> <p>Since PBM saves oplog slices and streams them into your storage between scheduled task runs, scheduling frequent PITR backups is not necessary. You can use the available oplog slices in your storage to restore a backup to any moment between snapshots.</p> <p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Select the Schedule Backup option in the Create Scheduled backup window.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select Logical as this is the only data model that currently supports PITR backups.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage.     However, restoring from local storage is not supported yet.     If no options are available here, see the Create a storage location topic.</li> <li>Specify the backup type and the schedule for your backup:<ul> <li>Backup Type: select the  PITR option.</li> <li>Schedule: configure the frequency and the start time for this backup.  </li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is not available for PITR backups. Currently, retention policies can only be specified for Snapshot backups stored on Amazon S3-compatible storage.</li> </ul> </li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual).      Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li> <p>In the Folder field, check the target directory available for the specified service and location. By default, this field comes prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre></p> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> </li> <li> <p>Click Schedule to start creating the backup artifact.</p> </li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol> <p></p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#failed-backup-alerts","title":"Failed backup alerts","text":"<p>If you want to be notified of any MongoDB backups that fail, you can create an alert based on the Backup Failed alert template. For information on working with alert templates, see the Percona Alerting topic.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#pitr-artifacts","title":"PITR artifacts","text":"<p>The PITR oplog is available a few minutes (10 by default) after your PITR job has run for the first time. To see the corresponding PITR artifact, check out the list under Backup &gt; All Backups.</p> <p></p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#pitr-and-other-scheduled-backups","title":"PITR and other scheduled backups","text":"<p>Make sure to disable any other scheduled backup jobs before creating a PITR backup. PMM displays an error message if you try to enable PITR while other scheduled backup jobs are active:</p> <p></p> <p>This constraint applies at the service level. You can still have PITR enabled for one service while having regular scheduled backup jobs for other services.</p> <p></p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/create_mongo_on_demand.html","title":"Create MongoDB on-demand and scheduled backups","text":"<p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <p>To schedule or create an on-demand backup, check the instructions below. If you want to create a Point-in-time-recovery (PITR) backup instead, see Create MongoDB PITR backups.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>In the Create Scheduled backup window, select whether you want to create an On Demand or a Schedule Backup.</li> <li>Enter a unique name for the backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select whether you want to create a Physical or Logical backup of your data, depending on your use case and requirements.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage. If no options are available here, see the Create a storage location topic.</li> <li> <p>Specify the backup type, the schedule, and a retention policy for your backup:</p> <ul> <li>Backup Type: select Full. If you want to create a PITR backup instead, see the Create MongoDB PITR backups topic</li> <li>Schedule: if you\u2019re creating a scheduled backup, configure its frequency and start time.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for snapshot backups stored on S3-compatible storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries. </li> <li> <p>In the Folder field, check the target directory available for the specified service and location. By default, this field is prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre> </p> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> </li> </ul> </li> <li> <p>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</p> </li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol> <p></p>"},{"location":"backup/mongodb-backup/create_mongo_on_demand.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/mongo_prerequisites.html","title":"MongoDB backup prerequisites","text":"<p>Before creating MongoDB backups, make sure to:</p> <ol> <li>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Management has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management  then click Apply changes.</li> <li>Prepare and create a storage location for your backups.</li> <li>Check that PMM Client is installed and running on all MongoDB nodes in the cluster.</li> <li>Check that Percona Backup for MongoDB (PBM) is installed and <code>pbm-agent</code> is running on all MongoDB nodes in the replica set. Make sure to configure the MongoDB connection URI for pbm-agent on all nodes.</li> <li>Check that installed mongod binary is added to PATH variable of the user under which PMM client is running, and that mongod is controlled as a service by systemctl. PMM only works with a single mongod installed on a node.</li> <li> <p>Check that your MongoDB Services are managed as clusters in PMM. Go to PMM Inventory &gt; Services page, expand the Details section  on the Options column, and make sure that all the services in the table specify a cluster name. Services that do not specify a cluster name should be removed and re-added using commands like the following:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre> </p> </li> <li> <p>Check that MongoDB nodes are members of replica set.</p> </li> <li>Check that you set the required permissions for creating and restoring MongoDB backups.</li> <li>Verify the MongoDB supported configurations and limitations.</li> </ol> <p>Important</p> <p>Use <code>pbm</code> in manual mode only for restoring sharded cluster backups or other operations that can only be completed via the PBM CLI! Since PMM takes care of the PBM configuration, any unnecessary manual intervention can break the state.</p> <p>PMM 3 and later require PBM 2.0.1 or newer.</p> <p></p>"},{"location":"backup/mongodb-backup/mongo_prerequisites.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/mongodb_limitations.html","title":"MongoDB Backup and Restore support matrix","text":"<p>Creating and restoring MongoDB backups in PMM currently has the following limitations and requirements:</p> <ul> <li>Physical backups and restores are supported only for Percona Server for MongoDB.</li> <li>Physical restores are not supported for deployments with arbiter nodes. For more information, see the Percona Backup for MongoDB documentation.</li> <li>Creating backups for sharded clusters is available straight from the UI. However, restoring these backup artifacts is only possible via the CLI, using Percona Backup for MongoDB. For information on restoring sharded backups, check the PBM documentation.</li> <li>Retention policy is supported only for snapshot types of scheduled backups and for the S3-compatible storage type.</li> <li>Before restoring, make sure to prevent clients from accessing the database.</li> </ul>"},{"location":"backup/mongodb-backup/mongodb_limitations.html#support-matrix","title":"Support matrix","text":""},{"location":"backup/mongodb-backup/mongodb_limitations.html#backup-logical","title":"Backup: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local Full Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#backup-physical","title":"Backup: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#restore-logical","title":"Restore: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local No Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#restore-physical","title":"Restore: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Partial* Full Local Partial* <p>* Partial support for non-containerized deployments and NO support for containerized deployments.                             </p> <p></p>"},{"location":"backup/mongodb-backup/mongodb_limitations.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html","title":"Restore a MongoDB backup","text":"<p>MongoDB backups can only be restored to the same service they were created from.</p> <p>To restore a backup:</p> <ol> <li>Go to  Backup &gt; All backups and find the backup that you want to restore.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  Restore from backup. This opens the Restore from backup dialog, with the Same service option automatically preselected. This is because, currently, MongoDB backups can only be restored to a service with identical properties.</li> <li>If you are restoring a PITR backup, select the point for the date and time that you want to restore the database to.</li> <li>Click Restore then go to the Restores tab to check the status of the restored backup.</li> </ol> <p>Important</p> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html#restore-to-a-new-cluster-manually","title":"Restore to a new cluster manually","text":"<p>To restore to a new cluster manually:</p> <ol> <li>Install MongoDB and Percona Backup for MongoDB. Pay attention to the versions. To minimize potential incompatibility, use the same versions that were used for taking backups.    For instructions, see the PBM install documentation.</li> <li> <p>Configure your environment:</p> <ul> <li>to restore to a new environment with the same replica set name, make sure that the replica set name in your new destination cluster use the same name as that in the cluster that was backed up.   For more information, see Restoring a backup into a new-environment in the PBM documentation.  </li> <li> <p>to restore logical backups to a new environment that has a different replica set name, configure the name mapping between the source and target environments.    For the new environment, you can either set the PBM_REPLSET_REMAPPING environment variable for pbm CLI, or use the <code>--replset-remapping</code> flag for PBM commands.</p> <p>The mapping format is <code>&lt;rsTarget&gt;=&lt;rsSource&gt;</code>.</p> <p>For example:</p> <p><code>$ export PBM_REPLSET_REMAPPING=\"targetRS=sourceRS\"</code></p> <p>OR </p> <p><code>$ pbm restore &lt;timestamp&gt; --replset-remapping=\"targetRS=sourceRS\"</code></p> <p>For more information, see Restoring into a replica set with a different name in the PBM documentation.</p> </li> </ul> </li> <li> <p>Make sure that Percona Backup for MongoDB configuration in the new environment points to the remote storage defined for the original environment, including the authentication credentials for object stores.</p> <p>The easiest way to configure it is to create a config file, called, for example, <code>pbm_config.yaml</code>.</p> <p>For this, you can either copy the config from the source host or create a new one.</p> <p>To redirect the config output from the existing environment, use: <pre><code>  pbm config &gt;&gt; pbm_config.yaml\n</code></pre> then copy the resulting file to the new environment.</p> <p>Here\u2019s an example of config file content for AWS S3-compatible storage:</p> <p><pre><code>storage:\n  type: s3\n  s3:\n    region: us-west-2\n    bucket: pbm-test-bucket\n    prefix: backup_name_from_pmm\n    credentials:\n      access-key-id: &lt;your-access-key-id-here&gt;\n      secret-access-key: &lt;your-secret-key-here&gt; \n</code></pre> The prefix name is the artifact name that appears in the Backup name column, under  Backup &gt; All Backups page:</p> <p> </p> <p>To implement the config, use the following command:     <pre><code>pbm config --file pbm_config.yaml\n</code></pre></p> <p>For more information, see Restoring a backup into a new-environment in the PBM documentation.  </p> </li> <li> <p>Run <code>pbm list</code> to check if pbm is ready to perform the restore procedure.</p> </li> <li> <p>Once all the backups made from the original environment are available, run the restore command:</p> <ul> <li> <p>For snapshot backups:</p> <p>a) run the following command:</p> <p><pre><code>pbm list\n  Backup snapshots: 2022-11-23T19:40:06Z [restore_to_time: 2021-01-13T15:53:40Z]\n</code></pre> b) provide the timestamp of the backup to the <code>pbm</code> command:</p> <p><code>pbm restore 2022-11-23T19:40:06Z</code></p> <p>For more information, see Restore a backup topic in the PBM documentation.</p> </li> <li> <p>For PITR backups:</p> <p>a) run the following command:</p> <p><pre><code>  pbm list\n  Backup snapshots:\n    2022-11-23T19:40:06Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:40:25Z]\n    2022-11-23T19:45:07Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:45:22Z]\n  PITR &lt;on&gt;:\n    2022-11-23T19:40:26Z - 2022-11-23T19:45:22Z\n</code></pre>     b) provide the timestamp from one of the PITR ranges to the <code>pbm</code> command:</p> <p><code>pbm restore --time=\"2022-11-23T19:40:26</code></p> </li> </ul> <p>For more information, see the Point-in-time Recovery topic in the PBM documentation.</p> </li> <li> <p>Check the progress of the restore operation, using one of the commands below:</p> <ul> <li> <p>For logical restores: <code>pbm describe-restore &lt;restore_name&gt;</code></p> </li> <li> <p>For physical restores: <code>pbm describe-restore --config=/path/to/pbm_config.yaml &lt;restore_name&gt;</code></p> </li> </ul> <p>Required arguments:</p> <ul> <li>PBM generates the <code>&lt;restore_name&gt;</code> information after you start the restoring.</li> <li>The pbm_config.yaml file required for physical restores is the PBM config file that you provided for step 3.</li> </ul> </li> </ol> <p>Important</p> <p>Make sure not to run pbm backup from the new environment while the Percona Backup for MongoDB config is pointing to the remote storage location of the original environment.</p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html#restoring-from-a-sharded-cluster","title":"Restoring from a sharded cluster","text":"<p>Sharded cluster backups are supported and PMM handles the backup process end-to-end. However, restoring such artifacts is currently possible only via the CLI, using Percona Backup for MongoDB.</p> <p>For information on restoring sharded backups, check the PBM documentation</p> <p></p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mysql-backup/backup_mysql.html","title":"Supported setups for MySQL backups","text":"<p>Important</p> <p>MySQL backup functionality is still in Technical Preview.</p> <p>PMM supports MySQL database server for:</p> <ul> <li>Creating and restoring physical backups</li> <li>Storing backups to Amazon S3-compatible object storage  </li> </ul>"},{"location":"backup/mysql-backup/backup_mysql.html#backing-up-mysql-databases-hosted-in-docker-container","title":"Backing up MySQL databases hosted in Docker container","text":"<p>To ensure PMM can correctly backup and restore databases from a MySQL Docker container, make sure that the container is compatible with systemd.</p> <p></p>"},{"location":"backup/mysql-backup/backup_mysql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mysql-backup/create_mysql_backup.html","title":"Create a MySQL backup","text":"<p>Before creating a backup, make sure to check the MySQL backup prerequisites.</p> <p>To create a backup:</p> <ol> <li>Go to   Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Specify the type of backup that you want to create: On Demand or Schedule Backup.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field and selects the Physical data model, as this is the only model available for MySQL backups.</li> <li>Choose a storage location for the backup. MySQL currently only supports storing backups to Amazon S3. If no options are available here, see the Create a storage location topic section above.</li> <li>If you\u2019re creating scheduled backups, also specify the backup type, the schedule, and a retention policy for your backup:<ul> <li>Backup Type: currently, PMM only supports Full backup types for MySQL.</li> <li>Schedule: configure the frequency and the start time for this backup.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for Snapshot backups stored on S3-compatible object storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> </ul> </li> <li>Leave the Folder field as is. This field is relevant for MongoDB backups to ensure compatibility with PBM wokflows and comes prefilled with the cluster label.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis indicator  shows that a backup is currently being created.</li> </ol> <p></p>"},{"location":"backup/mysql-backup/create_mysql_backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mysql-backup/mysql_prerequisites.html","title":"MySQL backup prerequisites","text":"<p>Before creating MySQL backups, make sure to:</p> <ol> <li> <p>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Managemt has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management then click Apply changes.    !!! caution alert alert-warning \u201cImportant\u201d     If PMM Server runs as a Docker container, enable backup features at container creation time by adding <code>-e ENABLE_BACKUP_MANAGEMENT=1</code> to your <code>docker run</code> command.</p> </li> <li> <p>Check that the PMM Client is installed and running on the node.</p> </li> <li> <p>To enable Xtrabackup for MySQL 8.0+, check that pmm-agent connects to MySQL with a user that has BACKUP_ADMIN privilege.</p> </li> <li> <p>Check that there is only one MySQL instance running on the node.</p> </li> <li> <p>Verify that MySQL is running:</p> <ul> <li> <p>as a service via <code>systemd</code>;</p> </li> <li> <p>with the name <code>mysql</code> or <code>mysqld</code> (to confirm, use <code>systemctl status mysql</code> or <code>systemctl status mysqld</code> respectively);</p> </li> <li> <p>from a <code>mysql</code> system user account.</p> </li> </ul> </li> <li> <p>Make sure that there is a <code>mysql</code> system group.</p> </li> <li> <p>Check that MySQL is using the <code>/var/lib/mysql</code> directory for database storage.</p> </li> <li> <p>Make sure that <code>pmm-agent</code> has read/write permissions to the <code>/var/lib/mysql</code> directory.</p> </li> <li> <p>Check that the latest versions of the following packages are installed and included in the <code>$PATH</code> environment variable:</p> <ul> <li> <p><code>xtrabackup</code>, which includes:</p> <ul> <li> <p><code>xbcloud</code></p> </li> <li> <p><code>xbstream</code></p> </li> </ul> </li> <li> <p>[<code>qpress</code>][PERCONA_QPRESS].</p> </li> </ul> </li> </ol> <p>Important</p> <p>The versions of each must be compatible with the installed version of MySQL.</p> <p></p>"},{"location":"backup/mysql-backup/mysql_prerequisites.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup/mysql-backup/restore_mysql_backup.html","title":"Restore a MySQL backup","text":""},{"location":"backup/mysql-backup/restore_mysql_backup.html#restore-compatibility","title":"Restore compatibility","text":"<p>MySQL backups can be restored to the same service it was created from, or to a compatible one. </p> <p>To restore a backup:</p> <ol> <li>Go to  Backup &gt; All backups and find the backup that you want to restore.</li> <li>Click the three dots  in the Actions column to check all the information for the backup, then click  Restore from backup.</li> <li>In the Restore from backup dialog, select Same service to restore to a service with identical properties or Compatible services to restore to a compatible service.</li> <li>Select one of the available service names from the drop-down menu.</li> <li>Check the values, then click Restore.</li> <li>Go to the Restores tab to check the status of the restored backup.</li> </ol> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p> <p></p>"},{"location":"backup/mysql-backup/restore_mysql_backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/advanced_settings.html","title":"Advanced PMM settings","text":""},{"location":"configure-pmm/advanced_settings.html#data-retention","title":"Data retention","text":"<p>Data retention specifies how long data is stored by PMM Server. By default, time-series data is stored for 30 days. You can adjust the data retention time to balance your system\u2019s available disk space with your metrics history requirements.</p>"},{"location":"configure-pmm/advanced_settings.html#telemetry","title":"Telemetry","text":"<p>The Telemetry switch enables gathering and sending basic anonymous data to Percona, which helps us to determine where to focus the development and what is the uptake for each release of PMM.  Specifically, gathering this information helps determine if we need to release patches to legacy versions beyond support, determine when supporting a particular version is no longer necessary, and understand the best frequency of releases.</p> <p>PMM Telemetry is based on data collected by various PMM components and stored inside PMM Server </p> <p>-!!! note alert alert-primary \u201c\u201d     When PMM is installed, telemetry is not sent immediately. Before the first telemetry report is generated, PMM provides users with a 24-hour grace period to disable telemetry.</p> <p>To see the metrics being collected by telemetry, from the main menu navigate to PMM Configuration &gt;  Settings &gt; Advanced Settings &gt; Telemetry and hover over the exclamation mark.</p> <p></p> <p>We do not gather anything that can identify your system, but consider the following:</p> <ol> <li> <p>The Country Code is evaluated from the submitting IP address before being discarded.</p> </li> <li> <p>We do create an \u201cinstance ID\u201d - a random string generated using UUID v4.  This instance ID is generated to distinguish new instances from existing ones, for figuring out instance upgrades.</p> </li> </ol> <p>The first telemetry reporting of a new PMM Server instance is delayed by 24 hours to allow enough time to disable the service for those that do not wish to share any information.</p> <p>The landing page for this service, check.percona.com, explains what this service is.</p> <p>Grafana\u2019s anonymous usage statistics is not managed by PMM. To activate it, you must change the PMM Server container configuration after each update.</p> <p>As well as via the PMM Settings page, you can also disable telemetry with the <code>-e DISABLE_TELEMETRY=1</code> option in your docker run statement for the PMM Server.</p> <p>For information on the various config parameters for telemetry, see the config file.</p> <p>When active, PMM will automatically check for updates and put a notification in the home page Updates dashboard if any are available.</p>"},{"location":"configure-pmm/advanced_settings.html#advisors","title":"Advisors","text":"<p>Advisors are sets of checks grouped by functionality that run a range of database health checks on a registered PMM instance.</p> <p>The findings are reported on the Advisors &gt; Advisor Insights page, and an overview is displayed on the Home dashboard.</p> <p>The Advisors option is enabled by default.  Checks are re-fetched and rerun at intervals.</p> <p>See Working with Advisor checks.</p>"},{"location":"configure-pmm/advanced_settings.html#percona-alerting","title":"Percona Alerting","text":"<p>Enables Percona Alerting and reveals the Percona templated alerts option on the Alerting page.</p>"},{"location":"configure-pmm/advanced_settings.html#backup-management","title":"Backup Management","text":"<p>Enables Backup Management option and reveals the Backup page from where you can:</p> <ul> <li>Create and restore MongoDB and MySQL backups</li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"configure-pmm/advanced_settings.html#public-address","title":"Public Address","text":"<p>The address or hostname PMM Server will be accessible at. Click Get from browser to have your browser detect and populate this field automatically.</p>"},{"location":"configure-pmm/advanced_settings.html#microsoft-azure-monitoring","title":"Microsoft Azure monitoring","text":"<p>Caution</p> <p>This is a technical preview feature.</p> <p>Activates Microsoft Azure monitoring.</p> <p></p>"},{"location":"configure-pmm/advanced_settings.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/alertmanager.html","title":"Alertmanager integration","text":"<p>Alertmanager manages alerts, de-duplicating, grouping, and routing them to the appropriate receiver or display component.</p> <p>This section lets you configure how VictoriaMetrics integrates with an external Alertmanager.</p> <p>Tip</p> <p>If possible, use Integrated Alerting instead of Alertmanager.</p> <ul> <li>The Alertmanager URL field should contain the URL of the Alertmanager which would serve your PMM alerts.</li> <li>The Prometheus Alerting rules field is used to specify alerting rules in the YAML configuration format.</li> </ul> <p>Fill in both fields and click the Apply Alertmanager settings button to proceed.</p> <p></p>"},{"location":"configure-pmm/alertmanager.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/configure.html","title":"Configure PMM","text":"<p>This section provides the instructions to configure your PMM instance after you have installed PMM.</p> <p>The PMM Configuration page gives you access to PMM setup\u2019s settings and inventory options:</p> <ul> <li>Metrics resolution</li> <li>Advanced Settings<ul> <li>Data Retention</li> <li>Telemetry</li> <li>Check for updates</li> <li>Advisors</li> </ul> </li> <li>Public address<ul> <li>Alerting</li> <li>Microsoft Azure Monitoring</li> <li>Public Address {: #public-address-1 }</li> </ul> </li> <li>SSH Key</li> <li>Alertmanager integration</li> <li>Percona Platform<ul> <li>Connect PMM to Percona Platform</li> <li>Password Reset</li> <li>Password Forgotten</li> <li>Change Password after Login</li> </ul> </li> </ul> <p>You can also use the Administration page to manage Grafana-related configurations and account settings.</p> <p></p>"},{"location":"configure-pmm/configure.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/metrics_res.html","title":"Metrics resolution","text":"<p>Metrics are collected at three intervals representing low, medium and high resolutions.</p> <p>The Metrics Resolution settings tab contains three fixed presets (Rare, Standard and Frequent) and an editable custom preset (Custom). Each preset is a group of low, medium and high resolutions. The values are in seconds.</p> <p></p> <p>Time intervals and resolutions</p> <p>Short time intervals are high resolution metrics. Longer time intervals are low resolution. So:</p> <ul> <li>A low resolution interval increases the time between collection, resulting in low-resolution metrics and lower disk usage.</li> <li>A high resolution interval decreases the time between collection, resulting in high-resolution metrics and higher disk usage.</li> </ul> <p>The default values (in seconds) for the fixed presets and their resolution names are:</p> Editable? Preset Low Medium High No Rare 300 180 60 No Standard 60 10 5 No Frequent 30 5 1 Yes Custom (defaults) 60 10 5 <p>Values for the Custom preset can be entered as values, or changed with the arrows.</p> <p>Note</p> <p>If there is poor network connectivity between PMM Server and PMM Client, or between PMM Client and the database server being monitored, scraping every second may not be possible when the network latency is greater than 1 second.</p> <p></p>"},{"location":"configure-pmm/metrics_res.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/public-address.html","title":"Public address","text":"<p>The address or hostname PMM Server will be accessible at. Click Get from browser to have your browser detect and populate this field automatically.</p>"},{"location":"configure-pmm/public-address.html#alerting","title":"Alerting","text":"<p>Enables Percona Alerting and reveals the Percona templated alerts option on the Alerting page.</p>"},{"location":"configure-pmm/public-address.html#microsoft-azure-monitoring","title":"Microsoft Azure Monitoring","text":"<p>Caution</p> <p>This is a technical preview feature.</p> <p>Activates Microsoft Azure monitoring.</p> <p></p>"},{"location":"configure-pmm/public-address.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/ssh.html","title":"SSH Key","text":"<p>This section enables you to upload your public SSH key for SSH access to the PMM Server, such as when accessing it as a virtual appliance.</p> <p></p> <p>Enter your public key in the SSH Key field and click Apply SSH Key.</p> <p></p>"},{"location":"configure-pmm/ssh.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html","title":"Connect PMM to Percona Platform","text":"<p>To connect your PMM Server to Percona Platform, copy your personal access token from Platform Portal and paste it into PMM. You will find your access token in Platform Portal as part of your user profile page.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#token-validity","title":"Token validity","text":"<p>For security reasons, access tokens expire after 30 minutes. Make sure to paste the code before that, or generate a new one if it expires.</p> <p>To connect your PMM Server to Percona Platform:</p> <ol> <li> <p>In PMM, go to PMM Configuration &gt; Settings &gt; Percona Platform tab to fill in the Connect PMM to Percona Portal form: </p> </li> <li> <p>The PMM Server ID field is automatically populated with the ID identified for your PMM instance. Enter the name of your PMM instance and click Get token to go to Percona Platform Portal and generate your access token.</p> </li> <li>Log into Percona Platform using your Percona Account (if you don\u2019t have an active current session).</li> <li>On the Profile Settings page, copy the code from the Percona Platform Access Token field.</li> <li>Back into PMM, paste the Access Token into the Percona Platform Access Token field, and click  Connect.</li> </ol> <p>To confirm that you have successfully connected the server and check the list of all servers currently connected to an organization, go to Percona Platform &gt; Dashboard tab and click View Instances next to the Connect your PMM step.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#check-percona-portal-entitlements","title":"Check Percona Portal entitlements","text":"<p>After connecting to the Percona Platform, PMM has access to additional alert templates, Advisor checks, and account information. See Check Percona Portal account information.</p> <p>After connecting to the Percona Platform, PMM has access to additional alert templates, Advisor checks, and account information. See Check Percona Portal account information.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#disconnect-a-pmm-instance","title":"Disconnect a PMM instance","text":"<p>Disconnect a PMM instance when you want to unlink it from your Percona Platform organization or stop monitoring it there.</p> <p>To disconnect a PMM Server, go to  Configuration &gt; Settings &gt; Percona Platform and click Disconnect.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#disconnecting-instances-as-an-admin","title":"Disconnecting instances as an Admin","text":"<p>In situations where you are not able to disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you cannot disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you are a PMM Admin, you can terminate any connections to Percona Platform, even if you are not logged into PMM with a Percona Account. However, we recommend logging in with a Percona Account before disconnecting servers, as this will automatically remove the disconnected servers from Percona Platform as well. </p> <p>If you do disconnect servers without being connected with a Percona Account, you\u2019ll have to manually remove the unavailable servers from Percona Platform. This ensures that your list of connected PMM instances stays up-to-date in Percona Platform. </p> <p>To do this, go to PMM instances, and remove any servers that you have already disconnected from PMM.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#sign-into-pmm-with-your-percona-account","title":"Sign into PMM with your Percona Account","text":"<p>Once you\u2019ve successfully connected your PMM instance to the Percona Platform, you can also sign into PMM using your Percona Account:</p> <ol> <li>Log out of your existing PMM session.</li> <li>On the PMM login screen, click Sign in with Percona Account.  If you have an active Percona Account session on the same browser, PMM will log you in automatically. Otherwise, enter your Percona Account credentials to start a new session.</li> </ol> <p></p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html","title":"Integrate PMM with Percona Platform","text":"<p>Percona Platform brings together database distributions, support expertise, services, management, and automated insights.</p> <p>Connect your PMM Servers to Percona Platform to boost the monitoring capabilities of your PMM installations and manage database deployments easier. In addition, you get access to PMM updates, automated insights, advanced advisor checks and more alert rule templates.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#connect-pmm-to-percona-platform","title":"Connect PMM to Percona Platform","text":"<p>You can connect to Percona Platform with a Percona Account or via Google or GitHub authentication. If Percona Support has enabled a custom identity provider for your account, you can also log in using your company\u2019s credentials.</p> <p>We recommend that you connect with a Percona Account, as this gives you access to other Percona services, including Percona Platform, Percona Customer Portal, and Community Forum. If you don\u2019t have a Percona Account, you can create one on the Percona Platform homepage using the Don\u2019t have an account? Create one? link.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#prerequisites","title":"Prerequisites","text":"<p>To ensure that PMM can establish a connection to Percona Platform:</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#check-that-you-are-a-member-of-an-existing-platform-organization","title":"Check that you are a member of an existing Platform organization","text":"<p>To check whether you are a member of an existing Platform organization:</p> <ol> <li> <p>Log in to Percona Platform using your Percona Account. If you are connecting via GitHub, make sure you set your email address as public in your GitHub account. If your email address is private instead, Percona Platform cannot access it to authenticate you.</p> </li> <li> <p>On the Getting Started page, check that the Create organization step shows an option to view your organization.</p> </li> </ol> <p>Contact your account administrator or create a new organization for your Percona Account if this is the case.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#set-the-public-address-of-your-pmm-server","title":"Set the public address of your PMM Server","text":"<p>PMM automatically detects and populates the public address of the PMM Server when this is not set up.  If you need to set it differently, go to Settings &gt; Advanced Settings and edit the  Public Address field.</p> <p></p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"discover-pmm/features.html","title":"Key features","text":"<p>The following features make Percona Monitoring and Management a powerful tool for database administrators and DevOps teams to monitor, analyze, and optimize the performance of their database infrastructure:</p> <ul> <li> <p>Query Analytics: PMM provides insights into database query performance and enables you to identify slow queries, analyze query execution plans, and optimize them.</p> </li> <li> <p>Monitoring: PMM comprehensively monitors the key performance metrics such as CPU usage, memory, disk I/O, network traffic, and other database-specific metrics. In addition to understanding the health of your database infrastructure, these metrics help you discover new patterns in database behavior and identify performance bottlenecks, regardless of where they are located or deployed.</p> </li> <li> <p>User-friendly dashboards: PMM provides an intuitive graphical user interface with customizable dashboards that enable you to visualize and analyze your database\u2019s performance.</p> </li> <li> <p>Alerting: PMM enables setting up alerts based on predefined thresholds for various metrics. When these thresholds are exceeded, PMM sends notifications via email or other channels, facilitating proactive management and quick resolution.</p> </li> <li> <p>Percona Advisors: Built-in Advisors run regular checks on the databases connected to PMM. The checks identify and alert you of potential security threats, performance degradation, data loss, and data corruption.</p> </li> <li> <p>Backup and restore: PMM enables you to back up critical data with zero downtime and minimal performance impact. Furthermore, you can schedule various backups (hot, incremental, physical) and restore databases up to a specific moment with the Point-in-Time-Recovery feature.</p> </li> </ul> <p></p>"},{"location":"discover-pmm/features.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"discover-pmm/supported-technologies.html","title":"Supported Technologies","text":"<p>PMM supports the following technologies:</p> <p></p>"},{"location":"discover-pmm/supported-technologies.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"discover-pmm/why-pmm.html","title":"Why PMM?","text":"<p>Percona Monitoring and Management (PMM) delivers:</p> <ul> <li>Comprehensive monitoring of MySQL, MariaDB, MongoDB, and PostgreSQL databases</li> <li>Query performance insights to identify and optimize slow queries for improved system efficiency</li> <li>Database-specific features tailored for deep monitoring of different database engines</li> <li>Built-in security with SSL encryption and robust authentication</li> <li>Flexible customization through custom dashboards, metrics, and exporters</li> <li>Centralized management of multiple database instances across different hosts</li> <li>Active community support with regular updates and improvements</li> </ul> <p></p> <p></p>"},{"location":"discover-pmm/why-pmm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/index.html","title":"How to","text":"<ul> <li>Configure via the PMM Settings page.</li> <li>Manage users via the PMM Users page.</li> <li>Upgrade PMM Server via the user interface.</li> <li>Secure your PMM installation.</li> <li>Optimize the performance of your PMM installation.</li> <li>Annotate charts to mark significant events.</li> <li>Share dashboards and panels to save or share.</li> <li>Extend Metrics with textfile collector.</li> <li>Troubleshoot</li> </ul>"},{"location":"how-to/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/account-info.html","title":"Check Percona Portal account information","text":"<p>When you connect your PMM instances to Percona Platform, PMM gets access to:</p> <ul> <li>more alert templates</li> <li>Registered Advisor Checks for additional database checks</li> <li>Paid Advisor Checks for more advanced database health checks. </li> </ul> <p>Paid checks are available when you connect to Percona Platform with a customer account.</p> <p>You can check the list of available Paid Advisor checks on the Advisors details page.</p> <p>When you connect with a customer account, PMM  reveals two new tabs on the main menu, where you can check all the information available for your customer accounts:  Entitlements and Support tickets:</p> <p></p> <p></p> <p></p>"},{"location":"how-to/account-info.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/extend-metrics.html","title":"Extend Metrics","text":"<p>When you need a metric that\u2019s not present in the default list of <code>node_exporter</code> metrics you may be able to use the <code>textfile</code> collector. The textfile collector allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has.</p>"},{"location":"how-to/extend-metrics.html#enable-the-textfile-collector","title":"Enable the textfile collector","text":"<p>The collector is enabled by default. The following folders are used for different resolutions:</p> Resolution Folder High <code>/usr/local/percona/pmm/collectors/textfile-collector/high-resolution</code> Medium <code>/usr/local/percona/pmm/collectors/textfile-collector/medium-resolution</code> Low <code>/usr/local/percona/pmm/collectors/textfile-collector/low-resolution</code> <p></p> <p>The exporter parses all files in these directories that match the filename wildcard expression <code>*.prom</code> using a simple text-based exposition format. Metrics are stored on the PMM Server-side with additional labels related to this Node.</p>"},{"location":"how-to/extend-metrics.html#examples-of-shell-commands-for-custom-metrics","title":"Examples of shell commands for custom metrics","text":"<p>To statically set roles for a machine using labels:</p> <pre><code>echo 'node_role{role=\"my_monitored_server_1\"} 1' &gt; /usr/local/percona/pmm/collectors/textfile-collector/low-resolution/node_role.prom\n</code></pre> <p>Here\u2019s an example of a <code>cron</code> job that automatically pushes logged-in users:</p> <pre><code>$ cat /etc/cron.d/loggedin_users\n*/1 * * * *     root    /usr/bin/who | /usr/bin/wc -l | sed -ne 's/^/node_loggedin_users /p' &gt; /usr/local/percona/pmm/collectors/textfile-collector/high-resolution/node_users.prom\n</code></pre> <p></p> <p></p>"},{"location":"how-to/extend-metrics.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/integrate-platform.html","title":"Integrate PMM with Percona Platform","text":"<p>Percona Platform brings together database distributions, support expertise, services, management, and automated insights.</p> <p>Connect your PMM Servers to Percona Platform to boost the monitoring capabilities of your PMM installations and manage database deployments easier. In addition, you get access to PMM updates, automated insights, advanced advisor checks and more alert rule templates.</p>"},{"location":"how-to/integrate-platform.html#connect-pmm-to-percona-platform","title":"Connect PMM to Percona Platform","text":"<p>You can connect to Percona Platform with a Percona Account or via Google or GitHub authentication. If Percona Support has enabled a custom identity provider for your account, you can also log in using your company\u2019s credentials.</p> <p>We recommend that you connect with a Percona Account, as this gives you access to other Percona services, including Percona Platform, Percona Customer Portal, and Community Forum. If you don\u2019t have a Percona Account, you can create one on the Percona Platform homepage using the Don\u2019t have an account? Create one? link.</p>"},{"location":"how-to/integrate-platform.html#prerequisites","title":"Prerequisites","text":"<p>To ensure that PMM can establish a connection to Percona Platform:</p>"},{"location":"how-to/integrate-platform.html#check-that-you-are-a-member-of-an-existing-platform-organization","title":"Check that you are a member of an existing Platform organization","text":"<ol> <li> <p>Log in to Percona Platform using your Percona Account. If you are connecting via GitHub, make sure you set your email address as public in your GitHub account. If your email address is private instead, Percona Platform cannot access it to authenticate you.</p> </li> <li> <p>On the Getting Started page, check that the Create organization step shows an option to view your organization.</p> </li> </ol> <p>Contact your account administrator or create a new organization for your Percona Account if this is the case.</p>"},{"location":"how-to/integrate-platform.html#set-the-public-address-of-your-pmm-server","title":"Set the public address of your PMM Server","text":"<p>PMM automatically detects and populates the public address of the PMM Server when this is not set up.  If you need to set it differently, go to Settings &gt; Advanced Settings and edit the  Public Address field.</p>"},{"location":"how-to/integrate-platform.html#connect-pmm-to-percona-platform_1","title":"Connect PMM to Percona Platform","text":"<p>To connect your PMM Server to Percona Platform, copy your personal access token from Platform Portal and paste it into PMM. You will find your access token in Platform Portal as part of your user profile page.</p>"},{"location":"how-to/integrate-platform.html#token-validity","title":"Token validity","text":"<p>For security reasons, access tokens expire after 30 minutes. Make sure to paste the code before that, or generate a new one if it expires.</p> <p>To connect your PMM Server to Percona Platform: 1. In PMM, go to Settings &gt; Percona Platform tab to fill in the Connect PMM to Percona Portal form: </p> <ol> <li>The PMM Server ID field is automatically populated with the ID identified for your PMM instance. Enter the name of your PMM instance and click Get token to go to Percona Platform Portal and generate your access token.</li> <li>Log into Percona Platform using your Percona Account (if you don\u2019t have an active current session).</li> <li>On the Profile Settings page, copy the code from the Percona Platform Access Token field.</li> <li>Back into PMM, paste the Access Token into the Percona Platform Access Token field, and click  Connect.</li> </ol> <p>To confirm that you have successfully connected the server and check the list of all servers currently connected to an organization, go to Percona Platform &gt; Dashboard tab and click View Instances next to the Connect your PMM step.</p>"},{"location":"how-to/integrate-platform.html#check-percona-portal-entitlements","title":"Check Percona Portal entitlements","text":"<p>After connecting to the Percona Platform, PMM has access to additional alert templates,   Advisors checks, and account information. See (../how-to/account-info.md)</p>"},{"location":"how-to/integrate-platform.html#disconnect-a-pmm-instance","title":"Disconnect a PMM instance","text":"<p>Disconnect a PMM instance when you want to unlink it from your Percona Platform organization or stop monitoring it there.</p> <p>To disconnect a PMM Server, go to &gt;  Configuration &gt; Settings &gt; Percona Platform and click Disconnect.</p>"},{"location":"how-to/integrate-platform.html#disconnecting-instances-as-an-admin","title":"Disconnecting instances as an Admin","text":"<p>In situations where you are not able to disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you cannot disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you are a PMM Admin, you can terminate any connections to Percona Platform, even if you are not logged into PMM with a Percona Account. However, we recommend logging in with a Percona Account before disconnecting servers, as this will automatically remove the disconnected servers from Percona Platform as well. </p> <p>If you do disconnect servers without being connected with a Percona Account, you\u2019ll have to manually remove the unavailable servers from Percona Platform. This ensures that your list of connected PMM instances stays up-to-date in Percona Platform.</p> <p>To do this, go to PMM instances, and remove any servers that you have already disconnected from PMM.</p>"},{"location":"how-to/integrate-platform.html#sign-into-pmm-with-your-percona-account","title":"Sign into PMM with your Percona Account","text":"<p>Once you\u2019ve successfully connected your PMM instance to the Percona Platform, you can also sign into PMM using your Percona Account:</p> <ol> <li>Log out of your existing PMM session.</li> <li>On the PMM login screen, click Sign in with Percona Account.  If you have an active Percona Account session on the same browser, PMM will log you in automatically. Otherwise, enter your Percona Account credentials to start a new session.</li> </ol> <p></p>"},{"location":"how-to/integrate-platform.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/manage-users.html","title":"Manage users","text":"<p>This topic explains user management in PMM.</p> <p>You can manage users from the main menu by navigating to Server Admin \u2192 Users page.</p> <p></p>"},{"location":"how-to/manage-users.html#add-users","title":"Add users","text":"<p>You can add a user in PMM from User \u2192 New user tab.</p> <p></p> <p>To add a new user in PMM:</p> <ol> <li>On the Users tab, click New user.</li> <li> <p>On the Add new user dialog box, enter the following:</p> <ul> <li>Name</li> <li>email address or username (if this is an existing grafana user)</li> <li>Username</li> <li>Password</li> </ul> </li> <li> <p>Click create user.</p> </li> </ol>"},{"location":"how-to/manage-users.html#edit-users","title":"Edit users","text":"<p>You can edit users by changing the information or settings for an individual user account.</p> <p>Important</p> <p>After changing the default admin password for the PMM Server, register the pmm-agent using the same credentials and add the services again. Otherwise, PMM will cease to monitor the service/nodes.</p>"},{"location":"how-to/manage-users.html#grant-or-revoke-admin-privileges","title":"Grant or Revoke admin privileges","text":"<p>You can grant or revoke admin access to a user as follows:</p> <ol> <li> <p>On the Users tab, click the user account you want to edit.</p> </li> <li> <p>To grant or revoke the privileges, click the user. User information dialog box opens.</p> </li> <li> <p>In the Permissions section, click Change and then select Yes/No, depending on whether you want to provide admin access or not.</p> </li> <li> <p>Click Change.</p> </li> </ol> <p>Important</p> <p>After connecting your PMM instance to the Percona Platform, when you log in using your Percona account, you will be granted the Viewer access. For Admin access, log in to PMM as an admin, and change the permissions for this user.</p>"},{"location":"how-to/manage-users.html#change-organization-role","title":"Change organization role","text":"<p>You can change the organization role assigned to your user account.</p> <p></p> <p>To change the role:</p> <ol> <li> <p>On the Users tab, click the user for whom you want to change the role.</p> </li> <li> <p>In the Organisations section, click Change role.</p> </li> <li> <p>Select the role from the drop-down and click save.</p> </li> </ol> <p>The following are the privileges for the various roles:</p> <ul> <li> <p>Admin - Managing data sources, teams, and users within an organization.</p> </li> <li> <p>Editor - Creating and editing dashboards.</p> </li> <li> <p>Viewer - Viewing dashboards.</p> </li> </ul> <p>For detailed information on the privileges for these roles and the different tasks that they can perform, refer to: Grafana organization roles.</p>"},{"location":"how-to/manage-users.html#delete-users","title":"Delete Users","text":"<p>You can delete a user in PMM as follows:</p> <ol> <li> <p>On the User tab, click the user you want to delete.</p> </li> <li> <p>Click Delete user.</p> </li> </ol> <p></p>"},{"location":"how-to/manage-users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/optimize.html","title":"Optimize","text":""},{"location":"how-to/optimize.html#improving-pmm-performance-with-table-statistics-options","title":"Improving PMM Performance with Table Statistics Options","text":"<p>If a MySQL instance has a lot of schemas or tables, there are two options to help improve the performance of PMM when adding instances with <code>pmm-admin add</code>:</p> <ul> <li><code>--disable-tablestats</code>, or,</li> <li><code>--disable-tablestats-limit</code>.</li> </ul> <p>Important</p> <ul> <li>These settings are only for adding an instance. To change them, you must remove and re-add the instances.</li> <li>Only one of these options can be used when adding an instance.</li> </ul>"},{"location":"how-to/optimize.html#disable-per-table-statistics-for-an-instance","title":"Disable per-table statistics for an instance","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats</code> option disables table statistics collection when there are more than the default number (1000) of tables in the instance.</p>"},{"location":"how-to/optimize.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats\n</code></pre>"},{"location":"how-to/optimize.html#change-the-number-of-tables-beyond-which-per-table-statistics-is-disabled","title":"Change the number of tables beyond which per-table statistics is disabled","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats-limit</code> option changes the number of tables (from the default of 1000) beyond which per-table statistics collection is disabled.</p>"},{"location":"how-to/optimize.html#usage_1","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats-limit=&lt;LIMIT&gt;\n</code></pre>"},{"location":"how-to/optimize.html#example","title":"EXAMPLE","text":"<p>Add a MySQL instance, disabling per-table statistics collection when the number of tables in the instance reaches 2000.</p> <pre><code>pmm-admin add mysql --disable-tablestats-limit=2000\n</code></pre> <p></p>"},{"location":"how-to/optimize.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-to/secure.html","title":"Secure","text":"<p>You can improve the security of your PMM installation with:</p> <ul> <li> <p>SSL encryption to secure traffic between client and server;</p> </li> <li> <p>Grafana HTTPS secure cookies</p> </li> </ul> <p>To see which security features are enabled:</p> <pre><code>pmm-admin status\n</code></pre> <p>Tip</p> <p>You can gain an extra level of security by keeping PMM Server isolated from the internet, if possible.</p>"},{"location":"how-to/secure.html#ssl-encryption","title":"SSL encryption","text":"<p>You need valid SSL certificates to encrypt traffic between client and server.</p> <p>With our Docker, OVF and AMI images, self-signed certificates are in <code>/srv/nginx</code>.</p> <p>To use your own, you can either:</p> <ul> <li> <p>mount the local certificate directory to the same location, or,</p> </li> <li> <p>copy your certificates to a running PMM Server container.</p> </li> </ul>"},{"location":"how-to/secure.html#mounting-certificates","title":"Mounting certificates","text":"<p>For example, if your own certificates are in <code>/etc/pmm-certs</code>:</p> <pre><code>docker run -d -p 443:443 --volumes-from pmm-data \\\n  --name pmm-server -v /etc/pmm-certs:/srv/nginx \\\n  --restart always perconalab/pmm-server:3.0.0-beta\n</code></pre> <ul> <li>The certificates must be owned by root. You can do this with: <code>chown 0:0 /etc/pmm-certs/*</code></li> <li>The mounted certificate directory (<code>/etc/pmm-certs</code> in this example) must contain the files <code>certificate.crt</code>, <code>certificate.key</code>, <code>ca-certs.pem</code> and <code>dhparam.pem</code>.</li> <li>For SSL encryption, the container must publish on port 443 instead of 80.</li> </ul>"},{"location":"how-to/secure.html#copying-certificates","title":"Copying certificates","text":"<p>If PMM Server is running as a Docker image, use <code>docker cp</code> to copy certificates. This example copies certificate files from the current working directory to a running PMM Server docker container.</p> <pre><code>docker cp certificate.crt pmm-server:/srv/nginx/certificate.crt\ndocker cp certificate.key pmm-server:/srv/nginx/certificate.key\ndocker cp ca-certs.pem pmm-server:/srv/nginx/ca-certs.pem\ndocker cp dhparam.pem pmm-server:/srv/nginx/dhparam.pem\n</code></pre>"},{"location":"how-to/secure.html#enabling-ssl-when-connecting-pmm-client-to-pmm-server","title":"Enabling SSL when connecting PMM Client to PMM Server","text":"<pre><code>pmm-admin config --server-url=https://&lt;user&gt;:&lt;password&gt;@&lt;server IP&gt;\n</code></pre>"},{"location":"how-to/secure.html#grafana-https-secure-cookies","title":"Grafana HTTPS secure cookies","text":"<p>To enable:</p> <ol> <li> <p>Start a shell within the Docker container.</p> <pre><code>docker exec -it pmm-server bash\n</code></pre> </li> <li> <p>Edit <code>/etc/grafana/grafana.ini</code>.</p> </li> <li> <p>Enable <code>cookie_secure</code> and set the value to <code>true</code>.</p> </li> <li> <p>Restart Grafana.</p> <pre><code>supervisorctl restart grafana\n</code></pre> </li> </ol> <p></p>"},{"location":"how-to/secure.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/index.html","title":"About PMM installation","text":"Summary <ol> <li>Install PMM Server.</li> <li>Install PMM Client(s).</li> <li>Add services.</li> </ol>"},{"location":"install-pmm/index.html#install-pmm-server","title":"Install PMM Server","text":"<p>Install and run at least one PMM Server. Choose from the following options:</p> <p>ARM support</p> <p>PMM Server is not currently available as a native ARM64 build. For ARM-based systems, consider using the Docker or Podman installation methods, which can run x86_64 images via emulation on ARM platforms.</p> Use Benefits Drawbacks Docker 1. Quick2. Simple 3. Rootless Additional network configuration required. Podman 1. Quick2. Simple3. Rootless Podman installation required. Helm (Technical Preview) 1. Quick2. Simple3. Cloud  4. Rootless Requires running Kubernetes cluster. Virtual appliance 1. Easily import into Hypervisor of your choice  2. Rootless More system resources compared to Docker footprint. Amazon AWS 1. Wizard-driven install.   2. Rootless Non-free solution (infrastructure costs)."},{"location":"install-pmm/index.html#install-pmm-client","title":"Install PMM Client","text":"<p>Install and run PMM Client on every node where there is a service you want to monitor. PMM Client now supports both x86_64 and ARM64 architectures.</p> <p>The installation choices are:</p> <pre><code>=== \"With Docker\"\n\n [Docker installation](client/index.md#docker) simplifies deployment across different architectures and automatically selects the appropriate image for your architecture (x86_64 or ARM64).=p][\\;]\n\n=== \"Native installation\"\n\n- [Linux package](client/index.md#package-manager). Use `apt`, `apt-get`, `dnf`, `yum`. The package manager automatically selects the correct version for your architecture.\n\n- [Binary package](client/index.md#binary-packa): Download the appropriate `.tar.gz` file for your architecture (x86_64 or ARM64).\n</code></pre> <p>Tips</p> <p>Both binary installation and Docker containers can be run without root permissions. When installing on ARM-based systems, ensure you\u2019re using ARM64-compatible versions. Performance may vary between architectures.</p>"},{"location":"install-pmm/index.html#add-services","title":"Add services","text":"<p>On each PMM Client instance, configure the nodes and services you want to monitor. </p> Which services you can monitor? <ul> <li>MySQL (and variants: Percona Server for MySQL, Percona XtraDB Cluster, MariaDB);</li> <li>MongoDB;</li> <li>PostgreSQL;</li> <li>ProxySQL;</li> <li>Amazon RDS;</li> <li>Microsoft Azure;</li> <li>Google Cloud Platform (MySQL and PostgreSQL);</li> <li>Linux;</li> <li>External services;</li> <li>HAProxy;</li> <li>Remote instances.</li> </ul> <p></p>"},{"location":"install-pmm/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/HA.html","title":"Install PMM in HA mode","text":"<p>Important</p> <p>This feature is currently in Technical Preview. Early adopters are advised to use this feature for testing purposes only as it is subject to change.</p> <p>Set up PMM using Docker containers in a high-availability (HA) configuration following these instructions. </p> <p>PMM Server is deployed in a high-availability setup where three PMM Server instances are configured, one being the leader and others are followers. These servers provide services including:</p> <ul> <li>ClickHouse: A fast, open-source analytical database.</li> <li>VictoriaMetrics: A scalable, long-term storage solution for time series data.</li> <li>PostgreSQL: A powerful open-source relational database management system, used in this setup to store PMM data like inventory, settings, and other feature-related data.</li> </ul>"},{"location":"install-pmm/HA.html#importance-of-ha","title":"Importance of HA","text":"<p>Having high availability increases the reliability of the PMM service, as the leader server handles all client requests, and subsequent servers take over if the leader fails.</p> <ul> <li>Gossip Protocol: This protocol facilitates PMM Servers to discover and share information about their states with each other. It is used for managing the PMM Server list and failure detection.</li> <li>Raft Protocol: This is a consensus algorithm that allows PMM Servers to agree on a leader and ensures that logs are replicated among all machines.</li> </ul>"},{"location":"install-pmm/HA.html#prerequisites","title":"Prerequisites","text":"<p>You will need the following before you can begin the deployment:</p> <ul> <li>Docker installed and configured on your system. If you haven\u2019t installed Docker, you can follow this guide.</li> </ul>"},{"location":"install-pmm/HA.html#procedure-to-set-up-pmm-in-ha-mode","title":"Procedure to set up PMM in HA mode","text":"<p>Note</p> <ul> <li>The sections below provide instructions for setting up the services on both the same and separate instances. However, it is not recommended to run the services on a single machine for production purposes. This approach is only recommended for the development environment.</li> <li>It is recommended to use clustered versions of PosgreSQL, Victoriametrics, Clickhouse, etc., instead of standalone versions when setting up the services.</li> </ul> <p>The steps to set up PMM in HA mode are:</p>"},{"location":"install-pmm/HA.html#step-1-define-environment-variables","title":"Step 1: Define environment variables","text":"<p>Before you start with the setup, define the necessary environment variables on each instance where the services will be running. These variables will be used in subsequent commands. </p> <p>For all IP addresses, use the format <code>17.10.1.x</code>, and for all usernames and passwords, use a string format like <code>example</code>.</p> Variable Description <code>CH_HOST_IP</code> The IP address of the instance where the ClickHouse service is running or the desired IP address for the ClickHouse container within the Docker network, depending on your setup.Example: <code>17.10.1.2</code> <code>VM_HOST_IP</code> The IP address of the instance where the VictoriaMetrics service is running or the desired IP address for the VictoriaMetrics container within the Docker network, depending on your setup.Example: <code>17.10.1.3</code> <code>PG_HOST_IP</code> The IP address of the instance where the PostgreSQL service is running or the desired IP address for the PostgreSQL container within the Docker network, depending on your setup. Example: <code>17.10.1.4</code> <code>PG_USERNAME</code> The username for your PostgreSQL server. Example: <code>pmmuser</code> <code>PG_PASSWORD</code> The password for your PostgreSQL server. Example: <code>pgpassword</code> <code>GF_USERNAME</code> The username for your Grafana database user.Example: <code>gfuser</code> <code>GF_PASSWORD</code> The password for your Grafana database user.Example: <code>gfpassword</code> <code>PMM_ACTIVE_IP</code> The IP address of the instance where the active PMM Server is running or the desired IP address for your active PMM Server container within the Docker network, depending on your setup.Example: <code>17.10.1.5</code> <code>PMM_ACTIVE_NODE_ID</code> The unique ID for your active PMM Server node.Example: <code>pmm-server-active</code> <code>PMM_PASSIVE_IP</code> The IP address of the instance where the first passive PMM Server is running or the desired IP address for your first passive PMM Server container within the Docker network, depending on your setup. Example: <code>17.10.1.6</code> <code>PMM_PASSIVE_NODE_ID</code> The unique ID for your first passive PMM Server node.Example: <code>pmm-server-passive</code> <code>PMM_PASSIVE2_IP</code> The IP address of the instance where the second passive PMM Server is running or the desired IP address for your second passive PMM Server container within the Docker network, depending on your setup.Example: <code>17.10.1.7</code> <code>PMM_PASSIVE2_NODE_ID</code> The unique ID for your second passive PMM Server node.Example: <code>pmm-server-passive2</code> <code>PMM_DOCKER_IMAGE</code> The specific PMM Server Docker image for this guide.Example: <code>perconalab/pmm-server:3.0.0-beta</code> Expected output <pre><code>export CH_HOST_IP=17.10.1.2\nexport VM_HOST_IP=17.10.1.3\nexport PG_HOST_IP=17.10.1.4\nexport PG_USERNAME=pmmuser\nexport PG_PASSWORD=pgpassword\nexport GF_USERNAME=gfuser\nexport GF_PASSWORD=gfpassword\nexport PMM_ACTIVE_IP=17.10.1.5\nexport PMM_ACTIVE_NODE_ID=pmm-server-active\nexport PMM_PASSIVE_IP=17.10.1.6\nexport PMM_PASSIVE_NODE_ID=pmm-server-passive\nexport PMM_PASSIVE2_IP=17.10.1.7\nexport PMM_PASSIVE2_NODE_ID=pmm-server-passive2\nexport PMM_DOCKER_IMAGE=perconalab/pmm-server:3.0.0-beta\n</code></pre> <p>Note</p> <p>Ensure that you have all the environment variables from Step 1 set in each instance where you run these commands.</p>"},{"location":"install-pmm/HA.html#step-2-create-docker-network-optional","title":"Step 2: Create Docker network (Optional)","text":"<p>To create Docker network:</p> <ol> <li> <p>Set up a Docker network for PMM services if you plan to run all the services on the same instance. As a result of this Docker network, your containers will be able to communicate with each other, which is essential for the High Availability (HA) mode to function properly in PMM. This step may be optional if you run your services on separate instances.</p> </li> <li> <p>Run the following command to create a Docker network:</p> <pre><code>docker network create pmm-network --subnet=17.10.1.0/16\n</code></pre> </li> </ol>"},{"location":"install-pmm/HA.html#step-3-set-up-clickhouse","title":"Step 3: Set up ClickHouse","text":"<p>ClickHouse is an open-source column-oriented database management system. In PMM, ClickHouse stores Query Analytics (QAN) metrics, which provide detailed information about your queries.</p> <p>To set up ClickHouse:</p> <ol> <li> <p>Pull the ClickHouse Docker image.</p> <pre><code>docker pull clickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> </li> <li> <p>Create a Docker volume for ClickHouse data.</p> <pre><code>docker volume create ch_data\n</code></pre> </li> <li> <p>Run the ClickHouse container.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ch \\\n--network pmm-network \\\n--ip ${CH_HOST_IP} \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <pre><code>docker run -d \\\n--name ch \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <p>Note</p> <ul> <li>If you run the services on the same instance, the <code>--network</code> and <code>--ip</code> flags assign a specific IP address to the container within the Docker network created in the previous step. This IP address is referenced in subsequent steps as the ClickHouse service address. </li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances since ClickHouse will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"install-pmm/HA.html#step-4-set-up-victoriametrics","title":"Step 4: Set up VictoriaMetrics","text":"<p>VictoriaMetrics provides a long-term storage solution for your time-series data. In PMM, it is used to store Prometheus metrics.</p> <p>To set up VictoriaMetrics:</p> <ol> <li> <p>Pull the VictoriaMetrics Docker image.</p> <pre><code>docker pull victoriametrics/victoria-metrics:v1.93.4\n</code></pre> </li> <li> <p>Create a Docker volume for VictoriaMetrics data.</p> <pre><code>docker volume create vm_data\n</code></pre> </li> <li> <p>Run the VictoriaMetrics container.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name vm \\\n--network pmm-network \\\n--ip ${VM_HOST_IP} \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <pre><code>docker run -d \\\n--name vm \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <p>Note</p> <ul> <li>If you run the services on the same instance,  the <code>--network</code> and <code>--ip</code> flags are used to assign a specific IP address to the container within the Docker network created in Step 2. This IP address is referenced in subsequent steps as the VictoriaMetrics service address. </li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances, as VictoriaMetrics will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"install-pmm/HA.html#step-5-set-up-postgresql","title":"Step 5: Set up PostgreSQL","text":"<p>PostgreSQL is a powerful, open-source object-relational database system. In PMM, it\u2019s used to store data related to inventory, settings, and other features.</p> <p>To set up PostgreSQL:</p> <ol> <li> <p>Pull the Postgres Docker image.</p> <pre><code>docker pull postgres:14\n</code></pre> </li> <li> <p>Create a Docker volume for Postgres data:</p> <pre><code>docker volume create pg_data\n</code></pre> </li> <li> <p>Create a directory to store init SQL queries:</p> <pre><code>mkdir -p /path/to/queries\n</code></pre> <p>Replace <code>/path/to/queries</code> with the path where you want to store your <code>init</code> SQL queries.</p> </li> <li> <p>Create an <code>init.sql.template</code> file in newly created directory with the following content:</p> <pre><code>CREATE DATABASE \"pmm-managed\";\nCREATE USER &lt;YOUR_PG_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_PG_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE \"pmm-managed\" TO &lt;YOUR_PG_USERNAME&gt;;\nCREATE DATABASE grafana;\nCREATE USER &lt;YOUR_GF_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_GF_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE grafana TO &lt;YOUR_GF_USERNAME&gt;;\n\n\\c pmm-managed\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n</code></pre> </li> <li> <p>Use <code>sed</code> to replace the placeholders with the environment variables and write the output to <code>init.sql</code>.</p> <pre><code>sed -e 's/&lt;YOUR_PG_USERNAME&gt;/'\"$PG_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_PG_PASSWORD&gt;/'\"$PG_PASSWORD\"'/g' \\\n    -e 's/&lt;YOUR_GF_USERNAME&gt;/'\"$GF_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_GF_PASSWORD&gt;/'\"$GF_PASSWORD\"'/g' \\\n    init.sql.template &gt; init.sql\n</code></pre> </li> <li> <p>Run the PostgreSQL container.</p> <p>You can either run all the services on the same instance or on a seperate instance.</p> <p>Note</p> <p>It is recommended to use absolute paths instead of relative paths for volume mounts.</p> Run services on same instanceRun services on a seperate instance <pre><code>  docker run -d \\\n    --name pg \\\n    --network pmm-network \\\n    --ip ${PG_HOST_IP} \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d/ \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <pre><code>   docker run -d \\\n    --name pg \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <p>Replace <code>/path/to/queries</code> with the path to your <code>init.sql</code> file. This command mounts the <code>init.sql</code> file to the <code>docker-entrypoint-initdb.d</code> directory, which is automatically executed upon container startup.</p> <p>Note</p> <ul> <li>If you run the services on the same instance, the <code>--network</code> and <code>--ip</code> flags are used to assign a specific IP address to the container within the Docker network created in Step 2. This IP address is referenced in subsequent steps as the PostgreSQL service address.</li> <li>The <code>--network</code> and <code>--ip</code> flags are not required if the services are running on separate instances, as PostgreSQL will bind to the default network interface.</li> </ul> </li> </ol>"},{"location":"install-pmm/HA.html#step-6-running-pmm-services","title":"Step 6: Running PMM Services","text":"<p>The PMM Server orchestrates the collection, storage, and visualization of metrics. In our high-availability setup, we\u2019ll have one active PMM Server and two passive PMM Servers.</p> <ol> <li> <p>Pull the PMM Server Docker image:</p> <pre><code>docker pull ${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Create a Docker volume for PMM-Server data:</p> <pre><code>docker volume create pmm-server-active_data\ndocker volume create pmm-server-passive_data\ndocker volume create pmm-server-passive-2_data\n</code></pre> </li> <li> <p>Run the active PMM managed server. This server will serve as the primary monitoring server.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n--hostname ${PMM_ACTIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_ACTIVE_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Run the first passive PMM managed server. This server will act as a standby server, ready to take over if the active server fails.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n--hostname ${PMM_PASSIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Run the second passive PMM managed server. Like the first passive server, this server will also act as a standby server.</p> <p>You can either run all the services on the same instance or a separate instance.</p> Run services on same instanceRun services on a seperate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n--hostname ${PMM_PASSIVE2_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE2_IP} \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive-2_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n-p 80:80 \\\n-p 443:443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=10000 \\\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=2 \\\n-e PERCONA_TEST_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PERCONA_TEST_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_URL=postgres://${GF_USERNAME}:${GF_PASSWORD}@${PG_HOST_IP}:5432/grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v /srv/pmm-data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>Note</p> <ul> <li>Ensure to set the environment variables from Step 1  in each instance where you run these commands.</li> <li>If you run the service on the same instance, remove the <code>-p</code> flags.</li> <li>If you run the service on a separate instance, remove the <code>--network</code> and <code>--ip</code> flags.</li> </ul> </li> </ol>"},{"location":"install-pmm/HA.html#step-7-running-haproxy","title":"Step 7: Running HAProxy","text":"<p>HAProxy provides high availability for your PMM setup by directing traffic to the current leader server via the <code>/v1/leaderHealthCheck</code> endpoint.</p> <ol> <li> <p>Pull the HAProxy Docker image.</p> <pre><code>docker pull haproxy:2.4.2-alpine\n</code></pre> </li> <li> <p>Create a directory to store the SSL certificate.</p> <pre><code>mkdir -p /path/to/certs\n</code></pre> <p>Replace <code>/path/to/certs</code> with the path where you want to store your SSL certificates.</p> </li> <li> <p>Navigate to this directory and generate a new private key.</p> <pre><code>openssl genrsa -out pmm.key 2048\n</code></pre> <p>This command generates a 2048-bit RSA private key and saves it to a file named <code>pmm.key</code>.</p> </li> <li> <p>Using the private key, generate a self-signed certificate.</p> <pre><code>openssl req -new -x509 -key pmm.key -out pmm.crt -days 365\n</code></pre> <p>Enter country, state, organization name, etc. when asked. Use <code>-days 365</code> option for 365-day certificate validity.    </p> </li> <li> <p>Copy your SSL certificate and private key to the directory you created in step 2. Ensure that the certificate file is named <code>pmm.crt</code> and the private key file is named <code>pmm.key</code>. </p> <p>Concatenate these two files to create a PEM file:</p> <pre><code>cat pmm.crt pmm.key &gt; pmm.pem\n</code></pre> </li> <li> <p>Create a directory to store HA Proxy configuration.</p> <pre><code>mkdir -p /path/to/haproxy-config\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path where you want to store your HAProxy configuration.</p> </li> <li> <p>Create an HAProxy configuration file named <code>haproxy.cfg.template</code> in that directory. This configuration tells HAProxy to use the <code>/v1/leaderHealthCheck</code> endpoint of each PMM Server to identify the leader.</p> <pre><code>global\n    log stdout    local0 debug\n    log stdout    local1 info\n    log stdout    local2 info\n    daemon\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend http_front\n    bind *:80\n    default_backend http_back\n\nfrontend https_front\n    bind *:443 ssl crt /etc/haproxy/certs/pmm.pem\n    default_backend https_back\n\nbackend http_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-http PMM_ACTIVE_IP:80 check\n    server pmm-server-passive-http PMM_PASSIVE_IP:80 check backup\n    server pmm-server-passive-2-http PMM_PASSIVE2_IP:80 check backup\n\nbackend https_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-https PMM_ACTIVE_IP:443 check ssl verify none\n    server pmm-server-passive-https PMM_PASSIVE_IP:443 check ssl verify none\n    server pmm-server-passive-2-https PMM_PASSIVE2_IP:443 check ssl verify none\n</code></pre> </li> <li> <p>Before starting the HAProxy container, use <code>sed</code> to replace the placeholders in <code>haproxy.cfg.template</code> with the environment variables, and write the output to <code>haproxy.cfg</code>.</p> <pre><code>sed -e \"s/PMM_ACTIVE_IP/$PMM_ACTIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE_IP/$PMM_PASSIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE2_IP/$PMM_PASSIVE2_IP/g\" \\\n    /path/to/haproxy.cfg.template &gt; /path/to/haproxy.cfg    \n</code></pre> </li> <li> <p>Run the HAProxy container.</p> <pre><code>docker run -d \\\n  --name haproxy \\\n  --network pmm-network \\\n  -p 80:80 \\\n  -p 443:443 \\\n  -v /path/to/haproxy-config:/usr/local/etc/haproxy \\\n  -v /path/to/certs:/etc/haproxy/certs \\\n  haproxy:2.4.2-alpine\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path to the <code>haproxy.cfg</code> file you created in step 6, and <code>/path/to/certs</code> with the path to the directory containing the SSL certificate and private key. </p> </li> </ol> <p>Note</p> <ul> <li>It is recommended to use absolute paths instead of relative paths for volume mounts.</li> <li>If you\u2019re running services on separate instances, you can remove the <code>--network</code> flag.</li> </ul> <p>HAProxy is now configured to redirect traffic to the leader PMM managed server. This ensures highly reliable service by redirecting requests to the remainder of the servers in the event that the leader server goes down.</p>"},{"location":"install-pmm/HA.html#step-8-accessing-pmm","title":"Step 8: Accessing PMM","text":"<p>You can access the PMM web interface via HAProxy once all the components are set up and configured:</p> <ol> <li>Access the PMM services by navigating to <code>https://&lt;HAProxy_IP&gt;</code> in your web browser. Replace <code>&lt;HAProxy_IP&gt;</code> with the IP address or hostname of the machine running the HAProxy container.</li> <li>You should now see the PMM login screen. Log in using the default credentials, unless you changed them during setup.</li> <li>You can use the PMM web interface to monitor your database infrastructure, analyze metrics, and perform various database management tasks.</li> </ol> <p>When you register PMM Clients, you must use the HAProxy IP address (or hostname) rather than the PMM Server address once your PMM environment has been set up in high-availability (HA) mode. Even if one PMM Server becomes unavailable, clients will still be able to communicate with the servers.</p> <p>You have now successfully set up PMM in HA mode using Docker containers. Your PMM environment is more resilient to failures and can continue providing monitoring services if any of the instances fail.</p> <p>Note</p> <p>Ensure that all containers are running and accessible. You can use <code>docker ps</code> to check the status of your Docker containers. If a container is not running, you can view its logs using the command <code>docker logs &lt;container_name&gt;</code> to investigate the issue.</p> <p></p>"},{"location":"install-pmm/HA.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/index.html","title":"About PMM client installation","text":"<p>There are different ways to install PMM Client on a node and register it with PMM Server. Choose from:</p> <ul> <li> <p>Docker: Run PMM Client as a Docker container.</p> </li> <li> <p>Package manager:</p> <ul> <li>On Debian or Red Hat Linux, install <code>percona-release</code> and use a Linux package manager (<code>apt</code>/<code>dnf</code>) to install PMM Client.</li> <li>On Debian or Red Hat, download <code>.deb</code>/<code>.rpm</code> PMM Client packages and manually install them.</li> </ul> </li> </ul> <p>Binary is only way to install PMM client without root permissions</p> <ul> <li>Binary package: For other Linux distributions, download and unpack generic PMM Client Linux binaries. Ensure you choose the correct package for your architecture (x86_64 or ARM64).</li> </ul> <p>When you have installed PMM Client, you must:</p> <ul> <li>Register the node with PMM Server.</li> <li>Configure and add services according to type.</li> </ul> <p>If you need to, you can unregister, remove services or remove PMM Client.</p> <p>Here\u2019s an overview of the choices.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/index.html#before-you-start","title":"Before you start","text":"<p>Before installing the PMM client, check Prerequisites to install PMM client.</p>"},{"location":"install-pmm/install-pmm-client/index.html#connect-services","title":"Connect services","text":"<p>You must configure and adding services according to the service type.</p> <ul> <li>MySQL (and variants Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> <li>ProxySQL</li> <li>Amazon RDS</li> <li>Microsoft Azure</li> <li>Google Cloud Platform (MySQL and PostgreSQL)</li> <li>Linux</li> <li>External services</li> <li>HAProxy</li> <li>Remote instances</li> </ul> <p>Tip</p> <p>To change the parameters of a previously-added service, remove the service and re-add it with new parameters.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/binary_package.html","title":"Install PMM Client manually using binaries","text":"<p>Choose your installation instructions based on whether you have root permissions:</p> With root permissionsWithout root permissions <p>To install PMM Client with binary package with root permissions:</p> <ol> <li> <p>Download the PMM Client package for your architecture:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-x86_64.tar.gz\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-aarch64.tar.gz\n</code></pre> </li> <li> <p>Download the corresponding checksum file:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Verify the download:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>sha256sum -c pmm-client-3.0.0-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>sha256sum -c pmm-client-3.0.0-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Unpack the package and move into the directory:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>tar xfz pmm-client-3.0.0-x86_64.tar.gz &amp;&amp; cd pmm-client-3.0.0\n</code></pre> <pre><code>tar xfz pmm-client-3.0.0-aarch64.tar.gz &amp;&amp; cd pmm-client-3.0.0\n</code></pre> </li> <li> <p>Set the installation directory:</p> <pre><code>export PMM_DIR=/usr/local/percona/pmm\n</code></pre> </li> <li> <p>Run the installer:</p> <pre><code>./install_tarball\n</code></pre> </li> <li> <p>Update your PATH:</p> <pre><code>PATH=$PATH:$PMM_DIR/bin\n</code></pre> </li> <li> <p>Set up the agent:</p> <pre><code>pmm-agent setup --config-file=/usr/local/percona/pmm/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin\n</code></pre> </li> <li> <p>Run the agent:</p> <pre><code>pmm-agent --config-file=${PMM_DIR}/config/pmm-agent.yaml\n</code></pre> </li> <li> <p>Open a new terminal and verify the installation:</p> <pre><code>pmm-admin status\n</code></pre> </li> </ol> <p>To install PMM Client with binary package without root permissions:</p> <ol> <li> <p>Download the PMM Client package for your architecture:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-x86_64.tar.gz\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-aarch64.tar.gz\n</code></pre> </li> <li> <p>Download the corresponding checksum file:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/binary/tarball/pmm-client-3.0.0-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Verify the download:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>sha256sum -c pmm-client-3.0.0-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>sha256sum -c pmm-client-3.0.0-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Unpack the package and move into the directory:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>tar xfz pmm-client-3.0.0-x86_64.tar.gz &amp;&amp; cd pmm-client-3.0.0\n</code></pre> <pre><code>tar xfz pmm-client-3.0.0-aarch64.tar.gz &amp;&amp; cd pmm-client-3.0.0\n</code></pre> </li> <li> <p>Set the installation directory:</p> <pre><code>export PMM_DIR=YOURPATH\n</code></pre> <p>Replace YOURPATH with a path where you have required access.</p> </li> <li> <p>Run the installer:</p> <pre><code>./install_tarball\n</code></pre> </li> <li> <p>Update your PATH:</p> <pre><code>PATH=$PATH:$PMM_DIR/bin\n</code></pre> </li> <li> <p>Set up the agent:</p> <pre><code>pmm-agent setup --config-file=${PMM_DIR}/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin --paths-tempdir=${PMM_DIR}/tmp --paths-base=${PMM_DIR}\n</code></pre> </li> <li> <p>Run the agent:</p> <pre><code>pmm-agent --config-file=${PMM_DIR}/config/pmm-agent.yaml\n</code></pre> </li> <li> <p>Open a new terminal and verify the installation:</p> <pre><code>pmm-admin status\n</code></pre> </li> </ol> <p>Tips</p> <ul> <li>Download tar.gz with pmm-client.</li> <li>Extract it.</li> <li>Run <code>./install_tarball script</code>with the <code>-u</code> flag.</li> </ul> <p>The configuration file will be overwritten if you do not provide the -<code>u</code> flag while the pmm-agent is updated.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/binary_package.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/docker.html","title":"Run PMM client as a Docker container","text":"<p>The PMM Client Docker image is a convenient way to run PMM Client as a preconfigured Docker container. </p> <p>The PMM Client Docker image is available for both x86_64 and ARM64 architectures. Docker will automatically pull the correct image for your system architecture.</p> <ol> <li> <p>Pull the PMM Client Docker image:</p> <pre><code>docker pull \\\npercona/pmm-client:2\n</code></pre> </li> <li> <p>Use the image as a template to create a persistent data store that preserves local data when the image is updated:</p> <pre><code>docker create \\\n--volume /srv \\\n--name pmm-client-data \\\npercona/pmm-client:2 /bin/true\n</code></pre> </li> <li> <p>Run the container to start pmm-agent in setup mode. Set <code>X.X.X.X</code> to the IP address of your PMM Server. (Do not use the <code>docker --detach</code> option as PMM agent only logs to the console.)</p> <pre><code>PMM_SERVER=X.X.X.X:443\ndocker run \\\n--rm \\\n--name pmm-client \\\n-e PMM_AGENT_SERVER_ADDRESS=${PMM_SERVER} \\\n-e PMM_AGENT_SERVER_USERNAME=admin \\\n-e PMM_AGENT_SERVER_PASSWORD=admin \\\n-e PMM_AGENT_SERVER_INSECURE_TLS=1 \\\n-e PMM_AGENT_SETUP=1 \\\n-e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n--volumes-from pmm-client-data \\\npercona/pmm-client:2\n</code></pre> </li> </ol> <p>Tips</p> <p>You can find a complete list of compatible environment variables here.</p> <ol> <li> <p>Check status.</p> <pre><code>docker exec pmm-client \\\npmm-admin status\n</code></pre> <p>In the PMM user interface you will also see an increase in the number of monitored nodes.</p> </li> </ol> <p>You can now add services with <code>pmm-admin</code> by prefixing commands with <code>docker exec pmm-client</code>.</p> <p>Tips</p> <ul> <li>Adjust host firewall and routing rules to allow Docker communications. (Read more</li> <li>For help: <code>docker run --rm percona/pmm-client:2 --help</code></li> </ul> <p>In the GUI:</p> <ul> <li>Select  PMM Dashboards \u2192  System (Node) \u2192  Node Overview.</li> <li>In the Node Names menu, select the new node.</li> <li>Change the time range to see data.</li> </ul> <p>Danger</p> <p><code>pmm-agent.yaml</code> contains sensitive credentials and should not be shared.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/package_manager.html","title":"Install PMM client with Percona repositories","text":"<p>PMM Client supports both x86_64 and ARM64 architectures. On Debian or Red Hat Linux, install <code>percona-release</code> and use a Linux package manager (<code>apt</code>/<code>dnf</code>) to install PMM Client. The package manager will automatically select the appropriate version for your system architecture.</p> <p>Tip</p> <p>If you have used <code>percona-release</code> before, disable and re-enable the repository:</p> <pre><code>percona-release disable all\npercona-release percona-release enable pmm3-client\n</code></pre> Debian-basedRed Hat-based <p>To install PMM client:</p> <ol> <li> <p>Configure repositories.</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the PMM Client package.</p> <p>Root permissions</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> <li> <p>Check.</p> <pre><code>pmm-admin --version\n</code></pre> </li> <li> <p>Register the node.</p> </li> </ol> <ol> <li> <p>Configure repositories.</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Install the PMM Client package.</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> <li> <p>Check.</p> <pre><code>pmm-admin --version\n</code></pre> </li> <li> <p>Register the node.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/package_manager.html#package-manager-manual-download","title":"Package manager \u2013 manual download","text":"<p>To manually download package manager:</p> <ol> <li>Visit the Percona Monitoring and Management 3 download page.</li> <li>Under Version:, select the one you want (usually the latest).</li> <li>Under Software:, select the item matching your software platform and architecture (x86_64 or ARM64).</li> <li> <p>Click to download the package file:</p> <ul> <li>For Debian, Ubuntu: <code>.deb</code></li> <li>For Red Hat, CentOS, Oracle Linux: <code>.rpm</code></li> </ul> </li> </ol> <p>(Alternatively, copy the link and use <code>wget</code> to download it.)</p> Debian-basedRed Hat-based <pre><code>dpkg -i *.deb\n</code></pre> <pre><code>dnf localinstall *.rpm\n</code></pre> Download page links <p>Here are the download page links for each supported platform.</p> <ul> <li>Debian 9 (Stretch)</li> <li>Debian 10 (Buster)</li> <li>Debian 11 (Bullseye)</li> <li>Red Hat/CentOS/Oracle 7</li> <li>Red Hat/CentOS/Oracle 8</li> <li>Ubuntu 18.04 (Bionic Beaver)</li> <li>Ubuntu 20.04 (Focal Fossa)</li> <li>Ubuntu 22.04 (Jammy Jellyfish)</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-client/package_manager.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html","title":"Prerequisites","text":"<p>The prerequisites to install PMM client are:</p> <ol> <li> <p>Install PMM Server with a known IP address accessible from the client node.</p> </li> <li> <p>Check that you have superuser (root) access on the client host. </p> </li> <li> <p>Check that you have superuser access to any database servers that you want to monitor.</p> </li> <li> <p>Install the following Linux packages: </p> <ul> <li> <p><code>curl</code></p> </li> <li> <p><code>gnupg</code></p> </li> <li> <p><code>sudo</code></p> </li> <li> <p><code>wget</code></p> </li> </ul> </li> <li> <p>If you use it, install Docker.</p> </li> <li> <p>Check system requirements.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/index.html","title":"About connecting services for monitoring","text":"<p>You must configure and add database/service according to the service type.</p> <ul> <li>MySQL (and variants Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> <li>ProxySQL</li> <li>Amazon RDS</li> <li>Microsoft Azure</li> <li>Google Cloud Platform (MySQL and PostgreSQL)</li> <li>Linux</li> <li>External services</li> <li>HAProxy</li> <li>Remote instances</li> </ul> <p>Tip</p> <p>To change the parameters of a previously-added service, remove the service and re-add it with new parameters.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html","title":"Connect Amazon RDS instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#required-settings","title":"Required settings","text":"<p>It is possible to use PMM for monitoring Amazon RDS. In this case, the PMM Client is not installed on the host where the database server is deployed. By using the PMM web interface, you connect to the Amazon RDS DB instance. You only need to provide the IAM user access key (or assign an IAM role) and PMM discovers the Amazon RDS DB instances available for monitoring.</p> <p>First of all, ensure that there is the minimal latency between PMM Server and the Amazon RDS instance.</p> <p>Network connectivity can become an issue for VictoriaMetrics to scrape metrics with 1 second resolution.  We strongly suggest that you run PMM Server on AWS (Amazon Web Services) in the same availability zone as Amazon RDS instances.</p> <p>It is crucial that enhanced monitoring be enabled for the Amazon RDS DB instances you intend to monitor.</p> <p>Set the Enable Enhanced Monitoring option in the settings of your Amazon RDS DB instance.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-user-with-permission-to-access-amazon-rds-db-instances","title":"Creating an IAM user with permission to access Amazon RDS DB instances","text":"<p>It is recommended that you use an IAM user account to access Amazon RDS DB instances instead of using your AWS account. This measure improves security as the permissions of an IAM user account can be limited so that this account only grants access to your Amazon RDS DB instances. On the other hand, you use your AWS account to access all AWS services.</p> <p>The procedure for creating IAM user accounts is well described in the Amazon RDS documentation. This section only goes through the essential steps and points out the steps required for using Amazon RDS with Percona Monitoring and Management.</p> <p>The first step is to define a policy which will hold all the necessary permissions. Then, you need to associate this policy with the IAM user or group. In this section, we will create a new user for this purpose.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-a-policy","title":"Creating a policy","text":"<p>A policy defines how AWS services can be accessed. Once defined it can be associated with an existing user or group.</p> <ol> <li> <p>Select the Policies option on the navigation panel and click the Create policy button.</p> <p></p> </li> <li> <p>On the Create policy page, select the JSON tab and replace the existing contents with the following JSON document.</p> JSON <pre><code>{ \"Version\": \"2012-10-17\",\n\"Statement\": [{ \"Sid\": \"Stmt1508404837000\",\n            \"Effect\": \"Allow\",\n            \"Action\": [ \"rds:DescribeDBInstances\",\n                        \"cloudwatch:GetMetricStatistics\",\n                        \"cloudwatch:ListMetrics\"],\n                        \"Resource\": [\"*\"] },\n            { \"Sid\": \"Stmt1508410723001\",\n            \"Effect\": \"Allow\",\n            \"Action\": [ \"logs:DescribeLogStreams\",\n                        \"logs:GetLogEvents\",\n                        \"logs:FilterLogEvents\" ],\n                        \"Resource\": [ \"arn:aws:logs:*:*:log-group:RDSOSMetrics:*\" ]}\n        ]\n}\n</code></pre> </li> <li> <p>Click Review policy and set a name to your policy, such as <code>AmazonRDSforPMMPolicy</code>. Then, click the Create policy button.</p> <p></p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-user","title":"Creating an IAM user","text":"<p>Policies are attached to existing IAM users or groups. To create a new IAM user, select Users on the Identity and Access Management page at AWS. Then click Add user and complete the following steps:</p> <ol> <li> <p>On the Add user page, set the user name and select the Programmatic access option under Select AWS access type. Set a custom password and then proceed to permissions by clicking the Permissions button.</p> <p></p> </li> <li> <p>On the Set permissions page, add the new user to one or more groups if necessary. Then, click Review.</p> </li> <li> <p>On the Add user page, click Create user.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-access-key-for-an-iam-user","title":"Creating an access key for an IAM user","text":"<p>To discover an Amazon RDS DB instance in PMM, you either need to use the access key and secret access key of an existing IAM user or an IAM role. To create an access key for use with PMM, open the IAM console and click Users on the navigation pane. Then, select your IAM user.</p> <p>To create the access key, open the Security credentials tab and click the Create access key button. The system automatically generates a new access key ID and a secret access key that you can provide on the PMM Add Instance dashboard to have your Amazon RDS DB instances discovered.</p> <p>In case, the PMM Server and Amazon RDS DB instance were created by using the same AWS account, you do not need create the access key ID and secret access key manually. PMM retrieves this information automatically and attempts to discover your Amazon RDS DB instances.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#attaching-a-policy-to-an-iam-user","title":"Attaching a policy to an IAM user","text":"<p>The last step before you are ready to create an Amazon RDS DB instance is to attach the policy with the required permissions to the IAM user.</p> <p>First, make sure that the Identity and Access Management page is open and open Users. Then, locate and open the IAM user that you plan to use with Amazon RDS DB instances. Complete the following steps, to apply the policy:</p> <ol> <li> <p>On the Permissions tab, click the Add permissions button.</p> </li> <li> <p>On the Add permissions page, click Attach existing policies directly.</p> </li> <li> <p>Using the Filter, locate the policy with the required permissions (such as <code>AmazonRDSforPMMPolicy</code>).</p> </li> <li> <p>Select a check-box next to the name of the policy and click Review.</p> </li> <li> <p>The selected policy appears on the Permissions summary page. Click Add permissions.</p> </li> </ol> <p>The <code>AmazonRDSforPMMPolicy</code> is now added to your IAM user.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-role","title":"Creating an IAM role","text":"<p>Instead of creating an IAM user you can create an IAM role for a service, to discover Amazon RDS DB instances automatically without the need for access and secret keys. (But this only works if you are running PMM through AWS.)</p> <p>To create an IAM role open the IAM console and click Roles on the navigation pane.</p> <ol> <li> <p>Click the Create role button.</p> </li> <li> <p>Select AWS service and select EC2 for the use case.</p> </li> <li> <p>Click the Next: Permissions button.</p> </li> <li> <p>Find the policy created previously and select it.</p> </li> <li> <p>Click the Next: Tags button.</p> </li> <li> <p>(Optional) Add a metadata tag to the role.</p> </li> <li> <p>Click the Next: Review button.</p> </li> <li> <p>Fill the role name and description.</p> </li> <li> <p>Click the Create role button</p> </li> </ol> <p>After the role is created EC2 instances running PMM will have permissions to discover RDS DB instances.</p> <p>It\u2019s also possible to create an IAM role to delegate permissions to an IAM user or to add permissions to a user belonging to another AWS account. See the official AWS documentation on creating IAM roles.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#setting-up-the-amazon-rds-db-instance","title":"Setting up the Amazon RDS DB Instance","text":"<p>Query Analytics requires Configuring Performance Schema as the query source, because the slow query log is stored on the AWS (Amazon Web Services) side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Amazon RDS.</p> <p>Important</p> <p>Enabling Performance Schema on T2 instances is not recommended because it can easily run the T2 instance out of memory.</p> <p>When adding a monitoring instance for Amazon RDS, specify a unique name to distinguish it from the local instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Amazon RDS instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, UPDATE, DELETE, DROP ON performance_schema.* TO 'pmm'@'%';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#adding-an-amazon-rds-aurora-or-remote-instance","title":"Adding an Amazon RDS, Aurora or Remote Instance","text":"<p>Important</p> <p>It may take longer for PMM to discover Amazon RDS instances in the <code>creating</code> state. You must wait a bit longer until PMM discovers these instances.</p> <p>The preferred method of adding an Amazon RDS database instance to PMM is via the   Configuration \u2192  PMM Inventory \u2192  Add Instance menu option.</p> <p>This method supports Amazon RDS database instances that use Amazon Aurora, MySQL, or MariaDB engines, as well as any remote PostgreSQL, ProxySQL, MySQL and MongoDB instances.</p> <p>The following steps are needed to add an Amazon RDS database instance to PMM:</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Instance &gt; Amazon RDS.</p> <p></p> </li> <li> <p>Enter the access key ID and the secret access key of your IAM user or leave these fields empty if an IAM role was created.</p> </li> <li> <p>Click the Discover button for PMM to retrieve the available Amazon RDS instances.</p> <p></p> </li> <li> <p>For the instance that you would like to monitor, select the Start monitoring button.</p> </li> <li> <p>You will see a new page with the number of fields. The list is divided into the following groups: Main details, RDS database, Labels, and Additional options. Some already known data, such as already entered AWS access key, are filled in automatically, and some fields are optional.</p> <p></p> <p>The Main details section allows you to specify the DNS hostname of your instance, the service name to use within PMM, the port your service is listening on, and the database user name and password.</p> <p></p> <p>The Labels section allows you to specify labels for the environment, the AWS region and availability zone to be used, the Replication set and Cluster names and also it allows you to set the list of custom labels in a key:value format.</p> <p></p> <p>The Additional options section contains specific flags which allow you to tune the RDS monitoring. They can allow you to skip connection check, to use TLS for the database connection, not to validate the TLS certificate and the hostname, as well as to disable basic and/or enhanced metrics collection for the RDS instance to reduce costs.</p> <p>Also this section contains a database-specific flag, which would allow Query Analytics for the selected remote database:</p> <ul> <li> <p>when adding some remote MySQL, AWS RDS MySQL or Aurora MySQL instance, you will be able to choose using performance schema for the database monitoring;</p> </li> <li> <p>when adding a PostgreSQL instance, you will be able to activate using <code>pg_stat_statements</code> extension;</p> </li> <li> <p>when adding a MongoDB instance, you will be able to choose using Query Analytics MongoDB profiler.</p> </li> </ul> </li> <li> <p>Finally press the Add service button to start monitoring your instance.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#adding-an-amazon-rds-postgresql-instance","title":"Adding an Amazon RDS PostgreSQL instance","text":"<p>For PostgreSQL, use the same method described above.</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Instance &gt; Amazon RDS.</p> <p></p> </li> <li> <p>Follow steps 4 to 6 as in the previous section. Fill the form and remember to select <code>PG Stat Statement</code> to enable Query Analytics.</p> <p>To get queries for Query Analytics, you need to enable <code>pg_stat_statements</code> in <code>postgres</code> database of your instance by running:</p> <pre><code>CREATE EXTENSION pg_stat_statements SCHEMA public;\n</code></pre> <p> </p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html","title":"Connect Azure instance","text":"<p>Caution</p> <p>Microsoft Azure functionality is currently in technical preview and is subject to change.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#activate-microsoft-azure","title":"Activate Microsoft Azure","text":"<p>The Microsoft Azure feature is turned off by default. To turn it on:</p> <ol> <li> <p>Go to  PMM Configuration &gt; Settings &gt; Advanced Settings.</p> </li> <li> <p>Click the  toggle in the Technical preview features section of the page.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#required-settings","title":"Required settings","text":"<p>It is possible to use PMM for monitoring Azure database instances like other remote instances. In this case, the PMM Client is not installed on the host where the database server is deployed. By using the PMM web interface, you connect to the Azure DB instance. Discovery is not yet implemented in PMM but it is possible to add known instances by providing the connection parameters.</p> <p>First of all, ensure that there is the minimal latency between PMM Server and the Azure instance.</p> <p>Second, add a firewall rule to enable access from PMM Client like this:</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#setting-up-a-mysql-instance","title":"Setting up a MySQL instance","text":"<p>Query Analytics requires you to configure Performance Schema as the query source, because the slow query log is stored on the Azure side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Azure MySQL databases.</p> <p>When adding a monitoring instance for Azure, specify a unique name to distinguish it from the local MySQL instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Azure MySQL database instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#adding-an-azure-instance","title":"Adding an Azure Instance","text":"<p>Follow the instructions for remotes instances explained here, Azure MySQL databases are similar to AWS RDS databases.</p> <p>Example:</p> <p></p> <p>and be sure to set Performance Schema as the query collection method for Query Analytics.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#mariadb","title":"MariaDB","text":"<p>MariaDB up to version 10.2 works out of the box but starting with MariaDB 10.3 instrumentation is disabled by default and cannot be enabled since there is no SUPER role in Azure-MariaDB. So, it is not possible to run the required queries to enable instrumentation. Monitoring will work but Query Analytics won\u2019t receive any query data.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#postgresql","title":"PostgreSQL","text":"<p>For PostgreSQL follow the same methods used for MySQL and MariaDB and enable <code>track_io_timing</code> in the instance configuration to enable Query Analytics.</p> <p></p> <p>For Query Analytics, set the server parameter:</p> <pre><code>pg_stat_statements.track = all\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#to-discover-databases-on-azure","title":"To discover databases on Azure","text":"<p>You need to get the Client ID, Client Secret, Tenant ID and Subscription ID.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#get-the-subscription-id","title":"Get the subscription ID","text":"<p>To get a subscription ID:</p> <ol> <li> <p>Search Subscriptions, click on your subscription name </p> </li> <li> <p>Copy the subscription ID</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#create-a-new-application-to-get-the-tenant-id-client-id-and-the-client-secret","title":"Create a new application to get the tenant ID, client ID and the client secret","text":"<p>To get the tenant ID, client ID and the client secret:</p> <ol> <li> <p>Search for Azure Active Directory </p> </li> <li> <p>Register a new application  </p> </li> <li> <p>At this point you can copy the client and tenant IDs. </p> </li> <li> <p>Create an application secret.  </p> </li> <li> <p>Copy the value of the application secret. Once you leave this page you won\u2019t be able to see the secret again and you will have to generate a new    one. </p> </li> <li> <p>Give API access permissions to your application.</p> <ul> <li> <p>Search for Subscriptions like in step 1.</p> </li> <li> <p>Select your application and grant Monitor Reader permissions. This might require you to have admin permissions in your Azure account.</p> </li> </ul> </li> </ol> <p> </p> <p>When you fill in all fields press the Discover button and you will see a list of available databases for monitoring.</p> <p></p> <p>You can monitor 6 types of databases:</p> <ul> <li><code>Microsoft.DBforMySQL/servers</code></li> <li><code>Microsoft.DBforMySQL/flexibleServers</code></li> <li><code>Microsoft.DBforMariaDB/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/flexibleServers</code></li> <li><code>Microsoft.DBforPostgreSQL/serversv2</code></li> </ul> <p>You can find more details on how to create DB on Azure at:</p> <ul> <li>https://docs.microsoft.com/en-us/azure/postgresql/</li> <li>https://docs.microsoft.com/en-us/azure/mysql/</li> </ul> <p>Tip</p> <p>You must set <code>pg_stat_statements.track = all</code> in your PostgreSQL Server settings to use PMM Query Analytics. (Read more.)</p> <p></p> <p>In the list of databases on the Discovery page click Start Monitoring to add the selected Azure Database to PMM.</p> <p>Fill in all required fields and click Add service.</p> <p>PMM can use 3 exporters to collect metrics:</p> <ul> <li> <p>Azure Metrics Exporter \u2013 collect \u201csystem\u201d metrics related to DB.</p> <ul> <li><code>node_cpu_average</code></li> <li><code>azure_resource_info</code></li> <li><code>node_filesystem_size_bytes</code></li> <li><code>azure_memory_percent_average</code></li> <li><code>azure_storage_percent_average</code></li> <li><code>azure_storage_used_bytes_average</code></li> <li><code>node_network_receive_bytes_total</code></li> <li><code>node_network_transmit_bytes_total</code></li> </ul> </li> <li> <p><code>mysql_exporter</code> or <code>postgres_exporter</code> \u2013 to collect database related metrics.</p> </li> <li> <p>pmm-agent to collect queries related metrics using <code>pg_stat_statements</code> for PostgreSQL or Performance Schema for MySQL (MariaDB)</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#adding-an-azure-instance-on-pmm-client-side","title":"Adding an Azure Instance on PMM Client side","text":"<p>TLS/SSL is enforced on the server by default. So please download the certificate needed to communicate over SSL with your Azure Database. It can be done on Networking tab for your Azure Database instance.</p> <p>Also enforced TLS/SSL connection option can be disabled on server side.</p> <p></p> <p>Command for adding an azure database service for monitoring without TLS/SSL.</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema\n</code></pre> <p>Downloaded certificate is named <code>DigiCertGlobalRootCA.crt.pem</code>.</p> <p>An example of the command for adding an Azure database service for monitoring with TLS/SSL would be:</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema --tls --tls-ca=DigiCertGlobalRootCA.crt.pem --tls-cert=client-cert.pem --tls-key=client-key.pem --tls-skip-verify\n</code></pre> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html","title":"Connect an external instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-general-external-services","title":"Add general external services","text":"<p>You can collect metrics from an external (custom) exporter on a node when:</p> <ul> <li>there is already a pmm-agent instance running and,</li> <li>this node has been configured using the <code>pmm-admin config</code> command.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#usage","title":"Usage","text":"<pre><code>pmm-admin add external --service-name=&lt;service-name&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre> <pre><code>pmm-admin add external-serverless --external-name=&lt;external-service-name&gt; --host=&lt;hostname&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#get-data-from-external-exporters","title":"Get data from external exporters","text":"<p>There two ways to get metrics from other exporters:</p> <ul> <li> <p><code>external</code> will collect metrics from the exporter that is run on the same host as PMM Client\u2019s connection to it by a port. (See more details with <code>pmm-admin add external --help</code>.)</p> </li> <li> <p><code>external-serverless</code> is useful for collecting metrics from cloud services. You need a host and port number to add it to PMM Server. (See more details with <code>pmm-admin add external-serverless --help</code>.)</p> </li> </ul> <p>Here are the differences between <code>external</code> and <code>external-serverless</code> types.</p> <p>Connection schema of external exporter:</p> <p></p> <p>Connection schema of external serverless exporter:</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-a-service-not-supported-by-pmm","title":"Add a service not supported by PMM","text":"<p>PMM can collect any metrics in Open metrics or Prometheus exposition format. You must specify the host and port of these metrics using the <code>pmm-admin add external</code> or <code>pmm-admin add external-serverless</code> commands.</p> <p>From this point, PMM will collect and store available metrics.</p> <p>To browse and visualize collected metrics as a first step, we can look at the Advanced Data Exploration dashboard and select informative services and metrics.</p> <p></p> <p>Another way is to create a new Grafana Dashboard to PMM as needed.</p> <p>One more way is to search for an already created dashboard at https://grafana.com/grafana/dashboards for the added exporter and import it into PMM.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#third-party-exporters","title":"Third-party exporters","text":"<p>You can find more exporters on the official Prometheus page.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#custom-exporter","title":"Custom exporter","text":"<p>You can write a custom external exporter or extend your application to expose metrics in Prometheus format.</p> <p>For more details see https://prometheus.io/docs/instrumenting/writing_exporters/.</p> Example <pre><code>root@mysql1:~# pmm-admin add external --group=processes  --listen-port=9256\nExternal Service added.\nService ID  : 6485f4fd-745b-4dfb-8b72-328e300f8b50\nService name: mysql1-processes\nGroup       : processes\n</code></pre> <ul> <li>Add an exporter running on local port 9256 to the group called <code>processes</code>.</li> <li>Use the group and host names to automatically generate a service name.</li> <li>Use the default scheme and metrics path.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-an-external-service-via-ui","title":"Add an external service via UI","text":"<p>To add an external service via PMM UI:</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Service &gt; External Service.</p> <p></p> </li> <li> <p>Fill in the form and set the external service endpoint: </p> </li> <li> <p>manually OR:</p> <p></p> </li> <li> <p>by parsing required data from a URL string. In this case you only need to pass a valid URL:</p> <p></p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html","title":"Connect Google Cloud Platform instance","text":"<p>PMM can monitor MySQL or PostgreSQL instances hosted on the Google Cloud Platform.</p> <p>The connection can be direct, or indirect using Cloud SQL Proxy.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#mysql","title":"MySQL","text":"<p>To add a MySQL instance on Google Cloud:</p> <ol> <li> <p>Set up a MySQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure Performance Schema on the MySQL server. Using the GCP console\u2019s Cloud Shell or your own <code>gcloud</code> installation, run:</p> <pre><code>gcloud sql instances patch &lt;instance_name&gt; --database-flags performance_schema=on\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; PMM Inventory &gt;  Service &gt; Add Service &gt; MySQL.</p> </li> <li> <p>Fill in the details for the remote MySQL instance and make sure to enable the Use performance schema option.</p> </li> <li> <p>Click Add service.</p> </li> <li> <p>Go to Dashboards and check for values in the MySQL Instance Summary dashboard and in Query Analytics.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#postgresql","title":"PostgreSQL","text":"<p>To add a PostgreSQL instance on Google Cloud:</p> <ol> <li> <p>Set up a PostgreSQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure <code>pg_stat_statements</code>. Open an interactive SQL session with your GCP PostgreSQL server and run:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; PMM Inventory &gt; Services &gt; Add Service &gt; PostgreSQL.</p> </li> <li> <p>Fill in the details for the remote PostgreSQL instance and make sure to PG Stat Statements option under Stat tracking options.</p> <p></p> </li> <li> <p>Click Add service.</p> </li> <li> <p>Go to Dashboards and check for values in the PostgreSQL Instances Overview  and Query Analytics.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#cloud-sql-proxy","title":"Cloud SQL Proxy","text":""},{"location":"install-pmm/install-pmm-client/connect-database/google.html#mysql_1","title":"MySQL","text":"<p>To add a MySQL instance:</p> <ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Enable Performance Schema.</p> </li> <li> <p>Run Cloud SQL Proxy (runs on PMM Client node).</p> As a Docker containerOn Linux <pre><code>docker run -d \\\n-v ~/path/to/admin-api-file.json:/config \\\n-p 127.0.0.1:3306:3306 \\\ngcr.io/cloudsql-docker/gce-proxy:1.19.1 \\\n/cloud_sql_proxy \\\n-instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:0.0.0.0:3306 \\\n-credential_file=/config\n</code></pre> <pre><code>wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\nchmod +x cloud_sql_proxy\n./cloud_sql_proxy -instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:3306 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> <li> <p>Add instance.</p> <pre><code>pmm-admin add mysql --host=127.0.0.1 --port=3306 \\\n--username=root --password=secret \\\n--service-name=MySQLGCP --query-source=perfschema\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#postgresql_1","title":"PostgreSQL","text":"<p>To add a PostgreSQL instance:</p> <ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Run Cloud SQL Proxy.</p> <pre><code>./cloud_sql_proxy -instances=example-project-NNNN:us-central1:pg-for-pmm=tcp:5432 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> <li> <p>Log into PostgreSQL.</p> </li> <li> <p>Load extension:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Add service:</p> <pre><code>pmm-admin add postgresql --host=127.0.0.1 --port=5432 \\\n--username=\"postgres\" --password=secret --service-name=PGGCP\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html","title":"Connect HAProxy instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#adding-haproxy","title":"Adding HAProxy","text":"<p>You can collect metrics from HAProxy on a node when:</p> <ul> <li> <p>There is already a configured haproxy instance.</p> </li> <li> <p>See How to configure HAProxy.</p> </li> <li>After HAProxy is running (default address http://localhost:8404/metrics) you can add it to PMM.</li> <li> <p>Use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</p> </li> <li> <p>There is already a pmm-agent instance running.</p> </li> <li> <p>This node has been configured using the <code>pmm-admin config</code> command.</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> <p>where <code>listen-port</code> is the port number where HAProxy running. (This is the only required flag.)</p> <p>The output of this command should look as follows:</p> <pre><code>HAProxy Service added.\nService ID  : c481183f-70a2-443f-91e5-cae5cecd06a2\nService name: Ubuntu-haproxy\n</code></pre> <p>Additionally, one positional argument can be appended to the command line flags: a service name to be used by PMM. If not specified, they are substituted automatically as <code>&lt;node&gt;-haproxy</code>.</p> <p>During adding here is connection check (can be skipped by flag <code>--skip-connection-check</code>). If HAProxy doesn\u2019t run properly on the given port then you will see an error message:</p> <pre><code>Connection check failed: Get \"http://127.0.0.1:8404/metrics\": dial tcp 127.0.0.1:8404: connect: connection refused.\n</code></pre> <p>Beside positional argument shown above you can specify service name  with the following flags: <code>--username</code>, <code>--password</code>, <code>--metrics-path</code> (path for scraping metrics, default: /metrics) and <code>--scheme</code> (http or https). Here are some examples:</p> <pre><code>pmm-admin add haproxy --listen-port=8404 --username=pmm --password=pmm new-haproxy\npmm-admin add haproxy --listen-port=8404 --metrics-path=/prom-metrics --scheme=https\n</code></pre> <p>Here you can check list of all available flags: pmm-admin.</p> <p>You can also add HAProxy by UI: Select  PMM Configuration &gt; PMM Inventory &gt; Add Instance.</p> <p>HAProxy data is visible in the Advanced Data Exploration dashboard:</p> <p></p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html","title":"Connect Linux instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#add-general-system-metrics-service","title":"Add general system metrics service","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html","title":"Connect MongoDB instance","text":"<p>How to set up PMM to monitor a MongoDB or Percona Server for MongoDB database instance.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address or hostname accessible from the client node.</li> <li>PMM Client is installed and the nodes are registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> <li>You have <code>adminUserAnyDatabase</code> or superuser role privilege to any database servers that you want to monitor.</li> <li>Your MongoDB server is version 4.0 or higher.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#create-pmm-account-and-set-permissions","title":"Create PMM account and set permissions","text":"<p>We recommend using a dedicated account to connect PMM Client to the monitored database instance.</p> <p>Run the example codes below in a <code>mongo</code> session to:</p> <ul> <li>create custom roles with the privileges required for creating/restoring backups and working with Query Analytics (QAN)</li> <li>create/update a database user with these roles above, plus the built-in  <code>clusterMonitor</code> role</li> </ul> <p>Values for username (<code>user</code>) and password (<code>pwd</code>) are examples. Replace them before using these code snippets.</p> Create roles with privileges for backups and QANCeate/update user and assign created roles <pre><code>db.getSiblingDB(\"admin\").createRole({\n    role: \"explainRole\",\n    privileges: [{\n        resource: {\n            db: \"\",\n            collection: \"\"\n            },\n        actions: [\n            \"listIndexes\",\n            \"listCollections\",\n            \"dbStats\",\n            \"dbHash\",\n            \"collStats\",\n            \"find\"\n            ]\n        }],\n    roles:[]\n})\n\ndb.getSiblingDB(\"admin\").createRole({ \"role\": \"pbmAnyAction\",\n    \"privileges\": [\n    { \"resource\": { \"anyResource\": true },\n        \"actions\": [ \"anyAction\" ]\n    }\n    ],\n    \"roles\": []\n });\n</code></pre> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    user: \"pmm\",\n    pwd: \"pmm\",\n    roles: [\n        { role: \"explainRole\", db: \"admin\" },\n        { role: \"clusterMonitor\", db: \"admin\" },\n        { role: \"read\", db: \"local\" },\n        { \"db\" : \"admin\", \"role\" : \"readWrite\", \"collection\": \"\" },\n        { \"db\" : \"admin\", \"role\" : \"backup\" },\n        { \"db\" : \"admin\", \"role\" : \"clusterMonitor\" },\n        { \"db\" : \"admin\", \"role\" : \"restore\" },\n        { \"db\" : \"admin\", \"role\" : \"pbmAnyAction\" }\n    ]\n})\ndb.getSiblingDB(\"admin\").updateUser(\"pmm\", {\nroles: [\n    { role: \"explainRole\", db: \"admin\" },\n    { role: \"clusterMonitor\", db: \"admin\" },\n    { role: \"read\", db: \"local\" },\n    { \"db\" : \"admin\", \"role\" : \"readWrite\", \"collection\": \"\" },\n    { \"db\" : \"admin\", \"role\" : \"backup\" },\n    { \"db\" : \"admin\", \"role\" : \"clusterMonitor\" },\n    { \"db\" : \"admin\", \"role\" : \"restore\" },\n    { \"db\" : \"admin\", \"role\" : \"pbmAnyAction\" }\n]\n})\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#permissions-for-advanced-metrics","title":"Permissions for advanced metrics","text":"<p>To fetch advanced metrics like usage statistics for collection and indexes, use the following to provide additional privileges to an existing PMM user:</p> <pre><code>db.getSiblingDB(\"admin\").updateRole(\n  \"explainRole\",\n  {\n    privileges: [\n      {\n        resource: { db: \"\", collection: \"\" },\n        actions: [\"collStats\", \"dbStats\", \"indexStats\"]\n      }\n    ]\n  }\n)\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#profiling","title":"Profiling","text":"<p>To use PMM Query Analytics, you must turn on MongoDB\u2019s profiling feature.</p> <p>You can set profiling:</p> <ul> <li>permanently, by editing the MongoDB configuration file  and restarting the database instance (recommended);</li> <li>when starting MongoDB, by passing arguments to <code>mongod</code> on the command line;</li> <li>until the next database instance restart, by running a command in a <code>mongo</code> session.</li> </ul> <p>Profiling is turned off by default as it can adversely affect the performance of the database server.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#set-profiling-in-the-configuration-file","title":"Set profiling in the configuration file","text":"<p>To set profiling in the configuration file:</p> <ol> <li> <p>Edit the configuration file (usually <code>/etc/mongod.conf</code>).</p> </li> <li> <p>Create or add this to the <code>operationProfiling</code> section. (Read more.)</p> <pre><code>operationProfiling:\n  mode: all\n  slowOpThresholdMs: 200\n  rateLimit: 100 # (Only available with Percona Server for MongoDB.)\n</code></pre> <p>Important</p> <p>This is a YAML file. Indentation matters.</p> </li> <li> <p>Restart the <code>mongod</code> service. (Example for <code>systemd</code>.)</p> <pre><code>systemctl restart mongod\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#set-profiling-on-the-command-line","title":"Set profiling on the command Line","text":"<pre><code>mongod --dbpath=DATABASEDIR --profile 2 --slowms 200 --rateLimit 100\n</code></pre> <ul> <li><code>--dbpath</code>: The path to database files (usually <code>/var/lib/mongo</code>).</li> <li><code>--profile</code>: The MongoDB profiling level. A value of <code>2</code> tells the server to collect profiling data for all operations. To lower the load on the server, use a value of <code>1</code> to only record slow operations.</li> <li><code>--slowms</code>: An operation is classified as slow if it runs for longer than this number of milliseconds.</li> <li> <p><code>--rateLimit</code>: (Only available with Percona Server for MongoDB.) The sample rate of profiled queries. A value of <code>100</code> means sample every 100<sup>th</sup> fast query. (Read more.)</p> <p>Caution</p> <p>Smaller values improve accuracy but can adversly affect the performance of your server.</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#set-profiling-in-a-mongo-session","title":"Set profiling in a <code>mongo</code> session","text":"<p>In a <code>mongo</code> session, the profiler should be enabled per database. For example, to enable the profiler in the <code>testdb</code>, run this:</p> <pre><code>use testdb\ndb.setProfilingLevel(2, {slowms: 0})\n</code></pre> <p>If you have already added a service, you should remove it and re-add it after changing the profiling level.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#add-service","title":"Add service","text":"<p>When you have configured your database server, you can add a MongoDB service with the user interface or on the command line.</p> <p>Important</p> <p>To monitor MongoDB sharded clusters, PMM requires access to all cluster components. Make sure to add all config servers, shards, and mongos. Otherwise, PMM will not be able to correctly collect metrics and populate dashboards.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#with-the-user-interface","title":"With the user interface","text":"<p>To add a service with the UI:</p> <ol> <li> <p>Select PMM Configuration &gt; Add Service &gt; MongoDB.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#on-the-command-line","title":"On the command line","text":"<p>Use <code>pmm-admin</code> to add the database server as a service using one of these example commands.</p> <p>When successful, PMM Client will print <code>MongoDB Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>-custom-labels</code> options to set tags for the service to help identify them.</p> <p>Tips</p> <ul> <li>When adding nodes of a sharded cluster, add each node separately using the <code>--cluster mycluster</code> option for the MongoDB Cluster Summary dashboard to populate correctly. Also use the <code>--replication-set</code> option to specify a replication set. Example: <code>--replication-set config</code> for your config servers; <code>--replication-set rs1</code> for your servers in the first replica set, <code>--replication-set rs2</code> for your servers in the second replica set, and so on.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#examples","title":"Examples","text":"<pre><code>pmm-admin add mongodb \\\n--username=pmm_mongodb --password=password \\\n--query-source=profiler --cluster=mycluster\n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm_mongodb --password=password \\\nmongo 127.0.0.1:27017\n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm_mongodb --password=password \\\n--service-name=mymongosvc --host=127.0.0.1 --port=27017\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#connect-via-unix-socket","title":"Connect via UNIX socket","text":"<pre><code>pmm-admin add mongodb --socket=/tmp/mongodb-27017.sock\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#connecting-via-ssltls","title":"Connecting via SSL/TLS","text":"<pre><code>pmm-admin add mongodb --tls \\\n--tls-certificate-key-file=PATHTOCER \\\n--tls-certificate-key-file-password=IFPASSWORDTOCERTISSET \\\n--tls-ca-file=PATHTOCACERT\n--authentication-mechanism=AUTHENTICATION-MECHANISM\n--authentication-database=AUTHENTICATION-DATABASE\n</code></pre> <p>where:</p> <ul> <li><code>PATHTOCERT</code>: Path to TLS certificate file.</li> <li><code>IFPASSWORDTOCERTISSET</code>: Password for TLS certificate file.</li> <li><code>PATHTOCACERT</code>: Path to certificate authority file.</li> <li><code>AUTHENTICATION-MECHANISM</code>: Authentication mechanism. Default is empty. Use <code>MONGODB-X509</code> for SSL certificates.</li> <li><code>AUTHENTICATION-DATABASE</code>: Authentication database. Default is empty. Use <code>$external</code> for SSL certificates.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#check-the-service","title":"Check the service","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#from-the-user-interface","title":"From the user interface","text":"<p>To check the servie from the UI:</p> <ol> <li> <p>Select  PMM Configuration &gt; Inventory &gt; MongoDB.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#on-the-command-line_1","title":"On the command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services --service-type=mongodb\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#check-data","title":"Check data","text":"<p>To check the data:</p> <ol> <li>Open the MongoDB Instances Overview dashboard.</li> <li>Set the Service Name to the newly-added service.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#query-analytics","title":"Query Analytics","text":"<p>To see the query analytics for the service:</p> <ol> <li>Open PMM Query Analytics.</li> <li>In the Filters panel:<ol> <li>Under Service Name, select your service.</li> <li>Under Service Type select <code>mongodb</code>.</li> </ol> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#remove-service","title":"Remove service","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#with-the-user-interface_1","title":"With the user interface","text":"<p>To remove the service from the UI:</p> <ol> <li>Select PMM Configuration &gt; Inventory.</li> <li>In the Services tab, verify the Service name, Addresses, and any other relevant values used when adding the service.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> <li> <p>If your MongoDB instance is configured to use TLS, click on the Use TLS for database connection check box and fill in TLS certificates and keys. If you use TLS, the authentication mechanism is automatically set to <code>MONGODB-X509</code>.</p> <p></p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#on-the-command-line_2","title":"On the command line","text":"<pre><code>pmm-admin remove mongodb SERVICE_NAME\n</code></pre> <ul> <li><code>SERVICE_NAME</code>: The name the service was added as. (Find it with <code>pmm-admin list</code>.)</li> </ul> <p>See also</p> <ul> <li><code>pmm-admin add mongodb</code></li> <li>Troubleshooting connection difficulties</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html","title":"Connect a self-hosted or an AWS EC2 MySQL database to PMM","text":"<p>PMM Client collects metrics from MySQL, Percona Server for MySQL, Percona XtraDB Cluster, and MariaDB. (Amazon RDS is also supported and explained in a separate section.)</p> Summary <ul> <li>Create PMM account and set permissions.</li> <li>Choose a data source:<ul> <li>Slow query log, or,</li> <li>Performance Schema.</li> </ul> </li> <li>Configure:<ul> <li>Query response time,</li> <li>Tablestats,</li> <li>User statistics.</li> </ul> </li> <li>Add service.</li> <li>Check the service.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address accessible from the client node.</li> <li>PMM Client is installed and the nodes are registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>It is good practice to use a non-superuser account to connect PMM Client to the monitored database instance. This example creates a database user with name <code>pmm</code>, password <code>pass</code>, and the necessary permissions.</p> On MySQL 5.7On MySQL 8.0 <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY 'pass' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD ON *.* TO 'pmm'@'localhost';\n</code></pre> <pre><code>CREATE USER 'pmm'@'localhost' IDENTIFIED BY 'pass' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'localhost';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#choose-and-configure-a-source","title":"Choose and configure a source","text":"<p>Decide which source of metrics to use, and configure your database server for it. The choices are Slow query log and Performance Schema.</p> <p>While you can use both at the same time we recommend using only one\u2013there is some overlap in the data reported, and each incurs a small performance penalty. The choice depends on the version and variant of your MySQL instance, and how much detail you want to see.</p> <p>Here are the benefits and drawbacks of Slow query log and Performance Schema metrics sources.</p>  Benefits  Drawbacks Slow query log 1. More detail.2. Lower resource impact (with query sampling feature in Percona Server for MySQL). 1. PMM Client must be on same host as database server or have access to slow query log.2. Log files grow and must be actively managed. Performance Schema 1. Faster parsing.2. Enabled by default on newer versions of MySQL. 1. Less detail."},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#data-source-recommendations","title":"Data source recommendations","text":"Database server Versions Recommended source MySQL 5.1-5.5 Slow query log MySQL 5.6+ Performance Schema MariaDB 10.0+ Performance Schema Percona Server for MySQL 5.7, 8.0 Slow query log Percona XtraDB Cluster 5.6, 5.7, 8.0 Slow query log"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#slow-query-log","title":"Slow query log","text":"<p>This section covers how to configure a MySQL-based database server to use the slow query log as a source of metrics.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#applicable-versions","title":"Applicable versions","text":"Server Versions MySQL 5.1-5.5 MariaDB 10.1.2+ Percona Server for MySQL 5.7.10+, 8.0.12+ Percona XtraDB Cluster 5.6, 5.7, 8.0 <p>The slow query log records the details of queries that take more than a certain amount of time to complete. With the database server configured to write this information to a file rather than a table, PMM Client parses the file and sends aggregated data to PMM Server via the Query Analytics part of pmm-agent.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#settings","title":"Settings","text":"Variable Value Description <code>slow_query_log</code> ON Enables the slow query log. <code>log_output</code> <code>'FILE'</code> Ensures the log is sent to a file. (This is the default on MariaDB.) <code>long_query_time</code> 0 The slow query threshold in seconds. In heavily-loaded applications, many quick queries can affect performance more than a few slow ones. Setting this value to <code>0</code> ensures all queries are captured. <code>log_slow_admin_statements</code> ON Includes the logging of slow administrative statements. <code>log_slow_slave_statements</code> ON Enables logging for queries that have taken more than <code>long_query_time</code> seconds to execute on the replica. Examples <ul> <li> <p>Configuration file.</p> <pre><code>slow_query_log=ON\nlog_output=FILE\nlong_query_time=0\nlog_slow_admin_statements=ON\nlog_slow_slave_statements=ON\n</code></pre> </li> <li> <p>Session.</p> <pre><code>SET GLOBAL slow_query_log = 1;\nSET GLOBAL log_output = 'FILE';\nSET GLOBAL long_query_time = 0;\nSET GLOBAL log_slow_admin_statements = 1;\nSET GLOBAL log_slow_slave_statements = 1;\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#slow-query-log-extended","title":"Slow query log \u2013 extended","text":"<p>Some MySQL-based database servers support extended slow query log variables.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#applicable-versions_1","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.7.10+, 8.0.12+ Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 10.0"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#settings_1","title":"Settings","text":"Variable Value Description <code>log_slow_rate_limit</code> 100 Defines the rate of queries captured by the slow query log. A good rule of thumb is 100 queries logged per second. For example, if your Percona Server instance processes 10,000 queries per second, you should set <code>log_slow_rate_limit</code> to <code>100</code> and capture every 100<sup>th</sup> query for the slow query log. Depending on the amount of traffic, logging could become aggressive and resource consuming. This variable throttles the level of intensity of the data capture without compromising information. <code>log_slow_rate_type</code> \u2018query\u2019 Set so that it applies to queries, rather than sessions. <code>slow_query_log_always_write_time</code> 1 Specifies which queries should ignore sampling. With query sampling this ensures that queries with longer execution time will always be captured by the slow query log, avoiding the possibility that infrequent slow queries might not get captured at all. <code>log_slow_verbosity</code> \u2018full\u2019 Ensures that all information about each captured query is stored in the slow query log. <code>slow_query_log_use_global_control</code> \u2018all\u2019 Configure the slow query log during runtime and apply these settings to existing connections. (By default, slow query log settings apply only to new sessions.) Examples <ul> <li> <p>Configuration file (Percona Server for MySQL, Percona XtraDB Cluster).</p> <pre><code>log_slow_rate_limit=100\nlog_slow_rate_type='query'\nslow_query_log_always_write_time=1\nlog_slow_verbosity='full'\nslow_query_log_use_global_control='all'\n</code></pre> </li> <li> <p>Configuration file (MariaDB).</p> <pre><code>log_slow_rate_limit=100\n</code></pre> </li> <li> <p>Session (Percona Server for MySQL, Percona XtraDB Cluster).</p> <pre><code>SET GLOBAL log_slow_rate_limit = 100;\nSET GLOBAL log_slow_rate_type = 'query';\nSET GLOBAL slow_query_log_always_write_time = 1;\nSET GLOBAL log_slow_verbosity = 'full';\nSET GLOBAL slow_query_log_use_global_control = 'all';\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#slow-query-log-rotation","title":"Slow query log rotation","text":"<p>Slow query log files can grow quickly and must be managed.</p> <p>When adding a service with the command line use the  <code>pmm-admin</code> option <code>--size-slow-logs</code> to set at what size the slow query log file is rotated. (The size is specified as a number with a suffix. See <code>pmm-admin add mysql</code>.)</p> <p>When the limit is reached, PMM Client will:</p> <ul> <li>remove the previous <code>.old</code> slow log file,</li> <li>rename the current file by adding the suffix <code>.old</code>,</li> <li>execute the MySQL command <code>FLUSH LOGS</code>.</li> </ul> <p>Only one <code>.old</code> file is kept. Older ones are deleted.</p> <p>You can manage log rotation yourself, for example, with <code>logrotate</code>. If you do, you can disable PMM Client\u2019s log rotation by providing a negative value to <code>--size-slow-logs</code> option when adding a service with <code>pmm-admin add</code>.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#performance-schema","title":"Performance Schema","text":"<p>This section covers how to configure a MySQL-based database server to use Performance Schema as a source of metrics.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#applicable-versions_2","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.6, 5.7, 8.0 Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 10.3+ <p>PMM\u2019s MySQL Performance Schema Details dashboard charts the various <code>performance_schema</code> metrics.</p> <p>To use Performance Schema, set these variables.</p> Variable Value Description <code>performance_schema</code> <code>ON</code> Enables Performance Schema metrics. This is the default in MySQL 5.6.6 and higher. <code>performance-schema-instrument</code> <code>'statement/%=ON'</code> Configures Performance Schema instruments. <code>performance-schema-consumer-statements-digest</code> <code>ON</code> Configures the <code>statements-digest</code> consumer. <code>innodb_monitor_enable</code> all Enables InnoDB metrics counters. Examples <ul> <li> <p>Configuration file.</p> <pre><code>performance_schema=ON\nperformance-schema-instrument='statement/%=ON'\nperformance-schema-consumer-statements-digest=ON\ninnodb_monitor_enable=all\n</code></pre> </li> <li> <p>Session.</p> <p>(<code>performance_schema</code> cannot be set in a session and must be set at server start-up.)</p> <pre><code>UPDATE performance_schema.setup_consumers\nSET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\nSET GLOBAL innodb_monitor_enable = all;\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#mariadb-1057-or-lower","title":"MariaDB 10.5.7 or lower","text":"<p>There is no Explain or Example data shown by default in Query Analytics when monitoring MariaDB instances version 10.5.7 or lower. A workaround is to set this variable.</p> Variable Value Description <code>performance_schema.setup_instruments</code> <code>'statement/%'</code> List of instrumented object classes. <ul> <li> <p>Session</p> <pre><code>UPDATE performance_schema.setup_instruments SET ENABLED = 'YES', TIMED = 'YES' WHERE NAME LIKE 'statement/%';\nUPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\n</code></pre> </li> <li> <p>Transactions</p> <p>MariaDB doesn\u2019t implement queries history for transactions. All queries executed within a transaction won\u2019t have query examples since PMM relies on the <code>performance_schema.events_statements_history</code> to grab the query example but that table won\u2019t have any query executed as part of a transaction.  </p> <p>This behavior is because MariaDB doesn\u2019t implement these consumers:</p> <pre><code>events_transactions_current\nevents_transactions_history\nevents_transactions_history_long\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#query-response-time","title":"Query response time","text":"<p>Query time distribution is a chart in the Details tab of Query Analytics showing the proportion of query time spent on various activities. It is enabled with the <code>query_response_time_stats</code> variable and associated plugins.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#applicable-versions_3","title":"Applicable versions","text":"Server Versions Percona Server for MySQL 5.7 (not Percona Server for MySQL 8.0.) MariaDB 10.0.4 <p>Set this variable to see query time distribution charts.</p> Variable Value Description <code>query_response_time_stats</code> ON Report query response time distributions. (Requires plugin installation. See below.) <ul> <li> <p>Configuration file.</p> <pre><code>query_response_time_stats=ON\n</code></pre> </li> </ul> <p>You must also install the plugins.</p> <ul> <li> <p>Session</p> <ol> <li>Check that <code>/usr/lib/mysql/plugin/query_response_time.so</code> exists.</li> <li>Install the plugins and activate.</li> </ol> For MariaDB 10.3For Percona Server for MySQL 5.7 <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre> <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#tablestats","title":"Tablestats","text":"<p>Some table metrics are automatically disabled when the number of tables exceeds a default limit of 1000 tables. This prevents PMM Client from affecting the performance of your database server.</p> <p>The limit can be changed when adding a service on the command line with the two <code>pmm-admin</code> options:</p> <code>pmm-admin</code> option Description <code>--disable-tablestats</code> Disables tablestats collection when the default limit is reached. <code>--disable-tablestats-limit=N</code> Sets the number of tables (<code>N</code>) for which tablestats collection is disabled. 0 means no limit. A negative number means tablestats is completely disabled (for any number of tables)."},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#user-statistics","title":"User statistics","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#applicable-versions_4","title":"Applicable versions","text":"<p>User activity, individual table and index access details are shown on the MySQL User Details dashboard when the <code>userstat</code> variable is set.</p> Server Versions Percona Server for MySQL 5.6, 5.7, 8.0 Percona XtraDB Cluster 5.6, 5.7, 8.0 MariaDB 5.2.0+ Examples <ul> <li> <p>Configuration file.</p> <pre><code>userstat=ON\n</code></pre> </li> <li> <p>Session.</p> <pre><code>SET GLOBAL userstat = ON;\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#add-service","title":"Add service","text":"<p>There are two ways to install  PMM Client  for monitoring your MySQL database:</p> <ol> <li>Local installation: Installs PMM Client directly on the database node, collecting both database and OS/host metrics. This option enables more effective comparison and problem identification.</li> <li>Remote instance: Use when local installation isn\u2019t possible. This method doesn\u2019t provide OS/Node metrics in PMM.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#install-pmm-client-locally","title":"Install PMM Client locally","text":"<p>Add the MySQL server as a service using one of the following example commands.  Upon successful addition, PMM Client will display \u201cMySQL Service added\u201d along with the service\u2019s ID and name. </p> <ol> <li> <p>Select PMM Configuration &gt; PMM Inventory &gt; Add Service &gt; MySQL.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p> <p>If your MySQL instance is configured to use TLS, click on the Use TLS for database connections check box and fill in your TLS certificates and key.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#on-the-command-line","title":"On the command line","text":"<p>Add the database server as a service using one of these example commands. If successful, PMM Client will print <code>MySQL Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>-custom-labels</code> options to set tags for the service to help identify them.</p> Examples"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#tls-connection","title":"TLS connection","text":"<pre><code>pmm-admin add mysql --environment=test --custom-labels='source=slowlog'  --username=root --password=password --query-source=slowlog MySQLSlowLog localhost:3306\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#install-pmm-client-as-a-remote-instance","title":"Install PMM Client as a remote instance","text":"<ol> <li> <p>Select  ** PMM Configuration &gt; PMM Inventory &gt;  Add Service**.</p> </li> <li> <p>Choose MySQL &gt; Add a remote instance.</p> </li> <li> <p>Complete the required fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#for-mysql-instances-using-tls","title":"For MySQL instances using TLS","text":"<p>If your MySQL instance is configured to use TLS: </p> <ol> <li>Click on the Use TLS for database connections check box.</li> <li>Fill in your TLS certificates and key.</li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#check-the-service","title":"Check the service","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#pmm-user-interface","title":"PMM user interface","text":"<p>To check the service with the UI:</p> <ol> <li>Select PMM Configuration &gt; PMM Inventory.</li> <li>In the Services tab, verify the Service name, Addresses, and any other relevant information in the form.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#command-line","title":"Command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services --service-type=mysql\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#check-data","title":"Check data","text":"<p>To check the data:</p> <ol> <li>Open the MySQL Instance Summary dashboard.</li> <li>Set the Service Name to the newly-added service.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#percona-server-for-mysql-mariadb","title":"Percona Server for MySQL, MariaDB","text":"<p>If query response time plugin was installed, check for data in the MySQL Query Response Time Details dashboard or select a query in PMM Query Analytics to see the Query time distribution bar.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#percona-xtradb-cluster","title":"Percona XtraDB Cluster","text":"<p>Open the PXC/Galera Cluster Summary dashboard.</p> See also <ul> <li>Percona Server for MySQL \u2013 Slow Query Log Extended</li> <li>Percona Server for MySQL \u2013 User Statistics</li> <li>MariaDB \u2013 Slow Query Log Overview</li> <li>MariaDB \u2013 Slow Query Log Extended Statistics</li> <li>MariaDB \u2013 User Statistics</li> <li>Percona Blog \u2013 PERFORMANCE_SCHEMA vs Slow Query Log</li> <li>Percona Blog \u2013 MySQL\u2019s INNODB_METRICS table</li> <li>Percona Blog \u2013 Rotating MySQL Slow Logs Safely</li> <li>Percona Blog \u2013 Impact of logging on MySQL\u2019s performance</li> <li>Percona Blog \u2013 Running Custom MySQL Queries in Percona Monitoring and Management</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html","title":"Connect PostgreSQL instance","text":"<p>How to set up PMM to monitor a PostgreSQL or Percona Distribution for PostgreSQL database instance.</p> Summary <ul> <li>Create PMM account and set permissions.</li> <li>Choose, install and configure an extension:<ul> <li><code>pg_stat_statements</code>, or,</li> <li><code>pg_stat_monitor</code>.</li> </ul> </li> <li>Add service.</li> <li>Check the service.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address accessible from the client node.</li> <li>PMM Client is installed and the nodes are registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> <li>You have superuser access to any database servers that you want to monitor.</li> </ul> <p>(PMM follows PostgreSQL\u2019s end-of-life policy. For specific details on supported platforms and versions, see Percona\u2019s Software Platform Lifecycle page.)</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>We recommend creating a PMM database account that can connect to the <code>postgres</code> database with the <code>SUPERUSER</code> role.</p> <ol> <li> <p>Create a user. This example uses <code>pmm</code>. (Replace <code>******</code> with a strong password of your choice.)</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '******';\n</code></pre> <p>If your database runs on Amazon RDS / Aurora PostgreSQL, The SUPERUSER cannot be assigned. So we have to create the user first and then grant the <code>rds_superuser</code> role to it.</p> <p><pre><code>CREATE USER pmm WITH ENCRYPTED PASSWORD '******';\nGRANT rds_superuser TO pmm;\n</code></pre> Optionally, you can also set up a connection limit (only if the user is not a SUPERUSER):</p> <pre><code>ALTER USER pmm CONNECTION LIMIT 10;\n</code></pre> </li> <li> <p>PMM must be able to log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> <p>(Ignore the second line. It is a comment to show field alignment.)</p> </li> <li> <p>Reload the configuration:</p> <pre><code>su - postgres\npsql -c \"select pg_reload_conf()\"\n</code></pre> </li> <li> <p>Check local login.</p> <pre><code>psql postgres pmm -c \"\\conninfo\"\n</code></pre> </li> <li> <p>Enter the password for the <code>pmm</code> user when prompted.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#choose-and-configure-an-extension","title":"Choose and configure an extension","text":"<p>Decide which database extension to use, and configure your database server for it. The choices are:</p> <ol> <li> <p><code>pg_stat_statements</code>, the original extension created by PostgreSQL, part of the <code>postgresql-contrib</code> package available on Linux.</p> </li> <li> <p><code>pg_stat_monitor</code> is a new extension created by Percona. <code>pg_stat_monitor</code> has all the features of <code>pg_stat_statements</code> but adds bucket-based data aggregation, provides more accurate data, and can expose Query Examples.</p> </li> </ol> <p>Here are the benefits and drawbacks of each.</p>  Benefits  Drawbacks <code>pg_stat_statements</code> 1. Part of official <code>postgresql-contrib</code> package. 1. No aggregated statistics or histograms.2. No Query Examples. <code>pg_stat_monitor</code> 1. Builds on <code>pg_stat_monitor</code> features.2. Bucket-based aggregation. <p>For a more detailed comparison of extensions, follow pg_stat monitor User Guide</p> <p>Bucket-based data aggregation</p> <p><code>pg_stat_monitor</code> collects statistics and aggregates data in a data collection unit called a bucket. These are linked together to form a bucket chain.</p> <p>You can specify:</p> <ul> <li>the number of buckets (the length of the chain);</li> <li>how much space is available for all buckets;</li> <li>a time limit for each bucket\u2019s data collection (the bucket expiry).</li> </ul> <p>When a bucket\u2019s expiration time is reached, accumulated statistics are reset and data is stored in the next available bucket in the chain.</p> <p>When all buckets in the chain have been used, the first bucket is reused and its contents are overwritten.</p> <p>If a bucket fills before its expiration time is reached, data is discarded.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#pg_stat_statements","title":"<code>pg_stat_statements</code>","text":""},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#install","title":"Install","text":"<ul> <li> <p>Debian/Ubuntu</p> <p>Root permissions</p> <pre><code>apt install -y postgresql-contrib\n</code></pre> </li> <li> <p>Red Hat/CentOS</p> <p>Root permissions</p> <pre><code>yum install -y postgresql-contrib\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#configure","title":"Configure","text":"<p>To configure the extension:</p> <ol> <li> <p>Add these lines to your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_statements'\ntrack_activity_query_size = 2048 # Increase tracked query string size\npg_stat_statements.track = all   # Track all statements including nested\ntrack_io_timing = on             # Capture read/write stats\n</code></pre> </li> <li> <p>Restart the database server. After the restart, the extension starts capturing statistics from every database.</p> </li> <li> <p>Install the extension. </p> <pre><code>psql postgres postgres -c \"CREATE EXTENSION pg_stat_statements SCHEMA public\"\n</code></pre> <p>This command creates the view where you can access the collected statistics.</p> </li> </ol> <p>We recommend that you create the extension for the <code>postgres</code> database. In this case, you receive access to the statistics collected from every database.    </p> <p>You can now add the service.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#pg_stat_monitor","title":"<code>pg_stat_monitor</code>","text":"<p><code>pg_stat_monitor</code> has been tested with:</p> <ul> <li>PostgreSQL versions 11, 12, 13, 14, 15.</li> <li>Percona Distribution for PostgreSQL versions 11, 12, 13, 14, 15.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#install_1","title":"Install","text":"<p>To install the extension:</p> <ul> <li> <p>If you use Percona Distribution for PostgreSQL, you can install the extension with your Linux package manager. See Installing Percona Distribution for PostgreSQL.</p> </li> <li> <p>If you use PostgreSQL you can install by downloading and compiling the source code. See Installing <code>pg_stat_monitor</code>.</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#configure_1","title":"Configure","text":"<p>To configure the extension:</p> <ol> <li> <p>Set or change the value for <code>shared_preload_library</code>.</p> <p>In your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> <p>Caution</p> <p>If you use both <code>pg_stat_statements</code> and <code>pg_stat_monitor</code>, set <code>pg_stat_monitor</code> after <code>pg_stat_statements</code>:</p> <pre><code>shared_preload_libraries = 'pg_stat_statements, pg_stat_monitor'\n</code></pre> </li> <li> <p>Set configuration values.</p> <p>In your <code>postgresql.conf</code> file: <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre></p> <p>Caution</p> <p>It is important to set maximal length of query to 2048 characters or more for PMM to work properly.</p> <p>You can get a list of other available settings with <code>SELECT * FROM pg_stat_monitor_settings;</code>.</p> <p>Other important parameters are: <pre><code>pg_stat_monitor.pgsm_normalized_query\n</code></pre> and <pre><code>pg_stat_monitor.pgsm_enable_query_plan\n</code></pre></p> <p>If the value for <code>pg_stat_monitor.pgsm_normalized_query</code> is set to 1, the actual query values are replaced by placeholders. If the value is 0, the examples are given in QAN. Examples can be found in QAN details tab example.</p> <p>If <code>pg_stat_monitor.pgsm_enable_query_plan</code> is enabled, the query plans are captured and will be available in the <code>Plan</code> tab on the Query Analytics dashboard.</p> <p>See <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Start or restart your PostgreSQL instance. The extension starts capturing statistics from every database.</p> </li> <li> <p>In a <code>psql</code> session:</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> <p>This command creates the view where you can access the collected statistics.</p> <p>We recommend that you create the extension for the <code>postgres</code> database. In this case, you receive the access to the statistics, collected from every database.</p> </li> <li> <p>Check the version.</p> <pre><code>SELECT pg_stat_monitor_version();\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#add-service","title":"Add service","text":"<p>When you have configured your database server, you can add a PostgreSQL service with the user interface or on the command line.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#with-the-user-interface","title":"With the user interface","text":"<p>To add the service With the user interface:</p> <ol> <li> <p>Go to  PMM Configuration  &gt; Add Service &gt; PostgreSQL.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p> <p>If your PostgreSQL instance is configured to use TLS, click on the Use TLS for database connections check box and fill in your TLS certificates and key.</p> <p></p> <p>Note</p> <p>For TLS connection to work SSL needs to be configured in your PostgreSQL instance. Make sure SSL is enabled in the server configuration file <code>postgresql.conf</code>, and that hosts are allowed to connect in the client authentication configuration file <code>pg_hba.conf</code>. (See PostgreSQL documentation on Secure TCP/IP Connections with SSL.)</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#auto-discovery-limit","title":"Auto-discovery limit","text":"<p>Limit for Auto-discovery in PostgreSQL is a feature that dynamically discovers all databases in your PostgreSQL instance. </p> <p>Limiting Auto-discovery reduces connections and prevents high CPU and RAM usage caused by multiple databases.</p> <p>Caution</p> <p>Limiting auto-discovery may result in fewer metrics being captured from the non-primary databases.  Ensure that you set the limit appropriately:</p> <ul> <li>Setting a high limit may impact performance adversely.</li> <li>Setting a low limit might result in some missing metrics due to Auto-discovery being disabled.</li> </ul> <p>By default, Auto-discovery is enabled (server defined with a limit 10). </p> <p></p> <p>When you select Disabled, the Auto-discovery limit will be set to <code>-1</code>.</p> <p></p> <p>For a custom value, select Custom and enter or choose your preferred value from the Auto-discovery limit field.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#on-the-command-line","title":"On the command line","text":"<p>Add the database server as a service using one of these example commands. If successful, PMM Client will print <code>PostgreSQL Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>-custom-labels</code> options to set tags for the service to help identify them.</p> Examples <p>Add instance with default node (<code>&lt;node&gt;-postgresql</code>).</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls\n</code></pre> <ul> <li><code>&lt;user name&gt;</code>: The PostgreSQL PMM user</li> <li><code>&lt;password&gt;</code>: The PostgreSQL user credentials.</li> </ul> <p>The service name will be automatically chosen.</p> <p>Add instance with specified service name.</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls \\\n--service-name=SERVICE-NAME\n</code></pre> <p>Add instance to connect with a UNIX socket.</p> <pre><code>pmm-admin add postgresql --socket=/var/run/postgresql\n</code></pre> <p>where: - <code>SOCKET</code>: directory containing the socket</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#connecting-via-ssltls","title":"Connecting via SSL/TLS","text":"<pre><code>pmm-admin add postgresql --tls \\\n--tls-cert-file=PATHTOCERT \\\n--tls-ca-file=PATHTOCACERT \\\n--tls-key-file=PATHTOKEY \\\n--host=HOST \\\n--port=PORT \\\n--username=USER \\\n--service-name=SERVICE-NAME\n</code></pre> <p>where:</p> <ul> <li><code>PATHTOCERT</code>: Path to client certificate file.</li> <li><code>PATHTOCACERT</code>: Path to certificate authority file.</li> <li><code>PATHTOKEY</code>: Path to client key file.</li> <li><code>HOST</code>: Instance hostname or IP.</li> <li><code>PORT</code>: PostgreSQL service port number.</li> <li><code>USER</code>: Database user allowed to connect via TLS. Should match the common name (CN) used in the client certificate.</li> <li><code>SERVICE</code>: Name to give to the service within PMM.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#automatic-discovery-limit-via-cli","title":"Automatic discovery limit via CLI","text":"<p>The <code>pmm-admin</code> flag limits Auto-discovery:</p> <p><code>--auto-discovery-limit=XXX</code></p> <ul> <li>If number of databases &gt; Auto-discovery limit, then auto discovery is OFF</li> <li>If number of databases &lt;= Auto-discovery limit, then auto discovery is ON</li> <li>If the Auto-discovery limit is not defined, it takes the default value, which is 0 (server defined with limit 10), and Auto-discovery is ON(if you do not have more than 10 databases).</li> <li>If Auto-discovery limit &lt; 0 then auto discovery is OFF.</li> </ul> Example <p>If you set the limit to 10 and your PostgreSQL instance has 11 databases, automatic discovery will be disabled.</p> <p><code>pmm-admin add postgresql --username=\"pmm-agent\" --password=\"pmm-agent-password\" --auto-discovery-limit=10</code></p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#check-the-service","title":"Check the service","text":""},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#check-service-pmm-user-interface","title":"Check service - PMM user interface","text":"<p>To check the service from the PMM UI:</p> <ol> <li>Select  Configuration \u2192  Inventory.</li> <li>In the Services tab, verify the Service name, Address and any other relevant details.</li> <li>In the Options column, expand the Details section and check that the Agents are using the desired data source.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#check-service-command-line","title":"Check service - Command line","text":"<p>Look for your service in the output of this command.</p> <pre><code>pmm-admin inventory list services\n</code></pre> <p>If using Docker, use <code>docker exec pmm-client pmm-admin inventory list services</code></p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#check-data","title":"Check data","text":"<p>To check the data:</p> <ol> <li> <p>Open the PostgreSQL Instance Summary dashboard.</p> </li> <li> <p>Set the Service Name to the newly-added service.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#running-custom-queries","title":"Running custom queries","text":"<p>The PostgreSQL exporter can run custom queries to add new metrics not provided by default. Those custom queries must be defined in the <code>/usr/local/percona/pmm/collectors/custom-queries/postgresql</code> in the same host where the exporter is running. There are 3 directories inside it:     - high-resolution/   - every 5 seconds     - medium-resolution/ - every 10 seconds     - low-resolution/ - every 60 seconds</p> <p>Depending on the desired resolution for your custom queries, you can place a file with the queries definition. The file is a yaml where each query can have these fields:</p> <pre><code>query_name:\n   query: the query definition\n   master: boolean to specify if the query should be executed only in the master\n   metrics:\n     - metric name:\n         usage: GAUGE, LABEL, COUNTER, MAPPEDMETRIC or DURATION\n         description: a human readable description\n</code></pre> Example <pre><code>pg_postmaster_uptime:\nquery: \"select extract(epoch from current_timestamp - pg_postmaster_start_time()) as seconds\"\nmaster: true\nmetrics:\n    - seconds:\n        usage: \"GAUGE\"\n        description: \"Service uptime\"\n</code></pre> <p>Check the see also section for a more detailed description on MySQL custom queries with more examples about how to use custom queries in dashboards.</p> <p>See also</p> <ul> <li><code>pmm-admin</code> man page for <code>pmm-admin add postgresql</code></li> <li>Configuring Percona Repositories with percona-release</li> <li>Percona Blog \u2013 Running Custom MySQL Queries in Percona Monitoring and Management</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html","title":"Connect ProxySQL instance","text":"<p>Use the <code>proxysql</code> alias to enable ProxySQL performance metrics monitoring.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <p>where <code>username</code> and <code>password</code> are credentials for the administration interface of the monitored ProxySQL instance.  You should configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL</p> <p>Additionally, two positional arguments can be appended to the command line flags: a service name to be used by PMM, and a service address. If not specified, they are substituted automatically as <code>&lt;node&gt;-proxysql</code> and <code>127.0.0.1:6032</code>.</p> <p>The output of this command may look as follows:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <pre><code>ProxySQL Service added.\nService ID  : f69df379-6584-4db5-a896-f35ae8c97573\nService name: ubuntu-proxysql\n</code></pre> <p>Beside positional arguments shown above you can specify service name and service address with the following flags: <code>--service-name</code>, and <code>--host</code> (the hostname or IP address of the service) and <code>--port</code> (the port number of the service), or <code>--socket</code> (the UNIX socket path). If both flag and positional argument are present, flag gains higher priority. Here is the previous example modified to use these flags for both host/port or socket connections:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=pmm --service-name=my-new-proxysql --host=127.0.0.1 --port=6032\npmm-admin add proxysql --username=pmm --password=pmm --service-name=my-new-proxysql --socket=/tmp/proxysql_admin.sock\n</code></pre> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html","title":"Connect a remote instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#recommended-settings","title":"Recommended settings","text":"<p>When monitoring remote instances including RDS and Google instances, network latency might affect the scrape process and throw timeout errors. For this reason, it is recommended to lower the metrics resolution.</p> <p>The scrape timeout in PMM is dynamically set based on the resolution of data collection. The following rules determine the scrape timeout: Scrape timeouts are managed based on resolution settings:</p> <ul> <li>For resolutions &lt;= 2 seconds, scrape timeout is 1 second.</li> <li>For resolutions &lt;= 10 seconds, timeout is set to resolution minus 1 second. For example, for 10 second resolution, timeout will be set at 9 seconds.</li> <li>For lower resolutions (values &gt; 10 seconds), the scrape timeout is set to 90% of the resolution time. For example, for 60 second resolution, the scrape timeout will be set to 54 seconds.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#how-to-check-for-scrape-timeouts","title":"How to check for scrape timeouts","text":"<p>Sometimes it is hard to check if you are using the correct values to scrape or if there some other reason why there is no data in a dashboard even when the instance has been added correctly and the agent is running.</p> <p>One additional step you can do is to check for scrape target statuses. Browse to <code>http://&lt;your-pmm-server-address&gt;/prometheus/targets</code> and then click on the Unhealthy button.</p> <p></p> <p>The page will show only agents having issues while scrapping and the scrape result including the error messages.</p> <p></p> <p>In the example here, there is a message that says: context deadline exceeded and the scrape duration column says the scrape took 10 seconds; this means that the exporter didn\u2019t respond in the 10 seconds the scrape process was allowed to run due to the configured metric resolutions and their timeouts.</p> <p>In this case, we can lower the metric resolutions increasing these values as shown in the image below.</p> <p></p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-client/connect-database/remove-services/index.html","title":"Remove services from monitoring","text":"<p>You must specify the service type and service name to remove services from monitoring.</p> <pre><code>pmm-admin remove &lt;service-type&gt; &lt;service-name&gt;\n</code></pre> <code>service-type</code> One of <code>mysql</code>, <code>mongodb</code>, <code>postgresql</code>, <code>proxysql</code>, <code>haproxy</code>, <code>external</code>. <p>See also</p> <ul> <li>Percona release</li> <li>PMM Client architecture</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/remove-services/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/index.html","title":"About PMM Server installation","text":"<p>Before installing PMM Server, read the Prerequisites to install PMM Server.</p> <p>Install and run at least one PMM Server using one of the following ways:</p> <ul> <li>Docker</li> <li>Podman</li> <li>Helm</li> <li>Virtual appliance</li> <li>Amazon AWS</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-server/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html","title":"Prerequisites","text":"<ol> <li> <p>Check your system requirements.</p> </li> <li> <p>Configure your network.</p> </li> <li> <p>Authenticate using Service Accounts.</p> <p>While adding clients to the PMM Server, you use the <code>admin</code> user. However, if you change the password for the admin user from the PMM UI, then the clients will not be able to access PMM. Also, due to multiple unsuccessful login attempts Grafana will lock out the <code>admin</code> user. The solution is to use Service Accounts for authentication. You can use Service Accounts as a replacement for basic authentication and API keys.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/aws.html","title":"Install PMM Server from AWS Marketplace","text":"<p>To install Percona Monitoring and Management (PMM) Server from AWS Marketplace:</p> <ol> <li> <p>Go to AWS Marketplace and search for Percona Monitoring and Management Server or access the PMM Server listing directly.</p> </li> <li> <p>Click Continue to Subscribe on the PMM Server listing page, review the terms and conditions, then click Continue to Configuration.</p> </li> <li> <p>Select the latest version (recommended), choose the AWS region where you want to deploy PMM, then click Continue to Launch.</p> </li> <li>Choose Launch from Website to configure and launch directly from the AWS Marketplace or Launch through EC2 if you prefer launching via the EC2 Management Console for more customization.</li> <li>In the EC2 Instance Type field, select an appropriate instance type based on your monitoring needs and anticipated load. </li> <li>In the VPC Settings field, choose an existing VPC or create a new one to host your PMM Server.</li> <li>In the Subnet Settings field, select an existing subnet or create a new one within your VPC.</li> <li>In the Security Group Settings field, choose an existing security group or create a new one based on the default settings provided by the seller.</li> <li>In the Key Pair Settings field, select an existing key pair for SSH access, or create a new one if necessary.</li> <li>Click Launch to deploy the PMM Server.</li> <li>Once the instance is launched, it will appear in the EC2 console.</li> </ol> <p>Make sure to assign a meaningful name to the instance to help distinguish it from others in your environment.</p>"},{"location":"install-pmm/install-pmm-server/aws/aws.html#security-consideration","title":"Security consideration","text":"<p>Ensure that your security group allows inbound traffic on ports 22 (SSH) and 443 (HTTPS).</p>"},{"location":"install-pmm/install-pmm-server/aws/aws.html#service-costs","title":"Service costs","text":"<p>While PMM Server itself is provided at no cost, be aware that you will incur AWS infrastructure costs based on the EC2 instance type, storage, and data transfer.</p>"},{"location":"install-pmm/install-pmm-server/aws/aws.html#disk-space-consumption","title":"Disk space consumption","text":"<p>The disk space required by PMM Server depends on the number of monitored hosts and the retention period for the data.</p> <p>As a reference, the PMM Demo site consumes approximately 230 MB per host per day, which totals around 6.9 GB per host over a 30-day retention period. Tip: You can estimate your disk space needs based on the number of hosts and the desired retention period.</p> <p>For more information, see our blog post How much disk space should I allocate for Percona Monitoring and Management.</p> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/aws.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/back_pmm_server.html","title":"Backup PMM Server","text":"<p>All data are stored in the <code>/srv</code> partition, so it\u2019s enough to back the PMM data volume. You can create a point-in-time snapshot of the volume and use it for data backup.</p> <p>The procedure of creating a snapshot is described in the Amazon documentation: Create Amazon EBS snapshots</p> <p></p> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/back_pmm_server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/limit_access.html","title":"Limit Access to an AWS instance","text":"<p>In the Security Group section, which acts like a firewall, you may use the preselected option <code>Create new based on seller settings</code> to create a security group with recommended settings. In the Key Pair select an already set up EC2 key pair to limit access to your instance.</p> <p></p> <p>Important</p> <p>The security group should allow communication via the the following ports: 22, 80, and 443. PMM should also be able to access port 3306 on the RDS that uses the instance.</p> <p></p> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/limit_access.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/remove_pmm_server.html","title":"Remove PMM Server from AWS","text":"<p>To remove PMM Server:</p> <ol> <li> <p>Find the instance in the EC2 Console.</p> <p></p> </li> <li> <p>Select Instance state menu and Terminate instance.</p> <p></p> </li> <li> <p>Confirm termination operation.</p> <p>.</p> </li> </ol> <p>See also</p> <ul> <li>Improving Percona Monitoring and Management EC2 Instance Resilience Using CloudWatch Alarm Actions </li> <li>Simplify the Use of ENV Variables in Percona Monitoring and Management AMI</li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/remove_pmm_server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/restore_pmm_server.html","title":"Restore PMM Server from a backup","text":"<p>To restore your PMM Server from a backup:</p> <ol> <li> <p>Create a new volume by using the latest snapshot of the PMM data volume.</p> <p></p> </li> <li> <p>Stop the PMM Server instance.</p> </li> <li> <p>Detach the current PMM data volume.</p> <p></p> </li> <li> <p>Attach the new volume.</p> <p></p> </li> <li> <p>Start the PMM Server instance.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/restore_pmm_server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/run.html","title":"Launch PMM Server on AWS","text":"<p>After installing PMM Server from AWS Marketplace: </p> <ol> <li>Wait until the AWS console reports that the instance is running. </li> <li> <p>Select your instance and open its IP address in a web browser. You can find the IP address in the IPv4 Public IP column or at the top of the Properties panel under the Public IP field:</p> <p> 3. Open the IP address in a web browser and log into PMM using the default credentials:  - Username: <code>admin</code>  - Password: <code>your instance ID</code>  4. Change the default credentials then use the new ones on the PMM Server home page:</p> </li> </ol> <p></p> <p>These credentials not only manage access to the PMM web interface but also facilitate authentication between the PMM Server and PMM Clients. You will need to reuse these credentials when configuring PMM Clients on other hosts.</p> <p>For SSH access instructions, see Connecting to Your Linux Instance Using SSH. Replace the user name <code>ec2-user</code> with <code>admin</code>. You can also add SSH keys later through the PMM Configuration &gt; Settings &gt; SSH Key page. </p>"},{"location":"install-pmm/install-pmm-server/aws/run.html#configure-pmm-server-ip-settings","title":"Configure PMM Server IP Settings","text":""},{"location":"install-pmm/install-pmm-server/aws/run.html#configure-pmm-server-to-use-a-private-ip-only","title":"Configure PMM Server to use a private IP only","text":"<p>By default, your EC2 instance will have a private IP for internal VPC network access.  To use only the private IP:</p> During EC2 instance creationFor an existing instance <p>To use only the private IP for your EC2 instance during EC2 instance creation:</p> <ol> <li>In the Network Settings section, uncheck Auto-assign public IP.</li> <li>Do not assign an Elastic IP to the instance.</li> </ol> <p>To use only the private IP for an existing instance EC instance:</p> <ol> <li>If a public IP is assigned, remove it by disassociating it in the EC2 console.</li> <li>If an Elastic IP is assigned, disassociate it from the instance.</li> </ol>"},{"location":"install-pmm/install-pmm-server/aws/run.html#access-pmm-server-using-only-a-private-ip","title":"Access PMM Server using only a private IP","text":"<p>To access your PMM Server using only a private IP:</p> <ol> <li>Ensure you\u2019re connected to your VPC.</li> <li>Use the private IP address to access the PMM Server dashboard.</li> </ol>"},{"location":"install-pmm/install-pmm-server/aws/run.html#configure-pmm-server-to-use-an-elastic-ip-optional","title":"Configure PMM Server to use an Elastic IP (Optional)","text":"<p>For a static, public-facing IP address:</p> <ol> <li>Allocate an Elastic IP address in the EC2 console.</li> <li>Associate the Elastic IP address with your EC2 instance\u2019s Network interface ID.</li> </ol> <p>Associating a new Elastic IP to an instance with an existing Elastic IP will disassociate the old one, but it will remain allocated to your account.</p> <p>For detailed information on EC2 instance IP addressing, see the AWS documentation on using instance addressing.</p>"},{"location":"install-pmm/install-pmm-server/aws/run.html#resize-the-ebs-volume","title":"Resize the EBS volume","text":"<p>To increase available disk space:</p> <ol> <li>Your AWS instance comes with a predefined size which can become a limitation. To make more disk space available to your instance, increase the size of the EBS volume as needed. For instructions, see Modifying the Size, IOPS, or Type of an EBS Volume on Linux.</li> <li>After updating the EBS volume, PMM Server will auto-detect changes within approximately 5 minutes and reconfigure itself.4</li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/run.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/aws/settings.html","title":"Applying settings","text":"<p>Scroll up to the top of the page to view your settings. Then, click the Launch with 1 click button to continue and adjust your settings in the EC2 console.</p> <p>Your instance settings are summarized in a special area. Click the Launch with 1 click button to continue.</p> <p></p> <p>Note</p> <p>The Launch with 1 click button may alternatively be titled as Accept Software Terms &amp; Launch with 1-Click.</p>"},{"location":"install-pmm/install-pmm-server/aws/settings.html#adjusting-instance-settings-in-the-ec2-console","title":"Adjusting instance settings in the EC2 Console","text":"<p>Your clicking the Launch with 1 click button, deploys your instance. To continue setting up your instance, run the EC2 console. It is available as a link at the top of the page that opens after you click the Launch with 1 click button.</p> <p>Your instance appears in the EC2 console in a table that lists all instances available to you. When a new instance is only created, it has no name. Make sure that you give it a name to distinguish it from other instances managed via the EC2 console.</p> <p></p> <p></p>"},{"location":"install-pmm/install-pmm-server/aws/settings.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html","title":"Install PMM Server with Docker container","text":"<p>This section provides instructions for running PMM Server with Docker based on the PMM Docker image.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html#running-pmm-server-with-watchtower","title":"Running PMM Server with Watchtower","text":"<p>To enable PMM Server upgrades via the Upgrade page and the Upgrade Now button on the Home dashboard, you must configure Watchtower during the PMM Server installation. Watchtower is a container monitoring tool that helps update Docker containers to their latest version when triggered.</p> <p>The Easy-install script script includes Watchtower commands, allowing for a one-step setup of PMM alongside Watchtower.</p> <p>You can also install PMM 3 manually, following the instructions below.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html#installing-pmm-server-manually","title":"Installing PMM Server manually","text":"<p>Before starting the installation, review the installation prerequisites below and choose a method to run PMM Server with Docker based on your preferred data storage option:</p> <ul> <li>Running Docker with Data container</li> <li>Running Docker with host directory</li> <li>Running Docker with volume</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html#manual-installation-prerequisites","title":"Manual installation prerequisites","text":"<ul> <li>Install Docker version 17.03 or higher.</li> <li>Ensure your CPU (and any virtualization layer you may be using) supports <code>x86-64-v2</code>.</li> <li> <p>Install Watchtower to automatically update your containers with the following considerations:</p> <ul> <li>Ensure Watchtower is only accessible from within the Docker network or local host to prevent unauthorized access and enhance container security.</li> <li>Configure network settings to expose only the PMM Server container to the external network, keeping Watchtower isolated within the Docker network.</li> <li>Grant Watchtower access to the Docker socket to monitor and manage containers effectively, ensuring proper security measures are in place to protect the Docker socket.</li> <li>Verify that both Watchtower and PMM Server are on the same network, or ensure PMM Server can connect to Watchtower for communication. This network setup is essential for PMM Server to initiate updates through Watchtower.</li> </ul> </li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html#run-docker-container","title":"Run Docker container","text":"Summary <ul> <li>Pull the Docker image.</li> <li>Copy it to create a persistent data container.</li> <li>Run the image.</li> <li>Open the PMM UI in a browser.</li> </ul> Key points <ul> <li> <p>To disable the Home Dashboard PMM Upgrade panel you can either add <code>-e DISABLE_UPDATES=true</code> to the <code>docker run</code> command (for the life of the container) or navigate to PMM \u2192 PMM Settings \u2192 Advanced Settings and disable \u201cCheck for Updates\u201d (can be turned back on by any admin in the UI).</p> </li> <li> <p>Eliminate browser certificate warnings by configuring a trusted certificate.</p> </li> <li> <p>You can optionally enable an (insecure) HTTP connection by adding <code>--publish 80:80</code> to the <code>docker run</code> command. However, running PMM insecure is not recommended. You should also note that PMM Client requires TLS to communicate with the server, only working on a secure port.</p> </li> </ul> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/backup_container.html","title":"Backup container","text":"Summary <ul> <li>Stop and rename the <code>pmm-server</code> container.</li> <li>Take a local copy of the <code>pmm-data</code> container\u2019s <code>/srv</code> directory.</li> </ul> <p>Important</p> <p>Grafana plugins have been moved to the data volume <code>/srv</code> since the 2.23.0 version. So if you are upgrading PMM from any version before 2.23.0 and have installed additional plugins then plugins should be installed again after the upgrade.</p> <p>To check used Grafana plugins:</p> <pre><code>docker exec -it pmm-server ls /var/lib/grafana/plugins\n</code></pre> <p>To backup container:</p> <ol> <li> <p>Stop the container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Move the image:</p> <pre><code>docker rename pmm-server pmm-server-backup\n</code></pre> </li> <li> <p>Create a subdirectory (e.g., <code>pmm-data-backup</code>) and move to it:</p> <pre><code>mkdir pmm-data-backup &amp;&amp; cd pmm-data-backup\n</code></pre> </li> <li> <p>Back up the data:</p> <pre><code>docker cp pmm-data:/srv .\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/backup_container.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/easy-install.html","title":"Easy install","text":""},{"location":"install-pmm/install-pmm-server/baremetal/docker/easy-install.html#run-docker-via-the-easy-install-script","title":"Run Docker via the Easy-install script","text":"<p>Caution</p> <p>You can download and check <code>get-pmm.sh</code> before running it from our github:</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/easy-install.html#linux-or-macos","title":"Linux or macOS","text":"<p>Download and install PMM Server using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>export PMM_REPO=perconalab/pmm-server PMM_TAG=3.0.0-beta\ncurl -fsSL https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash\n</code></pre> <pre><code>export PMM_REPO=perconalab/pmm-server PMM_TAG=3.0.0-beta\nwget -O - https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash\n</code></pre> What does the script do? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not already installed on your system.</li> <li>Stops and renames any currently running PMM Server Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old pmm-server container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Server Docker image.</li> <li> <p>Can run in Interactive mode to change the default settings:</p> <pre><code>curl -fsSLO https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh (or wget https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh)\nchmod +x pmm\n./pmm --interactive\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/easy-install.html#next-steps","title":"Next steps","text":"<p>Start by installing PMM client:</p> <p>Install PMM client </p> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/easy-install.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html","title":"Environment variables in PMM","text":"<p>Configure PMM Server by setting Docker container environment variables using the <code>-e var=value</code> syntax:</p> <pre><code>docker run -e PMM_DATA_RETENTION=720h -e PMM_DEBUG=true perconalab/pmm-server:3.0.0-beta\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#core-configuration-variables","title":"Core configuration variables","text":""},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#performance-storage","title":"Performance &amp; storage","text":"Variable Default Description Example <code>PMM_DATA_RETENTION</code> <code>30d</code> Duration to retain metrics data. Must be in multiples of 24h. <code>720h</code> (30 days) <code>PMM_METRICS_RESOLUTION</code> <code>1s</code> Base metrics collection interval <code>5s</code> <code>PMM_METRICS_RESOLUTION_HR</code> <code>5s</code> High-resolution metrics interval <code>10s</code> <code>PMM_METRICS_RESOLUTION_MR</code> <code>10s</code> Medium-resolution metrics interval <code>30s</code> <code>PMM_METRICS_RESOLUTION_LR</code> <code>60s</code> Low-resolution metrics interval <code>300s</code>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#feature-flags","title":"Feature flags","text":"Variable Default Effect when enabled <code>PMM_ENABLE_UPDATES</code> <code>true</code> Allows version checks and UI updates <code>PMM_ENABLE_TELEMETRY</code> <code>true</code> Enables usage data collection <code>PMM_ENABLE_ALERTING</code> <code>true</code> Enables Percona Alerting system <code>PMM_ENABLE_BACKUP_MANAGEMENT</code> <code>true</code> Enables backup features <code>PMM_ENABLE_AZURE_DISCOVER</code> <code>false</code> Enables Azure database discovery"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#debugging","title":"Debugging","text":"Variable Default Purpose <code>PMM_DEBUG</code> <code>false</code> Enables verbose logging <code>PMM_TRACE</code> <code>false</code> Enables detailed trace logging"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#advanced-configuration","title":"Advanced configuration","text":""},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#networking","title":"Networking","text":"Variable Description <code>PMM_PUBLIC_ADDRESS</code> External DNS/IP for PMM server <code>PMM_INTERFACE_TO_BIND</code> Network interface binding"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#database-connections","title":"Database connections","text":"Variable Purpose <code>PMM_CLICKHOUSE_*</code> ClickHouse connection settings <code>PMM_POSTGRES_*</code> PostgreSQL connection settings"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#supported-external-variables","title":"Supported external variables","text":"<ul> <li>Grafana: All <code>GF_*</code> variables</li> <li>VictoriaMetrics: All <code>VM_*</code> variables</li> <li>Kubernetes: All <code>KUBERNETES_*</code> variables</li> <li>System: Standard variables like <code>HOME</code>, <code>PATH</code>, etc.</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#variables-for-migrating-from-pmm-v2-to-pmm-v3","title":"Variables for migrating from PMM v2 to PMM v3","text":"<p>When migrating from PMM v2 to PMM v3, you\u2019ll need to update your environment variables to match the new naming convention. This is because PMM v3 introduces several important changes to improve consistency and clarity:</p> <ul> <li>environment variables now use <code>PMM_</code> prefix</li> <li>some boolean flags reversed (e.g., <code>DISABLE_</code> \u2192 <code>ENABLE_</code>)</li> <li>removed deprecated variables</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#examples","title":"Examples","text":"<pre><code># PMM v2\n-e DISABLE_UPDATES=true -e DATA_RETENTION=720h\n\n# PMM v3 equivalent\n-e PMM_ENABLE_UPDATES=false -e PMM_DATA_RETENTION=720h\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#migration-reference-table","title":"Migration reference table","text":"Click to expand migration reference table"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#configuration-variables","title":"Configuration variables","text":"PMM 2 PMM 3 Comments <code>DATA_RETENTION</code> <code>PMM_DATA_RETENTION</code> <code>DISABLE_ALERTING</code> <code>PMM_ENABLE_ALERTING</code> <code>DISABLE_UPDATES</code> <code>PMM_ENABLE_UPDATES</code> <code>DISABLE_TELEMETRY</code> <code>PMM_ENABLE_TELEMETRY</code> <code>DISABLE_BACKUP_MANAGEMENT</code> <code>PMM_ENABLE_BACKUP_MANAGEMENT</code> Note the reverted boolean <code>ENABLE_AZUREDISCOVER</code> <code>PMM_ENABLE_AZURE_DISCOVER</code> <code>ENABLE_RBAC</code> <code>PMM_ENABLE_ACCESS_CONTROL</code> <code>LESS_LOG_NOISE</code> Removed in PMM v3"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#metrics-configuration","title":"Metrics configuration","text":"PMM 2 PMM 3 <code>METRICS_RESOLUTION</code> <code>PMM_METRICS_RESOLUTION</code> <code>METRICS_RESOLUTION_HR</code> <code>PMM_METRICS_RESOLUTION_HR</code> <code>METRICS_RESOLUTION_LR</code> <code>PMM_METRICS_RESOLUTION_LR</code> <code>METRICS_RESOLUTION_MR</code> <code>PMM_METRICS_RESOLUTION_MR</code>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#clickhouse-configuration","title":"ClickHouse configuration","text":"PMM 2 PMM 3 Comments <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> <code>PMM_CLICKHOUSE_ADDR</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> <code>PMM_CLICKHOUSE_DATABASE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATASOURCE</code> <code>PMM_CLICKHOUSE_DATASOURCE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_HOST</code> <code>PMM_CLICKHOUSE_HOST</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_PORT</code> <code>PMM_CLICKHOUSE_PORT</code> <code>PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE</code> <code>PMM_DISABLE_BUILTIN_CLICKHOUSE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> Removed in PMM v3, new version <code>PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> Removed in PMM v3, new version"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#postgresql-configuration","title":"PostgreSQL configuration","text":"PMM 2 PMM 3 <code>PERCONA_TEST_POSTGRES_ADDR</code> <code>PMM_POSTGRES_ADDR</code> <code>PERCONA_TEST_POSTGRES_DBNAME</code> <code>PMM_POSTGRES_DBNAME</code> <code>PERCONA_TEST_POSTGRES_USERNAME</code> <code>PMM_POSTGRES_USERNAME</code> <code>PERCONA_TEST_POSTGRES_DBPASSWORD</code> <code>PMM_POSTGRES_DBPASSWORD</code> <code>PERCONA_TEST_POSTGRES_SSL_CA_PATH</code> <code>PMM_POSTGRES_SSL_CA_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_CERT_PATH</code> <code>PMM_POSTGRES_SSL_CERT_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_KEY_PATH</code> <code>PMM_POSTGRES_SSL_KEY_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_MODE</code> <code>PMM_POSTGRES_SSL_MODE</code> <code>PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES</code> <code>PMM_DISABLE_BUILTIN_POSTGRES</code>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#telemetry-development","title":"Telemetry &amp; development","text":"PMM 2 PMM 3 <code>PMM_TEST_TELEMETRY_DISABLE_SEND</code> <code>PMM_DEV_TELEMETRY_DISABLE_SEND</code> <code>PERCONA_TEST_TELEMETRY_DISABLE_START_DELAY</code> <code>PMM_DEV_TELEMETRY_DISABLE_START_DELAY</code> <code>PMM_TEST_TELEMETRY_FILE</code> <code>PMM_DEV_TELEMETRY_FILE</code> <code>PERCONA_TEST_TELEMETRY_HOST</code> <code>PMM_DEV_TELEMETRY_HOST</code> <code>PERCONA_TEST_TELEMETRY_INTERVAL</code> <code>PMM_DEV_TELEMETRY_INTERVAL</code> <code>PERCONA_TEST_TELEMETRY_RETRY_BACKOFF</code> <code>PMM_DEV_TELEMETRY_RETRY_BACKOFF</code> <code>PERCONA_TEST_VERSION_SERVICE_URL</code> <code>PMM_DEV_VERSION_SERVICE_URL</code> <code>PERCONA_TEST_STARLARK_ALLOW_RECURSION</code> <code>PMM_DEV_ADVISOR_STARLARK_ALLOW_RECURSION</code>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#removed-variables","title":"Removed variables","text":"PMM 2 PMM 3 Comments <code>PERCONA_TEST_AUTH_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code> <code>PERCONA_TEST_CHECKS_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code> <code>PERCONA_TEST_CHECKS_INTERVAL</code> Removed, not used <code>PERCONA_TEST_CHECKS_PUBLIC_KEY</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_PUBLIC_KEY</code> <code>PERCONA_TEST_NICER_API</code> Removed in PMM v3 <code>PERCONA_TEST_SAAS_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/env_var.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/isolated_hosts.html","title":"Isolated hosts","text":"<p>If the host where you will run PMM Server has no internet connection, you can download the Docker image on a separate (internet-connected) host and securely copy it.</p> <ol> <li> <p>On an internet-connected host, download the Docker image and its checksum file.</p> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.0.0/docker/pmm-server-3.0.0.docker\nwget https://downloads.percona.com/downloads/pmm/3.0.0/docker/pmm-server-3.0.0.sha256sum\n</code></pre> </li> <li> <p>Copy both files to where you will run PMM Server.</p> </li> <li> <p>Open a terminal on the PMM Server host.</p> </li> <li> <p>(Optional) Check the Docker image file integrity.</p> <pre><code>shasum -ca 256 pmm-server-3.0.0.sha256sum\n</code></pre> </li> <li> <p>Load the image.</p> <pre><code>docker load -i pmm-server-3.0.0.docker\n</code></pre> </li> <li> <p>Run the container as if your image is already pulled using your desired method for a storage volume (you can step over any docker pull commands as the image has been pre-staged).</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/isolated_hosts.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/preview_env_var.html","title":"Preview environment variables","text":"<p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production.</p> Variable Description <code>PERCONA_TEST_SAAS_HOST</code> SaaS server hostname. <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> Name of the host and port of the external ClickHouse database instance. <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> Database name of the external ClickHouse database instance. <code>\u200b\u200bPERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> The maximum number of threads in the current connection thread pool. This value cannot be bigger than max_thread_pool_size. <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> The number of rows to load from tables in one block for this connection. <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/preview_env_var.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/remove_container.html","title":"Remove container","text":"Summary <ul> <li>Stop the container.</li> <li>Remove (delete) both the server and data containers.</li> <li>Remove (delete) both images.</li> </ul> <p>Caution</p> <p>These steps delete the PMM Server Docker image and any accumulated PMM metrics data.</p> <p>To remove the container:</p> <ol> <li> <p>Stop pmm-server container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove containers.</p> <pre><code>docker rm pmm-server pmm-data\n</code></pre> </li> <li> <p>Remove the image.</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-server\" | awk {'print $3'})\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/remove_container.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/restore_container.html","title":"Restore container","text":"Summary <ul> <li>Stop and remove the container.</li> <li>Restore (rename) the backup container.</li> <li>Restore saved data to the data container.</li> <li>Restore permissions to the data.</li> </ul> <p>Important</p> <p>You must have a backup to restore from.</p> <p>To restore the container:</p> <ol> <li> <p>Stop the container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove it.</p> <pre><code>docker rm pmm-server\n</code></pre> </li> <li> <p>Revert to the saved image.</p> <pre><code>docker rename pmm-server-backup pmm-server\n</code></pre> </li> <li> <p>Change directory to the backup directory (e.g. <code>pmm-data-backup</code>).</p> </li> <li> <p>Remove Victoria Metrics data folder.</p> <pre><code>docker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta rm -r /srv/victoriametrics/data\n</code></pre> </li> <li> <p>Copy the data.</p> <pre><code>docker cp srv pmm-data:/\n</code></pre> </li> <li> <p>Restore permissions.</p> <pre><code>docker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R root:root /srv &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R pmm:pmm /srv/alertmanager &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R root:pmm /srv/clickhouse &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R grafana:grafana /srv/grafana &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R pmm:pmm /srv/logs &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R postgres:postgres /srv/postgres14 &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R pmm:pmm /srv/prometheus &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R pmm:pmm /srv/victoriametrics &amp;&amp; \\\ndocker run --rm --volumes-from pmm-data -it perconalab/pmm-server:3.0.0-beta chown -R postgres:postgres /srv/logs/postgresql14.log\n</code></pre> </li> <li> <p>Start the image.</p> <pre><code>docker start pmm-server\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/restore_container.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_data_container.html","title":"Run Docker with data container","text":"<p>To run Docker with data container:</p> <ol> <li> <p>Create a persistent data container:</p> <pre><code>docker create --volume /srv \\\n--name pmm-data \\\nperconalab/pmm-server:3.0.0-beta /bin/true\n</code></pre> <p>Important</p> <p>PMM Server expects the data volume to be <code>/srv</code>. Using any other value will result in data loss when upgrading.</p> <p>To check server and data container mount points:</p> <pre><code>docker inspect pmm-data | grep Destination &amp;&amp; \\\ndocker inspect pmm-server | grep Destination\n</code></pre> </li> <li> <p>Create the Docker network:</p> <pre><code>docker network create pmm_default\n</code></pre> </li> <li> <p>Run the image:</p> <pre><code>docker run --detach --restart always \\\n--publish 443:8443 \\\n--env PMM_WATCHTOWER_HOST=your_watchtower_host \\\n--env PMM_WATCHTOWER_TOKEN=your_watchtower_token \\\n--volumes-from pmm-data \\\n--network=pmm_default \\\n--name pmm-server \\\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Change the password for the default <code>admin</code> user, replacing <code>your_secure_password123</code> with a strong, unique password:</p> <pre><code>docker exec -t pmm-server change-admin-password your_secure_password123\n</code></pre> </li> <li> <p>Check the WatchTower prerequisites and pass the following command to Docker Socket to start Watchtower:</p> <pre><code>docker run -v /var/run/docker.sock:/var/run/docker.sock -e WATCHTOWER_HTTP_API_UPDATE=1 -e WATCHTOWER_HTTP_API_TOKEN=your_watchtower_token --hostname=your_watchtower_host --network=pmm_default docker.io/perconalab/watchtower\n</code></pre> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_data_container.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_host_dir.html","title":"Run Docker with the host directory","text":"<p>To run Docker with the host directory:</p> <ol> <li> <p>Pull the image:</p> <pre><code>docker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Run the image:</p> <pre><code>docker run --detach --restart always \\\n--publish 443:8443 \\\n--env PMM_WATCHTOWER_HOST=your_watchtower_host \\\n--env PMM_WATCHTOWER_TOKEN=your_watchtower_token \\\n--volumes-from pmm-data \\\n--network=pmm_default \\\n--name pmm-server \\\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Change the password for the default <code>admin</code> user:</p> <pre><code>docker exec -t pmm-server change-admin-password &lt;new_password&gt;\n</code></pre> </li> <li> <p>Check the WatchTower prerequisites and pass the following command to Docker Socket to start Watchtower:</p> <pre><code>docker run -v /var/run/docker.sock:/var/run/docker.sock -e WATCHTOWER_HTTP_API_UPDATE=1 -e WATCHTOWER_HTTP_API_TOKEN=your_watchtower_token --hostname=your_watchtower_host --network=pmm_default docker.io/perconalab/watchtower\n</code></pre> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. (If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_host_dir.html#migrate-from-data-container-to-host-directoryvolume","title":"Migrate from data container to host directory/volume","text":"<p>To migrate your PMM from data container to host directory or volume run the following command:</p> <pre><code>docker cp &lt;containerId&gt;:/srv /target/host/directory\n</code></pre> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_host_dir.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_vol.html","title":"Run Docker with volume","text":"<p>To run Docker with volume:</p> <ol> <li> <p>Pull the image:</p> <pre><code>docker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Create a volume:</p> <pre><code>docker volume create pmm-data\n</code></pre> </li> <li> <p>Run the image:</p> <pre><code>docker run --detach --restart always \\\n--publish 443:8443 \\\n--env PMM_WATCHTOWER_HOST=your_watchtower_host \\\n--env PMM_WATCHTOWER_TOKEN=your_watchtower_token \\\n--volumes-from pmm-data \\\n--network=pmm_default \\\n--name pmm-server \\\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Change the password for the default <code>admin</code> user, replacing <code>your_secure_password123</code> with a strong, unique password:</p> <pre><code>docker exec -t pmm-server change-admin-password your_secure_password123\n</code></pre> </li> <li> <p>Check the WatchTower prerequisites and pass the following command to Docker Socket to start Watchtower:</p> <pre><code>docker run -v /var/run/docker.sock:/var/run/docker.sock -e WATCHTOWER_HTTP_API_UPDATE=1 -e WATCHTOWER_HTTP_API_TOKEN=your_watchtower_token --hostname=your_watchtower_host --network=pmm_default docker.io/perconalab/watchtower\n</code></pre> </li> <li> <p>Visit <code>https://localhost:443</code> to see the PMM user interface in a web browser. If you are accessing the Docker host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/run_with_vol.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/upgrade_container.html","title":"Upgrade container","text":"Summary <ul> <li>Stop the running container.</li> <li>Backup (rename) the container and copy data.</li> <li>Pull the latest Docker image.</li> <li>Run it.</li> </ul> <p>Important</p> <p>Downgrades are not possible. To go back to using a previous version you must have created a backup of it before upgrading.</p> <p>Tip</p> <p>To see what release you are running, use the PMM Upgrade panel on the Home Dashboard, or run:</p> <pre><code>docker exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> <p>(If you are accessing the docker host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> <p>To upgrade the container:</p> <ol> <li> <p>Stop the container.</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Perform a backup.</p> </li> <li> <p>Pull the latest image.</p> <pre><code>docker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Rename the original container</p> <pre><code>docker rename pmm-server pmm-server-old\n</code></pre> </li> <li> <p>Run it.</p> <pre><code>docker run \\\n--detach \\\n--restart always \\\n--publish 443:443 \\\n--volumes-from pmm-data \\\n--name pmm-server \\\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/docker/upgrade_container.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html","title":"Install PMM Server with Helm on the Kubernetes clusters","text":"<p>Helm is the package manager for Kubernetes. Percona Helm charts can be found in percona/percona-helm-charts repository on Github.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#before-you-start","title":"Before you start","text":"<ul> <li>Install Helm following its official installation instructions.</li> <li>Kubernetes cluster that Helm supports</li> </ul> <p>Helm v3 is needed to run the following steps.</p> <p>Refer to Kubernetes Supported versions and Helm Version Support Policy to find the supported versions.</p> <p>PMM should be platform-agnostic, but it requires escalated privileges inside a container. It is necessary to have a <code>root</code> user inside the PMM container. Thus, PMM would not work for Kubernetes Platforms such as OpenShift or others that have hardened Security Context Constraints, for example:</p> <ul> <li>Security context constraints (SCCs) </li> <li>Managing security context constraints</li> </ul> <p>Kubernetes platforms offer a different set of capabilities. To use PMM in production, you would need backups and, thus storage driver that supports snapshots. Consult your provider for Kubernetes and Cloud storage capabilities.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#locality-and-availability","title":"Locality and Availability","text":"<p>You should not run the PMM monitoring server along with the monitored database clusters and services on the same system.</p> <p>Please ensure proper locality either by physically separating workloads in Kubernetes clusters or running separate Kubernetes clusters for the databases and monitoring workloads.</p> <p>You can physically separate workloads by properly configuring Kubernetes nodes, affinity rules, label selections, etc.</p> <p>Also, ensure that the Kubernetes cluster has high availability so that in case of a node failure, the monitoring service will be running and capturing the required data.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#install-pmm-server","title":"Install PMM Server","text":"Summary <ul> <li>Setup pmm-admin password</li> <li>Install</li> <li>Configuration parameters</li> <li>PMM environment variables</li> <li>PMM SSL certificates</li> <li>Backup</li> <li>Upgrade</li> <li>Restore</li> <li>Uninstall</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#set-up-pmm-admin-password","title":"Set up pmm-admin password","text":"<p>Create Kubernetes secret with pmm-admin password: <pre><code>cat &lt;&lt;EOF | kubectl create -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: pmm-secret\n  labels:\n    app.kubernetes.io/name: pmm\ntype: Opaque\ndata:\n# base64 encoded password\n# encode some password: `echo -n \"admin\" | base64`\n  PMM_ADMIN_PASSWORD: YWRtaW4=\nEOF\n</code></pre></p> <p>To get admin password execute:</p> <pre><code>kubectl get secret pmm-secret -o jsonpath='{.data.PMM_ADMIN_PASSWORD}' | base64 --decode\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#install","title":"Install","text":"<p>To install the chart with the release name <code>pmm</code>:</p> <p><pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\nhelm install pmm \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\npercona/pmm\n</code></pre> The command deploys PMM on the Kubernetes cluster in the default configuration and specified secret. The Parameters section lists the parameters that can be configured during installation.</p> <pre><code>helm uninstall pmm\n</code></pre> <p>Tip</p> <p>List all releases using <code>helm list</code>.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#parameters","title":"Parameters","text":"<p>The list of Parameters is subject to change from release to release. Check the Parameters section of the PMM Helm Chart.</p> <p>Tip</p> <p>You can list the default parameters values.yaml or get them from chart definition: <code>helm show values percona/pmm</code></p> <p>Specify each parameter using the <code>--set key=value[,key=value]</code> or <code>--set-string key=value[,key=value]</code> arguments to <code>helm install</code>. For example,</p> <pre><code>helm install pmm \\\n--set secret.create=false --set secret.name=pmm-secret \\\n--set service.type=\"NodePort\" \\\n--set storage.storageClassName=\"linode-block-storage-retain\" \\\n    percona/pmm\n</code></pre> <p>The above command installs PMM and sets the Service network type to <code>NodePort</code> and storage class to <code>linode-block-storage-retain</code> for persistence storage on LKE.</p> <pre><code>helm uninstall pmm\n</code></pre> <p>Important</p> <p>Once this chart is deployed, it is impossible to change the application\u2019s access credentials, such as password, using Helm. To change these application credentials after deployment, delete any persistent volumes (PVs) used by the chart and re-deploy it, or use the application\u2019s built-in administrative tools (if available)</p> <p>Alternatively, a YAML file that specifies the values for the above parameters can be provided while installing the chart. For example:</p> <pre><code>helm show values percona/pmm &gt; values.yaml\n\n#change needed parameters in values.yaml, you need `yq` tool pre-installed\nyq -i e '.secret.create |= false' values.yaml\n\nhelm install pmm -f values.yaml percona/pmm\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#pmm-environment-variables","title":"PMM environment variables","text":"<p>In case you want to add extra environment variables (useful for advanced operations like custom init scripts), you can use the <code>pmmEnv</code> property.</p> <pre><code>pmmEnv:\n  DISABLE_UPDATES: \"1\"\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#pmm-ssl-certificates","title":"PMM SSL certificates","text":"<p>PMM ships with self signed SSL certificates to provide secure connection between client and server (check here).</p> <p>You will see the warning when connecting to PMM. To further increase security, you should provide your certificates and add values of credentials to the fields of the <code>cert</code> section:</p> <pre><code>certs:\n  name: pmm-certs\n  files:\n    certificate.crt: &lt;content&gt;\n    certificate.key: &lt;content&gt;\n    ca-certs.pem: &lt;content&gt;\n    dhparam.pem: &lt;content&gt;\n</code></pre> <p>Another approach to set up TLS certificates is to use the Ingress controller, see TLS. PMM helm chart supports Ingress. See PMM network configuration.</p> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/backup_container_helm.html","title":"Back up Helm charts","text":"<p>PMM helm chart uses PersistentVolume and PersistentVolumeClaim to allocate storage in the Kubernetes cluster.</p> <p>Volumes could be pre-provisioned and dynamic. PMM chart supports both and exposes it through PMM storage configuration.</p> <p>Backups for the PMM Server currently support only storage layer backups and thus require StorageClass and VolumeSnapshotClass.</p> <p>Validate the correct configuration by using these commands: <pre><code>kubectl get sc\nkubectl get volumesnapshotclass\n</code></pre></p> <p>Storage</p> <p>Storage configuration is Hardware and Cloud specific. There could be additional costs associated with Volume Snapshots. Check the documentation for your Cloud or for your Kubernetes cluster.</p> <p>Before taking a VolumeSnapshot, stop the PMM Server. In this step, we will stop PMM (scale to 0 pods), take a snapshot, wait until the snapshot completes, then start PMM Server (scale to 1 pod): <pre><code>kubectl scale statefulset pmm --replicas=0\nkubectl wait --for=jsonpath='{.status.replicas}'=0 statefulset pmm\n\ncat &lt;&lt;EOF | kubectl create -f -\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: before-v2.34.0-upgrade\n  labels:\n    app.kubernetes.io/name: pmm\nspec:\n  volumeSnapshotClassName: csi-hostpath-snapclass\n  source:\n    persistentVolumeClaimName: pmm-storage-pmm-0\nEOF\n\nkubectl wait --for=jsonpath='{.status.readyToUse}'=true VolumeSnapshot/before-v2.34.0-upgrade\nkubectl scale statefulset pmm --replicas=1\n</code></pre></p> <p>Output:</p> <pre><code>statefulset.apps/pmm scaled\nstatefulset.apps/pmm condition met\nvolumesnapshot.snapshot.storage.k8s.io/before-v2.34.0-upgrade created\nvolumesnapshot.snapshot.storage.k8s.io/before-v2.34.0-upgrade condition met\nstatefulset.apps/pmm scaled\n</code></pre> <p>PMM scale</p> <p>Only one replica set is currently supported.</p> <p>You can view available snapshots by executing the following command: <pre><code>kubectl get volumesnapshot\n</code></pre></p> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/backup_container_helm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/restore_container_helm.html","title":"Restore Helm chart","text":"<p>The version of the PMM Server should be greater than or equal to the version in a snapshot. To restore from the snapshot, delete the old deployment first: <pre><code>helm uninstall pmm\n</code></pre></p> <p>And then use snapshot configuration to start the PMM Server again with the correct version and correct storage configuration: <pre><code>helm install pmm \\\n--set image.tag=\"2.34.0\" \\\n--set storage.name=\"pmm-storage-old\" \\\n--set storage.dataSource.name=\"before-v2.34.0-upgrade\" \\\n--set storage.dataSource.kind=\"VolumeSnapshot\" \\\n--set storage.dataSource.apiGroup=\"snapshot.storage.k8s.io\" \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\npercona/pmm\n</code></pre></p> <p>Here, we created a new <code>pmm-storage-old</code> PVC with data from the snapshot. So, there are a couple of PV and PVCs available in a cluster.</p> <pre><code>$ kubectl get pvc\nNAME                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\npmm-storage-old-pmm-0   Bound    pvc-70e5d2eb-570f-4087-9515-edf2f051666d   10Gi       RWO            csi-hostpath-sc   3s\npmm-storage-pmm-0       Bound    pvc-9dbd9160-e4c5-47a7-bd90-bff36fc1463e   10Gi       RWO            csi-hostpath-sc   89m\n\n$ kubectl get pv\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                           STORAGECLASS      REASON   AGE\npvc-70e5d2eb-570f-4087-9515-edf2f051666d   10Gi       RWO            Delete           Bound    default/pmm-storage-old-pmm-0   csi-hostpath-sc            4m50s\npvc-9dbd9160-e4c5-47a7-bd90-bff36fc1463e   10Gi       RWO            Delete           Bound    default/pmm-storage-pmm-0       csi-hostpath-sc            93m\n</code></pre> <p>Delete unneeded PVC when you are sure you don\u2019t need them.</p> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/helm/restore_container_helm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html","title":"Install PMM Server with Podman on Docker image","text":"<p>This section provides instructions for running PMM Server with Podman based on our Docker image.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#about-podman","title":"About Podman","text":"<p>See also</p> <ul> <li>Docker </li> <li>Other tags are available.</li> </ul> <p>Podman is an open-source, daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers and container images on Linux systems. It is widely supported across Linux distributions and hosted on GitHub.</p> <p>One of Podman\u2019s advantages is that it allows non-privileged users to run containers, enhancing security by avoiding elevated permissions.</p> <p>Podman is compatible with Docker; by using an alias (<code>alias docker=podman</code>), you can run Docker commands seamlessly with Podman. All instructions in the Docker section apply to Podman as well.</p> <p>Percona recommends running PMM with Podman as a non-privileged user and as part of the provided SystemD service. SystemD helps ensure that the service is actively running and offers logging and management functions, such as start, stop, and restart.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#before-you-start","title":"Before you start","text":"<ul> <li>Install Podman.</li> <li>Configure rootless Podman.</li> <li> <p>Install Watchtower to automatically update your containers with the following considerations:</p> <ul> <li>Ensure Watchtower is only accessible from within the Docker network or local host to prevent unauthorized access and enhance container security.</li> <li>Configure network settings to expose only the PMM Server container to the external network, keeping Watchtower isolated within the Docker network.</li> <li>Grant Watchtower access to the Docker socket to monitor and manage containers effectively, ensuring proper security measures are in place to protect the Docker socket.</li> <li>Verify that both Watchtower and PMM Server are on the same network, or ensure PMM Server can connect to Watchtower for communication. This network setup is essential for PMM Server to initiate updates through Watchtower.</li> </ul> </li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#update-mechanism","title":"Update mechanism","text":"<p>PMM Server updates work differently in Podman compared to Docker due to security policies:</p> <ul> <li>Docker updates use a simpler flow where PMM Server directly instructs Watchtower to replace the Docker container in one step.</li> <li>Podman updates require SystemD integration and follow a multi-step process with environment file changes for better security isolation.</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#install","title":"Install","text":"<p>You can install PMM with either automated UI-based updates or a manual update method, depending on your preferences.</p> <p>The UI-based method, using Watchtower, enables direct updates from the web interface without requiring command-line access and automates the process. </p> <p>On the other hand, the manual method offers a simpler setup with complete control over updates and no need for additional services, but it requires command-line access and manual intervention to track and apply updates.</p> Installation with UI updatesInstallation with manual updates <p>This method enables updates through the PMM web interface using Watchtower and SystemD services. When you initiate an update in the UI, PMM Server updates its image reference, prompting Watchtower to pull the new image. Watchtower then stops the existing container, and SystemD automatically restarts it with the updated image.</p> <ol> <li> <p>Create PMM Server service file at <code>~/.config/systemd/user/pmm-server.service</code>:</p> <pre><code>[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nEnvironmentFile=~/.config/systemd/user/pmm-server.env\nRestart=on-failure\nRestartSec=20\nExecStart=/usr/bin/podman run \\\n    --volume ~/.config/systemd/user/:/home/pmm/update/ \\\n    --rm --replace=true --name %N \\\n    --env-file=~/.config/systemd/user/pmm-server.env \\\n    --net pmm_default \\\n    --cap-add=net_admin,net_raw \\\n    --userns=keep-id:uid=1000,gid=1000 \\\n    -p 443:8443/tcp --ulimit=host ${PMM_IMAGE}\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Create the environment file at <code>~/.config/systemd/user/pmm-server.env</code>:</p> <pre><code>PMM_WATCHTOWER_HOST=http://watchtower:8080\nPMM_WATCHTOWER_TOKEN=123\nPMM_IMAGE=docker.io/perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Create or update the Watchtower service file at <code>~/.config/systemd/user/watchtower.service</code>:</p> <pre><code>[Unit]\nDescription=watchtower\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nRestart=on-failure\nRestartSec=20\nEnvironment=WATCHTOWER_HTTP_API_UPDATE=1\nEnvironment=WATCHTOWER_HTTP_API_TOKEN=123\nEnvironment=WATCHTOWER_NO_RESTART=1\nEnvironment=WATCHTOWER_DEBUG=1\nExecStart=/usr/bin/podman run --rm --replace=true --name %N \\\n    -v ${XDG_RUNTIME_DIR}/podman/podman.sock:/var/run/docker.sock \\\n    -e WATCHTOWER_HTTP_API_UPDATE=${WATCHTOWER_HTTP_API_UPDATE} \\\n    -e WATCHTOWER_HTTP_API_TOKEN=${WATCHTOWER_HTTP_API_TOKEN} \\\n    -e WATCHTOWER_NO_RESTART=${WATCHTOWER_NO_RESTART} \\\n    -e WATCHTOWER_DEBUG=${WATCHTOWER_DEBUG} \\\n    --net pmm_default \\\n    --cap-add=net_admin,net_raw \\\n    docker.io/perconalab/watchtower:latest\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Start services:</p> <pre><code>systemctl --user enable --now pmm-server\nsystemctl --user enable --now watchtower\n</code></pre> </li> <li> <p>Go to <code>https://localhost:8443</code> to access the PMM user interface in a web browser. If you are accessing the host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p>The installation with manual updates offers a straightforward setup with direct control over updates, without relying on additional services. In this approach, you manually update the <code>PMM_IMAGE</code> in the environment file and restart the PMM Server service. SystemD then automatically manages the container replacement.</p> <ol> <li> <p>Create PMM Server service file at <code>~/.config/systemd/user/pmm-server.service</code>:</p> <pre><code>[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nEnvironmentFile=~/.config/systemd/user/pmm-server.env\nRestart=on-failure\nRestartSec=20\nExecStart=/usr/bin/podman run \\\n    --rm --replace=true --name %N \\\n    --env-file=~/.config/systemd/user/pmm-server.env \\\n    --net pmm_default \\\n    --cap-add=net_admin,net_raw \\\n    --userns=keep-id:uid=1000,gid=1000 \\\n    -p 443:8443/tcp --ulimit=host ${PMM_IMAGE}\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Create the environment file at <code>~/.config/systemd/user/pmm-server.env</code>:</p> <pre><code>PMM_IMAGE=docker.io/perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Start services:</p> <pre><code>systemctl --user enable --now pmm-server\n</code></pre> </li> <li> <p>Go to <code>https://localhost:8443</code> to access the PMM user interface in a web browser. If you are accessing the host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p>For information on manually upgrading, see Upgrade PMM Server using Podman.</p> <p>=======</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#run-as-non-privileged-user-to-start-pmm","title":"Run as non-privileged user to start PMM","text":"Summary <ul> <li>Install.</li> <li>Configure.</li> <li>Enable and Start.</li> <li>Open the PMM UI in a browser.</li> </ul> <p>To run Podman as a non-privileged user:</p> <ol> <li> <p>Install:</p> <p>Create <code>~/.config/systemd/user/pmm-server.service</code> file:</p> <pre><code>mkdir -p ~/.config/systemd/user/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/systemd/user/pmm-server.service\n[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n\n[Service]\nType=simple\n\n# set environment for this unit\nEnvironment=PMM_PUBLIC_PORT=8443\nEnvironment=PMM_VOLUME_NAME=%N\nEnvironment=PMM_TAG=2.33.0\nEnvironment=PMM_IMAGE=docker.io/percona/pmm-server\nEnvironment=PMM_ENV_FILE=%h/.config/pmm-server/pmm-server.env\n\n# optional env file that could override previous env settings for this unit\nEnvironmentFile=-%h/.config/pmm-server/env\n\nExecStart=/usr/bin/podman run --rm --replace=true --name=%N -p ${PMM_PUBLIC_PORT}:443/tcp --ulimit=host --volume=${PMM_VOLUME_NAME}:/srv --env-file=${PMM_ENV_FILE} --health-cmd=none --health-interval=disable ${PMM_IMAGE}:${PMM_TAG}\nExecStop=/usr/bin/podman stop -t 10 %N\nRestart=on-failure\nRestartSec=20\n\n[Install]\nAlias=%N\nWantedBy=default.target\n\nEOF\n</code></pre> <p>Create <code>~/.config/pmm-server/pmm-server.env</code> file:</p> <pre><code>mkdir -p ~/.config/pmm-server/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/pmm-server/pmm-server.env\n# env file passed to the container\n# full list of environment variables:\n# https://www.percona.com/doc/percona-monitoring-and-management/2.x/setting-up/server/docker.html#environment-variables\n\n# keep updates disabled\n# do image replacement instead (update the tag and restart the service)\nDISABLE_UPDATES=1\nEOF\n</code></pre> </li> <li> <p>Configure:</p> <p>There are 2 configuration files: 1.  <code>~/.config/pmm-server/pmm-server.env</code> defines environment variables for PMM Server (PMM parameters like RBAC feature and etc) 2.  <code>~/.config/pmm-server/env</code> defines environment variables for SystemD service (image tags, repo and etc)</p> <p>SystemD service passes the environment parameters from the <code>pmm-server.env</code>file (in <code>~/.config/pmm-server/pmm-server.env</code>) to PMM. For more information about container environment variables, check [Docker Environment].</p> <p>SystemD service uses some environment variables that could be customized if needed:</p> <pre><code>Environment=PMM_PUBLIC_PORT=8443\nEnvironment=PMM_VOLUME_NAME=%N\nEnvironment=PMM_TAG=2.33.0\nEnvironment=PMM_IMAGE=docker.io/percona/pmm-server\n</code></pre> <p>You can override the environment variables by defining them in the file  <code>~/.config/pmm-server/env</code>. For example, to override the path to a custom registry <code>~/.config/pmm-server/env</code>:</p> <pre><code>mkdir -p ~/.config/pmm-server/\ncat &lt;&lt; \"EOF\" &gt; ~/.config/pmm-server/env\nPMM_TAG=2.31.0\nPMM_IMAGE=docker.io/percona/pmm-server\nPMM_PUBLIC_PORT=8443\nEOF\n</code></pre> <p>Important</p> <p>Ensure that you modify PMM_TAG in <code>~/.config/pmm-server/env</code> and update it regularly as Percona cannot update it. It needs to be done by you.</p> </li> <li> <p>Enable and start:</p> <pre><code>systemctl --user enable --now pmm-server\n</code></pre> </li> <li> <p>Activate the podman socket using the Podman socket activation instructions.</p> </li> <li> <p>Pass the following command to Docker Socket to start Watchtower. Make sure to modify the command to use your Podman socket path:</p> <pre><code>docker  run -v $XDG_RUNTIME_DIR/podman/podman.sock:/var/run/docker.sock -e WATCHTOWER_HTTP_API_UPDATE=1 -e WATCHTOWER_HTTP_API_TOKEN=123 --hostname=watchtower --network=pmm_default docker.io/perconalab/watchtower\n</code></pre> </li> <li> <p>Visit <code>https://localhost:8443</code> to see the PMM user interface in a web browser. (If you are accessing host remotely, replace <code>localhost</code> with the IP or server name of the host.)</p> </li> </ol> <pre><code>#first pull can take time\nsleep 80\ntimeout 60 podman wait --condition=running pmm-server\n</code></pre> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/backup_container_podman.html","title":"Backup podman container","text":"Summary <ul> <li>Stop PMM Server.</li> <li>Backup the data.</li> </ul> <p>Important</p> <p>Grafana plugins have been moved to the data volume <code>/srv</code> since the 2.23.0 version. So if you are upgrading PMM from any version before 2.23.0 and have installed additional plugins then plugins should be installed again after the upgrade. To check used grafana plugins: <code>podman exec -it pmm-server ls /var/lib/grafana/plugins</code></p> <p>To back up your container:</p> <ol> <li> <p>Stop PMM Server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Backup the data.</p> <p> <pre><code>podman wait --condition=stopped pmm-server || true\nsleep 30\n</code></pre> </p> <pre><code>podman volume export pmm-server --output pmm-server-backup.tar\n</code></pre> <p>Important</p> <p>If you changed the default name to <code>PMM_VOLUME_NAME</code> environment variable, use that name after <code>export</code> instead of <code>pmm-server</code> (which is the default volume name).</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/backup_container_podman.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/remove_container_podman.html","title":"Remove podman container","text":"Summary <ul> <li>Stop PMM Server.</li> <li>Remove (delete) volume.</li> <li>Remove (delete) images.</li> </ul> <p>Caution</p> <p>These steps delete the PMM Server Docker image and the associated PMM metrics data.</p> <p>To remove your contiainer:</p> <ol> <li> <p>Stop PMM Server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Remove volume.</p> <p> <pre><code>#wait for container to stop\npodman wait --condition=stopped pmm-server || true\nsleep 10\n</code></pre> </p> <pre><code>podman volume rm --force pmm-server\n</code></pre> </li> <li> <p>Remove the PMM images.</p> <pre><code>podman rmi $(podman images | grep \"pmm-server\" | awk {'print $3'})\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/remove_container_podman.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/restore_container_podman.html","title":"Restore podman container","text":"Summary <ul> <li>Stop PMM Server.</li> <li>Run PMM on the previous image.</li> <li>Restore the volume.</li> <li>Start PMM Server.</li> </ul> <p>Important</p> <p>You must have a backup to restore from. You need to perform restore only if you have issues with upgrade or with the data.</p> <p>To restore your container:</p> <ol> <li> <p>Stop PMM Server.</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Run PMM on the previous image.</p> <p>Edit <code>~/.config/pmm-server/env</code> file:</p> <pre><code>sed -i \"s/PMM_TAG=.*/PMM_TAG=2.31.0/g\" ~/.config/pmm-server/env\n</code></pre> <p>Important</p> <p>X.Y.Z (2.31.0) is the version you used before upgrade and you made Backup with it</p> </li> <li> <p>Restore the volume.</p> <pre><code>podman volume import pmm-server pmm-server-backup.tar\n</code></pre> </li> <li> <p>Start PMM Server.</p> <pre><code>systemctl --user start pmm-server\n</code></pre> <p> sleep 30 timeout 60 podman wait \u2013condition=running pmm-server ``` </p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/podman/restore_container_podman.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html","title":"Install PMM Server on the virtual machine","text":"<p>How to run PMM Server as a virtual machine.</p> Summary <ul> <li>Download and verify the latest OVF file.</li> <li>Import it.</li> <li>Reconfigure network.</li> <li>Start the VM and get IP.</li> <li>Log into PMM UI.</li> <li>(Optional) Change VM root password.</li> <li>(Optional) Set up SSH.</li> <li>(Optional) Set up static IP.</li> </ul> <p>Most steps can be done with either a user interface or on the command line, but some steps can only be done in one or the other. Sections are labelled UI for user interface or CLI for command line instructions.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html#terminology","title":"Terminology","text":"<ul> <li>Host is the desktop or server machine running the hypervisor.</li> <li>Hypervisor is software (e.g. VirtualBox, VMware) that runs the guest OS as a virtual machine.</li> <li>Guest is the CentOS virtual machine that runs PMM Server.</li> </ul>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html#ova-file-details","title":"OVA file details","text":"Item Value Download page https://www.percona.com/downloads/pmm/3.0.0/ova File name <code>pmm-server-3.0.0.ova</code> VM name <code>pmm-Server-2024-11-22-N</code> (<code>N</code>=build number)"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html#vm-specifications","title":"VM specifications","text":"Component Value OS Oracle Linux 9.3 CPU 1 Base memory 4096 MB Disks LVM, 2 physical volumes Disk 1 (<code>sda</code>) VMDK (SCSI, 40 GB) Disk 2 (<code>sdb</code>) VMDK (SCSI, 400 GB)"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html#users","title":"Users","text":"Default Username Default password <code>root</code> <code>percona</code> <code>admin</code> <code>admin</code>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/download_ova.html","title":"Download and verify OVA file","text":"<p>This section contains guidelines on how to download and verify the OVA file.</p> Download from the UIDownload from the CLI <p>To download an OVA file from the UI:</p> <ol> <li>Open a web browser.</li> <li>Visit the PMM Server download page.</li> <li>Choose a Version or use the default (the latest).</li> <li>Click the link for <code>pmm-server-3.0.0.ova</code> to download it. Note where your browser saves it.</li> <li>Right click the link for <code>pmm-server-3.0.0.sha256sum</code> and save it in the same place as the <code>.ova</code> file.</li> <li>(Optional) Verify.</li> </ol> <p>Download the latest PMM Server OVA and checksum files.</p> <pre><code>wget https://www.percona.com/downloads/pmm/3.0.0/ova/pmm-server-3.0.0.ova\nwget https://www.percona.com/downloads/pmm/3.0.0/ova/pmm-server-3.0.0.sha256sum\n</code></pre>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/download_ova.html#verify-ova-file-from-cli","title":"Verify OVA file from CLI","text":"<p>Verify the checksum of the downloaded .ova file.</p> <pre><code>shasum -ca 256 pmm-server-3.0.0.sha256sum\n</code></pre> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/download_ova.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/login_UI.html","title":"Log into user interface","text":"<p>To log in to the PMM user interface:</p> <ol> <li> <p>Open a web browser and visit the guest IP address.</p> </li> <li> <p>The PMM login screen appears.</p> </li> <li> <p>Enter the default username and password in the relevant fields and click Log in.</p> <ul> <li> <p>username: <code>admin</code></p> </li> <li> <p>password: <code>admin</code></p> </li> </ul> </li> <li> <p>(Recommended) Follow the prompts to change the default password.</p> <p>Note</p> <p>You also can change the default password through SSH by using the <code>change-admin-password</code> command.</p> </li> <li> <p>The PMM Home Dashboard appears.</p> </li> </ol> (optional) Change root password from UI <ol> <li> <p>Start the virtual machine in GUI mode.</p> </li> <li> <p>Log in with the default superuser credentials:</p> <ul> <li> <p>Username: <code>root</code></p> </li> <li> <p>Password: <code>percona</code></p> </li> </ul> </li> <li> <p>Follow the prompts to change the password.</p> </li> </ol> (optional) Set up SSH from UI/CLI <p>To set up SSH from UI/CLI:</p> <ol> <li> <p>Create a key pair for the <code>admin</code> user.</p> <pre><code>ssh-keygen -f admin\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; Settings &gt; SSH Key.</p> </li> <li> <p>Copy and paste the contents of the <code>admin.pub</code> file into the SSH Key field.</p> </li> <li> <p>Click Apply SSH Key. (This copies the public key to <code>/home/admin/.ssh/authorized_keys</code> in the guest).</p> </li> <li> <p>Log in via SSH (<code>N.N.N.N</code> is the guest IP address).</p> <pre><code>ssh -i admin admin@N.N.N.N\n</code></pre> </li> </ol> (optional) Set up static IP via CLI <p>When the guest OS starts, it will get an IP address from the hypervisor\u2019s DHCP server. This IP can change each time the guest OS is restarted. Setting a static IP for the guest OS avoids having to check the IP address whenever the guest is restarted.</p> <ol> <li> <p>Start the virtual machine in non-headless (GUI) mode.</p> </li> <li> <p>Log in as <code>root</code>.</p> </li> <li> <p>Edit <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code></p> </li> <li> <p>Change the value of <code>BOOTPROTO</code>:</p> <pre><code>BOOTPROTO=none\n</code></pre> </li> <li> <p>Add these values:</p> <pre><code>IPADDR=192.168.1.123 # replace with the desired static IP address\nNETMASK=255.255.255.0 # replace with the netmask for your IP address\nGATEWAY=192.168.1.1 # replace with the network gateway for your IP address\nPEERDNS=no\nDNS1=192.168.1.53 # replace with your DNS server IP\n</code></pre> </li> <li> <p>Restart the interface.</p> <pre><code>ifdown eth0 &amp;&amp; ifup eth0\n</code></pre> </li> <li> <p>Check the IP.</p> <pre><code>ip addr show eth0\n</code></pre> </li> <li> <p>Preserve the network configuration across reboots.</p> <pre><code>echo \"network: {config: disabled}\" &gt; /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/login_UI.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/remove_virtual_machine.html","title":"Remove virtual machine from UI","text":"<p>To remove a virtual machine from the UI:</p> <ol> <li> <p>Stop the virtual machine: select Close \u2192 Power Off.</p> </li> <li> <p>Remove the virtual machine: select Remove \u2192 Delete all files.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/remove_virtual_machine.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html","title":"VirtualBox - Import OVA file","text":"OVA file downloaded from UIOVA file downloaded via CLI <p>To import downloaded file from UI:</p> <ol> <li>Select File \u2192 Import appliance\u2026.</li> <li>In the File field, type the path to the downloaded <code>.ova</code> file, or click the folder icon to navigate and open it.</li> <li>Click Continue.</li> <li>On the Appliance settings page, review the settings and click Import.</li> <li>Click Start.</li> <li>When the guest has booted, note the IP address in the guest console.</li> </ol> <p>To import downloaded file from CLI:</p> <ol> <li> <p>Open a terminal and change directory to where the downloaded <code>.ova</code> file is.</p> </li> <li> <p>(Optional) Do a \u2018dry run\u2019 import to see what values will be used.</p> <pre><code>VBoxManage import pmm-server-3.0.0.ova --dry-run\n</code></pre> </li> <li> <p>Import the image.</p> <p>Choose one of:</p> <ul> <li> <p>With the default settings.</p> <pre><code>VBoxManage import pmm-server-3.0.0.ova\n</code></pre> </li> <li> <p>With custom settings (in this example, Name: \u201cPMM Server\u201d, CPUs: 2, RAM: 8192 MB).</p> <pre><code>VBoxManage import --vsys 0 --vmname \"PMM Server\" \\\n--cpus 2 --memory 8192 pmm-server-3.0.0.ova\n</code></pre> </li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#reconfigure-interface","title":"Reconfigure interface","text":""},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#reconfigure-with-ui","title":"Reconfigure with UI","text":"<p>To reconfigure the interface with the UI:</p> <ol> <li>Click Settings.</li> <li>Click Network.</li> <li>In the Adapter 1 field, click Attached to and change to Bridged Adapter.</li> <li>In the Name field, select your host\u2019s active network interface (e.g. <code>en0: Wi-Fi (Wireless)</code>).</li> <li>Click OK.</li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#reconfigure-via-cli","title":"Reconfigure via CLI","text":"<p>To reconfigure via the CLI:</p> <ol> <li> <p>Show the list of available bridge interfaces.</p> <pre><code>VBoxManage list bridgedifs\n</code></pre> </li> <li> <p>Find the name of the active interface you want to bridge to (one with Status: Up and a valid IP address). Example: <code>en0: Wi-Fi (Wireless)</code></p> </li> <li> <p>Bridge the virtual machine\u2019s first interface (<code>nic1</code>) to the host\u2019s <code>en0</code> ethernet adapter.</p> <pre><code>VBoxManage modifyvm 'PMM Server' \\\n--nic1 bridged --bridgeadapter1 'en0: Wi-Fi (Wireless)'\n</code></pre> </li> <li> <p>Redirect the console output into a host file.</p> <pre><code>VBoxManage modifyvm 'PMM Server' \\\n--uart1 0x3F8 4 --uartmode1 file /tmp/pmm-server-console.log\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#start-guest-and-get-ip-address-from-ui","title":"Start guest and get IP address from UI","text":"<p>To start the guest and get the IP address from the UI:</p> <ol> <li>Select the PMM Server virtual machine in the list.</li> <li>Click Start.</li> <li>When the guest has booted, note the IP address in the guest console.</li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#start-guest-and-get-ip-address-from-cli","title":"Start guest and get IP address from CLI","text":"<p>To start the guest and get the IP address from the CLI:</p> <ol> <li> <p>Start the guest.</p> <pre><code>VBoxManage startvm --type headless 'PMM Server'\n</code></pre> </li> <li> <p>(Optional) Watch the log file.</p> <pre><code>tail -f /tmp/pmm-server-console.log\n</code></pre> </li> <li> <p>Wait for one minute for the server to boot up.</p> </li> <li> <p>Choose one of:</p> <ul> <li>Read the IP address from the tailed log file.</li> <li> <p>Extract the IP address from the log file.</p> <pre><code>grep -e \"^IP:\" /tmp/pmm-server-console.log | cut -f2 -d' '\n</code></pre> </li> </ul> </li> <li> <p>(Optional) Stop the guest:</p> <pre><code>VBoxManage controlvm \"PMM Server\" poweroff\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/virtualbox.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html","title":"VMware - Import OVA file","text":"OVA file downloaded from UIOVA file downloaded via CLI <p>To import downloaded file from UI:</p> <ol> <li>Select File \u2192 Import.</li> <li>Click Choose file\u2026.</li> <li>Navigate to the downloaded <code>.ova</code> file and select it.</li> <li>Click Open.</li> <li>Click Continue.</li> <li> <p>In the Save as dialog:</p> <ul> <li>(Optional) Change the directory or file name.</li> <li>Click Save.</li> </ul> </li> <li> <p>Choose one of:</p> <ul> <li>(Optional) Click Finish. This starts the virtual machine.</li> <li>(Recommended) Click Customize Settings. This opens the VM\u2019s settings page without starting the machine.</li> </ul> </li> </ol> <p>To import downloaded file from the CLI:</p> <ol> <li>Install <code>ovftool</code>. (You need to register.)</li> <li> <p>Import and convert the OVA file. (<code>ovftool</code> can\u2019t change CPU or memory settings during import but it can set the default interface.)</p> <p>Choose one of:</p> <ul> <li> <p>Download and import the OVA file.</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=Wi-Fi \\\nhttps://www.percona.com/downloads/pmm/3.0.0/ova/pmm-server-3.0.0.ova \\\npmm-server-3.0.0.vmx\n</code></pre> </li> <li> <p>Import an already-downloaded OVA file.</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=WiFi \\\npmm-server-3.0.0.ova \\\npmm-server.vmx\n</code></pre> </li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html#reconfigure-interface","title":"Reconfigure interface","text":"<p>Note</p> <p>When using the command line, the interface is remapped during import.</p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html#reconfigure-with-ui","title":"Reconfigure with UI","text":"<p>To reconfigure the interface with the UI:</p> <ol> <li>If started, shut down the virtual machine.</li> <li>In the VMware main window, select the imported virtual machine.</li> <li>Click Virtual Machine \u2192 Settings\u2026.</li> <li>Click Network Adapter.</li> <li>In the Bridged Networking section, select Autodetect.</li> <li>Close the settings window.</li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html#start-guest-and-get-ip-address-from-ui","title":"Start guest and get IP address from UI","text":"<p>To start the guest and get the IP address from the UI:</p> <ol> <li>In the VMware main window, select the imported virtual machine.</li> <li>Click the play button  or select Virtual Machine \u2192 Start Up.</li> <li>When the instance has been booted, note the IP address in the guest console.</li> </ol>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html#start-guest-and-get-ip-address-from-cli","title":"Start guest and get IP address from CLI","text":"<p>To start the guest and get the IP address from the CLI:</p> <ol> <li> <p>Start the virtual machine in GUI mode. (There\u2019s no way to redirect a VMware VM\u2019s console to the host.)</p> <pre><code>vmrun -gu root -gp percona start \\\npmm-server.vmx gui\n</code></pre> </li> <li> <p>When the instance has been booted, note the IP address in the guest console.</p> </li> <li> <p>(Optional) Stop and restart the instance in headless mode.</p> <pre><code>vmrun stop pmm-server.vmx\nvmrun -gu root -gp percona start \\\npmm-server.vmx nogui\n</code></pre> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/baremetal/virtual/vmware.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html","title":"Hardware and system requirements","text":""},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#server-requirements","title":"Server requirements","text":"<ul> <li> <p>Disk</p> <p>Approximately 1 GB of storage per monitored database node with data retention set to one week. By default, retention is 30 days.</p> <p>Tip</p> <p>Disable table statistics to decrease the VictoriaMetrics database size.</p> </li> <li> <p>Memory</p> <p>A minimum of 2 GB per monitored database node. The increase in memory usage is not proportional to the number of nodes. For example, data from 20 nodes should be easily handled with 16 GB.</p> </li> <li> <p>Architecture</p> <ul> <li>Your CPU must support the <code>SSE4.2</code> instruction set, a requirement of ClickHouse, a third-party column-oriented database used by Query Analytics. If your CPU is lacking this instruction set you won\u2019t be able to use Query Analytics.</li> <li>For ARM64 systems, ensure you\u2019re using a supported ARM64 architecture (e.g., ARMv8). Note that some features may have different performance characteristics on ARM compared to x86_64 systems.</li> </ul> </li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#client-requirements","title":"Client requirements","text":"<ul> <li> <p>Disk</p> <p>A minimum of 100 MB of storage is required for installing the PMM Client package. With a good connection to PMM Server, additional storage is not required. However, the client needs to store any collected data that it cannot dispatch immediately, so additional storage may be required if the connection is unstable or the throughput is low. VMagent uses 1 GB of disk space for cache during a network outage. QAN, on the other hand, uses RAM to store cache.</p> </li> <li> <p>Operating system</p> <p>PMM Client runs on any modern 64-bit Linux distribution, including ARM-based systems. It is tested on supported versions of Debian, Ubuntu, CentOS, and Red Hat Enterprise Linux, on both x86_64 and ARM64 architectures. See Percona software support life cycle.</p> </li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#arm-specific-considerations","title":"ARM-specific considerations","text":"<ul> <li>Docker: If using Docker for PMM Client on ARM systems, ensure you\u2019re using the ARM64-compatible Docker images.</li> <li>Performance: Performance may vary across different ARM implementations. Conduct thorough testing to ensure optimal performance in your environment.</li> <li>Compatibility: Ensure you\u2019re using ARM-compatible versions of any additional software or databases you\u2019re monitoring with PMM.</li> <li>PMM Server: PMM Server is not currently available as a native ARM64 build. For ARM-based systems, consider using the Docker or Podman installation methods, which can run x86_64 images via emulation on ARM platforms.</li> <li>Resource usage: Monitor resource usage closely on ARM systems, as it may differ from x86_64 systems. Adjust your configuration as needed for optimal performance.</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html","title":"Network and firewall requirements","text":""},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#ports","title":"Ports","text":"<p>This is a list of ports used by the various components of PMM.</p> <p>For PMM to work correctly, your system\u2019s firewall should allow TCP traffic on these ports (UDP is not needed).</p> <p>Ports to expose:</p> PMM component TCP port Direction Description PMM Server 80 both HTTP server, used for gRPC over HTTP and web interface (insecure, use with caution). PMM Server 443 both HTTPS server, used for gRPC over HTTPS and web interface (secure, use of SSL certificates is highly encouraged). <p>Other ports:</p> PMM component TCP port Direction Description PMM Server 7771 both gRPC, used for communication between <code>pmm-agent</code>, <code>pmm-admin</code>. PMM Server 7772 out HTTP1 server, used for older links like <code>logs.zip</code>. PMM Server 7773 out Debugging. <code>pmm-agent</code> 7777 out Default <code>pmm-agent</code> listen port. <code>vm-agent</code> 8428 both VictoriaMetrics port. <code>pmm-agent</code> 42000 - 51999 in Default range for <code>pmm-agent</code> connected agents. <p>Important</p> <p>Depending on your architecture other ports may also need to be exposed.</p> <ul> <li>For <code>pmm-agent</code>, the default listen port is 7777.</li> <li>The default port range for <code>pmm-agent</code> is large by default to accomodate any architecture size but it can be modified using the <code>--ports-min</code> and <code>--ports-max</code> flags, or modifying the configuration file. In network constraint environments, the range can be reduced to a minimum by allocating at least one port per agent monitored. Learn more about available settings for <code>pmm-agent</code> in Percona PMM-Agent documentation.</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#network-configuration-for-locked-down-environments","title":"Network configuration for locked-down environments","text":"<p>For computers in a locked-down corporate environment without direct access to the Internet, make sure to enable access to Percona Platform services following the instructions in the Percona Platform documentation.</p> <p></p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-pmm/register-client-node/index.html","title":"Register client nodes on PMM Server","text":"<p>Register your client nodes with PMM Server.</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server.</li> <li><code>443</code> is the default port number.</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>Important</p> <p>Clients must be registered with the PMM Server using a secure channel. If you use http as your server URL, PMM will try to connect via https on port 443. If a TLS connection can\u2019t be established you will get an error and you must use https along with the appropriate secure port.</p> Example <p>Register on PMM Server with IP address <code>192.168.33.14</code> using the default <code>admin/admin</code> username and password, a node with IP address <code>192.168.33.23</code>, type <code>generic</code>, and name <code>mynode</code>.</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre> <p></p>"},{"location":"install-pmm/register-client-node/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"optimize/index.html","title":"About PMM optimization","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"optimize/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"optimize/change_number_tables.html","title":"Change the number of tables","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats-limit</code> option changes the number of tables (from the default of 1000) beyond which per-table statistics collection is disabled.</p>"},{"location":"optimize/change_number_tables.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats-limit=&lt;LIMIT&gt;\n</code></pre>"},{"location":"optimize/change_number_tables.html#example","title":"EXAMPLE","text":"<p>Add a MySQL instance, disabling per-table statistics collection when the number of tables in the instance reaches 2000.</p> <pre><code>pmm-admin add mysql --disable-tablestats-limit=2000\n</code></pre> <p></p>"},{"location":"optimize/change_number_tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"optimize/disable_table_stats.html","title":"Disable per-table statistics","text":"<p>You can optimize PMM by disabling per-table statistics for an instance as follows:</p> <p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats</code> option disables table statistics collection when there are more than the default number (1000) of tables in the instance.</p>"},{"location":"optimize/disable_table_stats.html#usage","title":"USAGE","text":"<pre><code>pmm-admin add mysql --disable-tablestats\n</code></pre>"},{"location":"optimize/disable_table_stats.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"optimize/improve_perf.html","title":"Improve PMM performance","text":"<p>You can improve PMM performance with the Table Statistics Options as follows:</p> <p>If a MySQL instance has a lot of schemas or tables, there are two options to help improve the performance of PMM when adding instances with <code>pmm-admin add</code>:</p> <ul> <li><code>--disable-tablestats</code>, or,</li> <li><code>--disable-tablestats-limit</code>.</li> </ul> <p>Important</p> <ul> <li>These settings are only for adding an instance. To change them, you must remove and re-add the instances.</li> <li>Only one of these options can be used when adding an instance.</li> </ul> <p></p>"},{"location":"optimize/improve_perf.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/index.html","title":"About PMM administration","text":"<p>Percona Monitoring and Management (PMM) administration involves  crucial tasks, including the following:</p> <ul> <li>User management</li> <li>Access control</li> <li>Security</li> </ul> <p></p>"},{"location":"pmm-admin/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/uninstall_docker.html","title":"Uninstall PMM client with Docker container","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"pmm-admin/uninstall_docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/uninstall_package_manager.html","title":"Uninstall PMM Client with Package manager","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"pmm-admin/uninstall_package_manager.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/unregister_client.html","title":"Unregister PMM client from PMM Server","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"pmm-admin/unregister_client.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-orgs/index.html","title":"\u200b\u200bAbout organizations in PMM","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"pmm-admin/manage-orgs/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-orgs/create_org.html","title":"Create an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"pmm-admin/manage-orgs/create_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-orgs/del_org.html","title":"Delete an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"pmm-admin/manage-orgs/del_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-orgs/edit_org.html","title":"Edit an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"pmm-admin/manage-orgs/edit_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-users/index.html","title":"About user management in PMM","text":"<p>A user refers to any individual who can log in to PMM. Each user is assigned a specific role that is associated with permissions. Permissions determine the tasks a user can perform in the system. For instance, the Admin role confers permissions that allow an authorized administrator to create and delete user profiles. </p> <p>The following topics are covered as part of access control:</p> <ul> <li>Add users</li> <li>Edit users</li> <li>Delete users</li> </ul>"},{"location":"pmm-admin/manage-users/index.html#next-steps","title":"Next steps","text":"<p>Access control in PMM </p> <p></p>"},{"location":"pmm-admin/manage-users/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-users/add_users.html","title":"Add users","text":"<p>You can add a user in PMM from Administration &gt; Users and access &gt; Users tab.</p> <p></p> <p>To add a new user in PMM:</p> <ol> <li>On the Users tab, click New user.</li> <li> <p>On the Add new user dialog box, enter the following:</p> <ul> <li>Name</li> <li>email address or username (if this is an existing grafana user)</li> <li>Username</li> <li>Password</li> </ul> </li> <li> <p>Click Create user.</p> </li> </ol> <p></p>"},{"location":"pmm-admin/manage-users/add_users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-users/delete_users.html","title":"Delete users","text":""},{"location":"pmm-admin/manage-users/delete_users.html#delete-users","title":"Delete Users","text":"<p>You can delete a user in PMM as follows:</p> <ol> <li>Go to PMM Administration &gt; Users and access &gt; Users tab</li> <li>Click the Edit user icon next to the user you want to delete.</li> <li>Click Delete user.</li> </ol> <p></p>"},{"location":"pmm-admin/manage-users/delete_users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-users/edit_users.html","title":"Edit users","text":"<p>You can edit users by changing the information or settings for an individual user account.</p> <p>Important</p> <p>After changing the default admin password for the PMM Server, register the pmm-agent using the same credentials and add the services again. Otherwise, PMM will cease to monitor the service/nodes.</p>"},{"location":"pmm-admin/manage-users/edit_users.html#grant-or-revoke-admin-privileges","title":"Grant or Revoke admin privileges","text":"<p>You can grant or revoke admin access to a user as follows:</p> <ol> <li> <p>On the Users tab, click the user account you want to edit.</p> </li> <li> <p>To grant or revoke the privileges, click the user. User information dialog box opens.</p> </li> <li> <p>In the Permissions section, click Change and then select Yes/No, depending on whether you want to provide admin access or not.</p> </li> <li> <p>Click Change.</p> </li> </ol> <p>Important</p> <p>After connecting your PMM instance to the Percona Platform, when you log in using your Percona account, you will be granted the Viewer access. For Admin access, log in to PMM as an admin, and change the permissions for this user.</p>"},{"location":"pmm-admin/manage-users/edit_users.html#change-organization-role","title":"Change organization role","text":"<p>You can change the organization role assigned to your user account.</p> <p></p> <p>To change the role:</p> <ol> <li> <p>On the Users tab, click the user for whom you want to change the role.</p> </li> <li> <p>In the Organisations section, click Change role.</p> </li> <li> <p>Select the role from the drop-down and click Save.</p> </li> </ol> <p>The following are the privileges for the various roles:</p> <ul> <li> <p>Admin - Managing data sources, teams, and users within an organization</p> </li> <li> <p>Editor - Creating and editing dashboards</p> </li> <li> <p>Viewer - Viewing dashboards</p> </li> </ul> <p>For detailed information on the privileges for these roles and the different tasks that they can perform, see Grafana organization roles.</p> <p></p>"},{"location":"pmm-admin/manage-users/edit_users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/manage-users/manage_users_in_org.html","title":"\u200b\u200bManage users in an organization","text":"<p>Important</p> <p>The content for this topic is yet to be developed.</p> <p></p>"},{"location":"pmm-admin/manage-users/manage_users_in_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/index.html","title":"About roles and permissions in PMM","text":"<p>Roles are the sets of permissions and configurations that determine which metrics a user can access.</p> <p>Each PMM user is associated with a role that includes permissions. Permissions determine the privileges that a user has in PMM.</p> <p>By creating roles, you can specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related to test environments.</p> <p></p>"},{"location":"pmm-admin/roles/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/delete_users.html","title":"Delete Users","text":"<p>You can delete a user in PMM as follows:</p> <ol> <li> <p>On the User tab, click the user you want to delete.</p> </li> <li> <p>Click Delete user.</p> </li> </ol> <p></p>"},{"location":"pmm-admin/roles/delete_users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/edit_users.html","title":"Edit users in PMM","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"pmm-admin/roles/edit_users.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/manage_users_in_org.html","title":"\u200b\u200bManage users in an organization","text":"<p>PMM collects Linux metrics automatically starting from the moment when you have configured your node for monitoring with <code>pmm-admin config</code>.</p> <p></p>"},{"location":"pmm-admin/roles/manage_users_in_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/assign_roles.html","title":"Assign roles to users","text":"<p>To assign access roles to users:</p> <ol> <li>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</li> <li> <p>Go to Administration &gt; Users and access &gt; Users.</p> </li> <li> <p>Select the User you want to assign to a role from the dropdown. You can assign several roles to a user.</p> <p></p> </li> </ol> <p></p>"},{"location":"pmm-admin/roles/access-control/assign_roles.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/config_access_cntrl.html","title":"Configure access control","text":"<p>You can configure access control in PMM as follows:</p> <ul> <li>Docker</li> <li>User Interface</li> </ul>"},{"location":"pmm-admin/roles/access-control/config_access_cntrl.html#configure-access-control-using-docker","title":"Configure access control using Docker","text":"<p>To configure access roles in a <code>pmm-server</code> docker container, pass an additional environment variable <code>ENABLE_RBAC=1</code> when starting the container.</p> <pre><code>docker run \u2026 -e ENABLE_RBAC=1\n</code></pre> <p>For compose add an additional variable:</p> <pre><code>services:\n  pmm-server:\n    \u2026\n    environment:\n      \u2026\n      ENABLE_RBAC=1\n</code></pre>"},{"location":"pmm-admin/roles/access-control/config_access_cntrl.html#configure-access-control-from-the-ui","title":"Configure access control from the UI","text":"<p>To configure access control from the UI:</p> <p>From the main menu, go to  PMM Configuration &gt; Settings &gt; Advanced Settings &gt; Access Control and click  toggle.</p> <p></p>"},{"location":"pmm-admin/roles/access-control/config_access_cntrl.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/create_roles.html","title":"Create access roles","text":"<p>Roles are a vital part of Access control. Roles provide users with access to specific, role-based metrics.</p> <p>To create access roles in PMM, do the following:</p> <ol> <li>From the main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</li> <li> <p>Go to Administration &gt; Users and access &gt; Access Roles.</p> <p></p> </li> <li> <p>Click Create.</p> </li> <li>On the Create role page, enter the Role name and Role description.</li> <li> <p>Select the following from the drop-downs for metrics access:</p> <ul> <li>Label</li> <li>Operator</li> <li>Value of the label</li> </ul> <p>If you want to add more than one label for a role, click + and select the values from the drop-down.</p> <p>For information on how the Prometheus selectors work, see Prometheus selectors.</p> </li> <li> <p>Click Create role.</p> </li> </ol> <p>Note</p> <p>To create roles, you must have admin privileges. For more information, see Manage users.</p> <p></p>"},{"location":"pmm-admin/roles/access-control/create_roles.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/intro.html","title":"About access control in PMM","text":"<p>Caution</p> <p>PMM Access Control is currently in technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Access control in PMM allows you to manage who has access to individual Prometheus (Victoria Metrics)  metrics based on labels. Thus, access management provides a standardized way of granting, changing, and revoking access to metrics based on the role assigned to the users.</p> <p>The following topics are covered as part of access control:</p> <ul> <li>Configure access control</li> <li>Labels for access control</li> <li>Create access roles</li> <li>Use case</li> </ul> <p></p>"},{"location":"pmm-admin/roles/access-control/intro.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/labels.html","title":"Labels for access control","text":"<p>Label-based access control in PMM allows you to manage who has access to metrics based on labels. By creating roles, you can specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related to test environments. </p> <p>With Label-based access control, you can associate multiple labels with a role, ensuring only data from series that match your defined labels is returned. </p>"},{"location":"pmm-admin/roles/access-control/labels.html#standard-vs-custom-labels","title":"Standard vs custom labels","text":"<p>PMM supports standard as well as custom labels. PMM automatically assigns standard labels. You can also set standard labels when an object (Node, Service, or Agent) is created. Custom labels are assigned and updated only by a user.</p> <p>Examples</p> Label Type Object **Label name ** Example Standard Node node_id 123 Service service_type - mysql, mongodb, postgresql etc. Custom Node, Service, Agent Any string matching regular expression:  [a-zA-Z_][a-zA-Z0-9_]*.  Also, it cannot start with two underscores. owner=\u201djoe\u201d _rack=\u201d12345\u201d"},{"location":"pmm-admin/roles/access-control/labels.html#adding-labels","title":"Adding labels","text":"<p>You can add custom or standard labels in PMM while adding a service for monitoring in PMM.</p>"},{"location":"pmm-admin/roles/access-control/labels.html#using-pmm-ui","title":"Using PMM UI","text":"<p>To set the labels using the user interface:</p> <ol> <li> <p>From the Main menu, go to PMM Configuration &gt; PMM Services &gt; Add Service.</p> </li> <li> <p>Select the service you want to add to PMM for monitoring. The page to add the service opens.</p> </li> <li> <p>Enter the details such as Hostname, Service name, Port, Username, Password, etc., along with Label or Custom labels.</p> </li> </ol> <p></p>"},{"location":"pmm-admin/roles/access-control/labels.html#using-pmm-admin","title":"Using pmm-admin","text":"<p>You can also assign labels using pmm-admin.</p> <p></p>"},{"location":"pmm-admin/roles/access-control/labels.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/manage_roles.html","title":"Manage access roles","text":"<p>You can manage roles in PMM by editing or deleting a role.</p>"},{"location":"pmm-admin/roles/access-control/manage_roles.html#edit-roles","title":"Edit roles","text":"<p>To edit access roles:</p> <ol> <li>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</li> <li> <p>Go to Administration &gt; Users and access &gt; Access Roles.</p> </li> <li> <p>On the role you want to edit, click the ellipsis (three vertical dots) &gt; edit role in the Options column. The Edit role page opens.</p> <p></p> </li> <li> <p>Make the required changes to the role.</p> </li> <li> <p>Click Save Changes.</p> </li> </ol>"},{"location":"pmm-admin/roles/access-control/manage_roles.html#set-a-role-as-default","title":"Set a role as default","text":"<p>When a user signs in to PMM for the first time and the user has no role assigned, the user is automatically assigned the Default role. For administrators, the default role provides a convenient way to configure default permissions for new users.</p> <p>To set a role as default, do the following:</p> <ol> <li>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</li> <li>Go to Administration &gt; Users and access &gt; Access Roles.</li> <li>On the role you want to set as default, click the ellipsis (three vertical dots) \u2192 set as default in the Options column.</li> </ol>"},{"location":"pmm-admin/roles/access-control/manage_roles.html#remove-roles","title":"Remove roles","text":"<p>To remove access roles, do the following:</p> <ol> <li> <p>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</p> </li> <li> <p>On the role you want to remove, click the ellipsis (three vertical dots) &gt; Delete in the Options column. Delete role pop-up opens.</p> </li> <li> <p>Click Confirm and delete the role.</p> </li> </ol> <p></p>"},{"location":"pmm-admin/roles/access-control/manage_roles.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/roles/access-control/usecase.html","title":"Use Case","text":""},{"location":"pmm-admin/roles/access-control/usecase.html#use-case-1","title":"Use case 1","text":"<p>This use case demonstrates the following scenario:</p> <p>Labels</p> <ul> <li> <p>Environments: prod and qa</p> </li> <li> <p>Projects: shop and bank</p> </li> </ul> <p>Roles</p> <ul> <li>Roles: Admin, Dev and QA</li> </ul> <p>An overview of the infrastructure can be seen in the diagram below. PMM monitors several services. The metrics that are stored in VictoriaMetrics have the appropriate labels.</p> <p></p> <p>This diagram shows several roles within a company structure that have access to PMM, as well as the permissions they should be granted:</p> <ul> <li>Admin role - has access to all the metrics</li> <li>DBA role - has access to all metrics within env=prod only</li> <li> <p>QA role - has access to all metrics within env=qa only</p> <p></p> </li> </ul>"},{"location":"pmm-admin/roles/access-control/usecase.html#use-case-2","title":"Use case 2","text":"<p>The use case demonstrates the following scenario:</p> <p>Labels</p> <ul> <li> <p>Environments: prod and dev</p> </li> <li> <p>Services: postgresql and mysql</p> </li> </ul> <p>Roles</p> <ul> <li>role_postresql</li> <li>role_mysql</li> </ul> Role assigned Labels applied to the role Accessible Metrics User 1 role_postresql dev, service_name=postgresql The metrics for service postgresql will be accessible. User 2 role_mysql prod, service_name=mysql The metrics for service mysql will be accessible. User 3 role_postgresql and role_mysql dev, service_name=postgresql and  prod, service_name=mysql The metrics for both the services mysql and postresql will be accessible. <p></p>"},{"location":"pmm-admin/roles/access-control/usecase.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/security/index.html","title":"About security in PMM","text":"<p>By Default, PMM ships with a self-signed certificate to enable usage out of the box.  While this does enable users to have encrypted connections between clients (database clients and web/API clients) and the PMM Server, it shouldn\u2019t be considered a properly secured connection.  Taking the following precautions will ensure that you are truly secure:</p> <ul> <li> <p>SSL encryption with trusted certificates to secure traffic between clients and server;</p> </li> <li> <p>Grafana HTTPS secure cookies</p> </li> </ul> <p></p>"},{"location":"pmm-admin/security/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/security/data_encryption.html","title":"PMM data encryption","text":"<p>Percona Monitoring and Management (PMM) implements robust encryption for sensitive data stored in its internal database\u2019s <code>agent</code> table. This includes access credentials and configuration details.</p>"},{"location":"pmm-admin/security/data_encryption.html#default-encryption","title":"Default encryption","text":"<p>PMM automatically manages encryption using a key file located at <code>/srv/pmm-encryption.key</code>. PMM generates this file upon the initial launch of PMM 3 or when upgrading from the latest version of PMM 2.</p>"},{"location":"pmm-admin/security/data_encryption.html#custom-encryption-key-configuration","title":"Custom encryption key configuration","text":"<p>For enhanced security control, PMM supports custom encryption keys.</p> <p>To set up a custom keys, configure the <code>PMM_ENCRYPTION_KEY_PATH</code> environment variable to point to your custom key file.</p> <p>Important</p> <p>Make sure to set this configuration  before any data encryption occurs\u2014specifically, either before upgrading to PMM 3 or before the initial startup of a new PMM 3.x container.</p>"},{"location":"pmm-admin/security/data_encryption.html#key-management-requirements","title":"Key management requirements","text":"<p>Once configured, PMM will use custom keys to encrypt and decrypt all sensitive data stored within the system.</p> <p>If the custom key is unavailable or misplaced, PMM will be unable to access and decrypt the stored data, which will prevent it from running correctly.</p> <p>Make sure to store and manage the custom encryption key securely to avoid potential loss of data access.</p>"},{"location":"pmm-admin/security/data_encryption.html#rotating-the-encryption-key","title":"Rotating the encryption key","text":"<p>You may want to change or update the encryption key when the original key is compromised or as part of routine security maintenance. For this, you can use the PMM Encryption Rotation Tool.</p> <p>This tool re-encrypts all existing sensitive data with a newly generated encryption key, ensuring continuous security with minimal disruption.</p> <p>To rotate or regenerate the encryption key:</p> <ol> <li> <p>Log in to the container that runs PMM Server.</p> </li> <li> <p>Run the Encryption Rotation Tool using the following the command:</p> <p><code>bash    pmm-encryption-rotation</code></p> <ul> <li>Ensure <code>PMM_ENCRYPTION_KEY_PATH</code> is set to the current custom key if using one, so the tool can decrypt data before re-encryption.</li> <li>If using custom credentials/SSL for the PMM internal database, provide them with the appropriate flags.</li> </ul> </li> <li> <p>Verify PMM functionality all components are functioning properly to ensure that the encryption key rotation was successful.</p> </li> </ol> <p>Once the rotation tool has completed, a new encryption key will be generated and saved either in the default location (<code>/srv/pmm-encryption.key</code>) or in the path specified by <code>PMM_ENCRYPTION_KEY_PATH</code>. The tool will automatically re-encrypt all sensitive data with the new key.</p>"},{"location":"pmm-admin/security/data_encryption.html#best-pracices-for-custom-key-management","title":"Best pracices for custom key management","text":"<ul> <li>Always keep a secure backup of your encryption key, especially when using <code>PMM_ENCRYPTION_KEY_PATH</code>, as it is critical to PMM\u2019s data decryption process.</li> <li>In containerized environments, ensure <code>PMM_ENCRYPTION_KEY_PATH</code> is persistently set in the container configuration to avoid issues during restarts.</li> <li>Test the encryption key rotation process in a staging environment before applying it in production to minimize potential downtime or configuration issues.</li> </ul>"},{"location":"pmm-admin/security/data_encryption.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/security/grafana_cookies.html","title":"Grafana HTTPS secure cookies","text":"<p>To enable:</p> <ol> <li> <p>Start a shell within the Docker container.</p> <pre><code>docker exec -it pmm-server bash\n</code></pre> </li> <li> <p>Edit <code>/etc/grafana/grafana.ini</code>.</p> </li> <li> <p>Enable <code>cookie_secure</code> and set the value to <code>true</code>.</p> </li> <li> <p>Restart Grafana.</p> <pre><code>supervisorctl restart grafana\n</code></pre> </li> </ol> <p></p>"},{"location":"pmm-admin/security/grafana_cookies.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-admin/security/ssl_encryption.html","title":"SSL encryption","text":"<p>Valid and trusted SSL certificates are needed to encrypt traffic between the client and server.  Certificates can be purchased online from various sources, or some organizations generate their own trusted certificates.  Regardless of which path you choose for enabling maximum security, the process to secure PMM consists of the following components:</p> <ol> <li> <p>Staging the files in the proper locations:</p> <ul> <li>You can directly mount to a local directory containing the required certificates or</li> <li>You can copy the files to the appropriate directory in your Container|AMI|OVF</li> </ul> </li> <li> <p>Restarting PMM</p> </li> <li>Ensuring the client(s) trust the certificate issuer (Ubuntu | RedHat can get you started but this is somewhat OS specific)</li> </ol> <p>With our Docker, OVF and AMI images, certificates are stored in <code>/srv/nginx</code> and our self-signed certificates are staged there by default.</p>"},{"location":"pmm-admin/security/ssl_encryption.html#mounting-certificates","title":"Mounting certificates","text":"<p>For container-based installation, if your certificates are in a directory called <code>/etc/pmm-certs</code> on the container host, run the following to mount that directory in the proper location so that PMM can find it when the container starts:</p> <pre><code>docker run -d -p 443:443 --volumes-from pmm-data \\\n  --name pmm-server -v /etc/pmm-certs:/srv/nginx \\\n  --restart always perconalab/pmm-server:3.0.0-beta\n</code></pre> <ul> <li>All certificates must be owned by root. You can do this with: <code>chown 0:0 /etc/pmm-certs/*</code></li> <li>The mounted certificate directory (<code>/etc/pmm-certs</code> in this example) must contain the files named <code>certificate.crt</code>, <code>certificate.key</code>, <code>ca-certs.pem</code>, and <code>dhparam.pem</code>.</li> <li>For SSL encryption, the container should publish on port 443 instead of 80.</li> </ul>"},{"location":"pmm-admin/security/ssl_encryption.html#copying-certificates","title":"Copying certificates","text":"<p>If PMM Server is running as a Docker image, use <code>docker cp</code> to copy certificates. This example copies certificate files from the current working directory to a running PMM Server docker container.</p> <pre><code>docker cp certificate.crt pmm-server:/srv/nginx/certificate.crt\ndocker cp certificate.key pmm-server:/srv/nginx/certificate.key\ndocker cp ca-certs.pem pmm-server:/srv/nginx/ca-certs.pem\ndocker cp dhparam.pem pmm-server:/srv/nginx/dhparam.pem\ndocker exec -it pmm-server chown root.root /srv/nginx/*\n</code></pre>"},{"location":"pmm-admin/security/ssl_encryption.html#use-trusted-ssl-when-connecting-pmm-client-to-pmm-server","title":"Use trusted SSL when connecting PMM Client to PMM Server","text":"<p>For the new trusted certificates to take effect, you\u2019ll just need to restart the PMM Server (or advanced users can restart just nginx from a shell: supervisorctl restart nginx). </p> <p>You can now register clients to the PMM Server using the following: <pre><code>pmm-admin config --server-url=https://&lt;user&gt;:&lt;password&gt;@&lt;server IP&gt;\n</code></pre></p> <p>Remember</p> <p>Your client machine(s) must trust the issuer of the certificate, or you will still see \u201cuntrusted connections\u201d messages when accessing the web interface. Thus, your client will need the <code>--server-insecure-tls</code> parameter when running the <code>pmm-admin config</code> command. Follow the instructions on your operating system to install the issuer certificate (ca-certs.pem). </p> <p>In case of PMM Client running in the container, mount certificates to <code>/etc/pki/tls/certs</code>:</p> <pre><code>PMM_SERVER=X.X.X.X:443\ndocker run \\\n--rm \\\n--name pmm-client \\\n-e PMM_AGENT_SERVER_ADDRESS=${PMM_SERVER} \\\n-e PMM_AGENT_SERVER_USERNAME=admin \\\n-e PMM_AGENT_SERVER_PASSWORD=admin \\\n-e PMM_AGENT_SETUP=1 \\\n-e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n-v /your_directory_with/certs:/etc/pki/tls/certs \\\n--volumes-from pmm-client-data \\\npercona/pmm-client:2\n</code></pre> <p></p>"},{"location":"pmm-admin/security/ssl_encryption.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/index.html","title":"About PMM Server upgrade","text":"<p>Upgrade PMM Server before Clients</p> <ul> <li>When upgrading PMM, always upgrade the PMM Server before upgrading any PMM Clients.</li> <li>Make sure that the PMM Server version is higher than or equal to the PMM Client version. Mismatched versions can lead to configuration issues and failures in Client-Server communication, as the PMM Server may not recognize all parameters in the client configuration.</li> </ul> <p>Find the detailed information on how to upgrade PMM in the following sections:</p> <ul> <li> <p>Upgrade PMM Server from the UI</p> </li> <li> <p>Upgrade PMM Client</p> </li> <li> <p>Upgrade PMM Server using Docker</p> </li> <li> <p>Migrate from PMM 2</p> </li> </ul> <p></p>"},{"location":"pmm-upgrade/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html","title":"Migrate PMM 2 to PMM 3","text":"<p>PMM 3 introduces significant architectural changes that require gradual transition from PMM 2:</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-1-upgrade-pmm-2-server-to-the-latest-version","title":"Step 1: Upgrade PMM 2 Server to the latest version","text":"<p>Before upgrading to PMM 3, ensure your PMM 2 Server is running the latest version:</p> <ol> <li>From the Home page, scroll to the PMM Upgrade panel and click the Refresh button to manually check for updates.</li> <li>If an update is available, click the Update button to install the latest PMM 2 version.</li> <li>Verify the update was successful by checking the version number after the update completes.</li> </ol>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-2-migrate-pmm-2-server-to-pmm-3","title":"Step 2: Migrate PMM 2 Server to PMM 3","text":"PMM 2 with Docker volumePMM 2 with data container <p>Follow these manual steps to upgrade your PMM 2 Server to PMM 3:</p> <ol> <li> <p>Stop all PMM Server services:</p> <pre><code>docker exec -t &lt;pmm-server&gt; supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:</p> <pre><code> docker exec -t &lt;pmm-server&gt; chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>List and note down your Docker volume:</p> <pre><code>docker inspect -f '{{ range .Mounts }}{{ if eq .Type \"volume\" }}{{ .Name }}{{ \"\\n\" }}{{ end }}{{ end }}' &lt;pmm-server&gt;\n</code></pre> </li> <li> <p>Stop and remove existing container:</p> <pre><code>docker stop pmm-server &amp;&amp; docker rm pmm-server\n</code></pre> </li> <li> <p>Pull PMM 3 Server image:</p> <pre><code>docker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Run new container with existing volume:</p> <pre><code>docker run -d -v pmm-server-data:/srv -p 443:8443 --name pmm-server --restart always perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol> <p>Follow these manual steps to upgrade your PMM 2 Server to PMM 3:</p> <ol> <li> <p>Stop all PMM Server services:</p> <pre><code>docker exec -t &lt;pmm-server&gt; supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:</p> <pre><code>docker exec -t &lt;pmm-server&gt; chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>Identify data container using either:</p> <pre><code>docker ps -a --filter \"status=created\"\n</code></pre> <p>OR</p> <pre><code>docker inspect -f '{{ range .Mounts }}{{ if eq .Type \"volume\" }}{{ .Name }}{{ \"\\n\" }}{{ end }}{{ end }}' &lt;pmm-server&gt;\n</code></pre> </li> <li> <p>Stop and remove existing container:</p> <pre><code>docker stop pmm-server &amp;&amp; docker rm pmm-server\n</code></pre> </li> <li> <p>Pull PMM 3 Server image:</p> <pre><code>docker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> <li> <p>Run new container with existing data container:</p> <pre><code>docker run -d --volumes-from pmm-server-data -p 443:8443 --name pmm-server --restart always perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-3-migrate-pmm-2-clients-to-pmm-3","title":"Step 3: Migrate PMM 2 Clients to PMM 3","text":"<p>Important</p> <p>PMM 3 Server provides limited support for PMM 2 Clients (metrics and Query Analytics only). This support will be removed in PMM 3.3.</p> <p>Depending on your initial installation method, update PMM Clients using your operating system\u2019s package manager or by updating from a tarball. For detailed instructions, see the Upgrade PMM Client topic.</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#post-migration-steps","title":"Post-migration steps","text":"<p>After you finish migrating:</p> <ol> <li>Verify that all PMM Clients are up to date by checking PMM Configuration &gt; Updates.</li> <li>Confirm all previously monitored services are reporting correctly to the new PMM 3 Server by reviewing Configuration &gt; PMM Inventory &gt; Services.</li> <li>Check the dashboards to make sure you\u2019re receiving the metrics information and QAN data.</li> </ol> <p></p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/ui_upgrade.html","title":"Upgrade PMM v3 Server from the UI","text":"<p>PMM Server and Client components are installed and updated separately.</p> <p>PMM v3 Server can run natively, as a Docker image, a virtual appliance, or an AWS cloud instance. While each environment has its own specific installation and update steps, the UI-based upgrade method is universal and recommended for most users.</p>"},{"location":"pmm-upgrade/ui_upgrade.html#upgrade-process","title":"Upgrade process","text":"<p>The preferred and simplest way to update PMM v3 Server is via the Updates page:</p> <ol> <li> <p>Go to PMM Configuration &gt; Updates in your PMM web interface. Here you can check the current PMM Server version, the timestamp of the last update check and whether your instance is up-to-date.  </p> </li> <li> <p>If an update is available, click the Update now button to install the latest version.</p> </li> </ol> <p></p>"},{"location":"pmm-upgrade/ui_upgrade.html#quick-upgrade-check","title":"Quick upgrade check","text":"<p>For a quick overview of your PMM v3 Server\u2019s update status, you can also check to the Upgrade panel on the Home page.</p> <p></p> <p></p>"},{"location":"pmm-upgrade/ui_upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/upgrade_aws.html","title":"Upgrade PMM Server on AWS","text":""},{"location":"pmm-upgrade/upgrade_aws.html#change-public-ip-address","title":"Change public IP address","text":"<p>To assign a public IP address for an Amazon EC2 instance, follow these steps:</p> <ol> <li> <p>Allocate Elastic IP address</p> <p></p> </li> <li> <p>Associate Elastic IP address with a Network interface ID of your EC2 instance</p> <p>If you associate an Elastic IP address to an instance that already has an Elastic IP address associated, this previously associated Elastic IP address will be disassociated but still allocated to your account.</p> <p></p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#upgrade-ec2-instance-class","title":"Upgrade EC2 instance class","text":"<p>Upgrading to a larger EC2 instance class is supported by PMM provided you follow the instructions from the AWS manual. The PMM AMI image uses a distinct EBS volume for the PMM data volume which permits independent resizing of the EC2 instance without impacting the EBS volume.</p> <ol> <li> <p>Open the Amazon EC2 console.</p> </li> <li> <p>In the navigation pane, choose PMM Server Instances.</p> </li> <li> <p>Select the instance and choose Actions, Instance state, Stop instance.</p> </li> <li> <p>In the Change instance type dialog box, select the instance type that you want.</p> <p></p> </li> <li> <p>Choose Apply to accept the new settings and start the stopped instance.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#expand-pmm-data-ebs-volume","title":"Expand PMM Data EBS Volume","text":"<p>The PMM data volume is mounted as an XFS formatted volume on top of an LVM volume. There are two ways to increase this volume size:</p> <ol> <li> <p>Add a new disk via EC2 console or API, and expand the LVM volume to include the new disk volume.</p> </li> <li> <p>Expand existing EBS volume and grow the LVM volume.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#expand-existing-ebs-volume","title":"Expand existing EBS volume","text":"<p>To expand the existing EBS volume for increased capacity, follow these steps.</p> <ol> <li> <p>Expand the disk from AWS Console/CLI to the desired capacity.</p> </li> <li> <p>Login to the PMM EC2 instance and verify that the disk capacity has increased. For example, if you have expanded your disk from 16G to 32G, <code>dmesg</code> output should look like below:</p> <pre><code>[  535.994494] xvdb: detected capacity change from 17179869184 to 34359738368\n</code></pre> </li> <li> <p>You can check information about volume groups and logical volumes with the <code>vgs</code> and <code>lvs</code> commands:</p> <pre><code>vgs\n</code></pre> <pre><code>VG     #PV #LV #SN Attr   VSize  VFree\nDataVG   1   2   0 wz--n- &lt;16.00g    0\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.74\nThinPool DataVG twi-aotz--  15.96g 1.39  1.29\n</code></pre> </li> <li> <p>Now we can use the <code>lsblk</code> command to see that our disk size has been identified by the kernel correctly, but LVM2 is not yet aware of the new size. We can use <code>pvresize</code> to make sure the PV device reflects the new size. Once <code>pvresize</code> is executed, we can see that the VG has the new free space available.</p> <pre><code>lsblk | grep xvdb\n</code></pre> <pre><code>xvdb                      202:16 0 32G 0 disk\n</code></pre> <pre><code>pvscan\n</code></pre> <pre><code>PV /dev/xvdb   VG DataVG    lvm2 [&lt;16.00 GiB / 0    free]\nTotal: 1 [&lt;16.00 GiB] / in use: 1 [&lt;16.00 GiB] / in no VG: 0 [0   ]\n</code></pre> <pre><code>pvresize /dev/xvdb\n</code></pre> <pre><code>Physical volume \"/dev/xvdb\" changed\n1 physical volume(s) resized / 0 physical volume(s) not resized\n</code></pre> <pre><code>pvs\n</code></pre> <pre><code>PV         VG     Fmt  Attr PSize   PFree\n/dev/xvdb  DataVG lvm2 a--  &lt;32.00g 16.00g\n</code></pre> </li> <li> <p>We then extend our logical volume. Since the PMM image uses thin provisioning, we need to extend both the pool and the volume:</p> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  15.96g                 1.42   1.32\n</code></pre> <pre><code>lvextend /dev/mapper/DataVG-ThinPool -l 100%VG\n</code></pre> <pre><code>Size of logical volume DataVG/ThinPool_tdata changed from 16.00 GiB (4096 extents) to 31.96 GiB (8183 extents).\nLogical volume DataVG/ThinPool_tdata successfully resized.\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> </li> <li> <p>Once the pool and volumes have been extended, we need to now extend the thin volume to consume the newly available space. In this example we\u2019ve grown available space to almost 32GB, and already consumed 12GB, so we\u2019re extending an additional 19GB:</p> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;12.80g ThinPool        1.77\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> <pre><code>lvextend /dev/mapper/DataVG-DataLV -L +19G\n</code></pre> <pre><code>Size of logical volume DataVG/DataLV changed from &lt;12.80 GiB (3276 extents) to &lt;31.80 GiB (8140 extents).\nLogical volume DataVG/DataLV successfully resized.\n</code></pre> <pre><code>lvs\n</code></pre> <pre><code>LV       VG     Attr       LSize   Pool    Origin Data%  Meta% Move Log Cpy%Sync Convert\nDataLV   DataVG Vwi-aotz-- &lt;31.80g ThinPool        0.71\nThinPool DataVG twi-aotz--  31.96g                 0.71   1.71\n</code></pre> </li> <li> <p>We then expand the XFS file system to reflect the new size using <code>xfs_growfs</code>, and confirm the file system is accurate using the <code>df</code> command.</p> <pre><code>df -h /srv\n</code></pre> <pre><code>Filesystem                  Size Used Avail Use% Mounted on\n/dev/mapper/DataVG-DataLV    13G 249M   13G   2% /srv\n</code></pre> <pre><code>xfs_growfs /srv\n</code></pre> <pre><code>meta-data=/dev/mapper/DataVG-DataLV isize=512    agcount=103, agsize=32752 blks\n         =                          sectsz=512   attr=2, projid32bit=1\n         =                          crc=1        finobt=0 spinodes=0\ndata     =                          bsize=4096   blocks=3354624, imaxpct=25\n         =                          sunit=16     swidth=16 blks\nnaming   =version 2                 bsize=4096   ascii-ci=0 ftype=1\nlog      =internal                  bsize=4096   blocks=768, version=2\n         =                          sectsz=512   sunit=16 blks, lazy-count=1\nrealtime =none                      extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 3354624 to 8335360\n</code></pre> <pre><code>df -h /srv\n</code></pre> <pre><code>Filesystem                 Size Used Avail Use% Mounted on\n/dev/mapper/DataVG-DataLV   32G 254M   32G   1% /srv\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#expand-amazon-ebs-root-volume","title":"Expand Amazon EBS root volume","text":"<p>To expand the Amazon EBS root volume:</p> <ol> <li> <p>Expand the disk from AWS Console/CLI to the desired capacity.</p> </li> <li> <p>Login to the PMM EC2 instance and verify that the disk capacity has increased. For example, if you have expanded disk from 8G to 10G, <code>dmesg</code> output should look like below:</p> <pre><code># dmesg | grep \"capacity change\"\n[63175.044762] nvme0n1: detected capacity change from 8589934592 to 10737418240\n</code></pre> </li> <li> <p>Use the <code>lsblk</code> command to see that our disk size has been identified by the kernel correctly, but LVM2 is not yet aware of the new size.</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0     8G  0 part /\n...\n</code></pre> </li> <li> <p>For volumes that have a partition, such as the root volume shown in the previous step, use the <code>growpart</code> command to extend the partition.</p> <pre><code># growpart /dev/nvme0n1 1\nCHANGED: partition=1 start=2048 old: size=16775168 end=16777216 new: size=20969439 end=20971487\n</code></pre> </li> <li> <p>To verify that the partition reflects the increased volume size, use the <code>lsblk</code> command again.</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0    10G  0 part /\n...\n</code></pre> </li> <li> <p>Extend the XFS file system on the root volume by <code>xfs_growfs</code> command. I</p> <pre><code># xfs_growfs -d /\nmeta-data=/dev/nvme0n1p1         isize=512    agcount=4, agsize=524224 blks\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0 spinodes=0\ndata     =                       bsize=4096   blocks=2096896, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal               bsize=4096   blocks=2560, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 2096896 to 2621120\n</code></pre> </li> <li> <p>Verify that file system reflects the increased volume size</p> <pre><code># df -hT /\nFilesystem     Type  Size  Used Avail Use% Mounted on\n/dev/nvme0n1p1 xfs    10G  5,6G  4,5G  56% /\n</code></pre> </li> </ol> <p></p>"},{"location":"pmm-upgrade/upgrade_aws.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/upgrade_client.html","title":"Upgrade PMM Client","text":"<p>There are two primary methods to update PMM Clients, depending on your initial installation method:</p> <ol> <li>Using your operating system\u2019s package manager</li> <li>Updating from a tarball</li> </ol>"},{"location":"pmm-upgrade/upgrade_client.html#1-package-manager-method","title":"1. Package Manager method","text":"<p>The package manager method is generally more convenient and efficient. Percona provides the percona-release package, which helps you install Percona software, including PMM Client. PMM Client is available from the <code>pmm-client</code> repository.</p> <p>To deploy a new version of the Client via package manager, simply replace the currently installed package with the latest version of the PMM Client or with a specific version.</p>"},{"location":"pmm-upgrade/upgrade_client.html#install-the-latest-pmm-client-version","title":"Install the latest PMM Client version","text":"<p>Run the commands below to install the latest PMM Client version via package manager and keep your existing Client configuration during the update process.</p> <p>For example, to install the latest version of the PMM Client on Red Hat or its derivatives:</p> <pre><code>percona-release enable pmm-client\nyum update pmm-client\n</code></pre>"},{"location":"pmm-upgrade/upgrade_client.html#deploy-a-specific-version","title":"Deploy a specific version","text":"<p>To deploy a specific version of the PMM Client via package manager, check the available versions and then provide the full name of the package. For example:</p> <pre><code>yum --showduplicates search pmm-client\npmm-client-3.0.0-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\npmm-client-3.0.1-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\nyum update pmm-client-3.0.1-6.el9.x86_64\n</code></pre>"},{"location":"pmm-upgrade/upgrade_client.html#2-tarball-method","title":"2. Tarball method","text":"<p>If you initially installed the PMM Client from a tarball, you can update it by replacing the currently installed package with the latest version:</p> <ol> <li>Download <code>tar.gz</code> with <code>pmm-client</code>.</li> <li>Extract the tarball.</li> <li>Run <code>./install_tarball</code> script with the <code>-u</code> flag.</li> </ol> <p>Important</p> <p>The configuration file will be overwritten if you do not provide the <code>-u</code> flag while the <code>pmm-agent</code> is updated.</p> <p></p>"},{"location":"pmm-upgrade/upgrade_client.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/upgrade_docker.html","title":"Upgrade PMM Server using Docker","text":""},{"location":"pmm-upgrade/upgrade_docker.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires an backup made prior to the upgrade.</p> </li> <li> <p>Verify your current PMM version: Check your current PMM version by navigating to PMM Configuration &gt; Updates or by running the following command: </p> <p><code>sh    docker exec -it pmm-server curl -ku admin:admin https://localhost:8443/v1/version</code></p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_docker.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings. In case of any issues, you can restore your system using the backup created in the preparation steps.</p> <ol> <li> <p>Stop the current container:</p> <p><code>sh    docker stop pmm-server</code></p> </li> <li> <p>Back up your data.</p> </li> <li> <p>Pull the latest image:</p> <p><code>sh    docker pull perconalab/pmm-server:3.0.0-beta</code></p> </li> <li> <p>Rename the original container:</p> <p><code>sh    docker rename pmm-server pmm-server-old</code></p> </li> <li> <p>Run the new container:</p> <p><code>sh    docker run \\    --detach \\    --restart always \\    --publish 443:8443 \\    --volumes-from pmm-data \\    --name pmm-server \\    perconalab/pmm-server:3.0.0-beta</code></p> </li> <li> <p>After upgrading, verify that PMM Server is running correctly and all your data is accessible.</p> </li> </ol> <p></p>"},{"location":"pmm-upgrade/upgrade_docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/upgrade_helm.html","title":"Upgrade PMM Server using Helm","text":"<p>Percona releases new chart versions to update containers when:</p> <ul> <li>A new version of the main container is available</li> <li>Significant changes are made</li> <li>Critical vulnerabilities are addressed</li> </ul> <p>UI Update feature disabled by default</p> <p>The UI update feature is disabled by default and should remain so. Do not modify or add the following parameter in your custom <code>values.yaml</code> file: <pre><code>pmmEnv:\nDISABLE_UPDATES: \"1\"\n</code></pre></p>"},{"location":"pmm-upgrade/upgrade_helm.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires a backup made prior to the upgrade.</p> </li> <li> <p>To reduce downtime, pre-pull the new image on the node where PMM is running:</p> <pre><code># Replace &lt;version&gt; with the latest PMM version\ndocker pull perconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_helm.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings\u2014you can restore from your backup if needed.</p> <ol> <li> <p>Update Helm repository:</p> <pre><code>helm repo update percona\n</code></pre> </li> <li> <p>Upgrade PMM:</p> <pre><code>helm upgrade pmm -f values.yaml percona/pmm\n</code></pre> </li> <li> <p>After the upgrade, verify that PMM Server is running correctly:</p> <pre><code>kubectl get pods | grep pmm-server\n</code></pre> </li> <li> <p>Check the logs for any errors:</p> <pre><code>kubectl logs deployment/pmm-server\n</code></pre> </li> </ol> <p></p>"},{"location":"pmm-upgrade/upgrade_helm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pmm-upgrade/upgrade_podman.html","title":"Upgrade PMM Server using Podman","text":""},{"location":"pmm-upgrade/upgrade_podman.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires an backup made prior to the upgrade.</p> </li> <li> <p>Verify your current PMM version: Check your current PMM version by navigating to PMM Configuration &gt; Updates or by running the following command: </p> <pre><code>podman exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_podman.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings\u2014you can restore from your backup if needed.</p> <ol> <li> <p>Back up your data.</p> </li> <li> <p>Update PMM tag by editing <code>~/.config/systemd/user/pmm-server.env</code> file and running the following command to set the latest release version:</p> <pre><code>sed -i \"s/PMM_IMAGE=.*/PMM_IMAGE=docker.io/percona/pmm-server:3.0.0/g\" ~/.config/systemd/user/pmm-server.env\n</code></pre> </li> <li> <p>Pre-pull the new image to ensure a faster restart:</p> <pre><code>source ~/.config/systemd/user/pmm-server.env\npodman pull ${PMM_IMAGE}:${PMM_TAG}\n</code></pre> </li> <li> <p>Restart PMM Server:</p> <pre><code>systemctl --user restart pmm-server\n</code></pre> </li> <li> <p>After the upgrade, verify that PMM Server is running correctly:</p> <pre><code>podman ps | grep pmm-server\n</code></pre> </li> <li> <p>Check the logs for any errors:</p> <pre><code>podman logs pmm-server\n</code></pre> </li> </ol> <p></p>"},{"location":"pmm-upgrade/upgrade_podman.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"quickstart/index.html","title":"Get started with PMM","text":"<p>To get up and running with Percona Monitoring and Management (PMM) in no time, install PMM on Bare Metal/Virtual using the Easy-install script for Docker.</p> <p>This is the simplest and most efficient way to install PMM.</p> Alternative installation options <p>For alternative setups, explore the additional installation options detailed in the Setting up chapter:</p> <ul> <li>Deploy on Podman</li> <li>Deploy based on a Docker image</li> <li>Deploy on Virtual Appliance</li> <li>Deploy on Kubernetes via Helm</li> <li>Run a PMM instance hosted at AWS Marketplace</li> </ul>"},{"location":"quickstart/index.html#prerequisites","title":"Prerequisites","text":"<p>Before you start installing PMM, verify that your system meets the compatibility requirements.</p> Verify system compatibility <ul> <li>Disk: Approximately 1 GB of storage per monitored database node with data retention set to one week. By default, retention is 30 days.</li> <li>Memory: A minimum of 2 GB per monitored database node. The increase in memory usage is not proportional to the number of nodes. For example, the data from 20 nodes should be easily handled with 16 GB.</li> <li>Ports: Your system\u2019s firewall should allow TCP traffic on port 443.</li> </ul>"},{"location":"quickstart/index.html#install-pmm","title":"Install PMM","text":"<p>The Easy-install script only runs on Linux-compatible systems. To use it, run the command with <code>sudo</code> privileges or as <code>root</code>:</p> <ol> <li> <p>Download and install PMM using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>curl -fsSL https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash\n</code></pre> <pre><code>wget -qO - https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash    \n</code></pre> </li> <li> <p>After the installation is complete, log into PMM with the default <code>admin:admin</code> credentials.</p> </li> </ol> What\u2019s happening under the hood? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not installed on your system.</li> <li>Stops and renames any currently running PMM Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old <code>pmm-server</code> container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Docker image.</li> </ul>"},{"location":"quickstart/index.html#connect-database","title":"Connect database","text":"<p>Once PMM is set up, choose the database or the application that you want it to monitor:</p>  MySQL PostgreSQL MongoDB ProxySQL HAProxy <p>To connect a self-hosted MySQL database:</p> <ol> <li> <p>Create database account for PMM using the following command example. This creates a database user with name <code>pmm</code>, password <code>&lt;your_password&gt;</code>, and the necessary permissions:</p> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY '&lt;your_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:    </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install the Percona Release Tool.  If this is already, make sure to update it to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install percona-release tool. If this is already installed, update percona-release to the latest version.</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MySQL database using Performance Schema:  </p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> Alternative database connection workflows <p>While the default instructions above focus on connecting a self-hosted MySQL database, PMM offers the flexibility to connect to various MySQL databases, including AWS RDS, Azure MySQL or Google Cloud MySQL. </p> <p>The PMM Client installation also comes with options: in addition to the installation via Package Manager described above, you can also install it as a Docker container or as a binary package. Explore alternative PMM Client installation options for more information.</p> <p>Additionally, if direct access to the database node isn\u2019t available, opt to Add remote instance via User Interface instead. </p> <p>To connect a PostgreSQL database: </p> <ol> <li> <p>Create a PMM-specific user for monitoring:</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '&lt;your_password&gt;';\n</code></pre> </li> <li> <p>Ensure that PMM can log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If  not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> </li> <li> <p>Set up the <code>pg_stat_monitor</code> database extension and configure your database server accordingly. </p> <p>If you need to use the <code>pg_stat_statements</code> extension instead, see Adding a PostgreSQL database and the <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Set or change the value for <code>shared_preload_library</code> in your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> </li> <li> <p>Set up configuration values in your <code>postgresql.conf</code> file:</p> <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre> </li> <li> <p>In a <code>psql</code> session, run the following command to create the view where you can access the collected statistics. We recommend that you create the extension for the <code>postgres</code> database so that you can receive access to statistics from each database.</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:  </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the PostgreSQL database:</p> <pre><code>pmm-admin add postgresql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions and advanced installation options, see Adding a PostgreSQL database.</p> <p>To connect a MongoDB database:</p> <ol> <li> <p>Run the following command in <code>mongo</code> shell to create a role with the monitoring permissions: </p> <pre><code>db.createRole({\n    \"role\":\"explainRole\",\n    \"privileges\":[\n        {\n            \"resource\":{\n                \"db\":\"\",\n                \"collection\":\"\"\n            },\n            \"actions\":[\n                \"collStats\",\n                \"dbHash\",\n                \"dbStats\",\n                \"find\",\n                \"listIndexes\",\n                \"listCollections\"\n            ]\n        }\n    ],\n    \"roles\":[]\n})\n</code></pre> </li> <li> <p>Create a user and grant it the role created above:</p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\":\"pmm\",\n    \"pwd\":\"&lt;your_password&gt;\",\n    \"roles\":[\n        {\n            \"role\":\"explainRole\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"clusterMonitor\",\n            \"db\":\"admin\"\n        },\n        {\n            \"role\":\"read\",\n            \"db\":\"local\"\n        }\n    ]\n})\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MongoDB database:</p> <pre><code>pmm-admin add mongodb --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Adding a MongoDB database for monitoring.</p> <p>To connect a ProxySQL service:</p> <ol> <li> <p>Configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL.</p> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the ProxySQL service:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Enable ProxySQL performance metrics monitoring.</p> <p>To connect an HAProxy service:</p> <ol> <li>Set up an HAproxy instance. </li> <li>Add the instance to PMM (default address is http://localhost:8404/metrics), and use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node: </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Run the command below, specifying the `listen-port`` as the port number where HAProxy is running. (This flag is mandatory.)</p> <pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> </li> </ol> <p>For detailed instructions and more information on the command arguments, see the HAProxy topic.</p>"},{"location":"quickstart/index.html#check-database-monitoring-results","title":"Check database monitoring results","text":"<p>After installing PMM and connecting the database, go to the database\u2019s Instance Summary dashboard. This shows essential information about your database performance and an overview of your environment.</p> <p>For more information, see PMM Dashboards.</p>"},{"location":"quickstart/index.html#next-steps","title":"Next steps","text":"<ul> <li>Configure PMM via the interface</li> <li>Manage users in PMM</li> <li>Set up roles and permissions</li> <li>Back up and restore data in PMM</li> </ul>"},{"location":"quickstart/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/index.html","title":"PMM Architecture","text":"<p>PMM is a client/server application built by Percona comprising its own and third-party components and tools.</p> <p></p>"},{"location":"reference/index.html#pmm-server","title":"PMM Server","text":"<p>PMM Server is the heart of PMM. It receives data from clients, collects it, and stores it. Metrics are drawn as tables, charts and graphs within dashboards, each a part of the web-based user interface.</p>"},{"location":"reference/index.html#pmm-client","title":"PMM Client","text":"<p>PMM Client is a collection of agents and exporters that run on the host being monitored.</p> <p>PMM Client runs on every database host or node you want to monitor. The client collects server metrics, general system metrics, query analytics and sends it to the server. Except when monitoring AWS RDS instances, a PMM Client must be running on the host to be monitored.</p>"},{"location":"reference/index.html#percona-platform","title":"Percona Platform","text":"<p>Percona Platform provides value-added services for PMM.</p>"},{"location":"reference/index.html#pmm-context","title":"PMM context","text":"<p>The PMM Client package provides:</p> <ul> <li>Exporters for each database and service type. When an exporter runs, it connects to the database or service instance, runs the metrics collection routines, and sends the results to PMM Server.</li> <li><code>pmm-agent</code>: Run as a daemon process, it starts and stops exporters when instructed.</li> <li><code>vmagent</code>: A VictoriaMetrics daemon process that sends metrics data (pushes) to PMM Server.</li> </ul> <p>The PMM Server package provides:</p> <ul> <li><code>pmm-managed</code></li> <li>Query Analytics</li> <li>Grafana</li> <li>VictoriaMetrics</li> </ul>"},{"location":"reference/index.html#pmm-server_1","title":"PMM Server","text":"<p>PMM Server includes the following tools:</p> <ul> <li> <p>Query Analytics (QAN) enables you to analyze database query performance over periods of time. In addition to the client-side QAN agent, it includes the following:</p> <ul> <li>QAN API is the back-end for storing and accessing query data collected by the QAN agent running on a PMM Client.</li> <li>QAN App is a web application for visualizing collected Query Analytics data, which is part of the PMM Server\u2019s UI.</li> </ul> </li> <li> <p>Metrics Monitor provides a historical view of metrics that are critical to a MySQL or MongoDB server instance. It includes the following:</p> </li> <li> <p>VictoriaMetrics, a scalable time-series database. </p> </li> <li>ClickHouse is a third-party column-oriented database that facilitates the Query Analytics functionality.</li> <li>Grafana is a third-party dashboard and graph builder for visualizing data aggregated (by VictoriaMetrics or Prometheus) in an intuitive web interface.</li> <li>Percona Dashboards is a set of dashboards for Grafana developed by Percona.</li> </ul>"},{"location":"reference/index.html#pmm-client_1","title":"PMM Client","text":"<p>The PMM Client package consists of the following:</p> <ul> <li> <p><code>pmm-admin</code> is a command-line tool for managing PMM Client, for example, adding and removing database instances that you want to monitor. (Read more).</p> </li> <li> <p><code>pmm-agent</code> is a client-side component of a minimal command-line interface, which is a central entry point in charge of bringing the client functionality: it carries on client\u2019s authentication, gets the client configuration stored on the PMM Server, manages exporters and other agents.</p> </li> <li> <p><code>node_exporter</code> is an exporter that collects general system metrics.</p> </li> <li> <p><code>mysqld_exporter</code> is an exporter that collects MySQL server metrics.</p> </li> <li> <p><code>mongodb_exporter</code> is an exporter that collects MongoDB server metrics.</p> </li> <li> <p><code>postgres_exporter</code> is an exporter that collects PostgreSQL performance metrics.</p> </li> <li> <p><code>proxysql_exporter</code> is an exporter that collects ProxySQL performance metrics.</p> </li> <li> <p><code>rds_exporter</code> is an exporter that collects Amazon RDS performance metrics.</p> </li> <li> <p><code>azure_database_exporter</code> is an exporter that collects Azure database performance metrics.</p> </li> </ul> <p>To make data transfer from PMM Client to PMM Server secure, all exporters are able to use SSL/TLS encrypted connections, and their communication with PMM Server is protected by the HTTP basic authentication.</p> <p></p> <p></p>"},{"location":"reference/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/copyright.html","title":"Copyright and licensing information","text":""},{"location":"reference/copyright.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Monitoring and Management documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p> <p></p>"},{"location":"reference/copyright.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/faq.html","title":"FAQ","text":""},{"location":"reference/faq.html#how-can-i-contact-the-developers","title":"How can I contact the developers?","text":"<ul> <li>Community forum.</li> <li>PMM project in JIRA.</li> </ul>"},{"location":"reference/faq.html#what-are-the-minimum-system-requirements","title":"What are the minimum system requirements?","text":"<ul> <li>Server:<ul> <li>Disk: 1 GB per monitored database (1 week data retention)</li> <li>Memory: 2 GB per monitored database</li> <li>CPU: Supports <code>SSE4.2</code></li> </ul> </li> <li>Client:<ul> <li>Disk: 100 MB</li> </ul> </li> </ul> <p>See also</p> <ul> <li>Setting up PMM Server</li> <li>Setting up PMM Client</li> </ul>"},{"location":"reference/faq.html#how-can-i-upgrade-from-version-2","title":"How can I upgrade from version 2?","text":"<p>PMM 3 introduces significant architectural changes that require gradual transition from PMM 2. For detailed instructions, see Upgrade from PMM2.</p>"},{"location":"reference/faq.html#retention","title":"How to control data retention?","text":"<p>Go to PMM Configuration &gt; Settings &gt; Advanced Settings &gt; Data retention to adjust the value in days.</p> <p>See also</p> <p>Configure data retention</p>"},{"location":"reference/faq.html#how-are-pmm-server-logs-rotated","title":"How are PMM Server logs rotated?","text":"<p>PMM Server embeds multiple components, like Victoria Metrics, Query Analytics, Grafana, <code>managed</code>, PostgreSQL, ClickHouse, etc. (components). All PMM Server component logs are rotated by <code>supervisord</code>. The components\u2019 log rotation settings are stored in <code>*.ini</code> files within the <code>/etc/supervisord.d</code> directory. Those settings define both the maximum size of a log file and the number of log files to keep. The log rotation takes place once the log file reaches its maximum size.</p>"},{"location":"reference/faq.html#what-privileges-are-required-to-monitor-a-mysql-instance","title":"What privileges are required to monitor a MySQL instance?","text":"<pre><code>SELECT, PROCESS, SUPER, REPLICATION CLIENT, RELOAD\n</code></pre> <p>See also</p> <p>Setting Up/Client/MySQL.</p>"},{"location":"reference/faq.html#can-i-monitor-multiple-service-instances","title":"Can I monitor multiple service instances?","text":"<p>Yes.</p> <p>You can add multiple instances of MySQL or any other service to be monitored from the same PMM Client.</p> <p>To do this, you provide a unique port and IP address, or a socket for each instance, and specify a unique name for each. (If a name is not provided, PMM uses the name of the PMM Client host.)</p> <p>For example, to add MySQL monitoring for two local MySQL servers:</p> <pre><code>pmm-admin add mysql --username root --password root instance-01 127.0.0.1:3001\npmm-admin add mysql --username root --password root instance-02 127.0.0.1:3002\n</code></pre> <p>See also</p> <p><code>pmm-admin add mysql</code></p>"},{"location":"reference/faq.html#can-i-rename-instances","title":"Can I rename instances?","text":"<p>Yes, by removing and re-adding with a different name.</p> <p>When you remove a monitoring service, previously collected data remains available in Grafana.  However, the metrics are tied to the instance name.  So if you add the same instance back with a different name, it will be considered a new instance with a new set of metrics.  So if you are re-adding an instance and want to keep its previous data, add it with the same name.</p>"},{"location":"reference/faq.html#can-i-add-an-aws-rds-mysql-or-aurora-mysql-instance-from-a-non-default-aws-partition","title":"Can I add an AWS RDS MySQL or Aurora MySQL instance from a non-default AWS partition?","text":"<p>By default, the RDS discovery works with the default <code>aws</code> partition. But you can switch to special regions, like the GovCloud one, with the alternative AWS partitions (e.g. <code>aws-us-gov</code>) adding them to the Settings via the PMM Server API.</p> <p></p> <p>To specify other than the default value, or to use several, use the JSON Array syntax: <code>[\"aws\", \"aws-cn\"]</code>.</p>"},{"location":"reference/faq.html#what-resolution-is-used-for-metrics","title":"What resolution is used for metrics?","text":"<p>The default values (in seconds):</p> Preset Low Medium High Rare 300 180 60 Standard 60 10 5 Frequent 30 5 1 Custom (defaults) 60 10 5 <p>See also</p> <p>Metrics resolution</p>"},{"location":"reference/faq.html#how-do-i-set-up-alerting","title":"How do I set up Alerting?","text":"<p>When a monitored service metric reaches a defined threshold, PMM Server can trigger alerts for it using embedded Grafana Alerting functionality.</p> <p>For this, you must configure alerting rules that define conditions under which an alert should be triggered, and the contact points used to send the alert (e.g. email).</p> <p>Percona templated alerts enable you to create alerts based on built-in or custom templates to simplify the alert setup process. Grafana managed alerts allows attaching rules to your dashboard panel and enables you to create more sophisticated alerting rules. In addition, it can be easier to manage installations with a large number of hosts. This additional flexibility comes at the expense of simplicity.</p> <p>See also</p> <p>Grafana Alerting</p>"},{"location":"reference/faq.html#how-do-i-use-a-custom-prometheus-configuration-file","title":"How do I use a custom Prometheus configuration file?","text":"<p>Normally, PMM Server fully manages the Prometheus configuration file.</p> <p>However, some users may want to change the generated configuration to add additional scrape jobs, configure remote storage, etc.</p> <p>From version 2.4.0, when <code>pmm-managed</code> starts the Prometheus file generation process, it tries to load the <code>/srv/prometheus/prometheus.base.yml</code> file first, to use it as a base for the <code>prometheus.yml</code> file.</p> <p>The <code>prometheus.yml</code> file can be regenerated by restarting the PMM Server container, or by using the <code>SetSettings</code> API call with an empty body.</p> <p>See also</p> <ul> <li>API</li> <li>Percona blog: Extending PMM\u2019s Prometheus Configuration</li> </ul>"},{"location":"reference/faq.html#how-to-troubleshoot-an-update","title":"How to troubleshoot an update?","text":"<p>See Troubleshoot update.</p>"},{"location":"reference/faq.html#what-are-my-login-credentials-when-i-try-to-connect-to-a-prometheus-exporter","title":"What are my login credentials when I try to connect to a Prometheus Exporter?","text":"<ul> <li>User name: <code>pmm</code></li> <li>Password: Agent ID</li> </ul> <p>PMM protects an exporter\u2019s output from unauthorized access by adding an authorization layer. To access an exporter, you can use <code>pmm</code> as a user name and the Agent ID as a password. You can find the Agent ID corresponding to a given exporter by running <code>pmm-admin list</code>.</p> <p>See also</p> <p><code>pmm-admin list</code></p>"},{"location":"reference/faq.html#how-to-provision-pmm-server-with-non-default-admin-password","title":"How to provision PMM Server with non-default admin password?","text":"<p>Currently, there is no API available to change the <code>admin</code> password. If you\u2019re deploying through Docker, you can use the following code snippet to change the password after starting the Docker container:</p> <pre><code>PMM_PASSWORD=\"mypassword\"\necho \"Waiting for PMM to initialize to set password...\"\nuntil [ \"`docker inspect -f {{.State.Health.Status}} pmm-server`\" = \"healthy\" ]; do sleep 1; done\ndocker exec -t pmm-server bash -c \u00a0\"grafana-cli --homepath /usr/share/grafana admin reset-admin-password $PMM_PASSWORD\"\n</code></pre> <p>(This example assumes your Docker container is named <code>pmm-server</code>.)</p>"},{"location":"reference/faq.html#how-to-change-the-pmm-password-for-a-default-admin-user","title":"How to change the PMM password for a default admin user?","text":"<p>If you\u2019re deploying through Docker, you can change the default password for an admin user after starting the Docker container:</p> <pre><code>```sh\ndocker exec -t pmm-server change-admin-password your_secure_password123\n```\n</code></pre>"},{"location":"reference/faq.html#how-to-use-a-non-default-listen-port-for-pmm-admin","title":"How to use a non-default listen-port for pmm-admin?","text":"<p>If you configure the PMM agent to use a non-default listen-port, for pmm-admin to communicate with the agent, use the global flag <code>--pmm-agent-listen-port=LISTEN_PORT</code>.</p> <pre><code>--pmm-agent-listen-port=LISTEN_PORT\n</code></pre> <p>Example: To use the listen-port 8000</p> <p><pre><code>pmm-admin --pmm-agent-listen-port=8000 add postgresql --username=pmm-agent --password=pmm-agent-password --query-source=pgstatmonitor nameofpostgres\n</code></pre> If you are using OVF/AMI, you can change the default password through SSH by using the following command:</p> <pre><code>change-admin-password &lt;new_password&gt;\n</code></pre>"},{"location":"reference/faq.html#how-does-pmm-handle-personal-and-confidential-data","title":"How does PMM handle personal and confidential data?","text":"<p>Read our Privacy Policy to learn how PMM manages personal and confidential data. More technical details can be found in Data handling in PMM.</p>"},{"location":"reference/faq.html#why-am-i-getting-a-user-already-exists-error-when-logging-back-into-pmm","title":"Why am I getting a \u201cUser already exists\u201d error when logging back into PMM?","text":"<p>Following CVE fix 2023-3128 in the 2.38 release, PMM increases security by only allowing authentications based on the unique user ID provided by the identity provider.</p> <p>If you are trying to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, PMM will show this error on second and subsequent authentications.</p> <p>Solution: we recommend logging into PMM using a Percona Account, as this is a highly secure authentication method. Workaround: if you need to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, you can use the following workaround to log into PMM:</p> <ul> <li>pass the <code>GF_AUTH_OAUTH_ALLOW_INSECURE_EMAIL_LOOKUP=1</code> environment variable to the PMM container OR</li> <li>set the <code>oauth_allow_insecure_email_lookup</code> config key in the auth section of the <code>grafana.ini</code> file. Keep in mind that any changes you make to this file are lost when upgrading PMM, so make sure to manually update this file after each upgrade.</li> </ul> <p>Important</p> <p>We do not recommend using the above workaround for an extended period. Instead, ensure user uniqueness across multiple identity providers, while also encouraging your identity provider to support a unique ID field, or choose a provider who does.</p> <p></p>"},{"location":"reference/faq.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/glossary.html","title":"Glossary","text":""},{"location":"reference/glossary.html#glossary","title":"Glossary","text":""},{"location":"reference/glossary.html#annotation","title":"Annotation","text":"<p>A way of showing a mark on dashboards signifying an important point in time.</p>"},{"location":"reference/glossary.html#dimension","title":"Dimension","text":"<p>In the Query Analytics dashboard, to help focus on the possible source of performance issues, you can group queries by dimension, one of: Query, Service Name, Database, Schema, User Name, Client Host</p>"},{"location":"reference/glossary.html#ebs","title":"EBS","text":"<p>Amazon\u2019s Elastic Block Store.</p>"},{"location":"reference/glossary.html#fingerprint","title":"Fingerprint","text":"<p>A normalized statement digest\u2014a query string with values removed that acts as a template or typical example for a query.</p>"},{"location":"reference/glossary.html#iam","title":"IAM","text":"<p>Identity and Access Management (for Amazon AWS).</p>"},{"location":"reference/glossary.html#mm","title":"MM","text":"<p>Metrics Monitor.</p>"},{"location":"reference/glossary.html#numa","title":"NUMA","text":"<p>Non-Uniform Memory Access.</p>"},{"location":"reference/glossary.html#pem","title":"PEM","text":"<p>Privacy Enhanced Mail.</p>"},{"location":"reference/glossary.html#qps","title":"QPS","text":"<p>Queries Per Second. A measure of the rate of queries being monitored.</p>"},{"location":"reference/glossary.html#query-analytics","title":"Query Analytics","text":"<p>Component of PMM Server that enables you to analyze MySQL query performance over periods of time.</p>"},{"location":"reference/glossary.html#advisors","title":"Advisors","text":"<p>Automated checks that you can run against connected databases to identify any potential security threats, configuration problems, performance concerns, policy non-compliance issues etc. </p>"},{"location":"reference/glossary.html#technical-preview","title":"Technical Preview","text":"<p>Releases intended for public preview and feedback, but with no support or service level agreement (SLA). Should not be used on production or business-critical systems. May contain breaking changes to UI, API, CLI. (Read more.)</p>"},{"location":"reference/glossary.html#vg","title":"VG","text":"<p>Volume Group.</p> <p></p>"},{"location":"reference/glossary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/personal_data_handling.html","title":"Data handling in PMM","text":"<p>The following questions are being answered related to personal and confidential data handling in PMM:</p> <ol> <li> <p>Which type of data is transmitted?</p> Data collection source Data collected DB host to PMM Database performance metrics  SQL query examples for query analytics (optional). PMM to DB Host DSN and credentials for database access. A separate DB user is used (limited access) to retreive metrics from the database. DB Host to S3 compatible storage location Database backup - optional if PMM Administrator configures it with Public Cloud (AWS, GCP, etc) as a possible storage location. PMM Server to Percona Cloud Telemetry data is collected.  PMM Server collects varying amounts of data from version to version, and no personal or confidential information is collected. See here for details on the data being transmitted. </li> <li> <p>Where is the data obtained from the DB host transmitted?</p> <p>All data gathered from the DB Host is transmitted to the PMM Server. It is possible to transmit DB backups to Cloud S3 storage (optional). </p> <p>Telemetry data is sent to Percona Cloud. This does not contain any sensitive or personally identifiable information.</p> </li> <li> <p>What is the purpose and nature of data processing?</p> <p>As per our Privacy Policy, the data collection purposes are to provide the services and product enhancements.</p> <p>Although, PMM does not collect nor transfer personal data explicitly, in case query analytics is enabled and query examples collection is not disabled, we gather SQL query examples with real data and personal data may appear there if it is stored in DB.  All QAN data always remains within the PMM Server, and is never transmitted anywhere else.</p> </li> <li> <p>What is the frequency and volume of processed data?</p> <p>By default, metrics data is gathered every 5, 10 or 60 minutes. In case Query Analytics is enabled and SQL query examples are gathered every minute, we don\u2019t use any special processing for personal or confidential data. PMM Server has no clue about the meaning of the data inside the SQL query.</p> <p>So it is processed as usual, which is to store inside the PMM Server and present on the PMM UI by request.</p> <p>Other than email addresses for Grafana users, PMM does not directly ask or collect any other personal data. For more information about the telemetry data that is collected, please refer to the Percona Privacy Policy. </p> </li> <li> <p>What applications or third parties can access the data created and processed by the cloud service?</p> <p>Third parties or other applications are not able to access the data gathered by the PMM Server.</p> </li> <li> <p>Is Personal Data processed for other applications or parties, and should the data that is processed in the cloud service be available to other applications or 3<sup>rd</sup> parties?</p> <p>PMM Server doesn\u2019t pass any gathered, personal or confidential data to any third party or other applications nor to Percona Cloud.</p> </li> <li> <p>How safe is the encryption? </p> <p>It\u2019s a must to encrypt all connections to and from the cloud including the data in the cloud storage and PMM does so by default. </p> <p>We use TLS (v1.2 at least) for connections between:</p> <ul> <li> <p>Database host to PMM Server (optionally, depending on user configuration)</p> </li> <li> <p>PMM Server to Percona Cloud</p> </li> <li>PMM Server to remote database (optionally, depending on user configuration)</li> <li>End-user to PMM Server web interface/api (self-signed by default)</li> </ul> <p>For more information about Percona security posture, please refer to our Trust Center here.</p> </li> </ol> <p></p>"},{"location":"reference/personal_data_handling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/pmm_components_and_versions.html","title":"PMM components and versions","text":"<p>The following table lists all the PMM client/server components and their versions:</p> PMM client/server component Version Documentation Location on GitHub Grafana 9.2.20* Grafana Documentation Github Grafana VictoriaMetrics 1.93.4 VictoriaMetrics Documentation Github VictoriaMetrics Nginx 1.20.1 Nginx Documentation Github Nginx Percona Distribution for PostgreSQL 14.5 Percona Distribution for PostgreSQL 14 Documentation Clickhouse 23.8.2.7 ClickHouse Documentation Documentation Github ClickHouse PerconaToolkit 3.4.0 Percona Toolkit Documentation Github Percona Toolkit Alertmanager 0.22.0 Alertmanager Documentation Github Alertmanager MongoDB exporter 0.37.0 Github MongoDB Exporter MySQL exporter v0.14.0* MySQL Server Exporter Documentation Github MySQL Server Exporter PostgreSQL exporter v0.14.0* Github PostgreSQL Server Exporter RDS exporter 0.7.2 Github RDS Exporter Node exporter v1.4.0* Node Exporter Documentation Github Node Exporter Azure exporter 2.30.0 Github Azure Metrics Exporter * - Original upstream version along with some changes authored by Percona <p></p>"},{"location":"reference/pmm_components_and_versions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/quickstart.html","title":"Quickstart","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/quickstart.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p> <p></p>"},{"location":"reference/trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html","title":"Advanced Data Exploration","text":"<p>The Advanced Data Exploration dashboard provides detailed information about the progress of a single Prometheus metric across one or more hosts.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#view-actual-metric-values-gauge","title":"View actual metric values (Gauge)","text":"<p>A gauge is a metric that represents a single numerical value that can arbitrarily go up and down.</p> <p>Gauges are typically used for measured values like temperatures or current memory usage, but also \u201ccounts\u201d that can go up and down, like the number of running goroutines.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#view-metric-rate-of-change-counter","title":"View Metric Rate of Change (Counter)","text":"<p>A counter is a cumulative metric that represents a single numerical value that only ever goes up. A counter is typically used to count requests served, tasks completed, errors occurred, etc. Counters should not be used to expose current counts of items whose number can also go down, e.g. the number of currently running goroutines. Use gauges for this use case.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#metric-rates","title":"Metric Rates","text":"<p>Shows the number of samples Per second stored for a given interval in the time series.</p> <p>This dashboard supports metrics related to NUMA. The names of all these metrics start with <code>node_memory_numa</code>.</p> <p></p> <p></p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html","title":"CPU Utilization Details","text":""},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-utilization","title":"Overall CPU Utilization","text":"<p>The Overall CPU Utilization metric shows how much of the overall CPU time is used by the server. It has these components:</p> Max Core Utilization No description System This component the proportion of time the CPUs spent inside the Linux kernel for operations like context switching, memory allocation and queue handling. User This component is the time spent in the user space.  Normally, most of the MySQL CPU time is in user space. A high value of user time indicates a CPU bound workload. Softirq This component is the portion of time the CPU spent servicing software interrupts generated by the device drivers.  A high value of softirq may indicates a poorly configured device.  The network devices are generally the main source of high softirq values. Steal When multiple virtual machines share the same physical host, some virtual machines may be allowed to use more of their share of CPU and that CPU time is accounted as Steal by the virtual machine from which the time is taken. Iowait This component is the time the CPU spent waiting for disk IO requests to complete.  A high value of iowait indicates a disk bound load. Nice No description <p>In addition, sampling of the Max utilization of a single core is shown.</p> <p>This metric presents global values: while there may be a lot of unused CPU, a single core may be saturated.  Look at the Max Core Utilization to see if any core is reaching close to 100%.</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#current-cpu-threads-utilization","title":"Current CPU Threads Utilization","text":"<p>This shows the total utilization of each CPU core along with the average utilization of all CPU cores.  Watch for any core close to 100% utilization and investigate the root cause.</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#cpu-threads-frequency","title":"CPU Threads Frequency","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#current-cpu-cores-temperature","title":"Current CPU Cores Temperature","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-threads-utilization-details","title":"Overall CPU Threads Utilization Details","text":"<p>No description</p> <p></p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-disk-details.html","title":"Disk Details","text":""},{"location":"reference/dashboards/dashboard-disk-details.html#mount-point-usage","title":"mount point Usage","text":"<p>Shows the percentage of disk space utilization for every mount point defined on the system. Having some of the mount points close to 100% space utilization is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where the mount point is close to 100% consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#mount-point","title":"mount point","text":"<p>Shows information about the disk space usage of the specified mount point.</p> <p>Used is the amount of space used.</p> <p>Free is the amount of space not in use.</p> <p>Used+Free is the total disk space allocated to the mount point.</p> <p>Having Free close to 0 B is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where Free is close to 0 B consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-latency","title":"Disk Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-operations","title":"Disk Operations","text":"<p>Shows amount of physical IOs (reads and writes) different devices are serving. Spikes in number of IOs served often corresponds to performance problems due to IO subsystem overload.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-bandwidth","title":"Disk Bandwidth","text":"<p>Shows volume of reads and writes the storage is handling. This can be better measure of IO capacity usage for network attached and SSD storage as it is often bandwidth limited.  Amount of data being written to the disk can be used to estimate Flash storage life time.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-load","title":"Disk Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows disk Utilization as percent of the time when there was at least one IO request in flight. It is designed to match utilization available in iostat tool. It is not very good measure of true IO Capacity Utilization. Consider looking at IO latency and Disk Load Graphs instead.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#avg-disks-operations-merge-ratio","title":"Avg Disks Operations Merge Ratio","text":"<p>Shows how effectively Operating System is able to merge logical IO requests into physical requests.  This is a good measure of the IO locality which can be used for workload characterization.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-io-size","title":"Disk IO Size","text":"<p>Shows average size of a single disk operation.</p> <p></p>"},{"location":"reference/dashboards/dashboard-disk-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-env-overview.html","title":"Environment Overview","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Dashboard provides the user with a high-level view of all the environments in PMM.</p> <p></p>"},{"location":"reference/dashboards/dashboard-env-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-environent-summary.html","title":"Environment Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Environment Summary Dashboard provides an at-a-glance view specific to the selected environment in PMM, including an overview of the services and nodes running in that environment.</p> <p></p>"},{"location":"reference/dashboards/dashboard-environent-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-haproxy-instance-summary.html","title":"HAProxy Instance Summary","text":""},{"location":"reference/dashboards/dashboard-haproxy-instance-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-home.html","title":"Home Dashboard","text":"<p>The Home Dashboard provides a high-level overview of your environment, such as the services, infrastructure, and critical issues (if any). It is the starting page of PMM from which you can open the tools of PMM and browse online resources.</p> <p>This Home Dashboard displays data that is organized in panels as given below.</p> <p></p>"},{"location":"reference/dashboards/dashboard-home.html#overview","title":"Overview","text":"<p>This panel lists all added hosts along with essential information about their performance. For each host, you can find the current values of the following metrics:</p> <ul> <li>Monitored DB Services</li> <li>Monitored DB Instances</li> <li>Monitored Nodes</li> <li>Memory Available</li> <li>Disk Reads</li> <li>Disk Writes</li> <li>Network IO</li> <li>DB Connections</li> <li>DB QPS</li> <li>Virtual CPUs</li> <li>RAM</li> <li>Host Uptime</li> <li>DB Uptime</li> <li>Advisors check</li> </ul> <p>This panel also displays the current version number. Use Upgrade to X.X.X version to upgrade to the most recent version of PMM.</p>"},{"location":"reference/dashboards/dashboard-home.html#anomaly-detection","title":"Anomaly Detection","text":"<p>The Anomaly Detection panel lists all the anomalies in your environment. Color-coded states on the panels provide a quick visual representation of the problem areas.</p> <p>The following anomalies are displayed on this panel:</p> <ul> <li>CPU anomalies (high as well as low)</li> <li>High CPU servers</li> <li>Low CPU servers</li> <li>Disk Queue anomalies</li> <li>High disk queue</li> <li>High Memory Used</li> </ul>"},{"location":"reference/dashboards/dashboard-home.html#command-center","title":"Command Center","text":"<p>You can find critical information such as CPU utlization, memory utilization, anomalies, read and write latency, etc., about your environment on the Command Center panel. </p> <p>The information is represented graphically on the Command Center panel. In this panel, the graphs for the last hour and the previous week are displayed adjacently, making it easy to identify the trends.</p> <p>The following information is displayed on the Command Center for the Top 20 nodes:</p> <ul> <li>CPU usage</li> <li>Disk queue</li> <li>Disk Write latency</li> <li>Disk Read latency</li> <li>Memory usage</li> </ul> <p>Command Center lists the </p>"},{"location":"reference/dashboards/dashboard-home.html#service-summary","title":"Service Summary","text":"<p>The Service Summary panel provides the following information for the services being monitored:</p> <ul> <li>DB connections</li> <li>DB QPS (Query per sec)</li> <li>DB uptime</li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-home.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-memory-details.html","title":"Memory Details","text":""},{"location":"reference/dashboards/dashboard-memory-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html","title":"MongoDB Cluster Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#current-connections-per-shard","title":"Current Connections Per Shard","text":"<p>TCP connections (Incoming) in mongod processes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#total-connections","title":"Total Connections","text":"<p>Incoming connections to mongos nodes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#cursors-per-shard","title":"Cursors Per Shard","text":"<p>The Cursor is a MongoDB Collection of the document which is returned upon the find method execution.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#mongos-cursors","title":"Mongos Cursors","text":"<p>The Cursor is a MongoDB Collection of the document which is returned upon the find method execution.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#operations-per-shard","title":"Operations Per Shard","text":"<p>Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#total-mongos-operations","title":"Total Mongos Operations","text":"<p>Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#change-log-events","title":"Change Log Events","text":"<p>Count, over last 10 minutes, of all types of configuration db changelog events.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#oplog-range-by-set","title":"Oplog Range by Set","text":"<p>Timespan \u2018window\u2019 between oldest and newest ops in the Oplog collection.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_details.html","title":"Experimental MongoDB Collection Details","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime experimental dashboard provides detailed information about the top collections by document count, size, and document read for MongoDB databases.</p> <p></p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_overview.html","title":"Experimental MongoDB Collection Overview","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime dashboard contains panels of data about the Hottest Collections in the MongoDB database.</p> <p>The Instance level includes two panels, one for the Hottest Collections by Read (Total) and the Hottest Collections by Write (total). </p> <p>The next panel displays data at the Database Level, where you can view MongoDB metrics such as Commands, Inserts, Updates, Removes, and Getmore.</p> <p>The last panel shows the number of operations in the chosen database.</p> <p></p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_oplog.html","title":"Experimental MongoDB Oplog Details","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime dashboard contains Oplog details such as Recovery Window, Processing Time, Buffer Capacity, and Oplog Operations.</p> <p></p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_oplog.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html","title":"MongoDB InMemory Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-transactions","title":"InMemory Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-capacity","title":"InMemory Capacity","text":"<p>Configured max and current size of the WiredTiger cache.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-sessions","title":"InMemory Sessions","text":"<p>Internal WiredTiger storage engine cursors and sessions currently open.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-pages","title":"InMemory Pages","text":"<p>Pages in the WiredTiger cache</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-concurrency-tickets","title":"InMemory Concurrency Tickets","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cTickets available\u201d = hard coded high value - \u201cTickets Out\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-cache-eviction","title":"InMemory Cache Eviction","text":"<p>This panel shows the number of pages that have been evicted from the WiredTiger cache for the given time period. The InMemory storage engine only evicts modified pages which signals a compaction of the data and removal of the dirty pages.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html","title":"MongoDB Instance Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#command-operations","title":"Command Operations","text":"<p>Ops or Replicated Ops/sec classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>). And (from the internal TTL threads) the docs deletes/sec by TTL indexes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#latency-detail","title":"Latency Detail","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#connections","title":"Connections","text":"<p>TCP connections (Incoming)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#cursors","title":"Cursors","text":"<p>Open cursors. Includes idle cursors.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#document-operations","title":"Document Operations","text":"<p>Docs per second inserted, updated, deleted or returned. (not 1-to-1 with operation counts.)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Ratio of Documents returned or Index entries scanned / full documents scanned</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-time","title":"<code>getLastError</code> Write Time","text":"<p>Legacy driver operation: Number of, and Sum of time spent, per second executing <code>getLastError</code> commands to confirm write concern.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-operations","title":"<code>getLastError</code> Write Operations","text":"<p>Legacy driver operation: Number of <code>getLastError</code> commands that timed out trying to confirm write concern.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#assert-events","title":"Assert Events","text":"<p>This panel shows the number of assert events per second on average over the given time period. In most cases assertions are trivial, but you would want to check your log files if this counter spikes or is consistently high.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html","title":"MongoDB Instances Compare","text":""},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#connections","title":"Connections","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#cursors","title":"Cursors","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#latency","title":"Latency","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#scan-ratios","title":"Scan Ratios","text":"<p>Ratio of index entries scanned or whole docs scanned / number of documents returned</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#index-filtering-effectiveness","title":"Index Filtering Effectiveness","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#requests","title":"Requests","text":"<p>Ops/sec (classified by (legacy) wire protocol request type)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#document-operations","title":"Document Operations","text":"<p>Documents inserted/updated/deleted or returned per sec</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#queued-operations","title":"Queued Operations","text":"<p>The number of operations that are currently queued and waiting for a lock</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#used-memory","title":"Used Memory","text":"<p>No description</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html","title":"MongoDB Instances Overview","text":"<p>This dashboard provides basic information about MongoDB instances.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#command-operations","title":"Command Operations","text":"<p>Shows how many times a command is executed per second on average during the selected interval.</p> <p>Look for peaks and drops and correlate them with other graphs.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#connections","title":"Connections","text":"<p>Keep in mind the hard limit on the maximum number of connections set by your distribution.</p> <p>Anything over 5,000 should be a concern, because the application may not close connections correctly.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#cursors","title":"Cursors","text":"<p>Helps identify why connections are increasing.  Shows active cursors compared to cursors being automatically killed after 10 minutes due to an application not closing the connection.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#document-operations","title":"Document Operations","text":"<p>When used in combination with Command Operations, this graph can help identify write amplification.  For example, when one <code>insert</code> or <code>update</code> command actually inserts or updates hundreds, thousands, or even millions of documents.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#queued-operations","title":"Queued Operations","text":"<p>Any number of queued operations for long periods of time is an indication of possible issues.  Find the cause and fix it before requests get stuck in the queue.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#getlasterror-write-time-getlasterror-write-operations","title":"<code>getLastError</code> Write Time, <code>getLastError</code> Write Operations","text":"<p>This is useful for write-heavy workloads to understand how long it takes to verify writes and how many concurrent writes are occurring.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#asserts","title":"Asserts","text":"<p>Asserts are not important by themselves, but you can correlate spikes with other graphs.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#memory-faults","title":"Memory Faults","text":"<p>Memory faults indicate that requests are processed from disk either because an index is missing or there is not enough memory for the data set.  Consider increasing memory or sharding out.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html","title":"MongoDB MMAPv1 Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#document-activity","title":"Document Activity","text":"<p>Docs per second inserted, updated, deleted or returned. Also showing replicated write ops and internal TTL index deletes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-lock-wait-time","title":"MMAPv1 Lock Wait Time","text":"<p>Time spent per second waiting to acquire locks.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-page-faults","title":"MMAPv1 Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-write-activity","title":"MMAPv1 Journal Write Activity","text":"<p>MB processed through the journal in memory.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-commit-activity","title":"MMAPv1 Journal Commit Activity","text":"<p>MB committed to disk for the journal.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-background-flushing-time","title":"MMAPv1 Background Flushing Time","text":"<p>Average time in ms, over full uptime of <code>mongod</code> process, the MMAP background flushes have taken.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#queued-operations","title":"Queued Operations","text":"<p>Queue size of ops waiting to be submitted to storage engine layer. (see WiredTiger concurrency tickets for number of ops being processed simultaneously in storage engine layer.)</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#client-operations","title":"Client Operations","text":"<p>Ops and Replicated Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html","title":"MongoDB ReplSet Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#replication-lag","title":"Replication Lag","text":"<p>MongoDB replication lag occurs when the secondary node cannot replicate data fast enough to keep up with the rate that data is being written to the primary node. It could be caused by something as simple as network latency, packet loss within your network, or a routing issue.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#operations-by-service-name","title":"Operations - by service name","text":"<p>Operations are classified by legacy wire protocol type (insert, update, and delete only).</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#max-member-ping-time-by-service-name","title":"Max Member Ping Time - by service name","text":"<p>This metric can show a correlation with the replication lag value.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#max-heartbeat-time","title":"Max Heartbeat Time","text":"<p>Time span between now and last heartbeat from replicaset members.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#elections","title":"Elections","text":"<p>Count of elections. Usually zero; 1 count by each healthy node will appear in each election. Happens when the primary role changes due to either normal maintenance or trouble events.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#oplog-recovery-window-by-service-name","title":"Oplog Recovery Window - by service name","text":"<p>Timespan \u2018window\u2019 between newest and the oldest op in the Oplog collection.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html","title":"MongoDB WiredTiger Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-transactions","title":"WiredTiger Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-activity","title":"WiredTiger Cache Activity","text":"<p>Data volume transferred per second between the WT cache and data files. Writes out always imply disk; Reads are often from OS file buffer cache already in RAM, but disk if not.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-block-activity","title":"WiredTiger Block Activity","text":"<p>Data volume handled by the WT block manager per second</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-sessions","title":"WiredTiger Sessions","text":"<p>Internal WT storage engine cursors and sessions currently open</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-concurrency-tickets-available","title":"WiredTiger Concurrency Tickets Available","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cAvailable\u201d = hard-coded high value - \u201cOut\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-checkpoint-time","title":"WiredTiger Checkpoint Time","text":"<p>The time spent in WT checkpoint phase. Warning: This calculation averages the cyclical event (default: 1 min) execution to a per-second value.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-eviction","title":"WiredTiger Cache Eviction","text":"<p>Least-recently used pages being evicted due to WT cache becoming full.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-capacity","title":"WiredTiger Cache Capacity","text":"<p>Configured max and current size of the WT cache.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-pages","title":"WiredTiger Cache Pages","text":""},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-operations","title":"WiredTiger Log Operations","text":"<p>WT internal write-ahead log operations.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-activity","title":"WiredTiger Log Activity","text":"<p>Data volume moved per second in WT internal write-ahead log.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-records","title":"WiredTiger Log Records","text":"<p>Number of records appended per second in WT internal log.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html","title":"MySQL Amazon Aurora Details","text":""},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-transaction-commits","title":"Amazon Aurora Transaction Commits","text":"<p>This graph shows the number of Commits which Amazon Aurora engine performed as well as average commit latency. Graph Latency does not always correlate with the number of performed commits and can be quite high in certain situations.</p> <ul> <li> <p>Number of Amazon Aurora Commits: The average number of commit operations per second.</p> </li> <li> <p>Amazon Aurora Commit avg Latency: The average amount of latency for commit operations</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-load","title":"Amazon Aurora Load","text":"<p>This graph shows us what statements contribute most load on the system as well as what load corresponds to Amazon Aurora transaction commit.</p> <ul> <li> <p>Write Transaction Commit Load: Load in Average Active Sessions per second for COMMIT operations</p> </li> <li> <p>UPDATE load: Load in Average Active Sessions per second for UPDATE queries</p> </li> <li> <p>SELECT load: Load in Average Active Sessions per second for SELECT queries</p> </li> <li> <p>DELETE load: Load in Average Active Sessions per second for DELETE queries</p> </li> <li> <p>INSERT load: Load in Average Active Sessions per second for INSERT queries</p> </li> </ul> <p>An active session is a connection that has submitted work to the database engine and is waiting for a response from it. For example, if you submit an SQL query to the database engine, the database session is active while the database engine is processing that query.</p>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#aurora-memory-used","title":"Aurora Memory Used","text":"<p>This graph shows how much memory is used by Amazon Aurora lock manager as well as amount of memory used by Amazon Aurora to store Data Dictionary.</p> <ul> <li> <p>Aurora Lock Manager Memory: the amount of memory used by the Lock Manager, the module responsible for handling row lock requests for concurrent transactions.</p> </li> <li> <p>Aurora Dictionary Memory: the amount of memory used by the Dictionary, the space that contains metadata used to keep track of database objects, such as tables and indexes.</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-statement-latency","title":"Amazon Aurora Statement Latency","text":"<p>This graph shows average latency for the most important types of statements. Latency spikes are often indicative of the instance overload.</p> <ul> <li> <p>DDL Latency: Average time to execute DDL queries</p> </li> <li> <p>DELETE Latency: Average time to execute DELETE queries</p> </li> <li> <p>UPDATE Latency: Average time to execute UPDATE queries</p> </li> <li> <p>SELECT Latency: Average time to execute SELECT queries</p> </li> <li> <p>INSERT Latency: Average time to execute INSERT queries</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-special-command-counters","title":"Amazon Aurora Special Command Counters","text":"<p>Amazon Aurora MySQL allows a number of commands which are not available in standard MySQL. This graph shows usage of such commands.  Regular <code>unit_test</code> calls can be seen in default Amazon Aurora install, the rest will depend on your workload.</p> <ul> <li> <p><code>show_volume_status</code>: The number of executions per second of the command SHOW VOLUME STATUS. The SHOW VOLUME STATUS query returns two server status variables, Disks and Nodes. These variables represent the total number of logical blocks of data and storage nodes, respectively, for the DB cluster volume.</p> </li> <li> <p><code>awslambda</code>: The number of AWS Lambda calls per second. AWS Lambda is an event-drive, server-less computing platform provided by AWS. It is a compute service that run codes in response to an event. You can run any kind of code from Aurora invoking Lambda from a stored procedure or a trigger.</p> </li> <li> <p><code>alter_system</code>: The number of executions per second of the special query ALTER SYSTEM, that is a special query to simulate an instance crash, a disk failure, a disk congestion or a replica failure. It\u2019s a useful query for testing the system.</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-problems","title":"Amazon Aurora Problems","text":"<p>This graph shows different kinds of Internal Amazon Aurora MySQL Problems which general should be zero in normal operation.</p> <p>Anything non-zero is worth examining in greater depth.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-command-handler-counters-compare.html","title":"MySQL Command/Handler Counters Compare","text":"<p>This dashboard shows server status variables. On this dashboard, you may select multiple servers and compare their counters simultaneously.</p> <p>Server status variables appear in two sections: Commands and Handlers. Choose one or more variables in the Command and Handler fields in the top menu to select the variables which will appear in the COMMANDS or HANDLERS section for each host. Your comparison may include from one up to three hosts.</p> <p>By default or if no item is selected in the menu, PMM displays each command or handler respectively.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-command-handler-counters-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html","title":"MySQL Group Replication Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#overview","title":"Overview","text":"<ul> <li>PRIMARY Service</li> <li>Group Replication Service States</li> <li>Replication Group Members</li> <li>Replication Lag</li> <li>Replication Delay</li> <li>Transport Time</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#transactions","title":"Transactions","text":"<ul> <li>Transaction Details</li> <li>Applied Transactions</li> <li>Sent Transactions</li> <li>Checked Transactions</li> <li>Rolled Back Transactions</li> <li>Transactions Row Validating</li> <li>Transactions in the Queue for Checking</li> <li>Received Transactions Queue</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#conflicts","title":"Conflicts","text":"<ul> <li>Detected Conflicts</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html","title":"MySQL InnoDB Compression Details","text":"<p>This dashboard helps you analyze the efficiency of InnoDB compression.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#compression-level-and-failure-rate-threshold","title":"Compression level and failure rate threshold","text":"InnoDB Compression Level The level of zlib compression to use for InnoDB compressed tables and indexes. InnoDB Compression Failure Threshold The compression failure rate threshold for a table. Compression Failure Rate Threshold The maximum percentage that can be reserved as free space within each compressed page, allowing room to reorganize the data and modification log within the page when a compressed table or index is updated and the data might be recompressed. Write Pages to the Redo Log Specifies whether images of re-compressed pages are written to the redo log. Re-compression may occur when changes are made to compressed data."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#statistic-of-compression-operations","title":"Statistic of compression operations","text":"Compress Attempts Number of compression operations attempted. Pages are compressed whenever an empty page is created or the space for the uncompressed modification log runs out. Uncompressed Attempts Number of uncompression operations performed. Compressed InnoDB pages are uncompressed whenever compression fails, or the first time a compressed page is accessed in the buffer pool and the uncompressed page does not exist."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#cpu-core-usage","title":"CPU Core Usage","text":"CPU Core Usage for Compression Shows the time in seconds spent by InnoDB Compression operations. CPU Core Usage for Uncompression Shows the time in seconds spent by InnoDB Uncompression operations."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#buffer-pool-total","title":"Buffer Pool Total","text":"Total Used Pages Shows the total amount of used compressed pages into the InnoDB Buffer Pool split by page size. Total Free Pages Shows the total amount of free compressed pages into the InnoDB Buffer Pool split by page size."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html","title":"MySQL InnoDB Details","text":"<p>Tip</p> <p>If metrics are missing, try running: <code>SET GLOBAL innodb_monitor_enable=all;</code> in the MySQL client.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-activity","title":"InnoDB Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#writes-rows","title":"Writes (Rows)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#writes-transactions","title":"Writes (Transactions)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rows-read-per-trx","title":"Rows Read Per Trx","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-space-per-trx","title":"Log Space per Trx","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollbacks","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-reqs-per-row","title":"BP Reqs Per Row","text":"<p>Number of Buffer Pool requests per Row Access. High numbers here indicate going through long undo chains, deep trees and other inefficient data access.  It can be less than zero due to several rows being read from single page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-fsync-per-trx","title":"Log Fsync Per Trx","text":"<p>Log Fsync Per Transaction.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-reads","title":"InnoDB Row Reads","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-writes","title":"InnoDB Row Writes","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations_1","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-only-transactions","title":"InnoDB Read-Only Transactions","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-write-transactions","title":"InnoDB Read-Write Transactions","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-transactions-information-rw","title":"InnoDB Transactions Information (RW)","text":"<p>The InnoDB Transactions Information graph shows details about the recent transactions.  Transaction IDs Assigned represents the total number of transactions initiated by InnoDB.  RW Transaction Commits are the number of transactions not read-only. Insert-Update Transactions Commits are transactions on the Undo entries.  Non Locking RO Transaction Commits are transactions commit from select statement in auto-commit mode or transactions explicitly started with \u201cstart transaction read only\u201d.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#misc-innodb-transactions-information","title":"Misc InnoDB Transactions Information","text":"<p>Additional InnoDB Transaction Information</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-storage-summary","title":"InnoDB Storage Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-tables","title":"InnoDB Tables","text":"<p>Current Number of InnoDB Tables in database</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-buffer-pool-fit","title":"Data Buffer Pool Fit","text":"<p>Buffer Pool Size as Portion of the Data</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-row-size","title":"Avg Row Size","text":"<p>Amount of Data Per Row</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-size-per-row","title":"Index Size Per Row","text":"<p>Index Size Per Row shows how much space we\u2019re using for indexes on per row basics</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-summary","title":"InnoDB Data Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#space-allocated","title":"Space Allocated","text":"<p>Total Amount of Space Allocated. May not exactly match amount of space used on file system but provided great guidance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#space-used","title":"Space Used","text":"<p>Space used in All InnoDB Tables. Reported Allocated Space Less Free Space.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-length","title":"Data Length","text":"<p>Space Used by Data (Including Primary Key).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-length","title":"Index Length","text":"<p>Space Used by Secondary Indexes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#estimated-rows","title":"Estimated Rows","text":"<p>Estimated number of Rows in InnoDB Storage Engine. It is not exact value and it can change abruptly as information is updated.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#indexing-overhead","title":"Indexing Overhead","text":"<p>How Much Indexes Take Compared to Data.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free-space-percent","title":"Free Space Percent","text":"<p>How Much Space is Free. Too high value wastes space on disk.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free","title":"Free","text":"<p>Allocated Space not currently used by Data or Indexes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-file-per-table","title":"InnoDB File Per Table","text":"<p>If Enabled, By Default every Table will have its own Tablespace represented as its own <code>.idb</code> file  rather than all tables stored in single system tablespace.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-disk-io","title":"InnoDB Disk IO","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-size","title":"InnoDB Page Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-data-read-rq-size","title":"Avg Data Read Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-data-write-rq-size","title":"Avg Data Write Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-log-write-rq-size","title":"Avg Log Write Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-written-per-fsync","title":"Data Written Per Fsync","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-written-per-fsync","title":"Log Written Per Fsync","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-read-per-row-read","title":"Data Read Per Row Read","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-written-per-row-written","title":"Data Written Per Row Written","text":"<p>Due to difference in timing of Row Write and Data Write the value may be misleading on short intervals.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-io","title":"InnoDB Data I/O","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of fsync() operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-bandwidth","title":"InnoDB Data Bandwidth","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-io","title":"InnoDB Log IO","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of <code>fsync()</code> operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fsyncs","title":"InnoDB FSyncs","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-io","title":"InnoDB Pending IO","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-fsyncs","title":"InnoDB Pending Fsyncs","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-extend-increment","title":"InnoDB Auto Extend Increment","text":"<p>When Growing InnoDB System Tablespace extend it by this size at the time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-double-write","title":"InnoDB Double Write","text":"<p>Whether InnoDB Double Write Buffer is enabled. Doing so doubles amount of writes InnoDB has to do to storage but is required to avoid potential data corruption during the crash on most storage subsystems.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fast-shutdown","title":"InnoDB Fast Shutdown","text":"<p>Fast Shutdown means InnoDB will not perform complete Undo Space and Change Buffer cleanup on shutdown, which is faster but may interfere with certain major upgrade operations.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-open-files","title":"InnoDB Open Files","text":"<p>Maximum Number of Files InnoDB is Allowed to use.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-file-use","title":"InnoDB File Use","text":"<p>Portion of Allowed InnoDB Open Files Use.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-objects","title":"InnoDB IO Objects","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-targets-write-load","title":"InnoDB IO Targets Write Load","text":"<p>Write Load Includes both Write and fsync (referred as misc).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool","title":"InnoDB Buffer Pool","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size","title":"Buffer Pool Size","text":"<p>InnoDB Buffer Pool Size</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size-of-total-ram","title":"Buffer Pool Size of Total RAM","text":"<p>InnoDB Buffer Pool Size % of Total RAM</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#numa-interleave","title":"NUMA Interleave","text":"<p>Interleave Buffer Pool between NUMA zones to better support NUMA systems.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-activity","title":"Buffer Pool Activity","text":"<p>Combined value of Buffer Pool Read and Write requests.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-data","title":"BP Data","text":"<p>Percent of Buffer Pool Occupied by Cached Data.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-data-dirty","title":"BP Data Dirty","text":"<p>Percent of Data which is Dirty.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-miss-ratio","title":"BP Miss Ratio","text":"<p>How often buffer pool read requests have to do read from the disk. Keep this percent low for good performance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-write-buffering","title":"BP Write Buffering","text":"<p>Number of Logical Writes to Buffer Pool Per logical Write.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-lru-sub-chain-churn","title":"InnoDB Buffer Pool LRU Sub-Chain Churn","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-chunk-size","title":"Buffer Pool Chunk Size","text":"<p>Size of the \u201cChunk\u201d for buffer pool allocation.  Allocation of buffer pool will be rounded by this number. It also affects the performance impact of online buffer pool resize.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-instances","title":"Buffer Pool Instances","text":"<p>Number of Buffer Pool Instances. Higher values allow to reduce contention but also increase overhead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#read-ahead-io-percent","title":"Read Ahead IO Percent","text":"<p>Percent of Reads Caused by InnoDB Read Ahead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#read-ahead-wasted","title":"Read Ahead Wasted","text":"<p>Percent of Pages Fetched by Read Ahead Evicted Without Access.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#dump-buffer-pool-on-shutdown","title":"Dump Buffer Pool on Shutdown","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#load-buffer-pool-at-startup","title":"Load Buffer Pool at Startup","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#portion-of-buffer-pool-to-dumpload","title":"Portion of Buffer Pool To Dump/Load","text":"<p>Larger Portion increases dump/load time but get more of original buffer pool content and hence may reduce warmup time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#include-buffer-pool-in-core-dump","title":"Include Buffer Pool in Core Dump","text":"<p>Whenever to Include Buffer Pool in Crash Core Dumps.  Doing so may dramatically increase core dump file slow down restart.  Only makes a difference if core dumping on crash is enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks","title":"InnoDB Old Blocks","text":"<p>Percent of The Buffer Pool To be Reserved for \u201cOld Blocks\u201d - which has been touched repeatedly over period of time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks-time","title":"InnoDB Old Blocks Time","text":"<p>The Time which has to pass between multiple touches for the block for it to qualify as old block.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead","title":"InnoDB Random Read Ahead","text":"<p>Is InnoDB Random ReadAhead Enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead_1","title":"InnoDB Random Read Ahead","text":"<p>The Threshold (in Pages) to trigger Linear Read Ahead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-io-threads","title":"InnoDB Read IO Threads","text":"<p>Number of Threads used to Schedule Reads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-write-io-threads","title":"InnoDB Write IO Threads","text":"<p>Number of Threads used to Schedule Writes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-native-aio-enabled","title":"InnoDB Native AIO Enabled","text":"<p>Whether Native Asynchronous IO is enabled.  Strongly recommended for optimal performance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-replacement-management","title":"InnoDB Buffer Pool - Replacement Management","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-scan-depth","title":"LRU Scan Depth","text":"<p>InnoDB LRU Scan Depth</p> <p>This variable defines InnoDB Free Page Target per buffer pool. When number of free pages falls below this number this number page cleaner will make required amount of pages free, flushing or evicting pages from the tail of LRU as needed.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-clean-page-searches","title":"LRU Clean Page Searches","text":"<p>When Page is being read (or created)  the Page need to be allocated in Buffer Pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free-list-miss-rate","title":"Free List Miss Rate","text":"<p>The most efficient way to get a clean page is to grab one from free list.  However if no pages are available in Free List the LRU scan needs to be performed.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-loops","title":"LRU Get Free Loops","text":"<p>If Free List was empty LRU Get Free Loop will be performed.  It may perform LRU scan or may use some other heuristics and shortcuts to get free page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-scans","title":"LRU Scans","text":"<p>If Page could not be find any Free list and other shortcuts did not work, free page will be searched by scanning LRU chain which is not efficient.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-in-lru-scans","title":"Pages Scanned in LRU Scans","text":"<p>Pages Scanned Per Second while doing LRU scans.  If this value is large (thousands) it means a lot of resources are wasted.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-lru-scan","title":"Pages scanned per LRU Scan","text":"<p>Number of pages scanned per LRU scan in Average. Large number of scans can consume a lot of resources and also introduce significant addition latency to queries.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-waits","title":"LRU Get Free Waits","text":"<p>If InnoDB could not find a free page in LRU list and had to sleep. Should be zero.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpointing-and-flushing","title":"InnoDB Checkpointing and Flushing","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-from-flush-list","title":"Pages Flushed from Flush List","text":"<p>Number of Pages Flushed from \u201cFlush List\u201d  This combines Pages Flushed through Adaptive Flush and Background Flush.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-flush-batches-executed","title":"Page Flush Batches Executed","text":"<p>InnoDB Flush Cycle typically Runs on 1 second intervals.  If too far off from this number it can indicate an issue.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-per-batch","title":"Pages Flushed Per Batch","text":"<p>How many pages are flushed per Batch.  Large Batches can \u201cchoke\u201d IO subsystem and starve other IO which needs to happen.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing-enabled","title":"Neighbor Flushing Enabled","text":"<p>Neighbor Flushing is Optimized for Rotational Media  and unless you\u2019re Running spinning disks you should disable it.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpoint-age","title":"InnoDB Checkpoint Age","text":"<p>InnoDB Checkpoint Age</p> <p>The maximum checkpoint age is determined by the total length of all transaction log files (<code>innodb_log_file_size</code>).</p> <p>When the checkpoint age reaches the maximum checkpoint age, blocks are flushed synchronously. The rules of the thumb is to keep one hour of traffic in those logs and let the check-pointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-adaptive","title":"Pages Flushed (Adaptive)","text":"<p>Adaptive Flush  Flushes pages from Flush List based on the need to advance Checkpoint (driven by Redo Generation Rate) and by maintaining number of dirty pages within set limit.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-flush-batches-executed","title":"Adaptive Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-adaptive","title":"Pages Per Batch (Adaptive)","text":"<p>Pages Flushed Per Adaptive Batch.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing","title":"Neighbor Flushing","text":"<p>To optimize IO for rotational Media InnoDB may flush neighbor pages. It can cause significant wasted IO for flash storage.    Generally for flash you should run with <code>innodb_flush_neighbors=0</code> but otherwise this shows how much IO you\u2019re wasting.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-lru","title":"Pages Flushed (LRU)","text":"<p>Flushing from the tail of the LRU list is needed to keep readily-available free pages for new data to be read when data does not fit in the buffer pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-flush-batches-executed","title":"LRU Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-lru","title":"Pages Per Batch (LRU)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lsn-age-flush-batch-target","title":"LSN Age Flush Batch Target","text":"<p>Target for Pages to Flush due to LSN Age.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-neighbor","title":"Pages Flushed (Neighbor)","text":"<p>Number of Neighbor pages flushed (If neighbor flushing is enabled)  from Flush List and LRU List Combined.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flush-batches-executed","title":"Neighbor Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-neighbor","title":"Pages Per Batch (Neighbor)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#sync-flush-waits","title":"Sync Flush Waits","text":"<p>If InnoDB could not keep up with Checkpoint Flushing and had to trigger Sync flush.  This should never happen.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-background","title":"Pages Flushed (Background)","text":"<p>Pages Flushed by Background Flush which is activated when server is considered to be idle.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#background-flush-batches-executed","title":"Background Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-background","title":"Pages Per Batch (Background)","text":"<p>Pages Flushed Per Background Batch.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo) is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-flushing-by-type","title":"InnoDB Flushing by Type","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-lru","title":"Pages Evicted (LRU)","text":"<p>This correspond to number of clean pages which were evicted (made free) from the tail of LRU buffer.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-eviction-batches","title":"Page Eviction Batches","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-per-batch","title":"Pages Evicted per Batch","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-log-space-used","title":"Max Log Space Used","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#single-page-flushes","title":"Single Page Flushes","text":"<p>Single Page flushes happen in rare case, then clean page could not be found in LRU list. It should be zero for most workloads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#single-page-flush-pages-scanned","title":"Single Page Flush Pages Scanned","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-single-page-flush","title":"Pages Scanned Per Single Page Flush","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity","title":"InnoDB IO Capacity","text":"<p>Estimated number of IOPS storage system can provide.  Is used to scale background activities. Do not set it to actual storage capacity.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity-max","title":"InnoDB IO Capacity Max","text":"<p>InnoDB IO Capacity to use when falling behind and need to catch up with Flushing.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-logging","title":"InnoDB Logging","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#total-log-space","title":"Total Log Space","text":"<p>Number of InnoDB Log Files Multiplied by Their Size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-buffer-size","title":"Log Buffer Size","text":"<p>InnoDB Log Buffer Size</p> <p>The size of buffer InnoDB uses for buffering writes to log files.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#at-transaction-commit","title":"At Transaction Commit","text":"<p>What to do with Log file At Transaction Commit. Do nothing and wait for timeout to  flush the data from Log Buffer,  Flush it to OS Cache but not FSYNC or Flush only.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#flush-transaction-log-every","title":"Flush Transaction Log Every","text":"<p>Every Specified Number of Seconds Flush Transaction Log.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-write-ahead-block-size","title":"InnoDB Write Ahead Block Size","text":"<p>This variable can be seen as minimum IO alignment InnoDB will use for Redo log file.  High Values cause waste, low values can make IO less efficient.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-write-amplification","title":"Log Write Amplification","text":"<p>How much Writes to Log Are Amplified compared to how much Redo is Generated.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-fsync-rate","title":"Log Fsync Rate","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generated-per-trx","title":"Redo Generated per Trx","text":"<p>Amount of Redo Generated Per Write Transaction.  This is a good indicator of transaction size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-usage-hourly","title":"InnoDB Log File Usage Hourly","text":"<p>InnoDB Log File Usage Hourly</p> <p>Along with the buffer pool size, <code>innodb_log_file_size</code> is the most important setting when we are working with InnoDB. This graph shows how much data was written to InnoDB\u2019s redo logs over each hour. When the InnoDB log files are full, InnoDB needs to flush the modified pages from memory to disk.</p> <p>The rules of the thumb is to keep one hour of traffic in those logs and let the checkpointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p> <p>This graph can help guide you in setting the correct <code>innodb_log_file_size</code>.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-padding-written","title":"Log Padding Written","text":"<p>Amount of Log Padding Written.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-size","title":"InnoDB Log File Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-files","title":"InnoDB Log Files","text":"<p>Number of InnoDB Redo Log Files.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-bandwidth","title":"Log Bandwidth","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate_1","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo)  is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-group-commit-batch-size","title":"InnoDB Group Commit Batch Size","text":"<p>The InnoDB Group Commit Batch Size graph shows how many bytes were written to the InnoDB log files per attempt to write. If many threads are committing at the same time, one of them will write the log entries of all the waiting threads and flush the file. Such process reduces the number of disk operations needed and enlarge the batch size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-locking","title":"InnoDB Locking","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lock-wait-timeout","title":"Lock Wait Timeout","text":"<p>InnoDB Lock Wait Timeout</p> <p>How long to wait for row lock before timing out.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-deadlock-detection","title":"InnoDB Deadlock Detection","text":"<p>If Disabled InnoDB Will not detect deadlocks but rely on timeouts.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-increment-lock-mode","title":"InnoDB Auto Increment Lock Mode","text":"<p>Will Define How much locking will come from working with Auto Increment Columns.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollback-on-timeout","title":"Rollback on Timeout","text":"<p>Whenever to rollback all transaction on timeout or just last statement.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-lock-blocking","title":"Row Lock Blocking","text":"<p>Percent of Active Sections which are blocked due to waiting on InnoDB Row Locks.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx_1","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollbacks_1","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-activity","title":"InnoDB Row Lock Wait Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-time","title":"InnoDB Row Lock Wait Time","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-load","title":"InnoDB Row Lock Wait Load","text":"<p>Average Number of Sessions blocked from proceeding due to waiting on row level lock.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-locks-activity","title":"InnoDB Row Locks Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-table-lock-activity","title":"InnoDB Table Lock Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-locks","title":"Current Locks","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-and-purging","title":"InnoDB Undo Space and Purging","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#undo-tablespaces","title":"Undo Tablespaces","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-undo-log-size","title":"Max Undo Log Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-log-truncate","title":"InnoDB Undo Log Truncate","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-threads","title":"Purge Threads","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag","title":"Max Purge Lag","text":"<p>Maximum number of  Unpurged Transactions, if this number exceeded delay will be introduced to incoming DDL statements.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag-delay","title":"Max Purge Lag Delay","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-purge-delay","title":"Current Purge Delay","text":"<p>The Delay Injected due to Purge Thread(s) unable to keep up with purge progress.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollback-segments","title":"Rollback Segments","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-activity","title":"InnoDB Purge Activity","text":"<p>The InnoDB Purge Performance graph shows metrics about the page purging process.  The purge process removed the undo entries from the history list and cleanup the pages of the old versions of modified rows and effectively remove deleted rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#transactions-and-undo-records","title":"Transactions and Undo Records","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-usage","title":"InnoDB Undo Space Usage","text":"<p>The InnoDB Undo Space Usage graph shows the amount of space used by the Undo segment.  If the amount of space grows too much, look for long running transactions holding read views opened in the InnoDB status.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#transaction-history","title":"Transaction History","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-throttling","title":"InnoDB Purge Throttling","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#records-per-undo-log-page","title":"Records Per Undo Log Page","text":"<p>How Many Undo Operations Are Handled Per Each Undo Log Page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-invoked","title":"Purge Invoked","text":"<p>How Frequently Purge Operation is Invoked.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ops-per-purge","title":"Ops Per Purge","text":"<p>Home Many Purge Actions are done Per invocation.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#undo-slots-used","title":"Undo Slots Used","text":"<p>Number of Undo Slots Used.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-transaction-history-length","title":"Max Transaction History Length","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-batch-size","title":"Purge Batch Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rseg-truncate-frequency","title":"Rseg Truncate Frequency","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-operations","title":"InnoDB Page Operations","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-splits-and-merges","title":"InnoDB Page Splits and Merges","text":"<p>The InnoDB Page Splits graph shows the InnoDB page maintenance activity related to splitting and merging pages.  When an InnoDB page, other than the top most leaf page, has too much data to accept a row update or a row insert, it has to be split in two.  Similarly, if an InnoDB page, after a row update or delete operation, ends up being less than half full, an attempt is made to merge the page with a neighbor page. If the resulting page size is larger than the InnoDB page size, the operation fails.  If your workload causes a large number of page splits, try lowering the <code>innodb_fill_factor</code> variable (5.7+).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-merge-success-ratio","title":"Page Merge Success Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorg-attempts","title":"InnoDB Page Reorg Attempts","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorgs-failures","title":"InnoDB Page Reorgs Failures","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fill-factor","title":"InnoDB Fill Factor","text":"<p>The portion of the page to fill then doing sorted Index Build.   Lowering this value will worsen space utilization but will reduce need to split pages when new data is inserted in the index.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-hash-index","title":"InnoDB Adaptive Hash Index","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-enabled","title":"Adaptive Hash Index Enabled","text":"<p>Adaptive Hash Index helps to optimize index Look-ups but can be severe hotspot for some workloads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-partitions","title":"Adaptive Hash Index Partitions","text":"<p>How many Partitions Used for Adaptive Hash Index (to reduce contention).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#percent-of-pages-hashed","title":"Percent of Pages Hashed","text":"<p>Number of Pages Added to AHI vs Number of Pages Added to Buffer Pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ahi-miss-ratio","title":"AHI Miss Ratio","text":"<p>Percent of Searches which could not be resolved through AHI.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rows-added-per-page","title":"Rows Added Per Page","text":"<p>Number of Rows \u201cHashed\u201d  Per Each Page which needs to be added to AHI.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ahi-roi","title":"AHI ROI","text":"<p>How Many Successful Searches using AHI are performed per each row maintenance operation.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-usage","title":"InnoDB AHI Usage","text":"<p>The InnoDB AHI Usage graph shows the search operations on the InnoDB adaptive hash index and its efficiency.  The adaptive hash index is a search hash designed to speed access to InnoDB pages in memory.  If the Hit Ratio is small, the working data set is larger than the buffer pool, the AHI should likely be disabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-miss-ratio","title":"InnoDB AHI Miss Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-rows","title":"InnoDB AHI Churn - Rows","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-pages","title":"InnoDB AHI Churn - Pages","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer","title":"InnoDB Change Buffer","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (as Percent of Buffer Pool Size).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size_1","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (Bytes).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer-merge-load","title":"InnoDB Change Buffer Merge Load","text":"<p>Number of Average of Active Merge Buffer Operations in Process.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention","title":"InnoDB Contention","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-concurrency","title":"InnoDB Thread Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-commit-concurrency","title":"InnoDB Commit Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time during Commit Stage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-sleep-delay","title":"InnoDB Thread Sleep Delay","text":"<p>The Time the thread will Sleep before Re-Entering InnoDB Kernel if high contention.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-max-sleep-delay","title":"InnoDB Adaptive Max Sleep Delay","text":"<p>If Set to Non-Zero Value InnoDB Thread Sleep Delay will be adjusted automatically depending on the load up to the value specified by this variable.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-concurrency-tickets","title":"InnoDB Concurrency Tickets","text":"<p>Number of low level operations InnoDB can do after it entered InnoDB kernel before it is forced to exit and yield to another thread waiting.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-delay","title":"InnoDB Spin Wait Delay","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-pause-multiplier","title":"InnoDB Spin Wait Pause Multiplier","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-sync-spin-loops","title":"InnoDB Sync Spin Loops","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-os-waits","title":"InnoDB Contention - OS Waits","text":"<p>The InnoDB Contention - OS Waits graph shows the number of time an OS wait operation was required while waiting to get the lock.  This happens once the spin rounds are exhausted.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-spin-rounds","title":"InnoDB Contention - Spin Rounds","text":"<p>The InnoDB Contention - Spin Rounds graph shows the number of spin rounds executed to get a lock.  A spin round is a fast retry to get the lock in a loop.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-misc","title":"InnoDB Misc","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-main-thread-utilization","title":"InnoDB Main Thread Utilization","text":"<p>The InnoDB Main Thread Utilization graph shows the portion of time the InnoDB main thread spent at various task.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-activity_1","title":"InnoDB Activity","text":"<p>The InnoDB Activity graph shows a measure of the activity of the InnoDB threads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-dedicated-server","title":"InnoDB Dedicated Server","text":"<p>InnoDB automatically optimized for Dedicated Server Environment (auto scaling cache and some other variables).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-sort-buffer-size","title":"InnoDB Sort Buffer Size","text":"<p>This Buffer is used for Building InnoDB Indexes using Sort algorithm.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-stats-auto-recalc","title":"InnoDB Stats Auto Recalc","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#update-stats-when-metadata-queried","title":"Update Stats when Metadata Queried","text":"<p>Refresh InnoDB Statistics when meta-data queries by <code>SHOW TABLE STATUS</code> or <code>INFORMATION_SCHEMA</code> queries.  If Enabled can cause severe performance issues.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-condition-pushdown-icp","title":"Index Condition Pushdown (ICP)","text":"<p>Index Condition Pushdown (ICP) is an optimization for the case where MySQL retrieves rows from a table using an index. Without ICP, the storage engine traverses the index to locate rows in the base table and returns them to the MySQL server which evaluates the\u00a0WHERE condition for the rows. With ICP enabled, and if parts of the\u00a0WHERE\u00a0condition can be evaluated by using only columns from the index, the MySQL server pushes this part of the\u00a0WHERE\u00a0condition down to the storage engine. The storage engine then evaluates the pushed index condition by using the index entry and only if this is satisfied is the row read from the table. ICP can reduce the number of times the storage engine must access the base table and the number of times the MySQL server must access the storage engine.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-statistics","title":"InnoDB Persistent Statistics","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-sample-pages","title":"InnoDB Persistent Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-transient-sample-pages","title":"InnoDB Transient Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Disabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-online-operations-mariadb","title":"InnoDB Online Operations (MariaDB)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-defragmentation","title":"InnoDB Defragmentation","text":"<p>The InnoDB Defragmentation graph shows the status information related to the InnoDB online defragmentation feature of MariaDB for the optimize table command.  To enable this feature, the variable <code>innodb-defragment</code> must be set to 1 in the configuration file.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-online-ddl","title":"InnoDB Online DDL","text":"<p>The InnoDB Online DDL graph shows the state of the online DDL (alter table) operations in InnoDB.  The progress metric is estimate of the percentage of the rows processed by the online DDL.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-summary","title":"MySQL Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-uptime","title":"MySQL Uptime","text":"<p>MySQL Uptime</p> <p>The amount of time since the last restart of the MySQL server process.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-qps","title":"Current QPS","text":"<p>Current QPS</p> <p>Based on the queries reported by MySQL\u2019s <code>SHOW STATUS</code> command, it is the number of statements executed by the server within the last second. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count <code>COM_PING</code> or <code>COM_STATISTICS</code> commands.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#file-handlers-used","title":"File Handlers Used","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-miss-ratio","title":"Table Open Cache Miss Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-size","title":"Table Open Cache Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-definition-cache-size","title":"Table Definition Cache Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-connections","title":"MySQL Connections","text":"<p>Max Connections</p> <p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that mysqld requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p>mysqld actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":"<p>MySQL Active Threads</p> <p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-handlers","title":"MySQL Handlers","text":"<p>MySQL Handlers</p> <p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#top-command-counters","title":"Top Command Counters","text":"<p>Top Command Counters</p> <p>The <code>Com_{{ xxx }}</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count <code>DELETE</code> and <code>UPDATE</code> statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to <code>DELETE</code> and <code>UPDATE</code> statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-network-traffic","title":"MySQL Network Traffic","text":"<p>MySQL Network Traffic</p> <p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#node-summary","title":"Node Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#system-uptime","title":"System Uptime","text":"<p>The parameter shows how long a system has been up and running without a shut down or restart.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#load-average","title":"Load Average","text":"<p>The system load is a measurement of the computational work the system is performing. Each running process either using or waiting for CPU resources adds 1 to the load.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ram","title":"RAM","text":"<p>RAM (Random Access Memory) is the hardware in a computing device where the operating system, application programs and data in current use are kept so they can be quickly reached by the device\u2019s processor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#memory-available","title":"Memory Available","text":"<p>Percent of Memory Available</p> <p>On Modern Linux Kernels amount of Memory Available for application is not the same as Free+Cached+Buffers.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#virtual-memory","title":"Virtual Memory","text":"<p>RAM + SWAP</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#disk-space","title":"Disk Space","text":"<p>Sum of disk space on all partitions.</p> <p>It can be significantly over-reported in some installations.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#min-space-available","title":"Min Space Available","text":"<p>Lowest percent of the disk space available.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p> <p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html","title":"MySQL Instance Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-connections","title":"MySQL Connections","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#max-connections","title":"Max Connections","text":"<p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that <code>mysqld</code> requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p><code>mysqld</code> actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-aborted-connections","title":"MySQL Aborted Connections","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#aborted-connections","title":"Aborted Connections","text":"<p>When a given host connects to MySQL and the connection is interrupted in the middle (for example due to bad credentials), MySQL keeps that info in a system table (since 5.6 this table is exposed in <code>performance_schema</code>).</p> <p>If the amount of failed requests without a successful connection reaches the value of <code>max_connect_errors</code>, <code>mysqld</code> assumes that something is wrong and blocks the host from further connection.</p> <p>To allow connections from that host again, you need to issue the <code>FLUSH HOSTS</code> statement.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-active-threads","title":"MySQL Active Threads","text":"<p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache","title":"MySQL Thread Cache","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache_1","title":"MySQL Thread Cache","text":"<p>The <code>thread_cache_size</code> variable sets how many threads the server should cache to reuse. When a client disconnects, the client\u2019s threads are put in the cache if the cache is not full. It is auto-sized in MySQL 5.6.8 and above (capped to 100). Requests for threads are satisfied by reusing threads taken from the cache if possible, and only when the cache is empty is a new thread created.</p> <ul> <li><code>threads_created</code>: The number of threads created to handle connections.</li> <li><code>threads_cached</code>: The number of threads in the thread cache.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries","title":"MySQL Slow Queries","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries_1","title":"MySQL Slow Queries","text":"<p>Slow queries are defined as queries being slower than the <code>long_query_time</code> setting. For example, if you have <code>long_query_time</code> set to 3, all queries that take longer than 3 seconds to complete will show on this graph.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types","title":"MySQL Select Types","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types_1","title":"MySQL Select Types","text":"<p>As with most relational databases, selecting based on indexes is more efficient than scanning an entire table\u2019s data. Here we see the counters for selects not done with indexes.</p> <ul> <li>Select Scan is how many queries caused full table scans, in which all the data in the table had to be read and either discarded or returned.</li> <li>Select Range is how many queries used a range scan, which means MySQL scanned all rows in a given range.</li> <li>Select Full Join is the number of joins that are not joined on an index, this is usually a huge performance hit.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts","title":"MySQL Sorts","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts_1","title":"MySQL Sorts","text":"<p>Due to a query\u2019s structure, order, or other requirements, MySQL sorts the rows before returning them. For example, if a table is ordered 1 to 10 but you want the results reversed, MySQL then has to sort the rows to return 10 to 1.</p> <p>This graph also shows when sorts had to scan a whole table or a given range of a table to return the results and which could not have been sorted via an index.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-locks","title":"MySQL Table Locks","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#table-locks","title":"Table Locks","text":"<p>MySQL takes a number of different locks for varying reasons. In this graph we see how many Table level locks MySQL has requested from the storage engine. In the case of InnoDB, many times the locks could actually be row locks as it only takes table level locks in a few specific cases.</p> <p>It is most useful to compare Locks Immediate and Locks Waited. If Locks waited is rising, it means you have lock contention. Otherwise, Locks Immediate rising and falling is normal activity.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-questions","title":"MySQL Questions","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-questions_1","title":"MySQL Questions","text":"<p>The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries used in the QPS calculation.</p> <p>This variable does not count the following commands:</p> <ul> <li><code>COM_PING</code></li> <li><code>COM_STATISTICS</code></li> <li><code>COM_STMT_PREPARE</code></li> <li><code>COM_STMT_CLOSE</code></li> <li><code>COM_STMT_RESET</code></li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic","title":"MySQL Network Traffic","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic_1","title":"MySQL Network Traffic","text":"<p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly","title":"MySQL Network Usage Hourly","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly_1","title":"MySQL Network Usage Hourly","text":"<p>Here we can see how much network traffic is generated by MySQL per hour. You can use the bar graph to compare data sent by MySQL and data received by MySQL.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-internal-memory-overview","title":"MySQL Internal Memory Overview","text":"<p>System Memory: Total Memory for the system.</p> <p>InnoDB Buffer Pool Data: InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.</p> <p>TokuDB Cache Size: Similar in function to the InnoDB Buffer Pool, TokuDB will allocate 50% of the installed RAM for its own cache.</p> <p>Key Buffer Size: Index blocks for MyISAM tables are buffered and are shared by all threads. <code>key_buffer_size</code> is the size of the buffer used for index blocks.</p> <p>Adaptive Hash Index Size: When InnoDB notices that some index values are being accessed very frequently, it builds a hash index for them in memory on top of B-Tree indexes.</p> <p>Query Cache Size: The query cache stores the text of a SELECT statement together with the corresponding result that was sent to the client. The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time.</p> <p>InnoDB Dictionary Size: The data dictionary is InnoDB\u2019s internal catalog of tables. InnoDB stores the data dictionary on disk, and loads entries into memory while the server is running.</p> <p>InnoDB Log Buffer Size: The MySQL InnoDB log buffer allows transactions to run without having to write the log to disk before the transactions commit.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters","title":"Top Command Counters","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters_1","title":"Top Command Counters","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly","title":"Top Command Counters Hourly","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly_1","title":"Top Command Counters Hourly","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers","title":"MySQL Handlers","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers_1","title":"MySQL Handlers","text":"<p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory","title":"MySQL Query Cache Memory","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory_1","title":"MySQL Query Cache Memory","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity","title":"MySQL Query Cache Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity_1","title":"MySQL Query Cache Activity","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status","title":"MySQL Table Open Cache Status","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status_1","title":"MySQL Table Open Cache Status","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables","title":"MySQL Open Tables","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables_1","title":"MySQL Open Tables","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache","title":"MySQL Table Definition Cache","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache_1","title":"MySQL Table Definition Cache","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-instances-compare.html","title":"MySQL Instances Compare","text":"<p>No description</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-instances-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-instances-overview.html","title":"MySQL Instances Overview","text":""},{"location":"reference/dashboards/dashboard-mysql-instances-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html","title":"MySQL MyISAM/Aria Details","text":""},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#myisam-key-buffer-performance","title":"MyISAM Key Buffer Performance","text":"<p>The <code>Key Read Ratio</code>  (<code>Key_reads</code> / <code>Key_read_requests</code>) ratio should normally be less than 0.01.</p> <p>The  <code>Key Write Ratio</code> (<code>Key_writes</code> / <code>Key_write_requests</code>) ratio is usually near 1 if you are using mostly updates and deletes, but might be much smaller if you tend to do updates that affect many rows at the same time or if you are using the <code>DELAY_KEY_WRITE</code> table option.</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-readswrites","title":"Aria Pagecache Reads/Writes","text":"<p>This graph is similar to InnoDB buffer pool reads/writes. <code>aria-pagecache-buffer-size</code> is the main cache for the Aria storage engine. If you see high reads/writes (physical IO), i.e. reads are close to read requests and/or writes are close to write requests you may need to increase the <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-transaction-log-syncs","title":"Aria Transaction Log Syncs","text":"<p>This is similar to InnoDB log file syncs. If you see lots of log syncs and want to relax the durability settings you can change <code>aria_checkpoint_interval</code> (in seconds) from 30 (default) to a higher number. It is good to look at the disk IO dashboard as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-blocks","title":"Aria Pagecache Blocks","text":"<p>This graph shows the utilization for the Aria pagecache. This is similar to InnoDB buffer pool graph. If you see all blocks are used you may consider increasing <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-myrocks-details.html","title":"MySQL MyRocks Details","text":"<p>The MyRocks storage engine developed by Facebook based on the RocksDB storage engine is applicable to systems which primarily interact with the database by writing data to it rather than reading from it. RocksDB also features a good level of compression, higher than that of the InnoDB storage engine, which makes it especially valuable when optimizing the usage of hard drives.</p> <p>PMM collects statistics on the MyRocks storage engine for MySQL in the Metrics Monitor information for this dashboard comes from the Information Schema tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-myrocks-details.html#metrics","title":"Metrics","text":"<ul> <li>MyRocks cache</li> <li>MyRocks cache data bytes R/W</li> <li>MyRocks cache index hit rate</li> <li>MyRocks cache index</li> <li>MyRocks cache filter hit rate</li> <li>MyRocks cache filter</li> <li>MyRocks cache data bytes inserted</li> <li>MyRocks bloom filter</li> <li>MyRocks memtable</li> <li>MyRocks memtable size</li> <li>MyRocks number of keys</li> <li>MyRocks cache L0/L1</li> <li>MyRocks number of DB ops</li> <li>MyRocks R/W</li> <li>MyRocks bytes read by iterations</li> <li>MyRocks write ops</li> <li>MyRocks WAL</li> <li>MyRocks number reseeks in iterations</li> <li>RocksDB row operations</li> <li>MyRocks file operations</li> <li>RocksDB stalls</li> <li>RocksDB stops/slowdowns</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-myrocks-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-performance-schema-details.html","title":"MySQL Performance Schema Details","text":"<p>The MySQL Performance Schema dashboard helps determine the efficiency of communicating with Performance Schema. This dashboard contains the following metrics:</p> <ul> <li>Performance Schema file IO (events)</li> <li>Performance Schema file IO (load)</li> <li>Performance Schema file IO (Bytes)</li> <li>Performance Schema waits (events)</li> <li>Performance Schema waits (load)</li> <li>Index access operations (load)</li> <li>Table access operations (load)</li> <li>Performance Schema SQL and external locks (events)</li> <li>Performance Schema SQL and external locks (seconds)</li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-performance-schema-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html","title":"MySQL Query Response Time Details","text":""},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time","title":"Average Query Response Time","text":"<p>The Average Query Response Time graph shows information collected using the Response Time Distribution plugin sourced from table <code>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</code>. It computes this value across all queries by taking the sum of seconds divided by the count of queries.</p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#query-response-time-distribution","title":"Query Response Time Distribution","text":"<p>Query response time counts (operations) are grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time_1","title":"Average Query Response Time","text":"<p>Available only in Percona Server for MySQL, provides  visibility of the split of READ vs WRITE query response time.</p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#read-query-response-time-distribution","title":"Read Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates READ query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#write-query-response-time-distribution","title":"Write Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates WRITE query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html","title":"MySQL Replication Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#io-thread-running","title":"IO Thread Running","text":"<p>This metric shows if the IO Thread is running or not. It only applies to a secondary host.</p> <p>SQL Thread is a process that runs on a secondary host in the replication environment. It reads the events from the local relay log file and applies them to the secondary server.</p> <p>Depending on the format of the binary log it can read query statements in plain text and re-execute them or it can read raw data and apply them to the local host.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values","title":"Possible values","text":"Yes The thread is running and is connected to a replication primary No The thread is not running because it is not launched yet or because an error has occurred connecting to the primary host Connecting The thread is running but is not connected to a replication primary No value The host is not configured to be a replication secondary <p>IO Thread Running is one of the parameters that the command <code>SHOW SLAVE STATUS</code> returns.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#sql-thread-running","title":"SQL Thread Running","text":"<p>This metric shows if the SQL thread is running or not. It only applies to a secondary host.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values_1","title":"Possible values","text":"Yes SQL Thread is running and is applying events from the relay log to the local secondary host No SQL Thread is not running because it is not launched yet or because of an error occurred while applying an event to the local secondary host"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#replication-error-no","title":"Replication Error No","text":"<p>This metric shows the number of the last error in the SQL Thread encountered which caused replication to stop.</p> <p>One of the more common errors is Error: 1022 Duplicate Key Entry. In such a case replication is attempting to update a row that already exists on the secondary. The SQL Thread will stop replication to avoid data corruption.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#read-only","title":"Read only","text":"<p>This metric indicates whether the host is configured to be in Read Only mode or not.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values_2","title":"Possible values","text":"Yes <p>The secondary host permits no client updates except from users who have the SUPER privilege or the REPLICATION SLAVE privilege.</p> <p>This kind of configuration is typically used for secondary hosts in a replication environment to avoid a user can inadvertently or voluntarily modify data causing inconsistencies and stopping the replication process.</p> No The secondary host is not configured in Read Only mode."},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#mysql-replication-delay","title":"MySQL Replication Delay","text":"<p>This metric shows the number of seconds the secondary host is delayed in replication applying events compared to when the primary host applied them, denoted by the <code>Seconds_Behind_Master</code> value, and only applies to a secondary host.</p> <p>Since the replication process applies the data modifications on the secondary asynchronously, it could happen that the secondary replicates events after some time. The main reasons are:</p> <ul> <li> <p>Network round trip time - high latency links will lead to non-zero replication lag values.</p> </li> <li> <p>Single threaded nature of replication channels - primary servers have the advantage of applying changes in parallel, whereas secondary ones are only able to apply changes in serial, thus limiting their throughput. In some cases Group Commit can help but is not always applicable.</p> </li> <li> <p>High number of changed rows or computationally expensive SQL - depending on the replication format (<code>ROW</code> vs <code>STATEMENT</code>), significant changes to the database through high volume of rows modified, or expensive CPU will all contribute to secondary servers lagging behind the primary.</p> </li> </ul> <p>Generally adding more CPU or Disk resources can alleviate replication lag issues, up to a point.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-size","title":"Binlog Size","text":"<p>This metric shows the overall size of the binary log files, which can exist on both primary and secondary servers.</p> <p>The binary log (also known as the binlog) contains events that describe database changes: <code>CREATE TABLE</code>, <code>ALTER TABLE</code>, updates, inserts, deletes and other statements or database changes.</p> <p>The binlog file is read by secondaries via their IO Thread process to replicate database changes modification on the data and on the table structures. There can be more than one binlog file depending on the binlog rotation policy (for example using the configuration variables <code>max_binlog_size</code> and <code>expire_logs_days</code>) or because of server reboots.</p> <p>When planning the disk space, take care of the overall dimension of binlog files and adopt a good rotation policy or think about having a separate mount point or disk to store the binlog data.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-data-written-hourly","title":"Binlog Data Written Hourly","text":"<p>This metric shows the amount of data written hourly to the binlog files during the last 24 hours. This metric can give you an idea of how big is your application in terms of data writes (creation, modification, deletion).</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-count","title":"Binlog Count","text":"<p>This metric shows the overall count of binary log files, on both primary and secondary servers.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlogs-created-hourly","title":"Binlogs Created Hourly","text":"<p>This metric shows the number of binlog files created hourly during the last 24 hours.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#relay-log-space","title":"Relay Log Space","text":"<p>This metric shows the overall size of the relay log files. It only applies to a secondary host.</p> <p>The relay log consists of a set of numbered files containing the events to be executed on the secondary host to replicate database changes.</p> <p>The relay log has the same format as the binlog.</p> <p>There can be multiple relay log files depending on the rotation policy adopted (using the configuration variable <code>max_relay_log_size</code>).</p> <p>As soon as the SQL thread completes to execute all events in the relay log file, the file is deleted.</p> <p>If this metric contains a high value, the variable <code>max_relay_log_file</code> is high too. Generally, this not a serious issue. If the value of this metric is constantly increased, the secondary is delaying too much in applying the events.</p> <p>Treat this metric in the same way as the MySQL Replication Delay metric.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#relay-log-written-hourly","title":"Relay Log Written Hourly","text":"<p>This metric shows the amount of data written hourly into relay log files during the last 24 hours.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html","title":"MySQL Table Details","text":""},{"location":"reference/dashboards/dashboard-mysql-table-details.html#largest-tables","title":"Largest Tables","text":"Largest Tables by Row Count The estimated number of rows in the table from <code>information_schema.tables</code>. Largest Tables by Size The size of the table components from <code>information_schema.tables</code>."},{"location":"reference/dashboards/dashboard-mysql-table-details.html#pie","title":"Pie","text":"Total Database Size The total size of the database: as data + index size, so freeable one. Most Fragmented Tables by Freeable Size The list of 5 most fragmented tables ordered by their freeable size"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#table-activity","title":"Table Activity","text":"<p>The next two graphs are available only for Percona Server and MariaDB and require <code>userstat</code> variable turned on.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#rows-read","title":"Rows read","text":"<p>The number of rows read from the table, shown for the top 5 tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#rows-changed","title":"Rows Changed","text":"<p>The number of rows changed in the table, shown for the top 5 tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#auto-increment-usage","title":"Auto Increment Usage","text":"<p>The current value of an <code>auto_increment</code> column from <code>information_schema</code>, shown for the top 10 tables.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-tokudb-details.html","title":"MySQL TokuDB Details","text":""},{"location":"reference/dashboards/dashboard-mysql-tokudb-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-user-details.html","title":"MySQL User Details","text":"<p>This dashboard requires Percona Server for MySQL 5.1+ or MariaDB 10.1/10.2 with XtraDB. Also <code>userstat</code> should be enabled, for example with the <code>SET GLOBAL userstat=1</code> statement. See Setting up MySQL.</p> <p>Data is displayed for the 5 top users.</p> Top Users by Connections Created The number of times user\u2019s connections connected using SSL to the server. Top Users by Traffic The number of bytes sent to the user\u2019s connections. Top Users by Rows Fetched/Read The number of rows fetched by the user\u2019s connections. Top Users by Rows Updated The number of rows updated by the user\u2019s connections. Top Users by Busy Time The cumulative number of seconds there was activity on connections from the user. Top Users by CPU Time The cumulative CPU time elapsed, in seconds, while servicing connections of the user. <p></p>"},{"location":"reference/dashboards/dashboard-mysql-user-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-mysql-wait-event-analyses-details.html","title":"MySQL Wait Event Analyses Details","text":"<p>This dashboard helps to analyze Performance Schema wait events. It plots the following metrics for the chosen (one or more) wait events:</p> <ul> <li>Count - Performance Schema Waits</li> <li>Load - Performance Schema Waits</li> <li>Avg Wait Time - Performance Schema Waits</li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-mysql-wait-event-analyses-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-network-details.html","title":"Network Details","text":""},{"location":"reference/dashboards/dashboard-network-details.html#last-hour-statistic","title":"Last Hour Statistic","text":"<p>This section reports the inbound speed, outbound speed, traffic errors and drops, and retransmit rate.</p>"},{"location":"reference/dashboards/dashboard-network-details.html#network-traffic","title":"Network Traffic","text":"<p>This section contains the Network traffic and network utilization hourly metrics.</p>"},{"location":"reference/dashboards/dashboard-network-details.html#network-traffic-details","title":"Network Traffic Details","text":"<p>This section offers the following metrics:</p> <ul> <li>Network traffic by packets</li> <li>Network traffic errors</li> <li>Network traffic drop</li> <li>Network traffic multicast</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#network-netstat-tcp","title":"Network Netstat TCP","text":"<p>This section offers the following metrics:</p> <ul> <li>Timeout value used for retransmitting</li> <li>Min TCP retransmission timeout</li> <li>Max TCP retransmission timeout</li> <li>Netstat: TCP</li> <li>TCP segments</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#network-netstat-udp","title":"Network Netstat UDP","text":"<p>In this section, you can find the following metrics:</p> <ul> <li>Netstat: UDP</li> <li>UDP Lite</li> </ul> <p>The graphs in the UDP Lite metric give statistics about:</p> <code>InDatagrams</code> Packets received <code>OutDatagrams</code> Packets sent <code>InCsumErrors</code> Datagrams with checksum errors <code>InErrors</code> Datagrams that could not be delivered to an application <code>RcvbufErrors</code> Datagrams for which not enough socket buffer memory to receive <code>SndbufErrors</code> Datagrams for which not enough socket buffer memory to transmit <code>NoPorts</code> Datagrams received on a port with no listener"},{"location":"reference/dashboards/dashboard-network-details.html#icmp","title":"ICMP","text":"<p>This section has the following metrics:</p> <ul> <li>ICMP Errors</li> <li>Messages/Redirects</li> <li>Echos</li> <li>Timestamps/Mask Requests</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#icmp-errors","title":"ICMP Errors","text":"<code>InErrors</code> Messages which the entity received but determined as having ICMP-specific errors (bad ICMP checksums, bad length, etc.) <code>OutErrors</code> Messages which this entity did not send due to problems discovered within ICMP, such as a lack of buffers <code>InDestUnreachs</code> Destination Unreachable messages received <code>OutDestUnreachs</code> Destination Unreachable messages sent <code>InType3</code> Destination unreachable <code>OutType3</code> Destination unreachable <code>InCsumErrors</code> Messages with ICMP checksum errors <code>InTimeExcds</code> Time Exceeded messages received"},{"location":"reference/dashboards/dashboard-network-details.html#messagesredirects","title":"Messages/Redirects","text":"<code>InMsgs</code> Messages which the entity received. Note that this counter includes all those counted by <code>icmpInErrors</code> <code>InRedirects</code> Redirect messages received <code>OutMsgs</code> Messages which this entity attempted to send. Note that this counter includes all those counted by <code>icmpOutErrors</code> <code>OutRedirects</code> Redirect messages sent. For a host, this object will always be zero, since hosts do not send redirects"},{"location":"reference/dashboards/dashboard-network-details.html#echos","title":"Echos","text":"<code>InEchoReps</code> Echo Reply messages received <code>InEchos</code> Echo (request) messages received <code>OutEchoReps</code> Echo Reply messages sent <code>OutEchos</code> Echo (request) messages sent"},{"location":"reference/dashboards/dashboard-network-details.html#timestampsmask-requests","title":"Timestamps/Mask Requests","text":"<code>InAddrMaskReps</code> Address Mask Reply messages received <code>InAddrMasks</code> Address Mask Request messages received <code>OutAddrMaskReps</code> Address Mask Reply messages sent <code>OutAddrMasks</code> Address Mask Request messages sent <code>InTimestampReps</code> Timestamp Reply messages received <code>InTimestamps</code> Timestamp Request messages received <code>OutTimestampReps</code> Timestamp Reply messages sent <code>OutTimestamps</code> Timestamp Request messages sent"},{"location":"reference/dashboards/dashboard-network-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-node-summary.html","title":"Node Summary","text":""},{"location":"reference/dashboards/dashboard-node-summary.html#system-summary","title":"System Summary","text":"<p>The output from <code>pt-summary</code>, one of the Percona Toolkit utilities.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#interrupts-and-context-switches","title":"Interrupts and Context Switches","text":"<p>Interrupt is an input signal to the processor indicating an event that needs immediate attention. An interrupt signal alerts the processor and serves as a request for the processor to interrupt the currently executing code, so that the event can be processed in a timely manner.</p> <p>Context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point. This allows multiple processes to share a single CPU, and is an essential feature of a multitasking operating system.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#swap-activity","title":"Swap Activity","text":"<p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#io-activity","title":"I/O Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#disk-io-latency","title":"Disk IO Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#disk-io-load","title":"Disk IO Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#local-network-errors","title":"Local Network Errors","text":"<p>Total Number of Local Network Interface Transmit Errors, Receive Errors and Drops.  Should be  Zero</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#tcp-retransmission","title":"TCP Retransmission","text":"<p>Retransmission, essentially identical with Automatic repeat request (ARQ), is the resending of packets which have been either damaged or lost. Retransmission is one of the basic mechanisms used by protocols operating over a packet switched computer network to provide reliable communication (such as that provided by a reliable byte stream, for example TCP).</p> <p></p>"},{"location":"reference/dashboards/dashboard-node-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html","title":"Node Temperature Details","text":"<p>The Node Temperature Details dashboard exposes hardware monitoring and sensor data obtained through the <code>sysfs</code> virtual file system of the node.</p> <p>Hardware monitoring devices attached to the CPU and/or other chips on the motherboard let you monitor the hardware health of a system. Most modern systems include several of such devices. The actual list can include temperature sensors, voltage sensors, fan speed sensors, and various additional features, such as the ability to control the rotation speed of the fans.</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#cpu-cores-temperatures","title":"CPU Cores Temperatures","text":"<p>Presents data taken from the temperature sensors of the CPU</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#chips-temperatures","title":"Chips Temperatures","text":"<p>Presents data taken from the temperature sensors connected to other system controllers</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#fan-rotation-speeds","title":"Fan Rotation Speeds","text":"<p>Fan rotation speeds reported in RPM (rotations per minute).</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#fan-power-usage","title":"Fan Power Usage","text":"<p>Describes the pulse width modulation of the PWN-equipped fans. PWM operates like a switch that constantly cycles on and off, thereby regulating the amount of power the fan gains: 100% makes it rotate at full speed, while lower percentage slows rotation down proportionally.</p> <p></p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-nodes-compare.html","title":"Nodes Compare","text":"<p>This dashboard lets you compare a wide range of parameters. Parameters of the same type are shown side by side for all servers, grouped into the following sections:</p> <ul> <li>System Information</li> <li>CPU</li> <li>Memory</li> <li>Disk Partitions</li> <li>Disk Performance</li> <li>Network</li> </ul> <p>The System Information section shows the System Info summary of each server, as well as System Uptime, CPU Cores, RAM, Saturation Metrics, and Load Average gauges.</p> <p>The CPU section offers the CPU Usage, Interrupts, and Context Switches metrics.</p> <p>In the Memory section, you can find the Memory Usage, Swap Usage, and Swap Activity metrics.</p> <p>The Disk Partitions section encapsulates two metrics, Mountpoint Usage and Free Space.</p> <p>The Disk Performance section contains the I/O Activity, Disk Operations, Disk Bandwidth, Disk IO Utilization, Disk Latency, and Disk Load metrics.</p> <p>Finally, Network section shows Network Traffic, and Network Utilization Hourly metrics.</p> <p></p>"},{"location":"reference/dashboards/dashboard-nodes-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-nodes-overview.html","title":"Nodes Overview","text":"<p>The Nodes Overview dashboard provides details about the efficiency of work of the following components. Each component is represented as a section in the dashboard.</p> <ul> <li>CPU</li> <li>Memory &amp; Swap</li> <li>Disk</li> <li>Network</li> </ul> <p>The CPU section offers the CPU Usage, CPU Saturation and Max Core Usage, Interrupts and Context Switches, and Processes metrics.</p> <p>In the Memory section, you can find the Memory Utilization, Virtual Memory Utilization, Swap Space, and Swap Activity metrics.</p> <p>The Disk section contains the I/O Activity, Global File Descriptors Usage, Disk IO Latency, and Disk IO Load metrics.</p> <p>In the Network section, you can find the Network Traffic, Network Utilization Hourly, Local Network Errors, and TCP Retransmission metrics.</p> <p></p>"},{"location":"reference/dashboards/dashboard-nodes-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-numa-details.html","title":"NUMA Details","text":"<p>For each node, this dashboard shows metrics related to Non-uniform memory access (NUMA).</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#memory-usage","title":"Memory Usage","text":"<p>Remotes over time the total, used, and free memory.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#free-memory-percent","title":"Free Memory Percent","text":"<p>Shows the free memory as the ratio to the total available memory.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#numa-memory-usage-types","title":"NUMA Memory Usage Types","text":"<code>Dirty</code> Memory waiting to be written back to disk <code>Bounce</code> Memory used for block device bounce buffers <code>Mapped</code> Files which have been mapped, such as libraries <code>KernelStack</code> The memory the kernel stack uses. This is not reclaimable."},{"location":"reference/dashboards/dashboard-numa-details.html#numa-allocation-hits","title":"NUMA Allocation Hits","text":"<p>Memory successfully allocated on this node as intended.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#numa-allocation-missed","title":"NUMA Allocation Missed","text":"<p>Memory missed is allocated on a node despite the process preferring some different node.</p> <p>Memory foreign is intended for a node, but actually allocated on some different node.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#anonymous-memory","title":"Anonymous Memory","text":"Active Anonymous memory that has been used more recently and usually not swapped out. Inactive Anonymous memory that has not been used recently and can be swapped out."},{"location":"reference/dashboards/dashboard-numa-details.html#numa-file-pagecache","title":"NUMA File (PageCache)","text":"<p>Active(file) Pagecache memory that has been used more recently and usually not reclaimed until needed.</p> <p>Inactive(file) Pagecache memory that can be reclaimed without huge performance impact.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#shared-memory","title":"Shared Memory","text":"<p>Shmem Total used shared memory (shared between several processes, thus including RAM disks, SYS-V-IPC and BSD like SHMEM).</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#hugepages-statistics","title":"HugePages Statistics","text":"Total Number of hugepages being allocated by the kernel (Defined with <code>vm.nr_hugepages</code>). Free The number of hugepages not being allocated by a process <code>Surp</code> The number of hugepages in the pool above the value in <code>vm.nr_hugepages</code>. The maximum number of surplus hugepages is controlled by <code>vm.nr_overcommit_hugepages</code>."},{"location":"reference/dashboards/dashboard-numa-details.html#local-processes","title":"Local Processes","text":"<p>Memory allocated on a node while a process was running on it.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#remote-processes","title":"Remote Processes","text":"<p>Memory allocated on a node while a process was running on some other node.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#slab-memory","title":"Slab Memory","text":"<code>Slab</code> Allocation is a memory management mechanism intended for the efficient memory allocation of kernel objects. <code>SReclaimable</code> The part of the Slab that might be reclaimed (such as caches). <code>SUnreclaim</code> The part of the Slab that can\u2019t be reclaimed under memory pressure"},{"location":"reference/dashboards/dashboard-numa-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html","title":"PostgreSQL Instance Summary","text":""},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#number-of-temp-files","title":"Number of Temp Files","text":"<p>Cumulative number of temporary files created by queries in this database since service start. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#size-of-temp-files","title":"Size of Temp Files","text":"<p>Cumulative amount of data written to temporary files by queries in this database since service start. All temporary files are counted, regardless of why the temporary file was created, and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#temp-files-activity","title":"Temp Files Activity","text":"<p>Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#temp-files-utilization","title":"Temp Files Utilization","text":"<p>Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#canceled-queries","title":"Canceled Queries","text":"<p>Based on <code>pg_stat_database_conflicts</code> view</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-compare.html","title":"PostgreSQL Instances Compare","text":"<p>No description</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html","title":"PostgreSQL Instances Overview","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#connected","title":"Connected","text":"<p>Reports whether PMM Server can connect to the PostgreSQL instance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#version","title":"Version","text":"<p>The version of the PostgreSQL instance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#shared-buffers","title":"Shared Buffers","text":"<p>Defines the amount of memory the database server uses for shared memory buffers. Default is <code>128MB</code>. Guidance on tuning is <code>25%</code> of RAM, but generally doesn\u2019t exceed <code>40%</code>.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#disk-page-buffers","title":"Disk-Page Buffers","text":"<p>The setting <code>wal_buffers</code> defines how much memory is used for caching the write-ahead log entries. Generally this value is small (<code>3%</code> of <code>shared_buffers</code> value), but it may need to be modified for heavily loaded servers.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#memory-size-for-each-sort","title":"Memory Size for each Sort","text":"<p>The parameter <code>work_mem</code> defines the amount of memory assigned for internal sort operations and hash tables before writing to temporary disk files. The default is <code>4MB</code>.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#disk-cache-size","title":"Disk Cache Size","text":"<p>PostgreSQL\u2019s <code>effective_cache_size</code> variable tunes how much RAM you expect to be available for disk caching. Generally adding Linux free+cached will give you a good idea. This value is used by the query planner whether plans will fit in memory, and when defined too low, can lead to some plans rejecting certain indexes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#autovacuum","title":"Autovacuum","text":"<p>Whether autovacuum process is enabled or not. Generally the solution is to vacuum more often, not less.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#postgresql-connections","title":"PostgreSQL Connections","text":"Max Connections The maximum number of client connections allowed. Change this value with care as there are some memory resources that are allocated on a per-client basis, so setting <code>max_connections</code> higher will generally increase overall PostgreSQL memory usage. Connections The number of connection attempts (successful or not) to the PostgreSQL server. Active Connections The number of open connections to the PostgreSQL server."},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#postgresql-tuples","title":"PostgreSQL Tuples","text":"Tuples The total number of rows processed by PostgreSQL server: fetched, returned, inserted, updated, and deleted. Read Tuple Activity The number of rows read from the database: as returned so fetched ones. Tuples Changed per 5 min The number of rows changed in the last 5 minutes: inserted, updated, and deleted ones."},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#postgresql-transactions","title":"PostgreSQL Transactions","text":"Transactions The total number of transactions that have been either been committed or rolled back. Duration of Transactions Maximum duration in seconds any active transaction has been running."},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#temp-files","title":"Temp Files","text":"Number of Temp Files The number of temporary files created by queries. Size of Temp files The total amount of data written to temporary files by queries in bytes. <p>All temporary files are taken into account by these two gauges, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the <code>log_temp_files</code> setting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#conflicts-and-locks","title":"Conflicts and Locks","text":"Conflicts/Deadlocks The number of queries canceled due to conflicts with recovery in the database (due to dropped tablespaces, lock timeouts, old snapshots, pinned buffers, or deadlocks). Number of Locks The number of deadlocks detected by PostgreSQL."},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#buffers-and-blocks-operations","title":"Buffers and Blocks Operations","text":"Operations with Blocks The time spent reading and writing data file blocks by back ends, in milliseconds. <p>Tip</p> <p>Capturing read and write time statistics is possible only if <code>track_io_timing</code> setting is enabled. This can be done either in configuration file or with the following query executed on the running system:</p> <pre><code>ALTER SYSTEM SET track_io_timing=ON;\nSELECT pg_reload_conf();\n</code></pre> Buffers The number of buffers allocated by PostgreSQL."},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#canceled-queries","title":"Canceled Queries","text":"<p>The number of queries that have been canceled due to dropped tablespaces, lock timeouts, old snapshots, pinned buffers, and deadlocks.</p> <p>Data shown by this gauge are based on the <code>pg_stat_database_conflicts</code> view.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#cache-hit-ratio","title":"Cache Hit Ratio","text":"<p>The number of times disk blocks were found already in the buffer cache, so that a read was not necessary.</p> <p>This only includes hits in the PostgreSQL buffer cache, not the operating system\u2019s file system cache.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#checkpoint-stats","title":"Checkpoint Stats","text":"<p>The total amount of time that has been spent in the portion of checkpoint processing where files are either written or synchronized to disk, in milliseconds.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#postgresql-settings","title":"PostgreSQL Settings","text":"<p>The list of all settings of the PostgreSQL server.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#system-summary","title":"System Summary","text":"<p>This section contains the following system parameters of the PostgreSQL server: CPU Usage, CPU Saturation and Max Core Usage, Disk I/O Activity, and Network Traffic.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-postgresql-vacuum-monitoring-experimental.html","title":"Experimental PostgreSQL Vacuum Monitoring","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>This dashbaord provides timely insights into the autovacuum process in PostgreSQL.</p> <p>This dashboard contains the following:</p> <ul> <li> <p>Dead tuples - Identifies the number of dead rows in each table even though the rows are physically removed from the table.</p> </li> <li> <p>Last time vacuum ran - Tracks the last time a vacuum or autovacuum process successfully ran on each of your tables.</p> </li> <li> <p>Number of rows modified since last Analyze - The number of rows changed since the last time ANALYZE ran.</p> </li> <li> <p>Manual vacuum events - Tracks the number of times a manual vacuum was run on each table.</p> </li> <li> <p>Table disk usage - Tracking the disk space used by each table is crucial as it enables you to gauge expected changes in the query performance over time - but it can also help you detect potential vacuuming-related issues.</p> </li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-vacuum-monitoring-experimental.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-processes-details.html","title":"Processes Details","text":"<p>The Processes Details dashboard displays Linux process information - PIDs, Threads, and Processes.  The dashboard shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O). When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound. When the number of process blocked waiting for I/O is large, the load is disk bound. The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p> <p>The dashboard consists of two parts: the first section describes metrics for all hosts, and the second part provides charts for each host.</p> <p>Charts for all hosts, available in the first section, are the following ones:</p> <ul> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> <li>Runnable Processes</li> <li>Blocked Processes Waiting for I/O</li> <li>Sleeping Processes</li> <li>Running Processes</li> <li>Disk Sleep Processes</li> <li>Stopped Processes</li> <li>Zombie Processes</li> <li>Dead Processes</li> </ul> <p>The following charts are present in the second part, available for each host:</p> <ul> <li>Processes</li> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> </ul>"},{"location":"reference/dashboards/dashboard-processes-details.html#runnable-processes","title":"Runnable Processes","text":""},{"location":"reference/dashboards/dashboard-processes-details.html#processes","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p>"},{"location":"reference/dashboards/dashboard-processes-details.html#blocked-processes-waiting-for-io","title":"Blocked Processes Waiting for I/O","text":""},{"location":"reference/dashboards/dashboard-processes-details.html#processes_1","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p> <p></p>"},{"location":"reference/dashboards/dashboard-processes-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-prometheus-exporter-status.html","title":"Prometheus Exporter Status","text":"<p>The Prometheus Exporter Status dashboard reports the consumption of resources by the Prometheus exporters used by PMM. For each exporter, this dashboard reveals the following information:</p> <ul> <li>CPU usage</li> <li>Memory usage</li> <li>File descriptors used</li> <li>Exporter uptime</li> </ul> <p></p>"},{"location":"reference/dashboards/dashboard-prometheus-exporter-status.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html","title":"Prometheus Exporters Overview","text":""},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-summary","title":"Prometheus Exporters Summary","text":"<p>This section provides a summary of how exporters are used across the selected hosts. It includes the average usage of CPU and memory as well as the number of hosts being monitored and the total number of running exporters.</p> Avg CPU Usage per Host Shows the average CPU usage in percent per host for all exporters. Avg Memory Usage per Host Shows the Exporters average Memory usage per host. Monitored Hosts Shows the number of monitored hosts that are running Exporters. Exporters Running Shows the total number of Exporters running with this PMM Server instance. <p>Note</p> <p>The CPU usage and memory usage do not include the additional CPU and memory usage required to produce metrics by the application or operating system.</p>"},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-node","title":"Prometheus Exporters Resource Usage by Node","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for the selected hosts.</p> CPU Usage Plots the Exporters\u2019 CPU usage across each monitored host (by default, All hosts). Memory Usage Plots the Exporters\u2019 Memory usage across each monitored host (by default, All hosts)."},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-type","title":"Prometheus Exporters Resource Usage by Type","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for host types: MySQL, MongoDB, ProxySQL, and the system.</p> CPU Cores Used Shows the Exporters\u2019 CPU Cores used for each type of Exporter. Memory Usage Shows the Exporters\u2019 memory used for each type of Exporter."},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#list-of-hosts","title":"List of Hosts","text":"<p>At the bottom, this dashboard shows details for each running host.</p> CPU Used Show the CPU usage as a percentage for all Exporters. Mem Used Shows total Memory Used by Exporters. Exporters Running Shows the number of Exporters running. RAM Shows the total amount of RAM of the host. Virtual CPUs Shows the total number of virtual CPUs on the host. <p>You can click the value of the CPU Used, Memory Used, or Exporters Running columns to open the Prometheus Exporter Status dashboard for further analysis.</p> <p>See also</p> <p>Percona blog: Understand Your Prometheus Exporters with Percona Monitoring and Management (PMM)</p> <p></p>"},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-proxysql-instance-summary.html","title":"ProxySQL Instance Summary","text":""},{"location":"reference/dashboards/dashboard-proxysql-instance-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p> <p></p>"},{"location":"reference/dashboards/dashboard-proxysql-instance-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary-experimental.html","title":"Experimental PXC/Galera Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>The experimental PXC/Galera Cluster Summary dashboard provides a high level information about the clusters, resource utilization and its state for MySQL databases.</p> <p></p> <p></p>"},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary-experimental.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary.html","title":"PXC/Galera Cluster Summary","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html","title":"PXC/Galera Node Summary","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-latency","title":"Galera Replication Latency","text":"<p>Shows figures for the replication latency on group communication. It measures latency from the time point when a message is sent out to the time point when a message is received. As replication is a group operation, this essentially gives you the slowest ACK and longest RTT in the cluster.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-queues","title":"Galera Replication Queues","text":"<p>Shows the length of receive and send queues.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-cluster-size","title":"Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-flow-control","title":"Galera Flow Control","text":"<p>Shows the number of <code>FC_PAUSE</code> events sent/received. They are sent by a node when its replication queue gets too full. If a node is sending out FC messages it indicates a problem.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-parallelization-efficiency","title":"Galera Parallelization Efficiency","text":"<p>Shows the average distances between highest and lowest seqno that are concurrently applied, committed and can be possibly applied in parallel (potential degree of parallelization).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writing-conflicts","title":"Galera Writing Conflicts","text":"<p>Shows the number of local transactions being committed on this node that failed certification (some other node had a commit that conflicted with ours) \u2013 client received deadlock error on commit and also the number of local transactions in flight on this node that were aborted because they locked something an applier thread needed \u2013 deadlock error anywhere in an open transaction. Spikes in the graph may indicate writing to the same table potentially the same rows from 2 nodes.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#available-downtime-before-sst-required","title":"Available Downtime before SST Required","text":"<p>Shows for how long the node can be taken out of the cluster before SST is required. SST is a full state transfer method.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-count","title":"Galera Writeset Count","text":"<p>Shows the count of transactions received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-size","title":"Galera Writeset Size","text":"<p>Shows the average transaction size received/replicated.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-traffic","title":"Galera Writeset Traffic","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-network-usage-hourly","title":"Galera Network Usage Hourly","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p> <p></p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-nodes-compare.html","title":"PXC/Galera Nodes Compare","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-nodes-compare.html#cluster-galera-cluster-size","title":"$cluster - Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p> <p></p>"},{"location":"reference/dashboards/dashboard-pxc-galera-nodes-compare.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-victoriametrics-agents-overview.html","title":"VictoriaMetrics Agents Overview","text":""},{"location":"reference/dashboards/dashboard-victoriametrics-agents-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/dashboard-victoriametrics.html","title":"VictoriaMetrics","text":"<p>Description coming soon</p> <p></p>"},{"location":"reference/dashboards/dashboard-victoriametrics.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/kubernetes_cluster_summary.html","title":"Kubernetes Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>Kubernetes Volumes dashboard provides a comprehensive overview of your Kubernetes cluster, including:</p> <ul> <li>Resources</li> <li>Node Status</li> <li>Pod Status</li> <li>PVC status</li> <li>CPU Overview</li> <li>Kubernetes Resource Count</li> <li>Memory Overview and more</li> </ul> <p>With this dashboard, you can view all workloads running in the cluster and optimize their performance.</p> <p></p>"},{"location":"reference/dashboards/kubernetes_cluster_summary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/kubernetes_monitor_db_clusters_managed.html","title":"DB clusters managed with Percona Kubernetes Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>This dashboard displays the primary parameters of database clusters created by Percona Operators for various databases and helps identify the performance issues.</p> <p></p> <p></p>"},{"location":"reference/dashboards/kubernetes_monitor_db_clusters_managed.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/dashboards/kubernetes_monitor_operators.html","title":"Kubernetes monitoring for Percona Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Monitoring the state of the database is crucial to timely identify and react to performance issues. Percona Monitoring and Management (PMM) solution enables you to do just that.</p> <p>However, the database state also depends on the state of the Kubernetes cluster itself. Hence it\u2019s important to have metrics that can depict the state of the Kubernetes cluster.</p> <p>For information on setting up monitoring for the Kubernetes cluster health, see documentation. </p> <p>This setup has been tested with the PMM Server as the centralized data storage and the Victoria Metrics Kubernetes monitoring stack as the metrics collector. These steps may also apply if you use another Prometheus-compatible storage.</p>"},{"location":"reference/dashboards/kubernetes_monitor_operators.html#kubernetes-overview","title":"Kubernetes overview","text":"<p>The Kubernetes Cluster overview dashboard gives you an overview of Kubernetes health and its objects, including Percona custom resources.</p> <p></p> <p></p>"},{"location":"reference/dashboards/kubernetes_monitor_operators.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/third-party/index.html","title":"About third party solutions used in PMM","text":""},{"location":"reference/third-party/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/third-party/clickhouse.html","title":"ClickHouse","text":"<p>You can use an external ClickHouse database instance outside the PMM Server container running on other hosts.</p>"},{"location":"reference/third-party/clickhouse.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use ClickHouse parameters as environment variables:</p> <p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production.</p> <p>To use ClickHouse as an external database instance, use the following environment variables: </p> <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> -&gt; hostname:port Name of the host and port of the external ClickHouse database instance.  <p>Optional environment variables</p> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> -&gt; database name Database name of the external ClickHouse database instance. <code>\u200b\u200bPERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> -&gt; pool size The maximum number of threads in the current connection thread pool. This value cannot be bigger than max_thread_pool_size. <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> -&gt; max block size The number of rows to load from tables in one block for this connection. <p>Example</p> <p>To use ClickHouse as an external database instance, start the PMM docker with the specified variables for external ClickHouse: \u200b\u200b</p> <pre><code>-e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=$ADDRESS:$PORT\n-e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=$DB\n-e PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE=1 \n-e PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE=65000\n</code></pre>"},{"location":"reference/third-party/clickhouse.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the ClickHouse troubleshooting documentation.</p> <p></p>"},{"location":"reference/third-party/clickhouse.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/third-party/postgresql.html","title":"PostgreSQL","text":"<p>You can use an external PostgreSQL database instance outside the PMM Server container running on the same or other hosts.</p>"},{"location":"reference/third-party/postgresql.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use PostgreSQL parameters as environment variables:</p> <p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. It is recommended that you use these variables for testing purposes only and not on production. The minimum supported PostgreSQL server version is 14.</p> <p>To use PostgreSQL as an external database instance, use the following environment variables:</p> Environment variable Flag Description PERCONA_TEST_POSTGRES_ADDR postgres-addr Hostname and port for external PostgreSQL database. PERCONA_TEST_POSTGRES_DBNAME postgres-name Database name for external or internal PostgreSQL database. PERCONA_TEST_POSTGRES_USERNAME postgres-username PostgreSQL user name to connect as. PERCONA_TEST_POSTGRES_DBPASSWORD postgres-password Password to be used for database authentication. PERCONA_TEST_POSTGRES_SSL_MODE postgres-ssl-mode This option determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the database. Currently supported: <code>disable</code>, <code>require</code>, <code>verify-ca</code>, <code>verify-full</code>. PERCONA_TEST_POSTGRES_SSL_CA_PATH postgres-ssl-ca-path This parameter specifies the name of a file containing SSL certificate authority (CA) certificate(s). PERCONA_TEST_POSTGRES_SSL_KEY_PATH postgres-ssl-key-path This parameter specifies the location for the secret key used for the client certificate. PERCONA_TEST_POSTGRES_SSL_CERT_PATH postgres-ssl-cert-path This parameter specifies the file name of the client SSL certificate. PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES Environment variable to disable built-in PMM Server database. Note that Grafana depends on built-in PostgreSQL. And if the value of this variable is \u201ctrue\u201d, then it is necessary to pass all the parameters associated with Grafana to use external PostgreSQL. <p>By default, communication between the PMM Server and the database is not encrypted. To secure a connection, follow PostgeSQL SSL instructions and provide <code>POSTGRES_SSL_*</code> variables.</p> <p>To use grafana with external PostgreSQL add <code>GF_DATABASE_*</code> environment variables accordingly.</p> <p>Example</p> <p>To use PostgreSQL as an external database:</p> <ol> <li>Generate all necessary SSL certificates.</li> <li> <p>Deploy PMM Server with certificates under read-only permissions and Grafana user and Grafana group.</p> <pre><code>```sh\n/pmm-server-certificates# la -la\ndrwxr-xr-x 1 root    root    4096 Apr  5 12:43 .\ndrwxr-xr-x 1 root    root    4096 Apr  5 12:43 ..\n-rw------- 1 grafana grafana 1391 Apr  5 12:38 certificate_authority.crt\n-rw------- 1 grafana grafana 1257 Apr  5 12:38 pmm_server.crt\n-rw------- 1 grafana grafana 1708 Apr  5 12:38 pmm_server.key\n```\n</code></pre> </li> <li> <p>Attach <code>pg_hba.conf</code> and certificates to the PostgreSQL image.</p> <pre><code>```sh\n/external-postgres-configuration# cat pg_hba.conf \nlocal     all         all                                    trust\nhostnossl all         example_user all                       reject\nhostssl   all         example_user all                       cert\n\n\n/external-postgres-certificates# ls -la\ndrwxr-xr-x 1 root     root     4096 Apr  5 12:38 .\ndrwxr-xr-x 1 root     root     4096 Apr  5 12:43 ..\n-rw------- 1 postgres postgres 1391 Apr  5 12:38 certificate_authority.crt\n-rw------- 1 postgres postgres 1407 Apr  5 12:38 external_postgres.crt\n-rw------- 1 postgres postgres 1708 Apr  5 12:38 external_postgres.key\n```\n</code></pre> </li> <li> <p>Create <code>user</code> and <code>database</code> for pmm-server to use. Set appropriate rights and access.</p> </li> <li> <p>Install <code>pg_stat_statements</code> in PostgreSQL in order to have all metrics according to this handy document.</p> </li> <li> <p>Run PostgreSQL server.</p> <pre><code>docker run\n--name external-postgres\n-e POSTGRES_PASSWORD=secret\n&lt;image_id&gt;\npostgres\n-c shared_preload_libraries=pg_stat_statements\n-c pg_stat_statements.max=10000\n-c pg_stat_statements.track=all\n-c pg_stat_statements.save=off\n-c ssl=on\n-c ssl_ca_file=$CA_PATH\n-c ssl_key_file=$KEY_PATH\n-c ssl_cert_file=$CERT_PATH\n-c hba_file=$HBA_PATH\n</code></pre> </li> <li> <p>Run PMM Server.</p> <pre><code>docker run \n--name pmm-server \n-e PERCONA_TEST_POSTGRES_ADDR=$ADDRESS:$PORT\n-e PERCONA_TEST_POSTGRES_DBNAME=$DBNAME\n-e PERCONA_TEST_POSTGRES_USERNAME=$USER\n-e PERCONA_TEST_POSTGRES_DBPASSWORD=$PASSWORD\n-e PERCONA_TEST_POSTGRES_SSL_MODE=$SSL_MODE\n-e PERCONA_TEST_POSTGRES_SSL_CA_PATH=$CA_PATH\n-e PERCONA_TEST_POSTGRES_SSL_KEY_PATH=$KEY_PATH\n-e PERCONA_TEST_POSTGRES_SSL_CERT_PATH=$CERT_PATH \n-e PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES=true\n-e GF_DATABASE_URL=$GF_DATABASE_URL\n-e GF_DATABASE_SSL_MODE=$GF_SSL_MODE\n-e GF_DATABASE_CA_CERT_PATH=$GF_CA_PATH\n-e GF_DATABASE_CLIENT_KEY_PATH=$GF_KEY_PATH\n-e GF_DATABASE_CLIENT_CERT_PATH=$GF_CERT_PATH\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol> <p></p>"},{"location":"reference/third-party/postgresql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/third-party/victoria.html","title":"VictoriaMetrics","text":"<p>VictoriaMetrics is a third-party monitoring solution and time-series database.</p>"},{"location":"reference/third-party/victoria.html#pushpull-modes","title":"Push/Pull modes","text":"<p>VictoriaMetrics metrics data can be both \u2018pushed\u2019 to the server and \u2018pulled\u2019 by the server. When setting up services, you can decide which mode to use.</p> <p>The mode (push/pull) is controlled by the <code>--metrics-mode</code> flag for the <code>pmm-admin config</code> and <code>pmm-admin add</code> commands.</p> <p>If you need to change the metrics mode for an existing Service, you must remove it and re-add it with the same name and the required flags. (You cannot update a service.)</p>"},{"location":"reference/third-party/victoria.html#remapped-targets-for-direct-prometheus-paths","title":"Remapped targets for direct Prometheus paths","text":"<p>Direct Prometheus paths return structured information directly from Prometheus, bypassing the PMM application.</p> <p>They are accessed by requesting a URL of the form <code>&lt;PMM SERVER URL&gt;/prometheus/&lt;PATH&gt;</code>.</p> <p>As a result of the move to VictoriaMetrics some direct Prometheus paths are no longer available.</p> Prometheus path VictoriaMetrics equivalent <code>/prometheus/alerts</code> No change. <code>/prometheus/config</code> No equivalent, but there is some information at <code>/prometheus/targets</code>. <code>/prometheus/flags</code> The <code>flag</code> metrics at <code>/prometheus/metrics</code>. <code>/prometheus/graph</code> <code>/graph/explore</code> (Grafana) or <code>graph/d/prometheus-advanced/advanced-data-exploration</code> (PMM dashboard). <code>/prometheus/rules</code> No change. <code>/prometheus/service-discovery</code> No equivalent. <code>/prometheus/status</code> Some information at <code>/prometheus/metrics</code>. High cardinality metrics information at <code>/prometheus/api/v1/status/tsdb</code>. <code>/prometheus/targets</code> <code>/victoriametrics/targets</code>"},{"location":"reference/third-party/victoria.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow users to set all other VictoriaMetrics parameters as environment variables:</p> <p>The environment variable must be prepended with <code>VM_</code>.</p> <p>Example</p> <p>To set downsampling, use the <code>downsampling.period</code> parameter as follows:</p> <pre><code>-e VM_downsampling_period=20d:10m,120d:2h\n</code></pre> <p>This instructs VictoriaMetrics to deduplicate samples older than 20 days with 10 minute intervals and samples older than 120 days with two hour intervals.</p>"},{"location":"reference/third-party/victoria.html#using-victoriametrics-external-database-instance","title":"Using VictoriaMetrics external database instance","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for evaluation purposes only.</p> <p>You can use an external VictoriaMetrics database for monitoring in PMM.</p> <p>The environment variable <code>PMM_VM_URL</code> has been added, which should point to the external VictoriaMetrics database and should have the following format:</p> <pre><code>http(s)://hostname:port/path.\n</code></pre> <p>If the external VictoriaMetrics database requires basic authentication, the following environment variables should be used:</p> <p><pre><code>VMAGENT_remoteWrite_basicAuth_username={username}\nVMAGENT_remoteWrite_basicAuth_password={password}\n</code></pre> If other authentication methods are used on the VictoriaMetrics side, users can use any of the <code>vmagent</code> environment variables by prepending <code>VMAGENT_ prefix</code>.</p> <p>When external VictoriaMetrics is configured, internal VictoriaMetrics stops. In this case, VM Agent on PMM Server pulls metrics from agents configured in the <code>pull metrics mode</code> and from remote nodes. Data is then pushed to external VictoriaMetrics.</p> <p>Note</p> <p>VM Agents run by PMM Clients push data directly to external VictoriaMetrics. </p> <p>Ensure that they can connect to external VictoriaMetrics.</p>"},{"location":"reference/third-party/victoria.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the VictoriaMetrics troubleshooting documentation.</p> <p>You can also contact the VictoriaMetrics team via:</p> <ul> <li>Google Groups</li> <li>Slack</li> <li>Reddit</li> <li>Telegram</li> </ul> <p></p>"},{"location":"reference/third-party/victoria.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/log_in.html","title":"Log into PMM","text":"<p>To log into PMM:</p> <ol> <li> <p>Start a web browser and in the address bar enter the server name or IP address of the PMM Server host.</p> </li> <li> <p>The page loads showing the PMM log in screen.</p> <p></p> </li> <li> <p>Enter the username and password given to you by your system administrator. The defaults are:</p> </li> <li> <p>Username: <code>admin</code></p> </li> <li> <p>Password: <code>admin</code></p> </li> <li> <p>Click Log in.</p> </li> <li> <p>If this is your first time logging in, you\u2019ll be asked to set a new password. We recommend you do.</p> </li> <li> <p>enter a new password in both fields and click Submit, or,</p> </li> <li> <p>click Skip to use the default password.</p> </li> <li> <p>The PMM Home dashboard loads:</p> </li> </ol> <p></p> <p></p>"},{"location":"reference/ui/log_in.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/timezone.html","title":"Set timezones","text":"<p>By default Grafana uses the timezone from your web browser. However, you can change this setting.</p> <p>To set the timezone:</p> <ol> <li>On the left menu, hover your cursor over your avatar and then click Preferences.</li> <li>Click to select an option in the Timezone list.</li> <li>Click Save.</li> </ol> <p></p>"},{"location":"reference/ui/timezone.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/ui_components.html","title":"UI components","text":"<p>How to log in, how the user interface is laid out, and what the controls do.</p> <p>PMM\u2019s user interface is a browser application based on Grafana.</p> <p></p>"},{"location":"reference/ui/ui_components.html#main-menu","title":"Main menu","text":"<p>The main menu is part of the Grafana framework and is visible on every page.</p> Item (Top) Name Description Starred Mark your favorite dashboards. Dashboards Create dashboards or [folders][Folders], manage dashboards, import dashboards, create playlists, manage snapshots. Explore Run queries with PromQL. Operating System (OS) Operating System dashboard Service Type dashboards Navigate to the dasboards available for the services added for monitoring (MySQL, MongoDB, PostgreSQL, HAproxy or ProxySQL). Query Analytics (QAN) Navigate to the Query Analytics dashboard where you can analyze database queries over time, optimize database performance, and identify the source of problems. Alerting Alerting, Create new alerts and manage your alert rules and alert templates. Advisors Run health assessment checks against your connected databases and check any failed checks. Backup [Backup management and storage location configuration][BACKUP]. The Backup icon appears when Backup Management is activated in  PMM Configuration &gt;  Settings &gt; Advanced Settings. Connections Access Grafana\u2019s built-in data sources within PMM to seamlessly integrate and visualize data from various systems like Prometheus, MySQL, PostgreSQL, InfluxDB, and Elasticsearch. PMM Configuration Administration Hosts all Grafana-related configuration and inventory options. Entitlements This tab is displayed after connecting PMM to Percona Portal, and shows all your Percona Platform account information. List of tickets opened by Customer Support Shows the list of tickets opened across your organization. This tab is only available after you connect PMM to Percona Platform. Environment Overview This tab is displayed after connecting PMM to Percona Portal. Shows the name and email of the Customer Success Manager assigned to your organization, who can help with any PMM queries. This tab will soon be populated with more useful information about your PMM environment. <p>See also</p> <ul> <li>How to render dashboard images</li> <li>How to annotate special events</li> </ul> <p></p>"},{"location":"reference/ui/ui_components.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/index.html","title":"About dashboards","text":"<p>Important</p> <p>The content is under development.</p> <p>The interface is a collection of web pages called dashboards.</p> <p>Dashboards are grouped into folders. You can customize these, by renaming them or creating new ones.</p> <p>The area inside dashboards is populated by panels. Some are in collapsible panel groups. A panel can show a value, a graph, a chart, or a visual representation of a set.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/annotate/annotate.html","title":"Annotation in dashboards","text":"<p>Annotations mark a moment in time. They are useful for marking system changes or other significant application events. They can be set globally or for specific nodes or services.</p> <p>You create them on the command line with the <code>pmm-admin annotate</code> command.</p> <p>Annotations show as a vertical dashed line on a dashboard graph. Reveal the annotation text by mousing over the caret indicator below the line.</p> <p></p> <p>You turn annotations on or off with the PMM Annotations switch in the second row menu bar.</p> <p></p> <p></p>"},{"location":"reference/ui/dashboards-panels/annotate/annotate.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_custom_for_org.html","title":"Set home dashboard for your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users</p> <ol> <li>Navigate to the dashboard that you want to set as the home dashboard.</li> <li>Click the  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>Hover your cursor over  Configuration</li> <li>Click Preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save.</li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_custom_for_org.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_custom_team.html","title":"Set home dashboard for your team","text":"<p>Organization and team Admins can set the home dashboard for their team as follows:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard to mark the dashboard as a favorite.</li> <li>On the main menu, hover your cursor over  Configuration. </li> <li>Click Teams. Grafana displays the team list.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_custom_team.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_personal_home.html","title":"Set custom Home Dashboard","text":"<p>The home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account. </p> <ol> <li>From the main menu, go to  Dashboards &gt; Browse and select the dashboard you want to set as your home dashboard.</li> <li> <p>Click the  star next to the dashboard title to mark it as a favorite.</p> <p></p> </li> <li> <p>From the side menu go to  Configuration &gt; Preferences. In the Home Dashboard field, select the dashboard that you want to set as your home dashboard. </p> <p></p> </li> <li> <p>Click Save.</p> </li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/custom_dashboard/set_personal_home.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/export-dashboards/export_dashboards.html","title":"Export a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/export-dashboards/export_dashboards.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/export-dashboards/import_dashboards.html","title":"Import a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/export-dashboards/import_dashboards.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/create-folders.html","title":"Create dashboard folders","text":"<p>Folders help you organize and group PMM dashboards, which is crucial when you have multiple dashboards or teams using the same PMM instance.</p> <p>Note</p> <p>To create a dashboard folder, you must have PMM\u2019s Admin privileges.</p> <p>To create a dashboard folder:</p> <ol> <li> <p>On the PMM dashboards page, from the side menu, go to  Dashboards &gt; New folder.</p> </li> <li> <p>Enter a unique name for your folder and click Create.</p> </li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/create-folders.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html","title":"Manage dashboard folders","text":"<p>This section describes how to delete multiple dashboards, move dashboards from one folder to another and navigate to a folder page where you can assign folder and dashboard permissions.</p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#delete-multiple-dashboards","title":"Delete multiple dashboards","text":"<p>To delete multiple dashboards at once:</p> <p>From the side menu, go to  Dashboards &gt; Browse and check the dashboards that you want to delete, and click Delete.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#move-dashboards-from-one-folder-to-another","title":"Move dashboards from one folder to another","text":"<p>You can move dashboards from one folder to another in the following two ways:</p> <ol> <li> <p>From the side menu, go to  Dashboards &gt; Browse and check the dashboards that you want to move. Click Move.</p> <p></p> </li> <li> <p>On the Choose Dashboard Folder dialog box select the dashboards that you want to move from the drop-down. Click Move.</p> </li> </ol> <p>The other way of moving dashboards from one folder to another is:</p> <ol> <li>Open the dashboard that you want to move to another folder.</li> <li>Click on  icon to open Dashboard Settings.</li> <li> <p>On the General page, under Folder select the folder name that you want to move from the dropdown.</p> <p></p> </li> <li> <p>Click Save Dashboard on the the left to save the change.</p> </li> </ol> <p>Note</p> <p>You should have atleast an Editor role to move a dashboard.</p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#navigate-to-a-dashboard-folder-page-to-assign-permissions","title":"Navigate to a dashboard folder page to assign permissions","text":"<ol> <li>From the side menu, go to  Dashboards &gt; Browse and hover over the dashboard folder whose permissions you want to set. Click Go to Folder.</li> <li> <p>Go to the Permissions tab and select the requisite permission from the drop-down for the various roles.</p> <p></p> </li> </ol>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#setting-custom-home-dashboard","title":"Setting custom Home Dashboard","text":"<p>The home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account. </p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#set-home-dashboard-for-your-organization","title":"Set home dashboard for your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users</p> <ol> <li>Navigate to the dashboard that you want to set as the home dashboard.</li> <li>Click the  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>Hover your cursor over  Configuration</li> <li>Click Preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#set-home-dashboard-for-your-team","title":"Set home dashboard for your team","text":"<p>Organization and team Admins can set the home dashboard for their team as follows:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard to mark the dashboard as a favorite.</li> <li>On the main menu, hover your cursor over  Configuration. </li> <li>Click Teams. Grafana displays the team list.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#set-your-personal-home-dashboard","title":"Set your Personal Home Dashboard","text":"<ol> <li>From the main menu, go to  Dashboards &gt; Browse and select the dashboard you want to set as your home dashboard.</li> <li> <p>Click the  star next to the dashboard title to mark it as a favorite.</p> <p></p> </li> <li> <p>From the side menu go to  Configuration &gt; Preferences. In the Home Dashboard field, select the dashboard that you want to set as your home dashboard. </p> <p></p> </li> <li> <p>Click Save.</p> </li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/manage-dashboards/manage-folders.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/publish_snapshot.html","title":"Publish snapshot","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/publish_snapshot.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/share_dashboard.html","title":"Share dashboards","text":"<p>When you need to share a dashboard with your team members, you can either send them a direct link to the dashboard, or render and send the dashboard as a .PNG image.</p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/share_dashboard.html#share-as-direct-link","title":"Share as direct link","text":"<ol> <li>Go to the dashboard that you want to share.</li> <li>Click at the top of the dashboard to display the panel menu.</li> <li>Select Share to reveal the Share Panel and either:  </li> <li>copy and send the full URL for the dashboard, OR</li> <li>toggle the Short URL option to generate a simple link with a unique identifier</li> </ol> <p>Tip</p> <p>If your current domain is different than the one specified in the Grafana .INI configuration file, PMM will ask you to correct this mismatch before you can generate a short URL:  To fix this</p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/share_dashboard.html#share-as-a-png-file","title":"Share as a PNG file","text":"<p>Rendering images requires the Image Renderer plug-in. If your PMM Admin has not installed this for your PMM instance, you will see the following error message under Share Panel &gt; Link. </p> <p>To install the dependencies:</p> <ol> <li> <p>Connect to your PMM Server Docker container.</p> <pre><code>docker exec -it pmm-server bash\n</code></pre> </li> <li> <p>Install Grafana plug-ins.</p> <pre><code>grafana-cli plugins install grafana-image-renderer\n</code></pre> </li> <li> <p>Restart Grafana.</p> <pre><code>supervisorctl restart grafana\n</code></pre> </li> <li> <p>Install libraries.</p> <pre><code>yum install -y libXcomposite libXdamage libXtst cups libXScrnSaver pango \\\natk adwaita-cursor-theme adwaita-icon-theme at at-spi2-atk at-spi2-core \\\ncairo-gobject colord-libs dconf desktop-file-utils ed emacs-filesystem \\\ngdk-pixbuf2 glib-networking gnutls gsettings-desktop-schemas \\\ngtk-update-icon-cache gtk3 hicolor-icon-theme jasper-libs json-glib \\\nlibappindicator-gtk3 libdbusmenu libdbusmenu-gtk3 libepoxy \\\nliberation-fonts liberation-narrow-fonts liberation-sans-fonts \\\nliberation-serif-fonts libgusb libindicator-gtk3 libmodman libproxy \\\nlibsoup libwayland-cursor libwayland-egl libxkbcommon m4 mailx nettle \\\npatch psmisc redhat-lsb-core redhat-lsb-submod-security rest spax time \\\ntrousers xdg-utils xkeyboard-config alsa-lib\n</code></pre> </li> </ol> <p>To render the image: </p> <ol> <li>Go to the dashboard that you want to share.</li> <li>Click at the top of the dashboard to display the panel menu.</li> <li>Select Share to reveal the Share Panel.</li> <li>Click Direct link rendered image. This opens a new browser tab.</li> <li>Wait for the image to be rendered, then use your browser\u2019s Image Save function to download the image.</li> </ol> <p></p>"},{"location":"reference/ui/dashboards-panels/share-dashboards/share_dashboard.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-feature.html","title":"Dashboard feature overview","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-feature.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-settings.html","title":"Dashboard settings","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-settings.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-time-range.html","title":"Set dashboard time range","text":""},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-time-range.html#time-units-and-relative-ranges","title":"Time units and relative ranges","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"reference/ui/dashboards-panels/use-dashboards/dashboard-time-range.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/index.html","title":"Release Notes","text":"<ul> <li>Percona Monitoring and Management 3.0.0 Beta</li> </ul>"},{"location":"release-notes/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/3.0.0_Beta.html","title":"Percona Monitoring and Management 3.0.0 Beta","text":"Release date November 22<sup>nd</sup>, 2024 Installation Installing Percona Monitoring and Management <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>It enables you to observe the health of your database systems, explore new patterns in their behavior, troubleshoot them and execute database management operations\u2014regardless of whether your databases are located on-premises or in the cloud.</p> <p>PMM 3.0.0 Beta introduces major security improvements with rootless deployments, encryption of sensitive data, enhanced stability through containerized architecture, and improved user experience with flexible monitoring configurations. Key changes include official ARM support, MongoDB 8.0 monitoring, and a streamlined upgrade process.</p>"},{"location":"release-notes/3.0.0_Beta.html#security-enhancements","title":"Security enhancements","text":""},{"location":"release-notes/3.0.0_Beta.html#support-for-rootless-deployments","title":"Support for rootless deployments","text":"<p>Using the root user in applications poses a significant security risk, particularly when outdated software is installed or resides in the environment.</p> <p>PMM Server now supports rootless deployment through multiple methods, including the latest versions of Podman, Helm, Docker, Virtual Appliance, and Amazon AWS.</p> <p>This rootless setup enhances security by eliminating the need for root privileges to create, run, and manage containers. By running PMM Server as a non-root user, you avoid granting root permissions on the host system, providing an additional layer of protection against potential vulnerabilities and security breaches.</p> <p>For instructions on deploying rootless PMM, check the Setting up PMM Server topic.</p>"},{"location":"release-notes/3.0.0_Beta.html#ui-based-upgrades-for-podman-installations","title":"UI-based upgrades for Podman installations","text":"<p>You can now upgrade PMM Server installations running under Podman directly through the PMM Configuration &gt; Updates panel in the UI. </p> <p>This functionality integrates Watchtower for automated container updates and requires configuration of new environment variables (<code>PMM_WATCHTOWER_HOST</code>, <code>PMM_WATCHTOWER_TOKEN</code>) as well as relevant systemd service settings.</p> <p>For detailed configuration instructions, see Installation with UI updates.</p>"},{"location":"release-notes/3.0.0_Beta.html#encryption-of-sensitive-data","title":"Encryption of sensitive data","text":"<p>Plaintext passwords and credentials are among the top ten security risks identified by OWASP (Open Web Application Security Project).</p> <p>To address this risk, PMM now encrypts all sensitive information stored in its database. This includes usernames, passwords, AWS keys, Azure credentials, and TLS/SSL certificates, significantly enhancing the security of your monitoring environment.  Even though we recommend minimal privileges for monitoring user accounts, you can rest assured that the sensitive data is protected! </p> <p>By default, PMM generates an encryption key and stores it at <code>/srv/pmm-encryption.key</code>. Alternatively, you can define a custom path for the encryption key using the new environment variable <code>PMM_ENCRYPTION_KEY_PATH</code>.</p> <p>When upgrading to PMM 3, any existing unencrypted PMM 2 data will be encrypted automatically.</p> <p>For more information, see PMM data encryption.</p>"},{"location":"release-notes/3.0.0_Beta.html#enhanced-api-authentication-with-grafana-service-accounts","title":"Enhanced API authentication with Grafana service accounts","text":"<p>We\u2019ve made a significant enhancement to the way API authentication is handled. PMM no longer relies on API keys as the primary method for controlling access to the PMM Server components and resources. Instead, PMM now leverages Grafana service accounts, which provide a more secure and manageable authentication mechanism compared to API keys.</p> <p>The transition to service accounts brings fine-grained access control and logging of all actions performed, providing more security, better visibility and auditing capabilities. </p> <p>When you install PMM 3, any existing API keys will be seamlessly converted to service accounts with corresponding service tokens. For more information about using service accounts in PMM, see Service account authentication.</p> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#enhanced-stability","title":"Enhanced stability","text":""},{"location":"release-notes/3.0.0_Beta.html#containerized-pmm-architecture-for-ami-and-ovf-deployments","title":"Containerized PMM architecture for AMI and OVF deployments","text":"<p>Previously, AMI and OVF instances of PMM were created as standalone images rather than being containerized like the primary Docker-based PMM version.</p> <p>This difference in architecture led to challenges in maintenance as fixes and updates for AMI and OVF instances required additional effort and were sometimes delayed due to their lower adoption rates.</p> <p>With this update, PMM now uses a unified containerized architecture across all deployment methods. In AMI and OVF environments, PMM components run as Podman-managed containers in rootless mode, eliminating the need for elevated system privileges.</p> <p>This transition not only aligns AMI and OVF deployments with PMM\u2019s core containerized model but also improves security, enables faster troubleshooting, and streamlines updates and patch management.</p>"},{"location":"release-notes/3.0.0_Beta.html#more-stable-and-quicker-upgrades","title":"More stable and quicker upgrades","text":"<p>PMM 3 introduces a significant upgrade system overhaul, replacing the earlier method based on internal package updates. While the previous approach offered the convenience of upgrading directly via the Update button on the Home dashboard, it was prone to connection issues and package corruption, often resulting in complex recovery challenges.</p> <p>The new upgrade method moves away from RPM updates to exclusive container updates, eliminating RPM-related complications. This streamlined approach provides consistent upgrade experiences across all deployment types\u2014Docker, Podman, and OVF/AMI.</p> <p>At the same time, we\u2019re maintaining the UI upgrade option by integrating Watchtower, an external upgrading tool. When you click the Upgrade Now button on the Home Dashboard, Watchtower seamlessly replaces the PMM Server container and links the new one to the existing volume, preserving all data and settings intact.</p> <p>For easy adoption, Watchtower comes pre-configured in our Easy-Install script, enabling one-step PMM setup.</p>"},{"location":"release-notes/3.0.0_Beta.html#improved-user-experience","title":"Improved user experience","text":""},{"location":"release-notes/3.0.0_Beta.html#new-upgrade-ui","title":"New upgrade UI","text":"<p>We\u2019ve introduced a new Updates page under PMM Configuration to support the new container-based upgrade system. This centralized interface offers clear visibility into the versions and configurations of both your PMM Server and Clients, simplifying the update process.</p> <p>With this update, you\u2019ll receive proactive notifications whenever new versions are release to help you make informed decisions before proceeding with available upgrades.</p> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#flexible-monitoring-configurations","title":"Flexible monitoring configurations","text":"<p>PMM extends its database monitoring setup process by adding an intuitive UI-driven approach alongside CLI-based configuration. After installing PMM Client on your database server, all further monitoring configurations can be managed directly through the PMM interface, eliminating the need for complex command-line operations.</p> <p>This simplified workflow combines with PMM\u2019s new ability to run database exporters on any PMM Client node rather than solely on PMM Server. By distributing the monitoring load across multiple PMM Clients, this approach enables more efficient monitoring of a larger number of remote and cloud-hosted databases, such as RDS instances.</p> <p>When adding new services through the PMM UI, you can now specify which PMM Client node will run the monitoring exporter. While PMM Server remains the default option, you can choose any node with PMM Client installed, including selecting specific clients on nodes with multiple installations.</p> <p>This distributed monitoring capability is currently available for new service additions, with support for existing service modification planned for a future release.</p> <p>For more details, see Connect services.</p> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#simplified-aws-installation-process","title":"Simplified AWS installation process","text":"<p>We\u2019ve simplified AWS installations to match our standard Docker/Podman workflow. After installation, you\u2019ll immediately see the PMM login screen.</p> <p>Use admin as the username and your EC2 Instance ID as the password (the default PMM password cannot be used for security reasons).</p> <p>You can find your Instance ID in the AWS Console. For detailed instructions, see Install PMM Server on AWS Marketplace.</p>"},{"location":"release-notes/3.0.0_Beta.html#official-arm-support-for-pmm-client","title":"Official ARM support for PMM Client","text":"<p>PMM 3 Beta now officially supports ARM architecture, upgrading from its experimental status in PMM 2.43. This means you can reliably monitor databases on ARM platforms, taking advantage of their cost-effective infrastructure and energy efficiency in data centers and cloud environments.</p> <p>Installation follows the standard PMM Client process, with no special requirements for ARM systems.  </p> <p>Try out this feature and share your experience on the PMM forum!</p>"},{"location":"release-notes/3.0.0_Beta.html#improved-ux-with-grafanas-latest-release","title":"Improved UX with Grafana\u2019s latest release","text":"<p>PMM now integrates Grafana 11.1.8, which delivers the following important enhancements alongside all the advancements introduced since the previous Grafana 9.2.20 integration in PMM2.</p> <p>For the full list of  Grafana changes included with this update, see Grafana\u2019s 11.1.8 changelog and Grafana release highlights.</p>"},{"location":"release-notes/3.0.0_Beta.html#improved-navigation","title":"Improved navigation","text":"<p>PMM now includes a revamped header with search, breadcrumbs, and a reorganized menu that groups related tools together, making it easier to navigate PMM\u2019s features and find what you need:</p> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#improved-alerting-workflow","title":"Improved Alerting workflow","text":"<p>Leveraging the new Grafana user interface updates, we\u2019ve taken the opportunity to refine the workflow for creating alerts from the Alert Rules and Alert Rule Templates pages.</p> <p>You\u2019ll notice separate, more visible options for creating different types of alert rules, cutting down on unnecessary steps and making it easier to manage various alert rules, templates, and configurations:</p> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#simplified-administration-settings-with-dedicated-menus","title":"Simplified administration settings with dedicated menus","text":"<p>Administration settings are now easier to manage with the new Administration menu. This menu brings together all Grafana-related configurations and account management options that were previously scattered across the general Configuration section. This change helps administrators locate and manage Grafana-specific settings more efficiently.</p> <p>Additionally, all PMM settings and inventory options are now grouped under a new PMM Configuration menu. This centralizes access to all PMM-related configurations, making it simpler for users to handle their PMM setup.</p> <p>These improvements make navigating easier and more organized, so you can quickly find and adjust settings for Grafana and PMM.</p>"},{"location":"release-notes/3.0.0_Beta.html#monitoring-improvements","title":"Monitoring improvements","text":""},{"location":"release-notes/3.0.0_Beta.html#added-monitoring-support-for-default-postgresql-database","title":"Added monitoring support for default PostgreSQL database","text":"<p>PMM now provides full monitoring support for the default <code>postgres</code> database on PostgreSQL instances, with metrics displayed across Query Analytics (QAN).</p> <p>This enhancement resolves a previous visibility gap where database activity was hidden when applications used the default database. </p> <p>While using the default database for applications is not recommended, PMM v3 ensures comprehensive visibility, empowering teams to identify and address this practice proactively and maintain better database management.</p>"},{"location":"release-notes/3.0.0_Beta.html#tech-preview-support-for-psmdb-and-community-mongodb-80","title":"[Tech Preview] Support for PSMDB  and Community MongoDB 8.0","text":"<p>The latest version of MongoDB, along with Percona Server for MongoDB 8.0, brings numerous improvements and significant performance enhancements. In this version of PMM, we are also adding support for MongoDB 8, allowing MongoDB users to monitor their new version and observe its performance impact.</p> <p>This includes updates to <code>mongodb_exporter</code> to accommodate PSMDB 8.0\u2019s revised metrics structure and renamed metrics (e.g., <code>wiredTiger.concurrentTransactions</code> is now <code>queues.execution</code>).</p> <p>This enhances monitoring, particularly for sharded cluster deployments, and requires PMM Agent version 2.43.1 or later.</p> <p>Keep in mind that some dashboard metrics may need further updates to fully support MongoDB 8.0\u2019s new format.</p>"},{"location":"release-notes/3.0.0_Beta.html#qan-improvements","title":"QAN improvements","text":""},{"location":"release-notes/3.0.0_Beta.html#increased-query-length-limit-for-mongodb-in-qan","title":"Increased query length limit for MongoDB in QAN","text":"<p>For MongoDB queries, the default maximum query length in Query Analytics (QAN) is now 4096 characters (up from 2048). This better supports long queries and aggregation pipelines while reducing truncation errors. Other databases retain the 2048-character limit.</p>"},{"location":"release-notes/3.0.0_Beta.html#enhanced-mysql-slowlog-query-identification","title":"Enhanced MySQL SlowLog query identification","text":"<p>Improved MySQL Slow Log query identification by extending the query ID length from 16 to 32 characters. This reduces the likelihood of ID collisions and ensures more accurate and reliable QAN results.</p>"},{"location":"release-notes/3.0.0_Beta.html#breaking-changes-and-deprecations","title":"Breaking changes and deprecations","text":""},{"location":"release-notes/3.0.0_Beta.html#oracle-enterprise-linux-9-images-only","title":"Oracle Enterprise Linux 9 images only","text":"<p>With Enterprise Linux 7 (EL7) approaching its end-of-life date, we\u2019ve made sure that PMM 3 exclusively uses Oracle Enterprise Linux 9 (EL9) as the base system for all PMM images.</p> <p>We began this transition from CentOS 7 to EL9 with the latest PMM 2 releases, and now with PMM 3, we are no longer building Docker containers, AMIs, or OVFs based on EL7.</p> <p>By moving to EL9, we ensure that PMM is built on most recent library versions and stays compatible with new technologies. Moreover, EL9 grants access to faster upstream responses to issues, particularly those concerning security, so that your PMM setup remains up-to-date and secure.</p> <p>Due to this change, PMM 3 cannot be started on host servers running EL7.</p>"},{"location":"release-notes/3.0.0_Beta.html#finalized-dbaas-migration-to-percona-everest","title":"Finalized DBaaS migration to Percona Everest","text":"<p>In previous PMM releases, the Database as a Service (DBaaS) functionality has been gradually transferred to Percona Everest, an open source cloud-native database platform that solves the challenge of public cloud DBaaS vendor lock-in.</p> <p>With Percona Everest, you gain the ability to provision and oversee highly performant database clusters on the infrastructure you manage, whether it\u2019s your preferred cloud environment or on-premises. This empowerment extends to regaining control over critical aspects such as data access, database configuration, and the costs associated with cloud-based database operations.</p> <p>While PMM 2.x versions continue to support existing DBaaS functionality, PMM 3 marks the complete deprecation of this feature, removing all references to DBaaS.</p> <p>If you are an existing PMM user who relies on DBaaS functionality, we encourage you to explore Percona Everest and leverage its advanced features for database deployment. Percona Everest also integrates with PMM to provide monitoring capabilities for your database infrastructure.</p> <p>To learn more about integrating Percona Everest with PMM and adding monitoring endpoints, see Add monitoring endpoints in the Everest documentation.</p>"},{"location":"release-notes/3.0.0_Beta.html#breaking-api-changes","title":"Breaking API changes","text":"<p>This release introduces major breaking API changes:</p> <ul> <li>Database record identifiers no longer use prefixes (e.g., <code>/agent_id/</code>) and are now represented as plain UUIDs.</li> <li>Feature toggles have been simplified from dual booleans to a single boolean control with an <code>enable_feature</code> property.  </li> <li>API responses now consistently emit all fields including those with default or zero values.</li> <li>Service, node, and agent management has been streamlined through consolidated endpoints where the resource type is specified as a top-level property in the request payload.</li> <li>Low-level Inventory API sections have been removed from documentation in favor of the Management API for inventory-related tasks.</li> </ul> <p>For detailed information about all these API changes and new endpoints, see the PMM API documentation. </p>"},{"location":"release-notes/3.0.0_Beta.html#new-upgrade-environment-variables","title":"New upgrade environment variables","text":"<p>When migrating from PMM v2 to PMM v3, you\u2019ll need to update your environment variables to match the new naming convention. This is because PMM v3 introduces several important changes to improve consistency and clarity:</p> <ul> <li>environment variables now use PMM_ prefix</li> <li>some boolean flags reversed (e.g., <code>DISABLE_</code> &gt; <code>ENABLE_</code>)</li> <li>removed deprecated variables</li> </ul> <p>To check the Migration reference table, see Environment variables in PMM.</p>"},{"location":"release-notes/3.0.0_Beta.html#grafana-angular-support-discontinuation","title":"Grafana Angular support discontinuation","text":"<p>Grafana will discontinue support for Angular starting with version 12, expected in 2025. This affects numerous panels and plugins, including but not limited to Graph and Table panels.</p> <p>We have already migrated many plugins to newer technologies and are actively working on the remaining components to ensure continued functionality. We recommend that you review all plugins in your dashboards and begin planning transitions to newer panel types where necessary.</p> <p>For the full list of affected plugins and guidance on migration, see Grafana\u2019s official documentation on Angular deprecation and plugin migration.</p> <p>We will provide regular updates on our migration progress in future releases to help you prepare for this change and modernize your dashboards.</p>"},{"location":"release-notes/3.0.0_Beta.html#components-upgrade","title":"Components upgrade","text":"<p>We\u2019ve upgraded following PMM components to their latest stable versions to enhance functionality, security, and performance:</p> <ul> <li>Grafana 11.1.8: Includes significant improvements over the previous version 9.2.20 integration in PMM2.</li> <li>Node Exporter 1.8.2: The latest stable release enhances system metrics collection with improved security, additional metrics for custom dashboards, and critical bug fixes. This version strengthens our ability to monitor crucial system-level metrics through upstream improvements.</li> <li>ClickHouse Datasource plugin: Updated to address security vulnerabilities and maintain system integrity. This update ensures continued reliable operation of ClickHouse-related dashboards.</li> <li>ClickHouse-go driver: Upgraded QAN to use version 2 of the driver, improving database connectivity and performance.</li> </ul>"},{"location":"release-notes/3.0.0_Beta.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-13399 - PMM Client packages (DEB, RPM, and tarball) now include the Nomad binary, laying the foundation for expanded functionality in future PMM releases. While the Nomad binary is now included and properly configured within the PMM Client ecosystem, Nomad agent configuration and execution capabilities will be implemented in future releases, which will unlock more capabilities for PMM.</p> </li> <li> <p>PMM-13315 - To prevent node registration failures, PMM now automatically shortens service account names longer than 200 characters. For this, PMM creates a truncated name in the format <code>{prefix}_{hash}</code>, where:</p> <ul> <li>prefix is a portion of the original name, providing context</li> <li>hash is a unique identifier to avoid naming conflicts</li> </ul> <p>For example, a long node name such as:</p> <ul> <li><code>Copyvery_long_mysql_database_server_in_production_environment_with_specific_location_details_and_multiple_configuration_settings_for_east_coast_datacenter_primary_backup_replica_instance_2024</code></li> </ul> <p>would now be shortened to:</p> <ul> <li><code>Copyvery_long_mysql_database_server_in_prod_4a7b3f9d</code>.</li> </ul> </li> <li> <p>PMM-12940 - We\u2019ve added automated update support for AMI/OVF deployments. The new Updates page also enables AMI and OVF deployments to update PMM Server directly from the UI, following the integration of the Watchtower container.</p> </li> <li> <p>PMM-11216 - Added ability to upgrade PMM Server between different version tags, enabling more flexible version management for Docker-based deployments.</p> </li> </ul>"},{"location":"release-notes/3.0.0_Beta.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-13122 - Fixed navigation between pages to properly maintain selected service names and timeframes when switching between different dashboards and metrics views.</p> </li> <li> <p>PMM-12013 - Fixed reliability and memory usage issues with RDS monitoring in large deployments by running separate RDS exporters per AWS access key. This improves metric collection stability and reduces memory consumption when monitoring multiple RDS instances.</p> </li> </ul> <p></p>"},{"location":"release-notes/3.0.0_Beta.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/index.html","title":"Troubleshoot PMM","text":"<p>This section provides comprehensive solutions to common issues and scenarios that may arise while using PMM, including a checklist.</p> <p>To quickly identify the isssues and find the appropriate solution, the issues are categorized into distinct groups as follows:</p> <ul> <li>Upgrade issues</li> <li>Configuration issues</li> <li>Percona Alerting issues</li> <li>QAN issues</li> <li>Plugins issues</li> </ul> <p></p>"},{"location":"troubleshoot/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/alerting_issues.html","title":"Percona Alerting issues","text":""},{"location":"troubleshoot/alerting_issues.html#no-alert-rule-templates-tab-on-the-alerting-page","title":"No Alert rule templates tab on the Alerting page","text":"<p>Percona Alerting option isn\u2019t active.</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced Settings.</li> <li>Enable Alerting.</li> </ol>"},{"location":"troubleshoot/alerting_issues.html#custom-alert-rule-templates-not-migrated-to-percona-alerting","title":"Custom alert rule templates not migrated to Percona Alerting","text":"<p>After upgrading from the latest PMM 2 version to PMM 3, you will find all your alert templates under Alerting &gt; Alert rule templates.</p> <p>If you have any templates available in the  <code>/srv/ia/templates</code> folder, make sure to transfer them to <code>/srv/alerting/templates</code> as PMM 3 will look for custom templates in this location.</p>"},{"location":"troubleshoot/alerting_issues.html#unreachable-external-ip-addresses","title":"Unreachable external IP addresses","text":"<p>If you get an email or page from your system that the IP is not reachable from outside my organization, do the following:</p> <p>To configure your PMM Server\u2019s Public Address, select  PMM Configuration &gt; Settings &gt; Advanced Settings, and supply an address to use in your alert notifications.</p>"},{"location":"troubleshoot/alerting_issues.html#alert-rule-templates-are-disabled","title":"Alert Rule Templates are disabled","text":"<p>Built-in alerts are not editable, but you can copy them and edit the copies. </p> <p>If you create a custom alert rule template, you will have access to edit.</p> <p></p>"},{"location":"troubleshoot/alerting_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/checklist.html","title":"Troubleshooting checklist","text":"<p>The following questions might help you identify the origin of the problem while using Percona Monitoring and Management:</p> <ol> <li>Are you using the latest PMM version?</li> <li>Did you check the known issues section in the Release Notes for that particular PMM release?</li> <li>Are you receiving any error messages?</li> <li>Do the logs contain any messages about the problem? See Message logs and Trace logs for more information.</li> <li>Does the problem occur while configuring PMM, such as:<ul> <li>Does the problem occur while you configure a specific function?</li> <li>Does the problem occur when you perform a particular task?</li> </ul> </li> <li>Are you using the recommended authentication method?</li> <li>Does your system\u2019s firewall allow TCP traffic on the ports used by PMM?</li> <li>Have you allocated enough disk space for installing PMM? If not, check the disk allocation space.</li> <li>Are you using a Technical Preview feature? Technical Preview features are not production-ready and should only be used in testing environments. For more information, see the relevant Release Notes.</li> <li>For installing the PMM client, are you using a package other than a binary package without root permissions?</li> <li>Is your PMM Server installed and running with a known IP address accessible from the client node?</li> <li>Is the PMM Client installed, and is the node registered with PMM Server?</li> <li>Is PMM Client configured correctly and has access to the config file?</li> <li>For monitoring MongoDB, do you have adminUserAnyDatabase or superuser role privilege to any database servers you want to monitor?</li> <li>For monitoring Amazon RDS using PMM, is there too much latency between PMM Server and the Amazon RDS instance?</li> <li>Have you upgraded the PMM Server before you upgraded the PMM Client? If yes, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> <li>Is the PMM Server version higher than or equal to the PMM Client version? Otherwise, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> </ol> <p></p>"},{"location":"troubleshoot/checklist.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/components_issues.html","title":"External components issues","text":"<p>Important</p> <p>The content for this section is still under development.</p>"},{"location":"troubleshoot/components_issues.html#clickhouse-issues","title":"ClickHouse issues","text":""},{"location":"troubleshoot/components_issues.html#victoriametrics-issues","title":"VictoriaMetrics issues","text":""},{"location":"troubleshoot/components_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/config_issues.html","title":"Configuration issues","text":"<p>This section focuses on configuration issues, such as PMM-agent connection, adding and removing services for monitoring, and so on.</p>"},{"location":"troubleshoot/config_issues.html#client-server-connections","title":"Client-Server connections","text":"<p>There are many causes of broken network connectivity.</p> <p>The container is constrained by the host-level routing and firewall rules when using using Docker. For example, your hosting provider might have default <code>iptables</code> rules on their hosts that block communication between PMM Server and PMM Client, resulting in DOWN targets in VictoriaMetrics. If this happens, check the firewall and routing settings on the Docker host.</p> <p>PMM can also generate diagnostics data that can be examined and/or shared with our support team to help solve an issue. You can get collected logs from PMM Client using the pmm-admin summary command.</p> <p>Logs obtained in this way include PMM Client logs and logs received from the PMM Server, and stored separately in the <code>client</code> and <code>server</code> folders. The <code>server</code> folder also contains its <code>client</code> subfolder with the self-monitoring client information collected on the PMM Server.</p> <p>For additional debugging information, use the <code>--pprof</code> flag to include pprof debug profiles: <code>pmm-admin summary --pprof</code>.</p> <p>You can get PMM Server logs with either of these methods:</p> <p>Direct download</p> <p>In a browser, visit <code>https://&lt;address-of-your-pmm-server&gt;/logs.zip</code>.</p> <p>From Help menu</p> <p>To obtain the logs from the Help menu:</p> <ol> <li> <p>Select  Help \u2192  PMM Logs.</p> </li> <li> <p>Click PMM Logs to retrieve PMM diagnostics data which can be examined and shared with our support team should you need help.</p> </li> </ol>"},{"location":"troubleshoot/config_issues.html#connection-difficulties","title":"Connection difficulties","text":""},{"location":"troubleshoot/config_issues.html#passwords","title":"Passwords","text":"<p>When adding a service, the host might not be detected if the password contains special symbols (e.g., <code>@</code>, <code>%</code>, etc.).</p> <p>In such cases, you should convert any password, replacing special characters with their escape sequence equivalents.</p> <p>One way to do this is to use the <code>encodeURIComponent</code> JavaScript function in your browser\u2019s web console (commonly found under a Development Tools menu). Run the function with your password as the parameter. For example:</p> <pre><code>&gt; encodeURIComponent(\"s3cR#tpa$$worD\")\n</code></pre> <p>will give:</p> <pre><code>\"s3cR%23tpa%24%24worD\"\n</code></pre>"},{"location":"troubleshoot/config_issues.html#password-change","title":"Password change","text":"<p>When adding clients to the PMM Server, you use the <code>admin</code> user. However, if you change the password for the admin user from the PMM UI, then the clients will not be able to access PMM due to authentication issues. Also, Grafana will lock out the admin user due to multiple unsuccessful login attempts.</p> <p>In such a scenario, use Service Accounts for authentication. You can use Service Accounts as a replacement for basic authentication and API keys.</p> <p></p>"},{"location":"troubleshoot/config_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/dashboard_issues.html","title":"Dashboard issues","text":"<p>Important</p> <p>The content for this section is still under development.</p> <p></p>"},{"location":"troubleshoot/dashboard_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/data_issues.html","title":"Missing data","text":"<p>Why don\u2019t I see any query-related information?</p> <p>There might be multiple places where the problem might come from:</p> <ul> <li>Connection problem between pmm-agent and pmm-managed</li> <li>PMM-agent cannot connect to the database.</li> <li>Data source is not properly configured.</li> </ul> <p>Why don\u2019t I see the whole query?</p> <p>Long query examples and fingerprints can be truncated to 1024 symbols to reduce space usage. In this case, the query explains section will not work.</p> <p></p>"},{"location":"troubleshoot/data_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/plugin_issues.html","title":"Plugin issues","text":""},{"location":"troubleshoot/plugin_issues.html#pmm-does-not-allow-to-install-upgrade-or-remove-plugins","title":"PMM does not allow to install, upgrade or remove plugins","text":"<p>Users have encountered issues with installing, updating and removing plugins from PMM. The cause of this issue is the incorrect permissions assigned to the <code>/srv/grafana/plugins</code> directory. These permissions are preventing the grafana component from writing to the directory.</p>"},{"location":"troubleshoot/plugin_issues.html#solution","title":"Solution","text":"<p>Set the ownership on the directory<code>/srv/grafana/plugins</code> to <code>grafana:grafana</code>.</p> <p></p>"},{"location":"troubleshoot/plugin_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/pmm_dump.html","title":"Export PMM data with PMM Dump","text":"<p>PMM data dumps are compressed tarball files containing a comprehensive export of your PMM metrics and QAN data collected by PMM Server.</p> <p>You can download these dataset files locally, or share them with Percona Support via an SFTP server. This enables you to share PMM data securely, which is especially useful when you need you troubleshoot PMM issues without without providing access to your PMM instance.</p> <p>Starting with 2.41, PMM enables you to generate PMM Datasets straight from PMM. If you are using an older PMM version, you can use the standalone PMM Dump utility instead.</p>"},{"location":"troubleshoot/pmm_dump.html#dump-contents","title":"Dump contents","text":"<p>The dump.tar.gz dump file is a .TAR archive compressed via Gzip. Here\u2019s what\u2019s inside the folders it contains:</p> <ul> <li>meta.json: metadata about the data dump</li> <li>vm: Victoria Metrics data chunks in native VM format, organized by timeframe</li> <li>ch: Query Analytics (QAN) data stored in ClickHouse, organized by rows count</li> <li>log.json: logs detailing the export and archive creation process</li> </ul>"},{"location":"troubleshoot/pmm_dump.html#create-a-data-dump","title":"Create a data dump","text":"<p>To create a dump of your dataset:</p> <ol> <li>From the main menu on the left, go to  Help &gt; PMM Dump.</li> <li>Click Create dataset to go to the Export new dataset page.</li> <li>Choose the service for which you want to create the dataset or leave it empty to export all data.</li> <li>Define the time range for the dataset.</li> <li>Enable Export QAN to include Query Analytics (QAN) metrics alongside the core metrics.</li> <li>Enable Ignore load to export the dump bypassing the default resource limit restrictions.</li> <li>Click Create dataset. This will generate a data dump file and automatically record an entry in the PMM Dump table. From there, you can use the options available in the Options menu to send the dump file to Percona Support or download it locally for internal usage.</li> </ol>"},{"location":"troubleshoot/pmm_dump.html#send-a-data-dump-to-percona-support","title":"Send a data dump to Percona Support","text":"<p>If you are a Percona Customer, you can securely share PMM data dumps with Percona Support via SFTP.</p> <ol> <li>From the main menu on the left, go to  Help &gt; PMM Dump.</li> <li>Select the PMM dump entry which you want to send to Support.</li> <li>In the Options column, expand the table row to check the PMM Service associated with the dataset, click the ellipsis (three vertical dots) and select Send to Support.</li> <li>Fill in the details of the SFTP server, then click Send.</li> <li>Update your Support ticket to let Percona know that you\u2019ve uploaded the dataset on the SFTP server.</li> </ol> <p></p>"},{"location":"troubleshoot/pmm_dump.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/qan_issues.html","title":"QAN issues","text":"<p>This section focuses on problems with QAN, such as queries not being retrieved so on.</p>"},{"location":"troubleshoot/qan_issues.html#missing-data","title":"Missing data","text":"<p>Why don\u2019t I see any query-related information?</p> <p>There might be multiple places where the problem might come from:</p> <ul> <li>Connection problem between pmm-agent and pmm-managed</li> <li>PMM-agent cannot connect to the database.</li> <li>Data source is not properly configured.</li> </ul> <p>Why don\u2019t I see the whole query?</p> <p>Long query examples and fingerprints can be truncated to 1024 symbols to reduce space usage. In this case, the query explains section will not work.</p> <p></p>"},{"location":"troubleshoot/qan_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot/upgrade_issues.html","title":"Troubleshoot upgrade issues","text":""},{"location":"troubleshoot/upgrade_issues.html#pmm-server-not-updating-correctly","title":"PMM Server not updating correctly","text":"<p>If the automatic update process isn\u2019t working, you can force an update using the API:</p> <ol> <li>Open your terminal.</li> <li>Run the update command, replacing : with your credentials and  with your PMM server address\u0416  <p><code>curl -X POST \\    --user &lt;username&gt;:&lt;password&gt; \\    'http://&lt;pmm-server-address&gt;/v1/server/updates:start' \\    -H 'Content-Type: application/json'</code> 3. Wait 2-5 minutes and refresh the PMM Home page to verify the update.</p> <p></p>"},{"location":"troubleshoot/upgrade_issues.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-pmm/index.html","title":"About uninstalling PMM","text":"<p>Refer to the following sections for detailed instructions on uninstalling PMM:</p> <ul> <li> <p>Uninstall PMM client with Docker container</p> </li> <li> <p>Uninstall PMM client with package manager</p> </li> <li> <p>Unregister PMM Client from PMM Server</p> </li> </ul> <p></p>"},{"location":"uninstall-pmm/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-pmm/uninstall_docker.html","title":"Uninstall PMM client using Docker container","text":"<p>To remove (uninstall) PMM Client, do the following steps in Docker:</p> <p>Caution</p> <p>These steps delete the PMM Client Docker image and client services configuration data.</p> <p>To uninstall PMM client with the Docker container:</p> <ol> <li> <p>Stop pmm-client container.</p> <pre><code>docker stop pmm-client\n</code></pre> </li> <li> <p>Remove containers.</p> <pre><code>docker rm pmm-client\n</code></pre> </li> <li> <p>Remove the image.</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-client\" | awk {'print $3'})\n</code></pre> </li> <li> <p>Remove the volume.</p> <pre><code>docker volume rm pmm-client-data\n</code></pre> </li> </ol> <p></p>"},{"location":"uninstall-pmm/uninstall_docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-pmm/uninstall_helm.html","title":"Uninstall PMM using Helm","text":"<p>To uninstall <code>pmm</code> deployment:</p> <pre><code>helm uninstall pmm\n</code></pre> <p>This command takes a release name and uninstalls the release.</p> <p>It removes all resources associated with the last release of the chart as well as the release history.</p> <p>Helm will not delete PVC, PV, and any snapshots. Those need to be deleted manually.</p> <p>Also, delete PMM <code>Secret</code> if no longer required:</p> <pre><code>kubectl delete secret pmm-secret\n</code></pre> <p></p>"},{"location":"uninstall-pmm/uninstall_helm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-pmm/uninstall_package_manager.html","title":"Uninstall PMM client using package manager","text":"<p>To uninstall PMM client with package manager, do the following steps:</p> Debian-based distributionsRed Hat-based distributions <p>To uninstall PMM client with Debian-based distributions:</p> <ol> <li> <p>Uninstall the PMM Client package.</p> <pre><code>apt remove -y pmm-client\n</code></pre> </li> <li> <p>Remove the Percona repository</p> <pre><code>dpkg -r percona-release\n</code></pre> </li> </ol> <p>To uninstall PMM client with Red Hat based distributions:</p> <ol> <li> <p>Uninstall the PMM Client package.</p> <pre><code>yum remove -y pmm-client\n</code></pre> </li> <li> <p>Remove the Percona repository</p> <pre><code>yum remove -y percona-release\n</code></pre> </li> </ol> <p></p>"},{"location":"uninstall-pmm/uninstall_package_manager.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-pmm/unregister_client.html","title":"Unregister PMM Client from PMM Server","text":"<p>To unregister PMM Client from PMM Server, run the following command:</p> <pre><code>pmm-admin unregister --force\n</code></pre> <p>All services monitored by this node will be removed from monitoring.</p> <p></p>"},{"location":"uninstall-pmm/unregister_client.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboard-inventory.html","title":"About PMM Inventory","text":"<p>The Inventory dashboard is a high-level overview of all objects registered in PMM.</p> <p>To check your inventory list, go to  Configuration &gt; Inventory.</p> <p></p> <p>Inventory objects form a hierarchy with Node at the top, then Service and Agents assigned to a Node. This information is detailed in the two tabs available on this page.</p>"},{"location":"use/dashboard-inventory.html#services-tab","title":"Services tab","text":"<p>The Services tab displays the individual services, the nodes on which they run, and the Agents that help collect the service metrics along with the following information:</p> Column Name Description Service name The name or identifier associated with the service being monitored. Node name Name or identifier associated with a specific node. Monitoring status The Monitoring column summarizes the status of all the Agents assigned to the service. Address The IP address or DNS where the service is currently running. Port The port number on which the service is running. Options * You can check QAN information and the Dashboard for each service by clicking on the  icon   * You can also check additional information about the service, by clicking on the  icon. This expands the service entry to show reference information like service labels and IDs. <p></p>"},{"location":"use/dashboard-inventory.html#attributes","title":"Attributes","text":"<p>These are some of the atributes for a service:</p> <ul> <li> <p>Each instance of a service gets a <code>service_type</code> attribute so one can clearly tell what type of database it is, for instance: <code>mysql</code>, <code>postgresql</code>, <code>mongodb</code>, etc. </p> </li> <li> <p>Every service is related to a certain node via its <code>node_id</code> attribute. This feature allows to support monitoring of multiple instances on a single node, with different service names, e.g. <code>mysql1-3306</code>, and <code>mysql1-3307</code>.</p> </li> <li> <p>Each instance of a service gets a <code>version</code> attribute to the response of the endpoint that provides a list of services being monitored by PMM. This makes it easy to visualize the database server version.</p> <p>However, following are the imitations:</p> <ul> <li>The version is not captured for the internal PostgreSQL database.</li> <li>The version is only captured when a new service is being added to PMM and the agent installed on the client side is equal to or greater than v2.41.0.</li> <li>When a database is upgraded, you will not see the database version updated automatically. It will be updated if you remove and then re-add the service.</li> </ul> </li> </ul>"},{"location":"use/dashboard-inventory.html#agents","title":"Agents","text":"<p>Each binary (exporter, agent) running on a client will get an <code>agent_type</code> value. </p> <p>Example</p> <ul> <li><code>pmm-agent</code> is at the top of the tree, assigned to pmm-agent itself</li> <li><code>node_exporter</code> is assigned to an agent that extracts the node metrics</li> <li><code>mysqld_exporter</code> and <code>qan-mysql-perfschema-agent</code> are assigned to agents that extract metrics from mysql and its performance schema respectively.</li> </ul> <p>To view the agents running on a service and their health status, click OK or Failed under the Monitoring column. Furthermore, you can also check the properties of a particular agent by clicking the  icon under the Options column.</p> <p></p>"},{"location":"use/dashboard-inventory.html#node-service-relationship","title":"Node-service relationship","text":"<p>Click on the link in the Node Name column to view the node on which a specific service is running and analyze how node-level resource utilization impacts the performance of those services.</p> <p>Understanding the relationship between nodes and services is key to gaining insights into the distribution and performance of individual services across nodes.</p> <ul> <li> <p>Deployment: Services within PMM are deployed on nodes and rely on them for resources, such as CPU, memory, and storage, to execute tasks.</p> </li> <li> <p>Resource allocation: It is essential to know which nodes host which services to allocate resources appropriately to avoid underuse or overload.</p> </li> <li> <p>Performance optimization: By analyzing node and service-level metrics, you can pinpoint and resolve issues that impede service performance, such as resource limitations and performance bottlenecks.</p> </li> <li> <p>Incident response: When an issue or incident occurs, understanding the node-service relationship helps in troubleshooting. You can quickly identify which nodes and services are affected and focus your efforts on resolving the problem.</p> </li> </ul>"},{"location":"use/dashboard-inventory.html#editing-labels-for-a-service","title":"Editing labels for a service","text":"<p>You can edit the labels as follows:</p> <ol> <li> <p>From the Main menu, go to PMM Configuration &gt; PMM Inventory &gt; Services.</p> </li> <li> <p>Click on the three dots next to the service you want to edit labels for.</p> </li> <li> <p>Click Edit to change the labels, then click Save Changes. </p> <p></p> </li> <li> <p>Click Confirm and save changes. You will be taken back to the Inventory/Services page.</p> </li> </ol>"},{"location":"use/dashboard-inventory.html#effect-of-editing-labels-for-a-service","title":"Effect of editing labels for a service","text":"<p>Editing existing labels can impact the following PMM functions:</p> <ul> <li> <p>Alerting </p> <p>Editing labels without updating alerting rules can lead to missed alerts. If an alert rule is based on specific labels that are changed or no longer apply, the alert may not trigger when it should.</p> <p>Update the alert rules promptly after editing the labels for a smooth alerting experience.</p> </li> <li> <p>Scheduled backups: Editing the cluster label will remove all scheduled backups for the imapcted service or cluster.</p> <p>To prevent any issues, make sure to recreate your backups once you\u2019ve configured the cluster.</p> </li> <li> <p>Dashboard data: Edited labels do not affect the existing time-series(metrics). It will only affect the new time-series(metrics).</p> </li> </ul>"},{"location":"use/dashboard-inventory.html#cluster-view","title":"Cluster view","text":"<p>Disclaimer</p> <p>This feature is still technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Organize by Clusters toggle shows related services grouped into clusters based on their <code>cluster</code> label, giving you a consolidated view of your infrastructure.</p> <p></p> <p>Click the downward arrow to view cluster details, including the services running on that cluster, agents, and labels.</p> <p></p> <p>Furthermore, you can filter the clusters by criteria such as Cluster name, Status, Service name, Node name, Monitoring, Address, and Port. </p> <p></p>"},{"location":"use/dashboard-inventory.html#nodes-tab","title":"Nodes tab","text":"<p>The Nodes tab helps you monitor where services and agents are running across your infrastructure. Each node has:</p> <ul> <li>A unique <code>node_id</code> linked to its <code>machine_id</code> (from <code>/etc/machine-id</code>)</li> <li>A <code>node_type</code> attribute (e.g., generic, container, remote, remote_rds) indicating its nature</li> </ul> <p>To see node information: - Click the expand icon in the Options column to see node labels and attributes. - Click any node to view its connected agents. - Click links in the Services column to see running services.</p> <p>To see agent details:</p> <ol> <li> <p>In the Nodes tab, under the Monitoring column, click OK or Failed based on the node\u2019s status to view information about the total number of agents deployed on that node:</p> <p></p> </li> <li> <p>Click on the  icon under the Options column to view the properties of a specific agent.</p> </li> <li> <p>On the Nodes tab, under the Options column, click on the  icon for the selected node to check the properties and the current health status of an agent.       </p> <p></p> </li> </ol>"},{"location":"use/dashboard-inventory.html#remove-items-from-the-inventory","title":"Remove items from the inventory","text":"<p>To remove items from the inventory:</p> <ol> <li> <p>Go to  PMM Configuration &gt; PMM Inventory.</p> </li> <li> <p>In the first column, select the items to be removed.</p> <p></p> </li> <li> <p>Click Delete and confirm the removal.</p> </li> </ol> <p></p>"},{"location":"use/dashboard-inventory.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/monitor.html","title":"About monitoring in PMM","text":"<p>PMM continuously collects, stores, visualizes, and analyzes various metrics from database engines, such as MySQL, PostgreSQL, and MongoDB, amongst many others. With PMM, you can monitor your database environment and gain insights into its behavior. </p> <p>Some of the key functionalities of monitoring in PMM are:</p> <ul> <li>Performance monitoring: PMM collects metrics such as query execution times, throughput, latency, and resource utilization (CPU, memory, disk I/O). This helps identify performance bottlenecks and optimize query execution for better efficiency.</li> <li>Resource utilization: PMM monitors CPU usage, memory, disk I/O, and network traffic to optimize resource allocation.</li> <li>Database health checks:  PMM monitors various metrics, such as replication status, uptime, connections, server status, and error rates, to ensure system availability and identify potential issues.</li> </ul> <p></p>"},{"location":"use/monitor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/using-pmm.html","title":"About using PMM","text":"<p>After installing PMM, it provides a user-friendly web-based interface that enables you to monitor your database instances. It offers comprehensive insights into the performance metrics and query analytics, which helps you optimize your database performance and troubleshoot any underlying issues.</p> <ul> <li>Monitoring: PMM gathers and displays a broad range of metrics related to the performance of your database. These metrics include, but are not limited to, CPU usage, memory usage, query execution times, disk I/O, and more. </li> <li>Query Analytics: Query analytics facilitates the identification of slow queries, enabling you to optimize your database by pinpointing inefficient queries. </li> <li>Alerting and notifications: PMM enables you to set up alerts based on predefined thresholds. This way, you can be notified when specific metrics exceed specified limits, allowing you to address issues before they impact performance.</li> <li>Dashboards and reporting: PMM provides customizable dashboards and reporting features to visualize the collected data and create comprehensive reports for in-depth performance analysis.</li> </ul> <p></p>"},{"location":"use/using-pmm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/commands/index.html","title":"About PMM commands","text":"<ul> <li><code>pmm-admin</code> \u2013 Command line tool for configuring and administering PMM</li> <li><code>pmm-agent</code> \u2013 Daemon process, communicating between PMM Client and PMM Server</li> </ul>"},{"location":"use/commands/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/commands/pmm-admin.html","title":"pmm-admin - PMM Administration Tool","text":""},{"location":"use/commands/pmm-admin.html#name","title":"NAME","text":"<p><code>pmm-admin</code> - Administer PMM</p>"},{"location":"use/commands/pmm-admin.html#synopsis","title":"SYNOPSIS","text":"<p><code>pmm-admin [FLAGS]</code></p> <p><code>pmm-admin config [FLAGS] --server-url=server-url</code></p> <p><code>pmm-admin add DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p>DATABASE:= [MongoDB | MySQL | PostgreSQL | ProxySQL]</p> <p><code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add haproxy [FLAGS] [NAME]</code></p> <p><code>pmm-admin add external [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add external-serverless [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin remove [FLAGS] service-type [service-name]</code></p> <p><code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]</code></p> <p><code>pmm-admin list [FLAGS] [node-address]</code></p> <p><code>pmm-admin status [FLAGS] [node-address]</code></p> <p><code>pmm-admin summary [FLAGS] [node-address]</code></p> <p><code>pmm-admin annotate [--node|--service] [--tags &lt;tags&gt;] [node-name|service-name]</code></p> <p><code>pmm-admin help [COMMAND]</code></p>"},{"location":"use/commands/pmm-admin.html#description","title":"DESCRIPTION","text":"<p><code>pmm-admin</code> is a command-line tool for administering PMM using a set of COMMAND keywords and associated FLAGS.</p> <p>PMM communicates with the PMM Server via a PMM agent process.</p>"},{"location":"use/commands/pmm-admin.html#common-flags","title":"COMMON FLAGS","text":"<code>-h</code>, <code>--help</code> Show help and exit. <code>--help-long</code> Show extended help and exit. <code>--help-man</code> Generate <code>man</code> page. (Use <code>pmm-admin --help-man | man -l -</code> to view.) <code>--debug</code> Enable debug logging. <code>--trace</code> Enable trace logging (implies debug). <code>--log-level</code> Set the level for the logs as per your requirement such as INFO, WARNING, ERROR, and FATAL. <code>--json</code> Enable JSON output. <code>--version</code> Show the application version and exit. <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--group=&lt;group-name&gt;</code> Group name for external services. Default: <code>external</code> <code>--expose-exporter</code> If you enable this flag, any IP address on the local network and anywhere on the internet can access exporter endpoints. If the flag is disabled/not present, exporter endpoints can be accessed only locally. The flag is disabled by default"},{"location":"use/commands/pmm-admin.html#commands","title":"COMMANDS","text":""},{"location":"use/commands/pmm-admin.html#general-commands","title":"GENERAL COMMANDS","text":"<code>pmm-admin help [COMMAND]</code> Show help for <code>COMMAND</code>."},{"location":"use/commands/pmm-admin.html#information-commands","title":"INFORMATION COMMANDS","text":"<code>pmm-admin list --server-url=server-url [FLAGS]</code> Show Services and Agents running on this Node, and the agent mode (push/pull). <code>pmm-admin status --server-url=server-url [FLAGS]</code> <p>Show the following information about a local pmm-agent, and its connected server and clients:</p> <ul> <li>Agent: Agent ID, Node ID.</li> <li>PMM Server: URL and version.</li> <li>PMM Client: connection status, time drift, latency, <code>vmagent</code> status, <code>pmm-admin</code> version.</li> <li>Agents: Agent ID path and client name.</li> </ul> <p>FLAGS:</p> <code>--wait=&lt;period&gt;&lt;unit&gt;</code> Time to wait for a successful response from pmm-agent. period is an integer. unit is one of <code>ms</code> for milliseconds, <code>s</code> for seconds, <code>m</code> for minutes, <code>h</code> for hours. <code>pmm-admin summary --server-url=server-url [FLAGS]</code> <p>Creates an archive file in the current directory with default file name <code>summary_&lt;hostname&gt;_&lt;year&gt;_&lt;month&gt;_&lt;date&gt;_&lt;hour&gt;_&lt;minute&gt;_&lt;second&gt;.zip</code>. The contents are two directories, <code>client</code> and <code>server</code> containing diagnostic text files.</p> <p>FLAGS:</p> <code>--filename=\"filename\"</code> The Summary Archive filename. <code>--skip-server</code> Skip fetching <code>logs.zip</code> from PMM Server. <code>--pprof</code> Include performance profiling data in the summary."},{"location":"use/commands/pmm-admin.html#configuration-commands","title":"CONFIGURATION COMMANDS","text":""},{"location":"use/commands/pmm-admin.html#pmm-admin-config","title":"<code>pmm-admin config</code>","text":"<code>pmm-admin config [FLAGS] [node-address] [node-type] [node-name]</code> <p>Configure a local <code>pmm-agent</code>.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--node-model=node-model</code> Node model. <code>--region=region</code> Node region. <code>--az=availability-zone</code> Node availability zone. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--paths-base=dir</code> Base path where all binaries, tools and collectors of PMM client are located <code>--agent-password=password</code> Custom agent password."},{"location":"use/commands/pmm-admin.html#pmm-admin-register","title":"<code>pmm-admin register</code>","text":"<code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]</code> <p>Register the current Node with the PMM Server.</p> <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--machine-id=\"9812826a1c45454a98ba45c56cc4f5b0\"</code> Node machine-id (default is auto-detected). <code>--distro=\"linux\"</code> Node OS distribution (default is auto-detected). <code>--container-id=container-id</code> Container ID. <code>--container-name=container-name</code> Container name. <code>--node-model=node-model</code> Node model. <code>--region=region</code> Node region. <code>--az=availability-zone</code> Node availability zone. <code>--custom-labels=labels</code> Custom user-assigned labels. <code>--agent-password=password</code> Custom agent password."},{"location":"use/commands/pmm-admin.html#pmm-admin-add-pmm-agent-listen-portlisten_port","title":"<code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT</code>","text":"<code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]</code> <p>Configure the PMM agent with a listen port.</p> <code>--pmm-agent-listen-port=LISTEN_PORT</code> The PMM agent listen port. <p>DATABASE:= [MongoDB | MySQL | PostgreSQL | ProxySQL]</p>"},{"location":"use/commands/pmm-admin.html#pmm-admin-remove","title":"<code>pmm-admin remove</code>","text":"<code>pmm-admin remove [FLAGS] service-type [service-name]</code> <p>Remove Service from monitoring.</p> <code>--service-id=service-id</code> Service ID. <code>--force</code> Remove service with that name or ID and all dependent services and agents. <p>When you remove a service, collected data remains on PMM Server for the specified retention period.</p>"},{"location":"use/commands/pmm-admin.html#pmm-admin-annotate","title":"<code>pmm-admin annotate</code>","text":"<code>pmm-admin annotate [--node|--service] &lt;annotation&gt; [--tags &lt;tags&gt;] [--node-name=&lt;node&gt;] [--service-name=&lt;service&gt;]</code> <p>Annotate an event. (Read more)</p> <code>&lt;annotation&gt;</code> The annotation string. If it contains spaces, it should be quoted. <code>--node</code> Annotate the current node or that specified by <code>--node-name</code>. <code>--service</code> Annotate all services running on the current node, or that specified by <code>--service-name</code>. <code>--tags</code> A quoted string that defines one or more comma-separated tags for the annotation. Example: <code>\"tag 1,tag 2\"</code>. <code>--node-name</code> The node name being annotated. <code>--service-name</code> The service name being annotated. <p>Combining flags</p> <p>Flags may be combined as shown in the following examples.</p> <code>--node</code> Current node. <code>--node-name</code> Node with name. <code>--node --node-name=NODE_NAME</code> Node with name. <code>--node --service-name</code> Current node and service with name. <code>--node --node-name --service-name</code> Node with name and service with name. <code>--node --service</code> Current node and all services of current node. <code>-node --node-name --service --service-name</code> Service with name and node with name. <code>--service</code> All services of the current node. <code>--service-name</code> Service with name. <code>--service --service-name</code> Service with name. <code>--service --node-name</code> All services of current node and node with name. <code>--service-name --node-name</code> Service with name and node with name. <code>--service --service-name -node-name</code> Service with name and node with name. <p>Tip</p> <p>If node or service name is specified, they are used instead of other parameters.</p>"},{"location":"use/commands/pmm-admin.html#database-commands","title":"DATABASE COMMANDS","text":""},{"location":"use/commands/pmm-admin.html#mongodb","title":"MongoDB","text":"<code>pmm-admin add mongodb [FLAGS] [node-name] [node-address]</code> <p>Add MongoDB to monitoring.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> MongoDB username. <code>--password=password</code> MongoDB password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=profiler</code> Source of queries, one of: <code>profiler</code>, <code>none</code> (default: <code>profiler</code>). <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-certificate-key-file=PATHTOCERT</code> Path to TLS certificate file. <code>--tls-certificate-key-file-password=IFPASSWORDTOCERTISSET</code> Password for TLS certificate file. <code>--tls-ca-file=PATHTOCACERT</code> Path to certificate authority file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 4096 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p>"},{"location":"use/commands/pmm-admin.html#advanced-options","title":"Advanced Options","text":"<p>PMM starts the MongoDB exporter by default only with <code>diagnosticdata</code> and <code>replicasetstatus</code> collectors enabled.</p> <p>FLAGS:</p> <code>--enable-all-collectors</code> Enable all collectors. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter. <code>--max-collections-limit=-1</code> <p>Disable collstats, dbstats, topmetrics and indexstats if there are more than  collections. 0: No limit. Default is -1, PMM automatically sets this value. <p>A very high limit of <code>max-collections-limit</code> could impact the CPU and Memory usage. Check <code>--stats-collections</code> to limit the scope of collections and DB\u2019s metrics to be fetched.</p> <code>--stats-collections=db1,db2.col1</code> Collections for collstats &amp; indexstats."},{"location":"use/commands/pmm-admin.html#enable-all-collectors","title":"Enable all collectors","text":"<p>To enable all collectors, pass the parameter <code>--enable-all-collectors</code> in the <code>pmm-admin add mongodb</code> command. This will enable <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code> collectors.</p>"},{"location":"use/commands/pmm-admin.html#disable-some-collectors","title":"Disable some collectors","text":"<p>To enable only some collectors, pass the parameter <code>--enable-all-collectors</code> along with the parameter <code>--disable-collectors</code>.</p> <p>For example, if you want all collectors except <code>topmetrics</code>, specify:</p> <pre><code>--enable-all-collectors --disable-collectors=topmetrics\n</code></pre>"},{"location":"use/commands/pmm-admin.html#limit-dbstats-collstats-and-indexstats","title":"Limit <code>dbStats</code>, <code>collStats</code> and <code>indexStats</code>","text":"<p>By default, PMM decides the limit for the number of collections to monitor the <code>collStats</code> and <code>indexStats</code> collectors.</p> <p>You can also set an additional limit for the <code>collStats</code>, <code>indexStats</code>, <code>dbStats</code>, and <code>topmetrics</code> collectors with the <code>--max-collections-limit</code> parameter.</p> <p>Set the value of the parameter <code>--max-collections-limit</code> to:</p> <ul> <li>0: which indicates that <code>collStats</code> and <code>indexStats</code> can handle unlimited collections.</li> <li>n, which indicates that <code>collStats</code> and <code>indexStats</code> can handle &lt;=n collections. If the limit is crossed - exporter stops collecting monitoring data for the <code>collStats</code> and <code>indexStats</code> collectors.</li> <li>-1 (default) doesn\u2019t need to be explicitly set. It indicates that PMM decides how many collections it would monitor, currently &lt;=200 (subject to change).</li> </ul> <p>To further limit collections to monitor, enable <code>collStats</code> and <code>indexStats</code> for some databases or collections:</p> <ul> <li>Specify the databases and collections that <code>collStats</code> and <code>indexStats</code> will use to collect data using the parameter <code>--stats-collections</code>. This parameter receives a comma-separated list of name spaces in the form <code>database[.collection]</code>.</li> </ul>"},{"location":"use/commands/pmm-admin.html#examples","title":"Examples","text":"<p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code>) with default limit detected by PMM (currently &lt;=200 collections, but subject to change):</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors mongodb_srv_1 127.0.0.1:27017</code></p> <p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code>) with <code>max-collections-limit</code> set to 1000:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=1000 mongodb_srv_1 127.0.0.1:27017</code></p> <p>To enable all the collectors with an unlimited number of collections monitored:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 mongodb_srv_1 127.0.0.1:27017</code></p> <p>To add MongoDB with default collectors (<code>diagnosticdata</code> and <code>replicasetstatus</code>):</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass mongodb_srv_1 127.0.0.1:27017</code></p> <p>Disable <code>collstats</code> collector and enable all the others without limiting <code>max-collections-limit</code>:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --disable-collectors=collstats mongodb_srv_1 127.0.0.1:27017</code></p> <p>If <code>--stats-collections=db1,db2.col1</code> then the collectors are run as follows:</p> Database Collector is run on <code>db1</code> All the collections <code>db2</code> Only for collection <code>col1</code> <p>Enable all collectors and limit monitoring for <code>dbstats</code>, <code>indexstats</code>, <code>collstats</code> and <code>topmetrics</code> for all collections in <code>db1</code> and <code>col1</code> collection in <code>db2</code>, without limiting <code>max-collections-limit</code> for a number of collections in <code>db1</code>:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --stats-collections=db1,db2.col1 mongodb_srv_1 127.0.0.1:27017</code></p>"},{"location":"use/commands/pmm-admin.html#resolutions","title":"Resolutions","text":"<p>PMM collects metrics in two resolutions to decrease CPU and Memory usage: high and low resolutions.</p> <p>In high resolution we collect metrics from collectors which work fast: - <code>diagnosticdata</code> - <code>replicasetstatus</code> - <code>topmetrics</code></p> <p>In low resolution we collect metrics from collectors which could take some time: - <code>dbstats</code> - <code>indexstats</code> - <code>collstats</code></p>"},{"location":"use/commands/pmm-admin.html#mysql","title":"MySQL","text":"<code>pmm-admin add mysql [FLAGS] node-name node-address | [--name=service-name] --address=address[:port] | --socket</code> <p>Add MySQL to monitoring.</p> <p>FLAGS:</p> <code>--address</code> MySQL address and port (default: 127.0.0.1:3306). <code>--socket=socket</code> Path to MySQL socket. (Find the socket path with <code>mysql -u root -p -e \"select @@socket\"</code>.) <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> MySQL username. <code>--password=password</code> MySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=slowlog</code> Source of SQL queries, one of: <code>slowlog</code>, <code>perfschema</code>, <code>none</code> (default: <code>slowlog</code>). For <code>slowlog</code> query source, you need change permissions for specific files. Root permissions are needed for this. <code>--size-slow-logs=N</code> <p>Rotate slow log file at this size. If <code>0</code>, use server-defined default. Negative values disable log rotation. A unit suffix must be appended to the number and can be one of:</p> <ul> <li><code>KiB</code>, <code>MiB</code>, <code>GiB</code>, <code>TiB</code> for base 2 units (1024, 1048576, etc).</li> </ul> <code>--disable-queryexamples</code> Disable collection of query examples. <code>--disable-tablestats</code> <p>Disable table statistics collection.</p> <p>Excluded collectors for low-resolution time intervals:</p> <ul> <li><code>--collect.auto_increment.columns</code></li> <li><code>--collect.info_schema.tables</code></li> <li><code>--collect.info_schema.tablestats</code></li> <li><code>--collect.perf_schema.indexiowaits</code></li> <li><code>--collect.perf_schema.tableiowaits</code></li> <li><code>--collect.perf_schema.file_instances</code></li> </ul> <p>Excluded collectors for medium-resolution time intervals:</p> <ul> <li><code>--collect.perf_schema.tablelocks</code></li> </ul> <code>--disable-tablestats-limit=disable-tablestats-limit</code> Table statistics collection will be disabled if there are more than specified number of tables (default: server-defined). 0=no limit. Negative value disables collection. <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-cert-file=PATHTOCERT</code> Path to TLS client certificate file. <code>--tls-key=PATHTOCERTKEY</code> Key for TLS client certificate file. <code>--tls-ca-file=PATHTOCACERT</code> Path to certificate authority file. <code>--ssl-ca=PATHTOCACERT</code> The path name of the Certificate Authority (CA) certificate file. If used, must specify the same certificate used by the server. (-ssl-capath is similar, but specifies the path name of a directory of CA certificate files.) <code>--ssl-cert=PATHTOCERTKEY</code> The path name of the client public key certificate file. <code>--ssl-key</code> The path name of the client private key file. <code>--ssl-skip-verify</code> Skip SSL certificate verification. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled."},{"location":"use/commands/pmm-admin.html#postgresql","title":"PostgreSQL","text":"<code>pmm-admin add postgresql [FLAGS] [node-name] [node-address]</code> <p>Add PostgreSQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=&lt;node id&gt;</code> Node ID (default is auto-detected). <code>--pmm-agent-id=&lt;pmm agent id&gt;</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=&lt;username&gt;</code> PostgreSQL username. <code>--password=&lt;password&gt;</code> PostgreSQL password. <code>--database=&lt;database&gt;</code> PostgreSQL database (default: postgres). <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=&lt;query source&gt;</code> Source of SQL queries, one of: <code>pgstatements</code>, <code>pgstatmonitor</code>, <code>none</code> (default: <code>pgstatements</code>). <code>--disable-queryexamples</code> Disable collection of query examples. Applicable only if <code>query-source</code> is set to <code>pgstatmonitor</code>. <code>--environment=&lt;environment&gt;</code> Environment name. <code>--cluster=&lt;cluster&gt;</code> Cluster name. <code>--replication-set=&lt;replication set&gt;</code> Replication set name. <code>--custom-labels=&lt;custom labels&gt;</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-ca-file</code> TLS CA certificate file. <code>--tls-cert-file</code> TLS certificate file. <code>--tls-key-file</code> TLS certificate key file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled."},{"location":"use/commands/pmm-admin.html#proxysql","title":"ProxySQL","text":"<code>pmm-admin add proxysql [FLAGS] [node-name] [node-address]</code> <p>Add ProxySQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> ProxySQL username. <code>--password=password</code> ProxySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter."},{"location":"use/commands/pmm-admin.html#haproxy","title":"HAProxy","text":"<code>pmm-admin add haproxy [FLAGS] [NAME]</code> <p>Add HAProxy to monitoring.</p> <p>FLAGS:</p> <code>--server-url=SERVER-URL</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--username=USERNAME</code> HAProxy username. <code>--password=PASSWORD</code> HAProxy password. <code>--scheme=SCHEME</code> Scheme to generate URI to exporter metrics endpoints (http or https). <code>--metrics-path=METRICS-PATH</code> Path under which metrics are exposed, used to generate URI (default: /metrics). <code>--listen-port=LISTEN-PORT</code> Listen port of haproxy exposing the metrics for scraping metrics (Required). <code>--service-node-id=SERVICE-NODE-ID</code> Node ID where service runs (default is auto-detected). <code>--environment=ENVIRONMENT</code> Environment name like \u2018production\u2019 or \u2018qa\u2019. <code>--cluster=CLUSTER</code> Cluster name. <code>--replication-set=REPLICATION-SET</code> Replication set name. <code>--custom-labels=CUSTOM-LABELS</code> Custom user-assigned labels. Example: region=east,app=app1. <code>--metrics-mode=MODE</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--skip-connection-check</code> Skip connection check."},{"location":"use/commands/pmm-admin.html#other-commands","title":"OTHER COMMANDS","text":"<code>pmm-admin add external [FLAGS]</code> <p>Add External source of data (like a custom exporter running on a port) to be monitored.</p> <p>FLAGS:</p> <code>--service-name=\"current-hostname\"</code> Service name (autodetected defaults to the hostname where <code>pmm-admin</code> is running). <code>--agent-node-id=AGENT-NODE-ID</code> Node ID where agent runs (default is autodetected). <code>--username=USERNAME</code> External username. <code>--password=PASSWORD</code> External password. <code>--scheme=http or https</code> Scheme to generate URI to exporter metrics endpoints. <code>--metrics-path=/metrics</code> Path under which metrics are exposed, used to generate URI. <code>--listen-port=LISTEN-PORT</code> Listen port of external exporter for scraping metrics. (Required.) <code>--service-node-id=SERVICE-NODE-ID</code> Node ID where service runs (default is autodetected). <code>--environment=prod</code> Environment name like \u2018production\u2019 or \u2018qa\u2019. <code>--cluster=east-cluster</code> Cluster name. <code>--replication-set=rs1</code> Replication set name. <code>--custom-labels=CUSTOM-LABELS</code> Custom user-assigned labels. Example: <code>region=east,app=app1</code>. <code>--metrics-mode=auto</code> Metrics flow mode, can be <code>push</code>: agent will push metrics, <code>pull</code>: server scrape metrics from agent or <code>auto</code>: chosen by server. <code>--group=\"external\"</code> Group name of external service. (Default: <code>external</code>.) <code>pmm-admin add external-serverless [FLAGS]</code> <p>Add External Service on Remote node to monitoring.</p> <p>Usage example: <code>pmm-admin add external-serverless --url=http://1.2.3.4:9093/metrics</code>.</p> <p>Also, individual parameters can be set instead of <code>--url</code> like: <code>pmm-admin add external-serverless --scheme=http --host=1.2.3.4 --listen-port=9093 --metrics-path=/metrics --container-name=ddd --external-name=e125</code>.</p> <p>Note that some parameters are mandatory depending on the context. For example, if you specify <code>--url</code>, <code>--schema</code> and other related parameters are not mandatory. But if you specify <code>--host</code> you must provide all other parameters needed to build the destination URL, or you can specify <code>--address</code> instead of host and port as individual parameters.</p> <p>FLAGS:</p> <code>--url=URL</code> Full URL to exporter metrics endpoints. <code>--scheme=https</code> Scheme to generate URL to exporter metrics endpoints. <code>--username=USERNAME</code> External username. <code>--password=PASSWORD</code> External password. <code>--address=1.2.3.4:9000</code> External exporter address and port. <code>--host=1.2.3.4</code> External exporters hostname or IP address. <code>--listen-port=9999</code> Listen port of external exporter for scraping metrics. <code>--metrics-path=/metrics</code> Path under which metrics are exposed, used to generate URL. <code>--environment=testing</code> Environment name. <code>--cluster=CLUSTER</code> Cluster name. <code>--replication-set=rs1</code> Replication set name. <code>--custom-labels='app=myapp,region=s1'</code> Custom user-assigned labels. <code>--group=\"external\"</code> Group name of external service. (Default: <code>external</code>.) <code>--machine-id=MACHINE-ID</code> Node machine-id. <code>--distro=DISTRO</code> Node OS distribution. <code>--container-id=CONTAINER-ID</code> Container ID. <code>--container-name=CONTAINER-NAME</code> Container name. <code>--node-model=NODE-MODEL</code> Node model. <code>--region=REGION</code> Node region. <code>--az=AZ</code> Node availability zone."},{"location":"use/commands/pmm-admin.html#examples_1","title":"EXAMPLES","text":"<pre><code>pmm-admin add mysql --query-source=slowlog --username=pmm --password=pmm sl-mysql 127.0.0.1:3306\n</code></pre> <pre><code>MySQL Service added.\nService ID  : a89191d4-7d75-44a9-b37f-a528e2c4550f\nService name: sl-mysql\n</code></pre> <pre><code>pmm-admin add mysql --username=pmm --password=pmm --service-name=ps-mysql --host=127.0.0.1 --port=3306\n</code></pre> <pre><code>pmm-admin status\npmm-admin status --wait=30s\n</code></pre> <pre><code>Agent ID: c2a55ac6-a12f-4172-8850-4101237a4236\nNode ID : 29b2cc24-3b90-4892-8d7e-4b44258d9309\nPMM Server:\n URL : https://x.x.x.x:443/\n Version: 2.5.0\nPMM Client:\n Connected : true\n Time drift: 2.152715ms\n Latency : 465.658\u00b5s\n pmm-admin version: 2.5.0\n pmm-agent version: 2.5.0\nAgents: aeb42475-486c-4f48-a906-9546fc7859e8 mysql_slowlog_agent Running\n</code></pre>"},{"location":"use/commands/pmm-admin.html#disable-collectors","title":"Disable collectors","text":"<pre><code>pmm-admin add mysql --disable-collectors='heartbeat,global_status,info_schema.innodb_cmp' --username=pmm --password=pmm --service-name=db1-mysql --host=127.0.0.1 --port=3306\n</code></pre> <p>For other collectors that you can disable with the <code>--disable-collectors</code> option, please visit the official repositories for each exporter:</p> <ul> <li><code>node_exporter</code></li> <li><code>mysqld_exporter</code></li> <li><code>mongodb_exporter</code></li> <li><code>postgres_exporter</code></li> <li><code>proxysql_exporter</code></li> </ul> <p></p>"},{"location":"use/commands/pmm-admin.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/commands/pmm-agent.html","title":"pmm-agent - PMM Client agent","text":""},{"location":"use/commands/pmm-agent.html#name","title":"NAME","text":"<p><code>pmm-agent</code> - The PMM Client daemon program.</p>"},{"location":"use/commands/pmm-agent.html#synopsis","title":"SYNOPSIS","text":"<p><code>pmm-agent [command] [options]</code></p>"},{"location":"use/commands/pmm-agent.html#description","title":"DESCRIPTION","text":"<p><code>pmm-agent</code>, part of the PMM Client package, runs as a daemon process on all monitored hosts.</p>"},{"location":"use/commands/pmm-agent.html#commands","title":"COMMANDS","text":"<code>pmm-agent run</code> Run pmm-agent (default). <code>pmm-agent setup [node-address] [node-type] [node-name]</code> Configure local pmm-agent (requires root permissions) <code>pmm-agent help [command]</code> Show help (for command) and exit."},{"location":"use/commands/pmm-agent.html#options-and-environment","title":"OPTIONS AND ENVIRONMENT","text":"<p>Most options can be set via environment variables (shown in parentheses).</p> Option Environment variable Description <code>--server-password=SERVER-PASSWORD</code> <code>PMM_AGENT_SERVER_PASSWORD</code> Password to connect to PMM Server. <code>--server-username=SERVER-USERNAME</code> <code>PMM_AGENT_SERVER_USERNAME</code> Username to connect to PMM Server. <code>--server-address=host:port</code> <code>PMM_AGENT_SERVER_ADDRESS</code> PMM Server address and port number. <code>--server-insecure-tls</code> <code>PMM_AGENT_SERVER_INSECURE_TLS</code> Skip PMM Server TLS certificate validation. <code>--az=AZ</code> <code>PMM_AGENT_SETUP_AZ</code> Node availability zone. <code>--config-file=path_to/pmm-agent.yaml</code> <code>PMM_AGENT_CONFIG_FILE</code> Configuration file path and name. <code>--container-id=CONTAINER-ID</code> <code>PMM_AGENT_SETUP_CONTAINER_ID</code> Container ID. <code>--container-name=CONTAINER-NAME</code> <code>PMM_AGENT_SETUP_CONTAINER_NAME</code> Container name. <code>--debug</code> <code>PMM_AGENT_DEBUG</code> Enable debug output. <code>--distro=distro</code> <code>PMM_AGENT_SETUP_DISTRO</code> Node OS distribution (default is auto-detected). <code>--force</code> <code>PMM_AGENT_SETUP_FORCE</code> Remove Node with that name and all dependent Services and Agents (if existing). <code>--id=...</code> <code>PMM_AGENT_ID</code> ID of this pmm-agent. <code>--listen-address=LISTEN-ADDRESS</code> <code>PMM_AGENT_LISTEN_ADDRESS</code> Agent local API address. <code>--listen-port=LISTEN-PORT</code> <code>PMM_AGENT_LISTEN_PORT</code> Agent local API port. <code>--machine-id=machine-id</code> <code>PMM_AGENT_SETUP_MACHINE_ID</code> Node machine ID (default is auto-detected). <code>--metrics-mode=auto</code> <code>PMM_AGENT_SETUP_METRICS_MODE</code> Metrics flow mode for agents node-exporter. Can be <code>push</code> (agent will push metrics), <code>pull</code> (server scrapes metrics from agent) or <code>auto</code> (chosen by server). <code>--node-model=NODE-MODEL</code> <code>PMM_AGENT_SETUP_NODE_MODEL</code> Node model. <code>--paths-base=PATH</code> <code>PMM_AGENT_PATHS_BASE</code> Base path for PMM client, where all binaries, tools and collectors are located. If not set, default is <code>/usr/local/percona/pmm</code>. <code>--paths-exporters_base=PATH</code> <code>PMM_AGENT_PATHS_EXPORTERS_BASE</code> Base path for exporters to use. If not set, or set to a relative path, uses value of <code>--paths-base</code> prepended to it. <code>--paths-mongodb_exporter=PATH</code> <code>PMM_AGENT_PATHS_MONGODB_EXPORTER</code> Path to <code>mongodb_exporter</code>. <code>--paths-mysqld_exporter=PATH</code> <code>PMM_AGENT_PATHS_MYSQLD_EXPORTER</code> Path to <code>mysqld_exporter</code>. <code>--paths-node_exporter=PATH</code> <code>PMM_AGENT_PATHS_NODE_EXPORTER</code> Path to <code>node_exporter</code>. <code>--paths-postgres_exporter=PATH</code> <code>PMM_AGENT_PATHS_POSTGRES_EXPORTER</code> Path to <code>postgres_exporter</code>. <code>--paths-proxysql_exporter=PATH</code> <code>PMM_AGENT_PATHS_PROXYSQL_EXPORTER</code> Path to <code>proxysql_exporter</code>. <code>--paths-pt-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_SUMMARY</code> Path to <code>pt-summary</code>. <code>--paths-pt-mysql-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_MYSQL_SUMMARY</code> Path to <code>pt-mysql-summary</code>. <code>--paths-pt-pg-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_PG_SUMMARY</code> Path to <code>pt-pg-summary</code>. <code>--paths-tempdir=PATH</code> <code>PMM_AGENT_PATHS_TEMPDIR</code> Temporary directory for exporters. <code>--ports-max=PORTS-MAX</code> <code>PMM_AGENT_PORTS_MAX</code> Highest allowed port number for listening sockets. <code>--ports-min=PORTS-MIN</code> <code>PMM_AGENT_PORTS_MIN</code> Lowest allowed port number for listening sockets. <code>--region=REGION</code> <code>PMM_AGENT_SETUP_REGION</code> Node region. <code>--skip-registration</code> <code>PMM_AGENT_SETUP_SKIP_REGISTRATION</code> Skip registration on PMM Server. <code>--trace</code> <code>PMM_AGENT_TRACE</code> Enable trace output (implies <code>--debug</code>). <code>-h</code>, <code>--help</code> Show help (synonym for <code>pmm-agent help</code>). <code>--version</code> Show application version, PMM version, time-stamp, git commit hash and branch. <code>--expose-exporter</code> If you enable this flag, any IP address on the local network and anywhere on the internet can access node exporter endpoints. If the flag is disabled, node exporter endpoints can be accessed only locally."},{"location":"use/commands/pmm-agent.html#config-file","title":"CONFIG FILE","text":"<p>PMM manages the configuration file, and it\u2019s not recommended to modify it manually. However, if necessary, you can make adjustments to specific properties in the config file, such as the username or password used for authorization through service accounts.</p> <p>To do this, set the username to <code>service_token</code> and add your service token as the password. For more information about service account authorization, see Service accounts authentication.</p>"},{"location":"use/commands/pmm-agent.html#usage-and-examples-of-paths-base-flag","title":"USAGE AND EXAMPLES OF <code>paths-base</code> FLAG","text":"<p>Since 2.23.0 this flag could be used for easier setup of PMM agent. With this flag the root permissions for PMM client aren\u2019t needed anymore and it will be fully working.</p> <p>Examples:</p> <ul> <li> <p>Case 1: There are no root permissions for <code>/usr/local/percona/pmm</code> folder or there is a need to change default folder for PMM files. Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: be568008-b1b4-4bd9-98c7-392d1f4b724e\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm\n    exporters_base: /home/user/custom/pmm/exporters\n    node_exporter: /home/user/custom/pmm/exporters/node_exporter\n    mysqld_exporter: /home/user/custom/pmm/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/custom/pmm/exporters/mongodb_exporter\n    postgres_exporter: /home/user/custom/pmm/exporters/postgres_exporter\n    proxysql_exporter: /home/user/custom/pmm/exporters/proxysql_exporter\n    rds_exporter: /home/user/custom/pmm/exporters/rds_exporter\n    azure_exporter: /home/user/custom/pmm/exporters/azure_exporter\n    vmagent: /home/user/custom/pmm/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above, base for all exporters and tools was changed only by setting <code>--paths-base</code>. With this tag the folder for PMM that doesn\u2019t require root access could be specified.</p> </li> <li> <p>Case 2: The older <code>--paths-exporters_base</code> flag could be passed along with the <code>--paths-base</code> Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm --paths-exporters_base=/home/user/exporters --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: afce1917-8836-4857-b3e5-ad372c2ddbe5\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm\n    exporters_base: /home/user/exporters\n    node_exporter: /home/user/exporters/node_exporter\n    mysqld_exporter: /home/user/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/exporters/mongodb_exporter\n    postgres_exporter: /home/user/exporters/postgres_exporter\n    proxysql_exporter: /home/user/exporters/proxysql_exporter\n    rds_exporter: /home/user/exporters/rds_exporter\n    azure_exporter: /home/user/exporters/azure_exporter\n    vmagent: /home/user/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above the behavior for the <code>--paths-base</code> was the same, but paths for all exporters were overwritten by the <code>--paths-exporter_base</code> flag.</p> </li> </ul> <p>Summary: Flag <code>--paths-base</code> will set path for all exporters and tools, but each one could be overridden by specific flag (like <code>--paths-mongodb_exporter</code>, <code>--paths-pt-mysql-summary</code> and etc).</p>"},{"location":"use/commands/pmm-agent.html#logging","title":"LOGGING","text":"<p>By default, pmm-agent sends messages to stderr and to the system log (<code>syslogd</code> or <code>journald</code> on Linux).</p> <p>To get a separate log file, edit the <code>pmm-agent</code> start-up script.</p> <p><code>systemd</code>-based systems</p> <ul> <li>Script file: <code>/usr/lib/systemd/system/pmm-agent.service</code></li> <li>Parameter: <code>StandardError</code></li> <li>Default value: <code>file:/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>StandardError=file:/var/log/pmm-agent.log\n</code></pre> <p><code>initd</code>-based systems</p> <ul> <li>Script file: <code>/etc/init.d/pmm-agent</code></li> <li>Parameter: <code>pmm_log</code></li> <li>Default value: <code>/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>pmm_log=\"/var/log/pmm-agent.log\"\n</code></pre> <p></p>"},{"location":"use/commands/pmm-agent.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards/index.html","title":"Dashboards","text":"Category Dashboard Elements Insight Advanced Data Exploration 7 Insight Home Dashboard 26 Insight Prometheus Exporter Status 57 Insight Prometheus Exporters Overview 27 Insight VictoriaMetrics 52 Insight VictoriaMetrics Agents Overview 58 PMM PMM Inventory 3 PMM Environment Overview 0 PMM Environment Summary 0 OS CPU Utilization Details 21 OS Disk Details 34 OS Network Details 70 OS Memory Details 116 OS Node Temperature Details 6 OS Nodes Compare 74 OS Nodes Overview 115 OS Node Summary 67 OS NUMA Details 72 OS Processes Details 35 Prometheus Prometheus Exporter Status 57 Prometheus Prometheus Exporters Overview 27 MySQL MySQL Amazon Aurora Details 20 MySQL MySQL Command/Handler Counters Compare 11 MySQL MySQL InnoDB Compression Details 41 MySQL MySQL InnoDB Details 339 MySQL MySQL MyISAM/Aria Details 55 MySQL MySQL MyRocks Details 101 MySQL MySQL Instance Summary 90 MySQL MySQL Instances Compare 70 MySQL MySQL Instances Overview 96 MySQL MySQL Wait Event Analyses Details 42 MySQL MySQL Performance Schema Details 48 MySQL MySQL Query Response Time Details 49 MySQL MySQL Replication Summary 50 MySQL MySQL Group Replication Summary 18 MySQL MySQL Table Details 45 MySQL MySQL User Details 62 MongoDB Experimental MongoDB Collection Overview 100 MongoDB Experimental MongoDB Collection Details 100 MongoDB Experimental MongoDB Oplog Details 100 MongoDB MongoDB Cluster Summary 55 MongoDB MongoDB Instance Summary 42 MongoDB MongoDB Instances Compare 19 MongoDB MongoDB ReplSet Summary 130 MongoDB MongoDB InMemory Details 46 MongoDB MongoDB MMAPv1 Details 52 MongoDB MongoDB WiredTiger Details 54 PostgreSQL PostgreSQL Instances Overview 114 PostgreSQL Experimental PostgreSQL Vacuum Monitoring 114 PostgreSQL PostgreSQL Instance Summary 67 PostgreSQL PostgreSQL Instances Compare 89 ProxySQL ProxySQL Instance Summary 55 High-availability PXC/Galera Node Summary 32 High-availability PXC/Galera Cluster Summary 19 High-availability Experimental PXC/Galera Cluster Summary 7 High-availability PXC/Galera Nodes Compare 55 High-availability HAProxy Instance Summary 113"},{"location":"use/dashboards/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards/dashboard-inventory.html","title":"About PMM Inventory","text":"<p>The Inventory dashboard is a high-level overview of all objects registered in PMM.</p> <p>To check your inventory list, go to  PMM Configuration &gt; PMM Inventory.</p> <p>Inventory objects form a hierarchy with Node at the top, then Service and Agents assigned to a Node. This information is detailed in the two tabs available on this page.</p>"},{"location":"use/dashboards/dashboard-inventory.html#services-tab","title":"Services tab","text":"<p>Shows individual services, the nodes on which they run, and the Agents that help collect the service metrics. The Status column shows the status of your databases based on metrics coming directly from the database. The Monitoring column summarizes the status of all the Agents assigned to the service.</p> <p>You can check Query Analytics information and the Service Overview Dashboard for each service by clicking on the  icon in the Options column.</p> <p>From here you can also check additional information about the service, by clicking on the  icon. This expands the service entry to show reference information like service labels and IDs.</p> <p></p> <p>Each instance of a service gets a <code>service_type</code> attribute so one can clearly tell what type of database it is, for instance: <code>mysql</code>, <code>postgresql</code>, <code>mongodb</code>, etc. Every service is related to a certain node via its <code>node_id</code> attribute. This feature allows to support multiple instances on a single node, with different service names, e.g. <code>mysql1-3306</code>, and <code>mysql1-3307</code>.</p> <p>Each binary (exporter, agent) running on a client will get an <code>agent_type</code> value. Examples:</p> <ul> <li><code>pmm-agent</code> is at the top of the tree, assigned to pmm-agent itself</li> <li><code>node_exporter</code> is assigned to an agent that extracts the node metrics</li> <li><code>mysqld_exporter</code> and <code>qan-mysql-perfschema-agent</code> are assigned to agents that extract metrics from mysql and its performance schema respectively.</li> </ul> <p>To view the agents running on a service and their health status, click OK or Failed under the Monitoring column. Furthermore, you can also check the properties of a particular agent by clicking the  icon under the Options column.</p>"},{"location":"use/dashboards/dashboard-inventory.html#nodes-tab","title":"Nodes tab","text":"<p>Shows where the service and agents run.</p> <p>Each <code>node_id</code> is associated with a <code>machine_id</code> (from <code>/etc/machine-id</code>). Nodes also have <code>node_type</code> attributes, which give an idea about their nature. Some examples are: generic, container, remote, remote_rds, etc.</p> <p>By expanding the entry from the options column, you can check the node labels and attributes.</p> <p>You can see the number of agents running on any particular node. When you click on any node, the UI navigates to the view of agents, which is filtered to display only agents related to that specific node. </p> <p>To see the details of the agents running, do the following:</p> <ol> <li> <p>On the Nodes tab, under the Monitoring column, click OK or Failed depending on the status of the node that you have selected. A page that provides the user with information regarding the total number of agents deployed on that node is displayed.</p> </li> <li> <p>Click on the  icon under the Options column to view the properties of a specific agent.</p> </li> <li> <p>On the Nodes tab, under the Options column, click on the  icon for the selected node to check the properties and the current health status of an agent.</p> <p></p> </li> </ol>"},{"location":"use/dashboards/dashboard-inventory.html#removing-items-from-the-inventory","title":"Removing items from the inventory","text":"<p>To remove items from the inventory:</p> <ol> <li> <p>Go to PMM Configuration &gt;  PMM Inventory.</p> </li> <li> <p>In the first column, select the items to be removed.</p> </li> <li>Click Delete and confirm the removal.</li> </ol> <p></p>"},{"location":"use/dashboards/dashboard-inventory.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards/dashboard-manage-dashboards.html","title":"Manage PMM dashboards","text":"<p>PMM offers various types of dashboards for monitoring and managing the performance of your databases:</p> <ol> <li>Standard dashboards: include database overviews, database-specific dashboards, query analytics, system-level metrics, replication, and high availability dashboards. These offer comprehensive insights into various aspects of your database environment.</li> <li>Experimental dashboards: newer, or less stable dashboards that usually introduce new metrics or visualizations or monitoring approaches.</li> <li>Custom dashboards: user-created dashboards tailored to specific metrics or needs, allowing you to combine data from different sources for customized monitoring and analysis.</li> </ol> <p>Standard and experimental dashboards are \u201cprovisioned dashboards\u201d, meaning they are:</p> <ul> <li>created by PMM out of the box based on predefined configurations to ensure consistency across deployments.</li> <li>protected from editing through the UI to prevent accidental modifications. Trying to modify these dashboards via the UI will result in a <code>Cannot save provisioned dashboard</code> error.</li> <li>replaced during PMM upgrades, to ensure they are always up-to-date with the latest version. Any manual changes will be overwritten.</li> </ul> <p>Remember:</p> <ul> <li>Always work with cloned copies of PMM dashboards.</li> <li>Changes to original PMM dashboards will be lost during updates.</li> <li>Experimental dashboards may change more frequently, therefore consider re-cloning them after upgrades.</li> </ul>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#create-dashboard-folders","title":"Create dashboard folders","text":"<p>Folders help you organize and group PMM dashboards, making it easier to manage numerous dashboards and accommodate multiple teams using the same PMM instance.</p> <p>To create a dashboard folder (requires Admin privileges):</p> <ol> <li> <p>From the side menu, go to  Dashboards &gt; New &gt; New folder.</p> </li> <li> <p>Enter a unique name for your folder and click Create.</p> </li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#manage-dashboard-folders","title":"Manage dashboard folders","text":""},{"location":"use/dashboards/dashboard-manage-dashboards.html#delete-multiple-dashboards","title":"Delete multiple dashboards","text":"<p>To delete multiple dashboards at once:</p> <ol> <li>From the side menu, go to  Dashboards page.</li> <li>Select the dashboards that you want to delete, and click Delete.</li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#move-dashboards-between-folders","title":"Move dashboards between folders","text":"<p>To move dashboards from one folder to another (requires Editor rights):</p>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#from-the-dasboards-page","title":"From the Dasboards page","text":"<ol> <li>On the Dashboards page, enter the name of the dashboard you want to move in the search bar.</li> <li>Check the box next to the dashboard name.</li> <li> <p>Select the target folder then click Move.</p> <p></p> </li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#from-within-the-dashboard","title":"From within the dashboard","text":"<p>The other way of moving dashboards from one folder to another is:</p> <ol> <li>Open the dashboard that you want to move to another folder.</li> <li>Click on {{ no such element: dict object[\u2018configuration\u2019] }} icon at the top right of the page to open Dashboard settings.</li> <li> <p>On the General tab, under Folder select the folder name that you want to move from the drop-down.</p> <p></p> </li> <li> <p>Click Save Dashboard on the top right of the page.</p> </li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#navigate-to-a-dashboard-folder-page-to-assign-folder-permissions","title":"Navigate to a dashboard folder page to assign folder permissions","text":"<p>Fine-tune access control for your dashboard folders, ensuring team members have the right level of access to the dashboards they need. To set permissions for a dashboard folder:</p> <ol> <li>Navigate to the Dashboards page.</li> <li>Locate and click on the target folder.</li> <li>In the top right corner, click Folder actions.</li> <li>From the dropdown menu, select Manage permissions.</li> <li> <p>For each user, role, team, or service account, select the appropriate permission level from the dropdown next to it.</p> <p></p> </li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#edit-dashboards","title":"Edit dashboards","text":"<p>You cannot directly edit provisioned dashboards. Instead, clone the dashboard and edit or move the cloned dashboard freely: </p> <ol> <li>Open the dashboard you wish to edit.</li> <li>Click the {{ no such element: dict object[\u2018configuration\u2019] }} icon at the top right of the page to open Dashboard settings.</li> <li>Click Make editable, then at the top right of the page, click Save as to create a copy.</li> <li>Name your copy and choose the location where you want to save it.</li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#setting-a-custom-home-dashboard","title":"Setting a custom Home dashboard","text":"<p>The Home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account.</p>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#for-your-organization","title":"For your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users</p> <ol> <li>Navigate to the dashboard that you want to set as the home dashboard.</li> <li>Click the  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>From the side menu, go to {{ no such element: dict object[\u2018configuration\u2019] }} Administration &gt; General &gt; Default preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save then confirm.</li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#for-a-team","title":"For a team","text":"<p>Organization and team Admins can set the home dashboard for their team:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard to mark the dashboard as a favorite.</li> <li>From the main menu, choose {{ no such element: dict object[\u2018configuration\u2019] }} Administration &gt; Teams. Grafana displays the team list.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#set-your-personal-home-dashboard","title":"Set your personal Home dashboard","text":"<ol> <li>From the main menu, go to  Dashboards &gt; Browse and select the dashboard you want to set as your home dashboard.</li> <li>Click the  star next to the dashboard title to mark it as a favorite.</li> <li> <p>From the side menu go to {{ no such element: dict object[\u2018configuration\u2019] }} Administration &gt; General &gt; Default preferences. In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</p> <p></p> </li> <li> <p>Click Save.</p> </li> </ol> <p></p>"},{"location":"use/dashboards/dashboard-manage-dashboards.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/index.html","title":"Dashboards overview","text":"<p>Dashboards are a compilation of visualizations, including charts and metrics, that enable you to view performance metrics from node to single query for multiple databases in a centralized location. </p> <p>A dashboard is a group of one or more panels organized and arranged into rows. Panels refer to individual components or visual elements that display specific data or visualizations within the dashboard\u2019s layout. These panels are the building blocks that collectively form a dashboard, providing a means to present and visualize data in various formats. Dashboards are grouped into folders. You can customize these by renaming them or creating new ones. </p> <p>Dashboards provide insightful and actionable data, enabling you to gain an overview of your system status quickly. These dashboards enable you to drill down into specific time frames, apply filters, and analyze data trends for troubleshooting and performance optimization. Customizable dashboards and real-time alerting facilitate seamless monitoring of database performance.</p>"},{"location":"use/dashboards-panels/index.html#available-dashboards","title":"Available dashboards","text":"<p>Performance Monitoring and Management (PMM) offers a range of dashboards you can access. Some of these dashboards are as follows:</p> Category Dashboard Elements Insight Advanced Data Exploration 7 Insight Home Dashboard 26 Insight Prometheus Exporter Status 57 Insight Prometheus Exporters Overview 27 Insight VictoriaMetrics 52 Insight VictoriaMetrics Agents Overview 58 PMM PMM Inventory 3 PMM Environment Overview 0 PMM Environment Summary 0 OS CPU Utilization Details 21 OS Disk Details 34 OS Network Details 70 OS Memory Details 116 OS Node Temperature Details 6 OS Nodes Compare 74 OS Nodes Overview 115 OS Node Summary 67 OS NUMA Details 72 OS Processes Details 35 Prometheus Prometheus Exporter Status 57 Prometheus Prometheus Exporters Overview 27 MySQL MySQL Amazon Aurora Details 20 MySQL MySQL Command/Handler Counters Compare 11 MySQL MySQL InnoDB Compression Details 41 MySQL MySQL InnoDB Details 339 MySQL MySQL MyISAM/Aria Details 55 MySQL MySQL MyRocks Details 101 MySQL MySQL Instance Summary 90 MySQL MySQL Instances Compare 70 MySQL MySQL Instances Overview 96 MySQL MySQL Wait Event Analyses Details 42 MySQL MySQL Performance Schema Details 48 MySQL MySQL Query Response Time Details 49 MySQL MySQL Replication Summary 50 MySQL MySQL Group Replication Summary 18 MySQL MySQL Table Details 45 MySQL MySQL User Details 62 MongoDB Experimental MongoDB Collection Overview 100 MongoDB Experimental MongoDB Collection Details 100 MongoDB Experimental MongoDB Oplog Details 100 MongoDB MongoDB Cluster Summary 55 MongoDB MongoDB Instance Summary 42 MongoDB MongoDB Instances Compare 19 MongoDB MongoDB ReplSet Summary 130 MongoDB MongoDB InMemory Details 46 MongoDB MongoDB MMAPv1 Details 52 MongoDB MongoDB WiredTiger Details 54 PostgreSQL PostgreSQL Instances Overview 114 PostgreSQL Experimental PostgreSQL Vacuum Monitoring 114 PostgreSQL PostgreSQL Instance Summary 67 PostgreSQL PostgreSQL Instances Compare 89 ProxySQL ProxySQL Instance Summary 55 High-availability PXC/Galera Node Summary 32 High-availability PXC/Galera Cluster Summary 19 High-availability Experimental PXC/Galera Cluster Summary 7 High-availability PXC/Galera Nodes Compare 55 High-availability HAProxy Instance Summary 113 <p></p>"},{"location":"use/dashboards-panels/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/annotate/annotate.html","title":"Annotation in dashboards","text":"<p>Annotations mark a moment in time. They are useful for marking system changes or other significant application events. They can be set globally or for specific nodes or services.</p> <p>You create them on the command line with the <code>pmm-admin annotate</code> command.</p> <p>Annotations show as a vertical dashed line on a dashboard graph. Reveal the annotation text by mousing over the caret indicator below the line.</p> <p></p> <p>You turn annotations on or off with the PMM Annotations switch in the second row menu bar.</p> <p></p> <p></p>"},{"location":"use/dashboards-panels/annotate/annotate.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/export-dashboards/export_dashboards.html","title":"Export a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/export-dashboards/export_dashboards.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/export-dashboards/import_dashboards.html","title":"Import a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/export-dashboards/import_dashboards.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/manage-dashboards/create-folders.html","title":"Create dashboard folders","text":"<p>Folders help you organize and group PMM dashboards, which is crucial when you have multiple dashboards or teams using the same PMM instance.</p> <p>Note</p> <p>To create a dashboard folder, you must have PMM\u2019s Admin privileges.</p> <p>To create a dashboard folder:</p> <ol> <li> <p>On the PMM dashboards page, from the side menu, go to  Dashboards &gt;  New &gt; New folder.</p> </li> <li> <p>Enter a unique name for your folder and click Create.</p> </li> </ol> <p></p>"},{"location":"use/dashboards-panels/manage-dashboards/create-folders.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html","title":"Manage dashboard folders","text":"<p>This section describes how to delete multiple dashboards, move dashboards from one folder to another and navigate to a folder page where you can assign folder and dashboard permissions.</p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#delete-multiple-dashboards","title":"Delete multiple dashboards","text":"<p>To delete multiple dashboards at once:</p> <p>From the side menu, go to  Dashboards, browse for the dashboards that you want to delete, and click Delete.</p> <p></p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#move-dashboards-from-one-folder-to-another","title":"Move dashboards from one folder to another","text":"<p>Note</p> <p>You should have at least an Editor role to move a dashboard.</p> <p>You can move dashboards from one folder to another in the following two ways:</p> <ol> <li>From the side menu, go to  Dashboards, select the dashboards that you want to move then click Move.</li> </ol> <p>The other way of moving dashboards from one folder to another is:</p> <ol> <li>On the Dashboards page, click on the dashboard that you want to move to another folder.</li> <li>Click on  Dasboard settings icon at the top of the page.</li> <li>On the General tab, use the Folder drop-down menu to select the new taget folder.</li> <li>Click Save Dashboard on the the left to save the change.    </li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#navigate-to-a-dashboard-folder-page-to-assign-permissions","title":"Navigate to a dashboard folder page to assign permissions","text":"<p>To navigate to a dashboard folder page to assign permissions:</p> <ol> <li>From the side menu, go to  Dashboards and click on the main folder whose permissions you want to set.</li> <li> <p>Click the Folder actions &gt; Manage permissions button at the top-right of the page and select the requisite permission from the drop-down for the various roles.</p> <p></p> </li> </ol> <p></p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html","title":"Setting custom Home dashboard","text":"<p>The home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account. </p>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html#set-home-dashboard-for-your-organization","title":"Set home dashboard for your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users.</p> <ol> <li>From the side menu, go to  Dashboards and click on the dashboard that you want to set as the home dashboard.</li> <li>Click the  star on top of the page to mark the dashboard as a favorite.</li> <li>From the main menu on the left, go to  Administration &gt; Default preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html#set-home-dashboard-for-your-team","title":"Set home dashboard for your team","text":"<p>Organization and team Admins can set the home dashboard for their team as follows:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>From the main menu on the left, go to  Administration &gt; Users and access &gt; Teams.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol> <p></p>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/share-dashboards/publish_snapshot.html","title":"Publish snapshot","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/share-dashboards/publish_snapshot.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html","title":"Share dashboards and panels","text":"<p>When you need to share a dashboard with your team members, you can either send them a direct link to the dashboard, or render and send each panel as a .PNG image.</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#share-panel-via-direct-link","title":"Share panel via direct link","text":"<p>To share a panel via direct link:</p> <ol> <li>Go to the dashboard with the panel that you want to share.</li> <li> <p>Click at the top of the panel to display the panel menu:     </p> </li> <li> <p>Select Share to reveal the Share Panel window and either:</p> <ul> <li>copy and send the full URL for the dashboard, OR</li> <li>toggle the Shorten URL option to generate a simple link with a unique identifier</li> </ul> </li> </ol> <p>Tip</p> <p>If your current domain is different than the one specified in the Grafana .INI configuration file, PMM will ask you to correct this mismatch before you can generate a short URL.</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#share-a-panel-as-a-png-file","title":"Share a panel as a PNG file","text":"<p>To enable image rendering:</p> <ol> <li> <p>Deploy the Grafana Image Renderer container alongside PMM Server:</p> <pre><code>docker run -d \\\n--name renderer \\\n-e IGNORE_HTTPS_ERRORS=true \\\ngrafana/grafana-image-renderer:latest\n</code></pre> </li> <li> <p>Stop your existing PMM Server container:</p> <pre><code>docker stop pmm-server\ndocker rm pmm-server\n</code></pre> </li> <li> <p>Start a new PMM Server container with the required environment variables:</p> <pre><code>docker run -d \\\n--name pmm-server \\\n--network=pmm-network \\\n-p 8443:443 \\\n-e GF_RENDERING_SERVER_URL=http://renderer:8081/render \\\n-e GF_RENDERING_CALLBACK_URL=https://pmm-server:8443/graph/ \\\nperconalab/pmm-server:3.0.0-beta\n</code></pre> </li> </ol>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#render-panel-image","title":"Render panel image","text":"<p>To Render a panel image:</p> <ol> <li>Go to the dashboard with the panel that you want to share.</li> <li>Click at the top of the panel to display the panel menu.</li> <li>Select Share to reveal the Share Panel window.</li> <li>In the Link tab, click Direct link rendered image. This opens a new browser tab.</li> <li>Wait for the image to be rendered, then use your browser\u2019s Image Save function to download the image.</li> </ol> <p></p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-feature.html","title":"Dashboard feature overview","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-feature.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-settings.html","title":"Dashboard settings","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-settings.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-time-range.html","title":"Set dashboard time range","text":""},{"location":"use/dashboards-panels/use-dashboards/dashboard-time-range.html#time-units-and-relative-ranges","title":"Time units and relative ranges","text":"<p>Important</p> <p>The content for this topic is under development.</p> <p></p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-time-range.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/metrics/index.html","title":"About PMM metrics","text":"<p>Percona Monitoring and Management (PMM) collects a range of metrics across database systems to provide comprehensive monitoring and analysis capabilities. PMM supports monitoring for databases such as MySQL, PostgreSQL,  MongoDB, among many others. It gathers metrics related to database performance, resource utilization, health, and other important aspects. </p> <p></p>"},{"location":"use/metrics/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/metrics/extend_metrics.html","title":"Extend metrics","text":"<p>When you need a metric that\u2019s not present in the default list of <code>node_exporter</code> metrics you may be able to use the <code>textfile</code> collector. The textfile collector allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has.</p>"},{"location":"use/metrics/extend_metrics.html#enable-the-textfile-collector","title":"Enable the textfile collector","text":"<p>The collector is enabled by default. The following folders are used for different resolutions:</p> Resolution Folder High <code>/usr/local/percona/pmm/collectors/textfile-collector/high-resolution</code> Medium <code>/usr/local/percona/pmm/collectors/textfile-collector/medium-resolution</code> Low <code>/usr/local/percona/pmm/collectors/textfile-collector/low-resolution</code> <p></p> <p>The exporter parses all files in these directories that match the filename wildcard expression <code>*.prom</code> using a simple text-based exposition format. Metrics are stored on the PMM Server-side with additional labels related to this Node.</p>"},{"location":"use/metrics/extend_metrics.html#examples-of-shell-commands-for-custom-metrics","title":"Examples of shell commands for custom metrics","text":"<p>To statically set roles for a machine using labels:</p> <pre><code>echo 'node_role{role=\"my_monitored_server_1\"} 1' &gt; /usr/local/percona/pmm/collectors/textfile-collector/low-resolution/node_role.prom\n</code></pre> <p>Here\u2019s an example of a <code>cron</code> job that automatically pushes logged-in users:</p> <pre><code>$ cat /etc/cron.d/loggedin_users\n*/1 * * * *     root    /usr/bin/who | /usr/bin/wc -l | sed -ne 's/^/node_loggedin_users /p' &gt; /usr/local/percona/pmm/collectors/textfile-collector/high-resolution/node_users.prom\n</code></pre> <p></p> <p></p>"},{"location":"use/metrics/extend_metrics.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/index.html","title":"About query analytics (QAN)","text":"<p>The Query Analytics dashboard shows how queries are executed and where they spend their time.  It helps you analyze database queries over time, optimize database performance, and find and remedy the source of problems.</p> <p></p> <p>Query Analytics supports MySQL, MongoDB and PostgreSQL. The minimum requirements for MySQL are:</p> <ul> <li>MySQL 5.1 or later (if using the slow query log).</li> <li>MySQL 5.6.9 or later (if using Performance Schema).</li> </ul> <p>Query Analytics displays metrics in both visual and numeric form. Performance-related characteristics appear as plotted graphics with summaries.</p> <p>The dashboard contains three panels:</p> <ul> <li>the Filters Panel;</li> <li>the Overview Panel;</li> <li>the Details Panel.</li> </ul> <p>Note</p> <p>Query Analytics data retrieval is not instantaneous and can be delayed due to network conditions. In such situations no data is reported and a gap appears in the sparkline.</p> <p></p>"},{"location":"use/qan/index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/qan_mongo.html","title":"Query Analytics for MongoDB","text":"<p>MongoDB is conceptually different from relational database management systems, such as MySQL and MariaDB.</p> <p>Relational database management systems store data in tables that represent single entities. Complex objects are represented by linking tables.</p> <p>In contrast, MongoDB uses the concept of a document where all essential information for a complex object is stored in one place.</p> <p>Query Analytics can monitor MongoDB queries. Although MongoDB is not a relational database management system, you analyze its databases and collections in the same interface using the same tools.</p> <p></p>"},{"location":"use/qan/qan_mongo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/share_link.html","title":"Share a link for Query Analytics","text":"<p>To share a link for Query Analytics, use Copy Link. It copies the link to the clipboard with all the relevant information such as selected query, table page, selected filters, details tab, and time range. Thus, when you open the link, it will display the exact information.</p> <p>Important</p> <p>Ensure that you use Copy Link to copy the link instead of using the browser address bar or the standard Grafana functionality (to share a dashboard). Otherwise, Query Analytics might not display the exact information that existed while sharing the link.</p> <p>By default, Grafana uses a relative time range and not an absolute range, so it will have a different timestamp when this link is opened.</p> <p></p> <p></p>"},{"location":"use/qan/share_link.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/panels/details.html","title":"Details panel","text":"<ul> <li>Selecting an item in the Overview panel opens the Details panel with a Details Tab.</li> <li>If the dimension is Query, the panel also contains the Examples Tab, Explain Tab, and Tables Tab.</li> </ul>"},{"location":"use/qan/panels/details.html#details-tab","title":"Details Tab","text":"<p>The Details tab contains a Query time distribution bar (only for MySQL databases) and a set of Metrics in collapsible subpanels.</p> <p></p> <ul> <li> <p>The Query time distribution bar shows a query\u2019s total time made up of colored segments, each segment representing the proportion of time spent on a named activity.</p> <ul> <li><code>query_time</code>: Statement execution time.</li> <li><code>lock_time</code>: Time to acquire locks.</li> <li><code>blk_read_time</code>: Total time the statement spent reading blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>blk_write_time</code>: Total time the statement spent writing blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>innodb_io_r_wait</code>: Time for InnoDB to read the data from storage.</li> <li><code>innodb_queue_wait</code>: Time the query spent either waiting to enter the InnoDB queue, or in it pending execution.</li> <li><code>innodb_rec_lock_wait</code>: Time the query waited for row locks.</li> <li><code>other</code>: Remaining uncategorized query time.</li> </ul> </li> <li> <p>Metrics is a table with headings:</p> <ul> <li>Metric: The Metric name, with a question-mark tool-tip that reveals a description of the metric on mouse-over;</li> <li>Rate/Second: A sparkline chart of real-time values per unit time;</li> <li>Sum: A summation of the metric for the selected query, and the percentage of the total;</li> <li>Per Query Stats: The value of the metric per query.</li> </ul> </li> <li> <p>Each row in the table is a metric. The contents depends on the chosen dimension.</p> </li> </ul> <p>For PostgreSQL queries (when using <code>pg_stat_monitor</code>) the top query will also be shown in the details section if the query was called by an outer query.</p> <p></p> <p>Other useful metrics (when using pg_stat_monitor) to monitor PostgreSQL Server performance are Histograms.  Histograms provide more explicit information about number of queries for fingerprint (<code>queryid</code>). Ranges are from 0 seconds up to 100 seconds.  </p> <p>Here is picture of histogram in graph:</p> <p></p>"},{"location":"use/qan/panels/details.html#examples-tab","title":"Examples Tab","text":"<p>(For Query dimension.)</p> <p>The Examples tab shows an example of the selected query\u2019s fingerprint or table element.</p> <p></p> <p>Query example and fingerprint can be truncated to 1024 long to reduce space usage. In this case, the query explains section will not work.</p>"},{"location":"use/qan/panels/details.html#explain-tab","title":"Explain Tab","text":"<p>(For Query dimension.)</p> <p>The Explain tab shows the <code>explain</code> output for the selected query, in Classic or JSON formats.</p> <ul> <li>MySQL: Classic and JSON.</li> <li>MongoDB: JSON only.</li> <li>PostgreSQL: Not supported.</li> </ul> <p>The Explain tab for MySQL queries works without enabling Examples. For security, sensitive data appears as placeholders that you must fill in before running Explain:</p> <p></p> <p>Below is an illustration of the same query using values instead of placeholders.</p> <p></p> <p>The image shown above illustrates a query with two placeholders. Therefore, you must enter the correct values in both fields. After filling in these values, click Explain to get the results like in the previous PMM versions without data leaks. You will get result like in previous PMM versions. This method of <code>explain</code> prevents data leak.</p> <p>\u2018Explain\u2019 for MongoDB</p> <p>To run Explain you need the same permissions as for executing the original query. For example, to run explain on <code>updates</code> you need update permissions.  </p> <p>Example: Grant the <code>explainRole</code> with update permissions.</p> <pre><code>db.grantPrivilegesToRole( \"explainRole\", [ { resource: { db: \"\", collection: \"\" }, actions: [ \"update\" ] } ])\n</code></pre> <p></p>"},{"location":"use/qan/panels/details.html#tables-tab","title":"Tables Tab","text":"<p>(For Query dimension.)</p> <p>The Tables tab shows information on the tables and indexes involved in the selected query.</p> <p></p>"},{"location":"use/qan/panels/details.html#plan-tab","title":"Plan Tab","text":"<p>(For Query dimension.)</p> <p>The Plan tab shows the plan for PostgreSQL queries (only available when using pg_stat_monitor).</p> <p></p> <p></p>"},{"location":"use/qan/panels/details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/panels/filters.html","title":"Filters Panel","text":"<ul> <li>The Filter panel on the left hand side of the dashboard lists the filters grouped by category. It also shows the percentage of the main metrics (explained below). If you select a different metric, the percentages on the left panel will change as per this metric. When you select a metric, it reduces the overview list as per the matching filter.</li> <li>The first five of each category are shown. If there are more, the list is expanded by clicking Show all beside the category name, and collapsed again with Show top 5.</li> <li>Applying a filter may make other filters inapplicable. These become grayed out and inactive.</li> <li>Click the chart symbol  to navigate directly to an item\u2019s associated dashboard.</li> <li>Separately, the global Time range setting filters results by time, either your choice of Absolute time range, or one of the predefined Relative time ranges.</li> </ul>"},{"location":"use/qan/panels/filters.html#custom-filter-groups","title":"Custom filter groups","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Filter queries using custom key=value pairs from query comments. This feature is disabled by default.</p>"},{"location":"use/qan/panels/filters.html#supported-technologies-and-agents","title":"Supported technologies and agents","text":"<ul> <li>MySQL (<code>perfschema</code>, <code>slowlog</code>),</li> <li>PostgreSQL (<code>pg_stat_statements</code>, <code>pg_stat_monitor</code>)</li> </ul> <p>Example</p> <p></p> <p>In the image above we have tagged queries running databases on Windows using the following comment: </p> <p><pre><code>comment: /* OperationSystem='windows' */. \n</code></pre> Queries from the database running on Linux are tagged with:</p> <pre><code>/* OperationSystem='linux' */. \n</code></pre> <p>All types of comments and multicomments are supported <code>(/* */, --, # etc)</code>. </p> <p>So the queries are as follows:</p> <pre><code>SELECT * /* OperationSystem='windows' */ FROM city;\nSELECT city /* OperationSystem='linux' */ FROM world;\n</code></pre> <p>In the output, you can see another custom group in the <code>OperationSystem</code> filter. Use this to easily filter by any custom key or value.</p>"},{"location":"use/qan/panels/filters.html#enabling-custom-filter-groups","title":"Enabling custom filter groups","text":"<ul> <li> <p>CLI: While adding a service through CLI use the flag <code>comments-parsing</code>. Possible values are <code>on/off</code>. </p> <p>Example for adding MySQL with comments parsing on:</p> <pre><code>pmm-admin add mysql --username=root --password=root-password --comments-parsing=\"on\"\n</code></pre> </li> <li> <p>UI: While adding a service through the UI you will see new checkbox to <code>enable/disable</code> comments parsing for current service.</p> <p></p> </li> </ul> <p>MySQL CLI</p> <ul> <li>If you are using official MySQL CLI to trigger queries, start mysql with <code>--comments</code> flag. Otherwise comments will not be parsed.</li> <li>In case of PGSM (<code>pg_stat_monitor</code>), set the DB variable <code>pgsm_extract_comments=yes</code></li> </ul> <p></p>"},{"location":"use/qan/panels/filters.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use/qan/panels/overview.html","title":"Overview Panel","text":"<p>To the right of the Filters panel and occupying the upper part of the dashboard is the Overview panel.</p> <p></p> <p>Each row of the table represents the metrics for a chosen object type, one of:</p> <ul> <li>Query;</li> <li>Service Name;</li> <li>Database;</li> <li>Schema;</li> <li>User Name;</li> <li>Client Host.</li> </ul> <p>At the top of the second column is the dimension menu. Use this to choose the object type.</p> <p></p> <p>On the right side of the dimension column is the Dimension Search bar.</p> <p></p> <p>Enter a string and press Enter to limit the view to queries containing only the specified keywords.</p> <p>Delete the search text and press Enter to see the full list again.</p>"},{"location":"use/qan/panels/overview.html#columns","title":"Columns","text":"<ul> <li>The first column is the object\u2019s identifier. For Query, it is the query\u2019s Fingerprint.</li> <li>The second column is the Main metric, containing a reduced graphical representation of the metric over time, called a sparkline, and a horizontal meter, filled to reflect a percentage of the total value.</li> <li>Additional values are revealed as mouse-over tool-tips.</li> </ul>"},{"location":"use/qan/panels/overview.html#tool-tips","title":"Tool-tips","text":"<ul> <li>For the Query dimension, hovering over the information icon  reveals the query ID and its example.</li> <li>Hovering on a column header reveals an informative tool-tip for that column.</li> <li>Hovering on the main metric sparkline highlights the data point and a tooltip shows the data value under the cursor.</li> </ul> <ul> <li> <p>Hovering on the main metric meter reveals the percentage of the total, and other details specific to the main metric.</p> <p></p> </li> <li> <p>Hovering on column values reveals more details on the value. The contents depends on the type of value.</p> <p></p> </li> </ul>"},{"location":"use/qan/panels/overview.html#adding-and-removing-columns","title":"Adding and removing columns","text":"<ul> <li> <p>Metrics columns are added with the Add column button.</p> <p></p> </li> <li> <p>When clicked, a text field and list of available metrics are revealed. Select a metric or enter a search string to reduce the list. Selecting a metric adds it to the panel.</p> </li> <li>A metric column is removed by clicking on the column heading and selecting Remove column.</li> <li>The value plotted in the main metric column can be changed by clicking a metric column heading and selecting Swap with main metric.</li> </ul>"},{"location":"use/qan/panels/overview.html#sorting","title":"Sorting","text":"<ul> <li>The entire list is sorted by one of the columns.</li> <li>Click either the up or down caret to sort the list by that column\u2019s ascending or descending values.</li> </ul>"},{"location":"use/qan/panels/overview.html#pagination","title":"Pagination","text":"<ul> <li> <p>The pagination device lets you move forwards or backwards through pages, jump to a specific page, and choose how many items are listed per page.</p> <p></p> </li> <li> <p>Queries are grouped into pages of 25, 50 or 100 items.</p> </li> </ul> <p></p>"},{"location":"use/qan/panels/overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"}]}