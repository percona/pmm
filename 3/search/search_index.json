{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"About PMM","text":"<p> Info: This is the documentation for the latest PMM 3 release. For details, see the PMM 3.3.1 release notes.</p> <p>Percona Monitoring and Management (PMM) is an open source database observability, monitoring, and management platform that gives you a single view of performance metrics - from entire database clusters down to individual queries.</p> <p>Key features:</p> <ul> <li>Complete visibility of MySQL, PostgreSQL, and MongoDB performance</li> <li>Unified dashboard for all your database metrics and query analytics</li> <li>Flexible deployment options: on-premises, cloud, or hybrid environments</li> <li>Easy setup with just two components: Server and Client</li> </ul>"},{"location":"index.html#try-pmm-demo","title":"Try PMM Demo","text":"<p>Want to see PMM in action before installing? Visit our live demo at https://pmmdemo.percona.com/ to explore PMM\u2019s features and interface with sample data.</p>"},{"location":"index.html#discover","title":"Discover","text":"<p>Discover how PMM can help you monitor your systems and make informed decisions.</p> <p>Discover PMM </p>"},{"location":"index.html#install","title":"Install","text":"<p>Ready to dive into PMM? Follow our simple, step-by-step installation instructions to get started in no time!</p> <p>Quickstart guide </p>"},{"location":"index.html#configure","title":"Configure","text":"<p>Are you ready to begin configuring PMM  but need help figuring out how to begin? Let\u2019s dive in together.</p> <p>Configure PMM </p>"},{"location":"index.html#resources","title":"Resources","text":"<p>Looking for reliable and easy-to-use resources to tackle your daily challenges with database monitoring and management?</p> <p>Additional resources </p>"},{"location":"get-help.html","title":"Get help from Percona","text":"<p>Our documentation guides are packed with information, but they can\u2019t cover everything you need to know about Percona Monitoring and Management (PMM). They also won\u2019t cover every scenario you might come across. Don\u2019t be afraid to try things out and ask questions when you get stuck.</p>"},{"location":"get-help.html#perconas-community-forum","title":"Percona\u2019s Community Forum","text":"<p>Be a part of a space where you can tap into a wealth of knowledge from other database enthusiasts and experts who work with Percona\u2019s software every day. While our service is entirely free, keep in mind that response times can vary depending on the complexity of the question. You are engaging with people who genuinely love solving database challenges.</p> <p>Visit the PMM Community Forum. It\u2019s an excellent place for discussions, technical insights, and support around Percona database software. If you\u2019re new and feeling a bit unsure, our FAQ and Guide for new users can ease you in.</p> <p>If you have thoughts, feedback, or ideas, the community team would like to hear from you at Any ideas on how to make the forum better?. We\u2019re always excited to connect and improve everyone\u2019s experience.</p>"},{"location":"get-help.html#percona-experts","title":"Percona Experts","text":"<p>Percona experts bring years of experience in tackling tough database performance issues and design challenges.</p> <p>We understand your challenges when managing complex database environments. That\u2019s why we offer various services to help you simplify your operations and achieve your goals.</p> Service Description 24/7 Expert support Our dedicated team of database experts is available 24/7 to assist you with any database issues. We provide flexible support plans tailored to your specific needs. Hands-on database management Our managed services team can take over the day-to-day management of your database infrastructure, freeing up your time to focus on other priorities. Expert consulting Our experienced consultants provide guidance on database topics like architecture design, migration planning, performance optimization, and security best practices. Comprehensive training Our training programs help your team develop skills to manage databases effectively, offering virtual and in-person courses. <p>We\u2019re here to help you every step of the way. Whether you need a quick fix or a long-term partnership, we\u2019re ready to provide your expertise and support.</p>"},{"location":"admin/index.html","title":"About PMM administration","text":"<p>Percona Monitoring and Management (PMM) administration involves  crucial tasks, including the following:</p> <ul> <li>User management</li> <li>Access control</li> <li>Security</li> </ul>"},{"location":"admin/manage-orgs/index.html","title":"\u200b\u200bAbout organizations in PMM","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"admin/manage-orgs/create_org.html","title":"Create an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"admin/manage-orgs/del_org.html","title":"Delete an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"admin/manage-orgs/edit_org.html","title":"Edit an organization","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"admin/manage-users/index.html","title":"About user management in PMM","text":"<p>A user refers to any individual who can log in to PMM. Each user is assigned a specific role that is associated with permissions. Permissions determine the tasks a user can perform in the system. For instance, the Admin role confers permissions that allow an authorized administrator to create and delete user profiles. </p> <p>The following topics are covered as part of access control:</p> <ul> <li>Add users</li> <li>Edit users</li> <li>Delete users</li> </ul>"},{"location":"admin/manage-users/index.html#next-steps","title":"Next steps","text":"<p>Access control in PMM </p>"},{"location":"admin/manage-users/add_users.html","title":"Add users","text":"<p>You can add a user in PMM from Administration &gt; Users and access &gt; Users tab.</p> <p></p> <p>To add a new user in PMM:</p> <ol> <li>On the Users tab, click New user.</li> <li> <p>On the Add new user dialog box, enter the following:</p> <ul> <li>Name</li> <li>email address or username (if this is an existing grafana user)</li> <li>Username</li> <li>Password</li> </ul> </li> <li> <p>Click Create user.</p> </li> </ol>"},{"location":"admin/manage-users/delete_users.html","title":"Delete users","text":""},{"location":"admin/manage-users/delete_users.html#delete-users","title":"Delete Users","text":"<p>You can delete a user in PMM as follows:</p> <ol> <li>Go to PMM Administration &gt; Users and access &gt; Users tab</li> <li>Click the Edit user icon next to the user you want to delete.</li> <li>Click Delete user.</li> </ol>"},{"location":"admin/manage-users/edit_users.html","title":"Edit users","text":"<p>You can edit users by changing the information or settings for an individual user account.</p> <p>Important</p> <p>After changing the default admin password for the PMM Server, register the pmm-agent using the same credentials and add the services again. Otherwise, PMM will cease to monitor the service/nodes.</p>"},{"location":"admin/manage-users/edit_users.html#grant-or-revoke-admin-privileges","title":"Grant or Revoke admin privileges","text":"<p>You can grant or revoke admin access to a user as follows:</p> <ol> <li> <p>On the Users tab, click the user account you want to edit.</p> </li> <li> <p>To grant or revoke the privileges, click the user. User information dialog box opens.</p> </li> <li> <p>In the Permissions section, click Change and then select Yes/No, depending on whether you want to provide admin access or not.</p> </li> <li> <p>Click Change.</p> </li> </ol> <p>Important</p> <p>After connecting your PMM instance to the Percona Platform, when you log in using your Percona account, you will be granted the Viewer access. For Admin access, log in to PMM as an admin, and change the permissions for this user.</p>"},{"location":"admin/manage-users/edit_users.html#change-organization-role","title":"Change organization role","text":"<p>You can change the organization role assigned to your user account.</p> <p></p> <p>To change the role:</p> <ol> <li> <p>On the Users tab, click the user for whom you want to change the role.</p> </li> <li> <p>In the Organisations section, click Change role.</p> </li> <li> <p>Select the role from the drop-down and click Save.</p> </li> </ol> <p>The following are the privileges for the various roles:</p> <ul> <li> <p>Admin - Managing data sources, teams, and users within an organization</p> </li> <li> <p>Editor - Creating and editing dashboards</p> </li> <li> <p>Viewer - Viewing dashboards</p> </li> </ul> <p>For detailed information on the privileges for these roles and the different tasks that they can perform, see Grafana organization roles.</p>"},{"location":"admin/manage-users/manage_users_in_org.html","title":"\u200b\u200bManage users in an organization","text":"<p>Important</p> <p>The content for this topic is yet to be developed.</p>"},{"location":"admin/roles/index.html","title":"Standard role permissions","text":"<p>Roles are the sets of permissions and configurations that determine which metrics a user can access in Percona Monitoring and Management (PMM). Each PMM user is associated with a role that includes permissions. PMM Users then inherit permissions defined in the role which then determines the privileges that a user has in PMM.</p> <p>PMM provides two methods of access control: standard roles (Viewer, Editor, Admin) that determine feature-level permissions, and label-based access control that allows administrators to create custom roles to specify which data can be queried based on specific label criteria, for instance, allowing the QA team to view data related only to test environments.</p> <p>For more granular data access control, see Labels for access control which allows you to restrict which metrics users can query based on labels.</p>"},{"location":"admin/roles/index.html#role-types-in-pmm","title":"Role types in PMM","text":"<p>PMM inherits its basic role structure from Grafana but with customizations specific to database monitoring. PMM has three main role types:</p> <ul> <li>Admin: Has access to all resources and features within a PMM instance. This role can manage all aspects of PMM including users, teams, data sources, dashboards, and server settings.</li> <li>Editor: Can view and edit dashboards, create custom visualizations, work with alerts, and manage specific configurations. Editors cannot modify server-wide settings or manage users.</li> <li>Viewer: Has read-only access to monitoring data and dashboards. Viewers can query data but cannot make changes to configurations.</li> </ul>"},{"location":"admin/roles/index.html#default-role-assignment","title":"Default role assignment","text":"<p>When a user signs in to PMM for the first time and has no role assigned, they are automatically assigned the default role. Administrators can configure which role is used as the default through the access control settings.</p> <p>If an Admin has not configured a custom default role, PMM assigns:</p> <ul> <li>Grafana role: Viewer</li> <li>PMM access control: Full Access to all metrics</li> </ul>"},{"location":"admin/roles/index.html#dashboard-permissions","title":"Dashboard permissions","text":"<p>Dashboard creators in PMM automatically get Admin permissions for the dashboards they create. Folder permissions cascade to all dashboards within that folder.</p>"},{"location":"admin/roles/index.html#permission-matrix","title":"Permission matrix","text":"<p>Use the matrix below to check which permissions users have based on their assigned role:</p> Dashboard &amp; MonitoringAlerting &amp; AdvisorsConfiguration &amp; ManagementData sourcesAPI access Permission Viewer Editor Admin View dashboards \u2713 \u2713 \u2713 Add, edit, delete dashboards \u2717 \u2713 \u2713 Add, edit, delete folders \u2717 \u2713 \u2713 View playlists \u2713 \u2713 \u2713 Add, edit, delete playlists \u2717 \u2713 \u2713 Access Explore \u2717 \u2713 \u2713 Query data sources \u2713 \u2713 \u2713 View Query Analytics (QAN) \u2713 \u2713 \u2713 View Insights \u2713 \u2713 \u2713 Permission Viewer Editor Admin View alert rules \u2713 \u2713 \u2713 Add, edit, delete alert rules \u2717 \u2713 \u2713 View fired alerts \u2713 \u2713 \u2713 Silence alerts \u2717 \u2713 \u2713 View alert templates \u2717 \u2713 \u2713 Create alerts from templates \u2717 \u2713 \u2713 Add, edit, delete alert templates \u2717 \u2713 \u2713 View Advisor checks \u2717 \u2713 \u2713 Run, disable, edit Advisor checks \u2717 \u2717 \u2713 Run Advisor checks \u2717 \u2717 \u2713 Permission Viewer Editor Admin View inventory \u2717 \u2717 \u2713 Add, edit, delete services \u2717 \u2717 \u2713 View and run system actions \u2717 \u2717 \u2713 View server settings \u2717 \u2717 \u2713 Modify server settings \u2717 \u2717 \u2713 Add, edit, delete users \u2717 \u2717 \u2713 Add, edit, delete teams \u2717 \u2717 \u2713 View backups \u2717 \u2717 \u2713 Manage backups \u2717 \u2717 \u2713 View update status \u2717 \u2717 \u2713 Start updates \u2717 \u2717 \u2713 Permission Viewer Editor Admin View data sources \u2713 \u2713 \u2713 Add, edit, delete data sources \u2717 \u2717 \u2713 Configure data source access \u2717 \u2717 \u2713 API Path Minimum role required Purpose <code>/v1/alerting</code> Viewer Access alert information <code>/v1/advisors</code> Editor Access advisor functionality <code>/v1/advisors/checks</code> Admin Run advisor checks <code>/v1/actions/</code> Viewer View and execute actions <code>/v1/backups</code> Admin Manage backups <code>/v1/inventory/</code> Admin Manage inventory items <code>/v1/inventory/services:getTypes</code> Viewer View service types <code>/v1/management/</code> Admin Server management functions <code>/v1/management/Jobs</code> Viewer View management jobs <code>/v1/server/updates</code> Viewer Check for updates <code>/v1/server/updates:start</code> Admin Start update process <code>/v1/server/settings/readonly</code> Viewer View read-only settings <code>/v1/server/settings</code> Admin Configure server settings <code>/v1/platform:</code> Admin Platform management <code>/v1/platform/</code> Viewer Platform information <code>/v1/qan</code> Viewer Query Analytics (QAN)"},{"location":"admin/roles/access-control/assign_roles.html","title":"Assign access roles to users","text":"<p>To assign access roles to users:</p> <ol> <li>From the main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</li> <li>Go to Administration &gt; Users and access &gt; Users.</li> <li>Click on the user you want to assign roles to.</li> <li>From the Roles drop-down select the appropriate roles.</li> <li>Verify the assigned roles appear in the Access Role column.</li> </ol> <p></p>"},{"location":"admin/roles/access-control/create_roles.html","title":"Create access roles","text":"<p>Roles are essential components of PMM\u2019s access control system. They allow you to limit users\u2019 access to specific metrics based on their responsibilities and permissions.</p>"},{"location":"admin/roles/access-control/create_roles.html#before-you-begin","title":"Before you begin","text":"<ul> <li>You must have administrator privileges to create roles. For more information, see Manage users.</li> <li>Access control must be enabled in PMM settings</li> </ul>"},{"location":"admin/roles/access-control/create_roles.html#create-a-new-role","title":"Create a new role","text":"<p>To create access roles in PMM:</p> <ol> <li>From the main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access control option.</li> <li> <p>Go to Administration &gt; Users and access &gt; Access Roles.</p> <p></p> </li> <li> <p>Click Create.</p> </li> <li>On the Create role page, enter the Role name and Role description.</li> <li> <p>Configure metrics access by setting label selectors:</p> <ul> <li>select a Label (e.g., \u201cservice_name\u201d, \u201cenvironment\u201d)</li> <li>choose an Operator (e.g., \u201c=\u201d, \u201c!=\u201d, \u201c=~\u201d)</li> <li>enter the Value for the selected label</li> </ul> <p>If you want to add more than one label for a role, click + and select the values from the drop-down.</p> <p>For information on how the Prometheus selectors work, see Prometheus selectors.</p> </li> <li> <p>Review your selections, then click Create to finalize the role.</p> </li> </ol>"},{"location":"admin/roles/access-control/enable_access_control.html","title":"Enable access control","text":"<p>Access control in PMM lets you restrict user access to specific metrics and Query Analytics data based on their roles.  Choose your preferred method to enable this feature:</p> Via DockerVia Docker ComposeVia user interface <p>When deploying PMM Server with Docker, enable access control by passing an environment variable:</p> <pre><code>docker run -d \\\n  --name pmm-server \\\n  -p 443:8443 \\\n  -e PMM_ENABLE_ACCESS_CONTROL=1 \\\n  percona/pmm-server:latest\n</code></pre> <p>For Docker Compose deployments, add the environment variable to your <code>docker-compose.yml</code> file:</p> <pre><code>services:\n  pmm-server:\n    image: percona/pmm-server:latest\n    ports:\n      - \"443:8443\"\n    environment:\n      - PMM_ENABLE_ACCESS_CONTROL=1\n    volumes:\n      - pmm-data:/srv\n</code></pre> <p>To enable access control from the PMM web interface:</p> <ol> <li>Log in to PMM with an administrator account.</li> <li>From the main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings &gt; Access Control.</li> <li>Toggle the  toggle.</li> <li>Click Apply changes to save your settings.</li> </ol>"},{"location":"admin/roles/access-control/enable_access_control.html#after-enabling-access-control","title":"After enabling access control","text":"<p>Once access control is enabled:</p> <ul> <li>All existing users will have full access until you assign specific roles.</li> <li>Create access roles for different user types.</li> <li>Assign the new roles to your PMM users.</li> <li>Test that restrictions work as expected.</li> </ul>"},{"location":"admin/roles/access-control/intro.html","title":"About label based access control (LBAC) in PMM","text":"<p>Access control in PMM allows you to manage access to data. By using access control you can restrict access to monitoring metrics and Query Analytics data. </p> <p>This is particularly important in environments where sensitive data is involved, and it helps ensure that only authorized users can access specific information, which is crucial for maintaining security and compliance.</p>"},{"location":"admin/roles/access-control/intro.html#how-lbac-works","title":"How LBAC works","text":"<p>PMM uses Prometheus label selectors to control access to metrics and Query Analytics data. </p> <p>Here\u2019s how LBAC works:</p> <ol> <li>Create roles with label selectors. For example <code>environment=prod</code> for a specific environment or <code>service_type=mysql</code> for specific databases.</li> <li>Assign roles to users based on their responsibilities.</li> <li>Users see only the metrics and (Query Analytics) QAN data that match their role\u2019s label selectors.</li> </ol>"},{"location":"admin/roles/access-control/intro.html#key-benefits","title":"Key benefits","text":"<ul> <li>Granular permissions: Restrict access to specific services, environments, or regions.</li> <li>Enhanced security: Prevent unauthorized access to sensitive database metrics and query data.</li> <li>Compliance support: Meet regulatory requirements for data access control.</li> <li>Team-specific views: Allow teams to focus only on their relevant systems and queries.</li> <li>Simplified management: Manage access through roles instead of individual user permissions.</li> </ul>"},{"location":"admin/roles/access-control/intro.html#example-scenarios","title":"Example scenarios","text":"User type Possible role configuration What they can see DBA team lead All services across environments Complete monitoring data for all databases and queries MySQL administrators <code>service_type=mysql</code> Only MySQL-related metrics and queries Production support <code>environment=production</code> Only production environment metrics and queries Regional team <code>region=us-east</code> Only metrics and queries from a specific region"},{"location":"admin/roles/access-control/intro.html#getting-started-with-lbac","title":"Getting started with LBAC","text":"<p>To implement label-based access control in PMM:</p> <ol> <li>Enable access control in your PMM settings</li> <li>Learn about the labels available for filtering</li> <li>Create access roles based on your organizational needs</li> <li>Review common use cases and examples for inspiration</li> </ol> <p>Best practice</p> <p>Start with broader access controls and refine them over time as you understand your organization\u2019s specific needs. Test LBAC behavior in both dashboards and QAN to ensure proper access control.</p>"},{"location":"admin/roles/access-control/intro.html#related-topics","title":"Related topics","text":"<ul> <li>Manage PMM users</li> </ul>"},{"location":"admin/roles/access-control/labels.html","title":"Labels for access control","text":"<p>Label-based access control in PMM allows you to precisely manage which monitoring data users can access based on their roles and responsibilities. </p> <p>This feature is essential for organizations with multiple teams, compliance requirements, or where different users need different levels of visibility.</p>"},{"location":"admin/roles/access-control/labels.html#how-lbac-works","title":"How LBAC works","text":"<p>Access control in PMM uses Prometheus label selectors to filter metrics and Query Analytics data.</p> <p>Here\u2019s how it works: </p> <ol> <li>Create roles with specific label selectors. For example, you might allow the QA team to access only metrics related to test environments by assigning them a role with the <code>environment=test</code> label or limit visibility to metrics related only to MySQL services with the <code>service_type=mysql</code> label.</li> <li>Assign roles to users based on their responsibilities. Each role can include multiple labels, and only data series matching all associated labels will be visible to users with that role. This ensures precise, fine-grained access control to your data.</li> <li>Users see only the metrics and data that match their role\u2019s label selectors</li> </ol>"},{"location":"admin/roles/access-control/labels.html#standard-vs-custom-labels","title":"Standard vs custom labels","text":"<p>PMM supports two types of labels for access control. When a user adds a service to monitoring, PMM automatically assigns standard labels based on the service type, such as <code>service_type</code>, <code>agent_type</code>, and <code>node_name</code>. Additional labels like <code>service_id</code> and <code>node_id</code> are also auto-generated by PMM.</p> <p>You can override some standard labels when creating objects such as Nodes, Services, or Agents. You can also define and assign custom labels. Unlike standard labels, custom labels are user-defined and can only be added or updated manually.</p> <p>Both standard and custom labels are propagated to the relevant metrics collected by the PMM Client. These labels are preserved during metric collection and can be used in PromQL queries.</p> <p>Examples</p> Label Type Object Label name Example Standard Node node_id 5bdfb1b4-c6c4-4086-83a2-e8daa0b84d4b Standard Service service_type mysql, mongodb, postgresql etc. Custom Node, Service, Agent Any string matching the regular expression:  [a-zA-Z_][a-zA-Z0-9_]*.  Also, it cannot start with two underscores. owner=\u201djoe\u201d _rack=\u201d12345\u201d"},{"location":"admin/roles/access-control/labels.html#adding-labels-when-creating-services","title":"Adding labels when creating services","text":"<p>You can add standard or custom labels while adding a service to monitoring in PMM.</p> Using the PMM UIUsing pmm-admin <p>To set the labels via the user interface:</p> <ol> <li> <p>From the Main menu, go to PMM Configuration &gt; PMM Services &gt; Add Service.</p> </li> <li> <p>Select the service you want to monitor.</p> </li> <li> <p>Complete the required connection details. </p> </li> <li> <p>Enter standard labels via the input section <code>Labels</code>.</p> </li> <li> <p>Enter custom labels via section <code>Custom labels</code>.</p> </li> </ol> <p></p> <p>You can also add standard and custom labels using pmm-admin.</p>"},{"location":"admin/roles/access-control/labels.html#modifying-existing-labels","title":"Modifying existing labels","text":"<p>PMM allows modifying certain standard labels after a service is created:</p> <ul> <li><code>environment</code></li> <li><code>cluster</code></li> <li><code>replication_set</code></li> <li><code>external_group</code></li> </ul> <p>For other standard labels that cannot be modified directly, you must remove the service and re-add it with the desired labels.</p> <p>This can be done either via PMM UI or via an API endpoint.</p> <p>Modifying the custom labels can be done as well via PMM UI of via the same API endpoint.</p>"},{"location":"admin/roles/access-control/manage_roles.html","title":"Manage access roles","text":"<p>You can manage roles in PMM by editing or deleting a role.</p>"},{"location":"admin/roles/access-control/manage_roles.html#edit-roles","title":"Edit roles","text":"<p>To edit access roles:</p> <ol> <li> <p>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</p> </li> <li> <p>Go to Administration &gt; Users and access &gt; Access Roles.</p> </li> <li> <p>On the role you want to edit, click the ellipsis (three vertical dots) &gt; edit role in the Options column. The Edit role page opens.</p> <p></p> </li> <li> <p>Make the required changes to the role.</p> </li> <li> <p>Click Save Changes.</p> </li> </ol>"},{"location":"admin/roles/access-control/manage_roles.html#set-a-role-as-default","title":"Set a role as default","text":"<p>When a user signs in to PMM for the first time and the user has no role assigned, the user is automatically assigned the Default role. For administrators, the default role provides a convenient way to configure default permissions for new users.</p> <p>To set a role as default, do the following:</p> <ol> <li> <p>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</p> </li> <li> <p>Go to Administration &gt; Users and access &gt; Access Roles.</p> </li> <li> <p>On the role you want to set as default, click the ellipsis (three vertical dots) \u2192 set as default in the Options column.</p> </li> </ol>"},{"location":"admin/roles/access-control/manage_roles.html#remove-roles","title":"Remove roles","text":"<p>To remove access roles, do the following:</p> <ol> <li> <p>From main menu, go to PMM Configuration &gt; Settings &gt; Advanced Settings and enable the Access Roles option.</p> </li> <li> <p>On the role you want to remove, click the ellipsis (three vertical dots) &gt; Delete in the Options column. Delete role pop-up opens.</p> </li> <li> <p>Click Confirm and delete the role.</p> </li> </ol>"},{"location":"admin/roles/access-control/use_cases.html","title":"Implementing LBAC: practical scenarios","text":"<p>Here are a few practical examples of how label-based access control can be implemented in PMM to meet specific organizational needs.</p>"},{"location":"admin/roles/access-control/use_cases.html#infrastructure-overview","title":"Infrastructure overview","text":"<p>The diagram below shows a sample infrastructure monitored by PMM. Notice how the metrics stored in VictoriaMetrics include labels like environment and region that can be used for access control.</p> <p></p>"},{"location":"admin/roles/access-control/use_cases.html#use-case-1-simple-selectors","title":"Use case 1: Simple selectors","text":"<p>This scenario demonstrates how to create three distinct roles with different levels of access:</p> <p></p> Role Access needs Label selectors Effect Admin Complete visibility across all environments <code>environment=prod</code> OR <code>environment=qa</code> Full access to all metrics in both production and QA environments across all regions DBA Production database management <code>environment=prod</code> Access to all production metrics across all regions, but no visibility into QA QA Testing environment monitoring <code>environment=qa</code> Access to all QA metrics across all regions, but no visibility into production <p>This approach allows for a clear separation of responsibilities while ensuring each team has access to exactly what they need.</p>"},{"location":"admin/roles/access-control/use_cases.html#use-case-2-compound-selectors","title":"Use case 2 - Compound selectors","text":"<p>This advanced use case demonstrates how compound selectors create more granular access control by combining multiple label conditions using logical operators (AND, OR). </p> <p>By requiring matches on multiple labels simultaneously, you can implement sophisticated access patterns that reflect real-world organizational structures and security requirements.</p> <p></p> Role Access needs Label selectors Effect Admin Complete visibility across all environments and regions <code>environment=prod</code> OR <code>environment=qa</code> Full access to all metrics in both production and QA environments across all regions DBA Production database management in EMEA region <code>environment=prod</code> AND <code>region=emea</code> Access only to production metrics in the EMEA region QA Testing environment monitoring in US-East region <code>environment=qa</code> AND <code>region=us-east</code> Access only to QA metrics in the US-East region"},{"location":"admin/security/index.html","title":"About security in PMM","text":"<p>By default, PMM ships with a self-signed certificate to enable usage out of the box.  While this does enable users to have encrypted connections between clients (database clients and web/API clients) and the PMM Server, it shouldn\u2019t be considered a properly secured connection.  </p> <p>Taking the following precautions will ensure that you are truly secure:</p> <ul> <li> <p>SSL encryption with trusted certificates to secure traffic between clients and server;</p> </li> <li> <p>Grafana HTTPS secure cookies</p> </li> </ul>"},{"location":"admin/security/data_encryption.html","title":"PMM data encryption","text":"<p>Percona Monitoring and Management (PMM) implements robust encryption for sensitive data stored in its internal database\u2019s <code>agent</code> table. This includes access credentials and configuration details.</p>"},{"location":"admin/security/data_encryption.html#default-encryption","title":"Default encryption","text":"<p>PMM automatically manages encryption using a key file located at <code>/srv/pmm-encryption.key</code>. PMM generates this file upon the initial launch of PMM 3 or when upgrading from the latest version of PMM 2.</p>"},{"location":"admin/security/data_encryption.html#custom-encryption-key-configuration","title":"Custom encryption key configuration","text":"<p>For enhanced security control, PMM supports custom encryption keys.</p> <p>To set up a custom keys, configure the <code>PMM_ENCRYPTION_KEY_PATH</code> environment variable to point to your custom key file.</p> <p>Important</p> <p>Make sure to set this configuration  before any data encryption occurs\u2014specifically, either before upgrading to PMM 3 or before the initial startup of a new PMM 3.x container.</p>"},{"location":"admin/security/data_encryption.html#key-management-requirements","title":"Key management requirements","text":"<p>Once configured, PMM will use custom keys to encrypt and decrypt all sensitive data stored within the system.</p> <p>If the custom key is unavailable or misplaced, PMM will be unable to access and decrypt the stored data, which will prevent it from running correctly.</p> <p>Make sure to store and manage the custom encryption key securely to avoid potential loss of data access.</p>"},{"location":"admin/security/data_encryption.html#rotating-the-encryption-key","title":"Rotating the encryption key","text":"<p>You may want to change or update the encryption key when the original key is compromised or as part of routine security maintenance. For this, you can use the PMM Encryption Rotation Tool.</p> <p>This tool re-encrypts all existing sensitive data with a newly generated encryption key, ensuring continuous security with minimal disruption.</p> <p>To rotate or regenerate the encryption key:</p> <ol> <li> <p>Log in to the container that runs PMM Server.</p> </li> <li> <p>Run the Encryption Rotation Tool using the following the command:</p> <p><code>bash    pmm-encryption-rotation</code></p> <ul> <li>Ensure <code>PMM_ENCRYPTION_KEY_PATH</code> is set to the current custom key if using one, so the tool can decrypt data before re-encryption.</li> <li>If using custom credentials/SSL for the PMM internal database, provide them with the appropriate flags.</li> </ul> </li> <li> <p>Verify PMM functionality all components are functioning properly to ensure that the encryption key rotation was successful.</p> </li> </ol> <p>Once the rotation tool has completed, a new encryption key will be generated and saved either in the default location (<code>/srv/pmm-encryption.key</code>) or in the path specified by <code>PMM_ENCRYPTION_KEY_PATH</code>. The tool will automatically re-encrypt all sensitive data with the new key.</p>"},{"location":"admin/security/data_encryption.html#best-pracices-for-custom-key-management","title":"Best pracices for custom key management","text":"<ul> <li>Always keep a secure backup of your encryption key, especially when using <code>PMM_ENCRYPTION_KEY_PATH</code>, as it is critical to PMM\u2019s data decryption process.</li> <li>In containerized environments, ensure <code>PMM_ENCRYPTION_KEY_PATH</code> is persistently set in the container configuration to avoid issues during restarts.</li> <li>Test the encryption key rotation process in a staging environment before applying it in production to minimize potential downtime or configuration issues.</li> </ul>"},{"location":"admin/security/grafana_cookies.html","title":"Grafana HTTPS secure cookies","text":"<p>To enable:</p> <ol> <li> <p>Start a shell within the Docker container.</p> <pre><code>docker exec -it pmm-server bash\n</code></pre> </li> <li> <p>Edit <code>/etc/grafana/grafana.ini</code>.</p> </li> <li> <p>Enable <code>cookie_secure</code> and set the value to <code>true</code>.</p> </li> <li> <p>Restart Grafana.</p> <pre><code>supervisorctl restart grafana\n</code></pre> </li> </ol>"},{"location":"admin/security/ssl_encryption.html","title":"SSL encryption","text":"<p>Securing your PMM deployment with SSL/TLS encryption protects sensitive database metrics and authentication credentials in transit. This guide walks you through configuring SSL certificates for both PMM Server and PMM Clients.</p> <p>You have several certificate options:</p> <ul> <li>Commercial certificates from public CAs (automatically trusted by all systems)</li> <li>Internal CA certificates from your organization\u2019s certificate authority  </li> <li>Self-signed certificates for testing and development environments</li> </ul>"},{"location":"admin/security/ssl_encryption.html#configure-ssl-encryption","title":"Configure SSL encryption","text":"<p>Configure both the Server and Client to implement SSL/TLS encryption in your PMM environment. The Server needs proper certificates installed, while Clients must be able to verify those certificates:</p> <ol> <li>Prepare your certificates: Choose one method to provide certificates to PMM Server:<ul> <li>Mount certificates from a local directory on the host</li> <li>Copy certificates directly into the PMM Server container</li> </ul> </li> <li>Restart PMM Server to apply the new certificates</li> <li>Configure client trust: Ensure PMM Clients can verify the server certificate:<ul> <li>Add the CA certificate to the system trust store (Ubuntu guide | Red Hat guide)</li> <li>Or use the <code>SSL_CERT_FILE</code> environment variable for custom CA certificates</li> </ul> </li> </ol>"},{"location":"admin/security/ssl_encryption.html#certificate-storage-location","title":"Certificate storage location","text":"<p>With Docker, OVF, and AMI deployments, certificates are stored in <code>/srv/nginx</code> where self-signed certificates are placed by default.</p>"},{"location":"admin/security/ssl_encryption.html#configure-server-side-certificates","title":"Configure server-side certificates","text":""},{"location":"admin/security/ssl_encryption.html#required-certificate-files","title":"Required certificate files","text":"<p>PMM Server requires these certificate files in <code>/srv/nginx</code>:</p> File Description <code>certificate.crt</code> Server certificate (may include intermediate certificates) <code>certificate.key</code> Private key for the server certificate <code>ca-certs.pem</code> Certificate Authority bundle <code>dhparam.pem</code> Diffie-Hellman parameters for enhanced security"},{"location":"admin/security/ssl_encryption.html#mount-certificates","title":"Mount certificates","text":"<p>For container-based installation, mount your certificate directory to <code>/srv/nginx</code>:</p> <pre><code>docker run -d -p 443:8443 --volumes-from pmm-data \\\n  --name pmm-server -v /etc/pmm-certs:/srv/nginx \\\n  --restart always percona/pmm-server:3\n</code></pre> <p>Certificate requirements</p> <p>Before mounting certificates, make sure to configure them correctly:</p> <ul> <li>All certificates must be owned by root: <code>chown 0:0 /etc/pmm-certs/*</code></li> <li>Set proper permissions: <code>chmod 644 /etc/pmm-certs/*.crt /etc/pmm-certs/*.pem &amp;&amp; chmod 600 /etc/pmm-certs/*.key</code></li> <li>The certificate directory must contain all four required files</li> <li>Use port <code>443</code> for SSL encryption instead of port <code>80</code></li> </ul>"},{"location":"admin/security/ssl_encryption.html#copy-certificates","title":"Copy certificates","text":"<p>If PMM Server is already running, copy certificates directly into the container:</p> <pre><code># Copy certificate files\ndocker cp certificate.crt pmm-server:/srv/nginx/certificate.crt\ndocker cp certificate.key pmm-server:/srv/nginx/certificate.key\ndocker cp ca-certs.pem pmm-server:/srv/nginx/ca-certs.pem\ndocker cp dhparam.pem pmm-server:/srv/nginx/dhparam.pem\n\n# Set proper ownership and permissions\ndocker exec -it pmm-server chown root:root /srv/nginx/*\ndocker exec -it pmm-server chmod 644 /srv/nginx/*.crt /srv/nginx/*.pem\ndocker exec -it pmm-server chmod 600 /srv/nginx/*.key\n</code></pre>"},{"location":"admin/security/ssl_encryption.html#apply-certificate-changes","title":"Apply certificate changes","text":"<p>Restart PMM Server to load the new certificates:</p> <pre><code># Full container restart (recommended)\ndocker restart pmm-server\n\n# Or restart only nginx (advanced users)\ndocker exec -it pmm-server supervisorctl restart nginx\n</code></pre> <p>Verify the certificates are working: <pre><code>curl -I https://&lt;server-hostname&gt;:443\n</code></pre></p>"},{"location":"admin/security/ssl_encryption.html#client-side-certificate-configuration","title":"Client-side certificate configuration","text":"Basic client connectionSystem-wide certificate trust <p>Register PMM Clients using the HTTPS URL:</p> <pre><code>pmm-admin config --server-url=https://&lt;user&gt;:&lt;password&gt;@&lt;server-hostname&gt;\n</code></pre> <p>For successful connection</p> <ul> <li>Use the server\u2019s hostname (not IP address) to match the certificate</li> <li>Ensure that client system time is synchronized</li> <li>Test the connection: <code>curl -I https://&lt;server-hostname&gt;</code></li> </ul> <p>For production environments, install CA certificates in the system trust store:</p> Ubuntu/DebianRed Hat/CentOS/Fedora <pre><code># Install CA certificate\nsudo cp custom-ca.pem /usr/local/share/ca-certificates/custom-ca.crt\nsudo update-ca-certificates\n\n# Verify installation\nsudo update-ca-certificates --verbose\n</code></pre> <pre><code># Install CA certificate  \nsudo cp custom-ca.pem /etc/pki/ca-trust/source/anchors/custom-ca.pem\nsudo update-ca-trust\n\n# Verify installation\nsudo update-ca-trust check\n</code></pre>"},{"location":"admin/security/ssl_encryption.html#use-custom-ca-certificates-with-pmm-client","title":"Use custom CA certificates with PMM Client","text":"<p>The <code>SSL_CERT_FILE</code> environment variable specifies the path to a custom certificate chain file that pmm-agent uses for all SSL/TLS connections. This approach is ideal when:</p> <ul> <li>PMM Server uses certificates signed by an internal/custom certificate authority</li> <li>You want to avoid modifying system-wide certificate settings  </li> <li>Running in containerized or restricted environments</li> <li>Testing with different CA configurations</li> </ul>"},{"location":"admin/security/ssl_encryption.html#set-ssl_cert_file-for-pmm-admin-commands","title":"Set SSL_CERT_FILE for pmm-admin commands","text":"<p>Export the <code>SSL_CERT_FILE</code> environment variable before running <code>pmm-admin</code> commands:</p> <pre><code>export SSL_CERT_FILE=/path/to/custom-ca-bundle.pem\npmm-admin config --server-url=https://&lt;user&gt;:&lt;password&gt;@&lt;server-hostname&gt;\n</code></pre> <p>Testing first</p> <p>Before configuring pmm-admin, test the connection with curl: <code>curl -v https://&lt;server-hostname&gt;/ping</code></p>"},{"location":"admin/security/ssl_encryption.html#persistent-configuration","title":"Persistent configuration","text":"Shell profileSystemd serviceDocker container <p>Add to your shell profile (.bashrc, .zshrc, etc.): <pre><code>export SSL_CERT_FILE=/etc/ssl/certs/custom-ca-bundle.pem\n</code></pre> Then reload: <code>source ~/.bashrc</code></p> <p>For pmm-agent running as a systemd service: <pre><code>[Unit]\nDescription=PMM Agent\nAfter=network.target\n\n[Service]\nType=simple\nUser=pmm-agent\nEnvironment=\"SSL_CERT_FILE=/etc/ssl/certs/custom-ca-bundle.pem\"\nExecStart=/usr/local/bin/pmm-agent --config-file=/etc/pmm-agent.yaml\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>When running pmm-client in a container: <pre><code>docker run \\\n    --rm --name pmm-client \\\n    -e PMM_AGENT_SERVER_ADDRESS=&lt;server-hostname&gt;:443 \\\n    -e PMM_AGENT_SERVER_USERNAME=admin \\\n    -e PMM_AGENT_SERVER_PASSWORD=admin \\\n    -e PMM_AGENT_SETUP=1 \\\n    -e SSL_CERT_FILE=/etc/ssl/certs/custom-ca-bundle.pem \\\n    -v /path/to/ca-bundle.pem:/etc/ssl/certs/custom-ca-bundle.pem:ro \\\n    percona/pmm-client:3\n</code></pre></p>"},{"location":"admin/security/ssl_encryption.html#create-ca-bundle-files","title":"Create CA bundle files","text":"<p>File permissions</p> <p>Ensure the CA bundle file is readable by the user running pmm-agent.</p> <p>The CA bundle file should contain one or more PEM-encoded certificate authority certificates:</p> <pre><code># Single CA certificate\ncp /path/to/your-ca.pem /etc/ssl/certs/custom-ca-bundle.pem\n\n# Multiple CA certificates\ncat /path/to/root-ca.pem \\\n    /path/to/intermediate-ca.pem &gt; /etc/ssl/certs/custom-ca-bundle.pem\n\n# Include system CAs plus custom CAs\ncat /etc/ssl/certs/ca-certificates.crt \\\n    /path/to/your-custom-ca.pem &gt; /etc/ssl/certs/custom-ca-bundle.pem\n\n# Set proper file permissions\nchmod 644 /etc/ssl/certs/custom-ca-bundle.pem\n</code></pre>"},{"location":"admin/security/ssl_encryption.html#verify-ca-bundle","title":"Verify CA bundle","text":"<p>To test your SSL configuration:</p> <pre><code># Test certificate validation\nexport SSL_CERT_FILE=/etc/ssl/certs/custom-ca-bundle.pem\nopenssl s_client -connect &lt;server-hostname&gt;:443 -CAfile /etc/ssl/certs/custom-ca-bundle.pem -verify_return_error\n\n# Test HTTP connection\ncurl -v https://&lt;server-hostname&gt;/ping\n\n# Test pmm-admin connection\npmm-admin status\n</code></pre>"},{"location":"advisors/advisor-details.html","title":"Advisor details","text":""},{"location":"advisors/advisor-details.html#list-of-database-advisors","title":"List of database Advisors","text":"<p>Percona Monitoring and Management (PMM) offers four categories of database Advisors to help you improve database performance: Configuration, Performance, Query and Security Advisors.</p> <p>Each Advisor includes a set of automated checks, which investigate a specific range of possible issues and areas of improvement: security threats, non-compliance issues, performance degradation, query and index optimization strategies etc.</p> <p>This page presents the complete list of database Advisors along with the corresponding subscription tier for which they are available.</p> <p>You can also access this list through the Advisor checks for PMM section in the Percona Portal documentation, as the Advisors are hosted on the Percona Platform. PMM Server automatically downloads them from this source when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both options are enabled by default.</p>"},{"location":"advisors/advisor-details.html#configuration-advisors","title":"Configuration Advisors","text":"Advisor Name Description Subscription Database Technology Version Configuration Notifies of newly released database versions to streamline database maintenance and ensure the most up-to-date performance. All Users MySQL, MongoDB, PostgreSQL Generic Configuration Provides basic recommendations for improving your database configuration. All Users MySQL, MongoDB, PostgreSQL Resources Configuration Watches your database and gives you recommendations for efficient management of resources like binaries architecture, CPU number versus DB Configuration, etc. All Users MySQL, MongoDB Connection Configuration Provides recommendations on configuring database connection parameters for improving database performance. Customers only MySQL, MongoDB, PostgreSQL Replication Configuration Provides recommendations for scalable replication in database clusters. Customers only MySQL, MongoDB InnoDB Configuration Advises on configuring InnoDB optimization for high performance. Customers only MySQL Vacuum Configuration Provides recommendations on optimizing Vacuum operations. Customers only PostgreSQL"},{"location":"advisors/advisor-details.html#performance-advisors","title":"Performance Advisors","text":"Advisor Name Description Subscription Database Technology Generic Performance Provides basic database configuration recommendations for high-performance query execution. All Users MongoDB, PostgreSQL Vacuum Performance Helps improve the efficiency and execution speed of database Vacuum commands. Customers only PostgreSQL Replication Performance Checks efficient replication usage of your database. Customers only MongoDB, PostgreSQL"},{"location":"advisors/advisor-details.html#security-advisors","title":"Security Advisors","text":"Advisor Name Description Subscription Database Technology CVE Security Informs you of any database versions affected by CVE. All Users MongoDB, PostgreSQL Configuration Security Checks your database configuration to ensure that security best practices are correctly implemented. All Users MySQL, MongoDB, PostgreSQL Authentication Security Ensures that all database authentication parameters are configured securely. Customers only MySQL, MongoDB, PostgreSQL Replication Security Helps safeguard data replication by assessing security risks and providing recommendations for improving protection. Customers only MySQL Connection Security Helps identify security issues on network connections and provides recommendations for enhancing security. Customers only MySQL, MongoDB"},{"location":"advisors/advisor-details.html#query-advisors","title":"Query Advisors","text":"Advisor Name Description Subscription Database Technology Index Query Provides query and index optimization strategies for peak database performance. Customers only MySQL, MongoDB, PostgreSQL Schema Design Query Helps create efficient database schemas by analyzing queries and offering suggestions for optimization. All Users MySQL"},{"location":"advisors/advisor-details.html#list-of-checks","title":"List of checks","text":"<p>Every Advisor consists of one or more Advisor checks.  We have listed the checks and their details here.</p>"},{"location":"advisors/advisor-details.html#mongodb","title":"MongoDB","text":"Advisor Check Name Description Summary Connection Configuration mongodb_connection_sudden_spike Warns about any significant increase in the number of connections exceeding 50% of the recent or typical connection count. MongoDB Sudden Increase in Connection Count Connection Configuration mongodb_connections Returns the current number of connections as an informational notice when connection counts exceed 5000. MongoDB High Connections Generic Configuration mongo_cache_size Warns when Mongo wiredtiger cache size is greater than the default 50%. Mongo Storage Cache Generic Configuration mongodb_active_vs_available_connections Warns if the ratio between active and available connections is higher than 75%. MongoDB Active vs Available Connections Generic Configuration mongodb_journal Warns if the journal is disabled. MongoDB Journal Generic Configuration mongodb_loglevel Warns if MongoDB is not using the default Log level. MongoDB Non-Default Log Level Generic Configuration mongodb_read_tickets Warns if MongoDB is using more than 128 read tickets. MongoDB Read Tickets Generic Configuration mongodb_write_tickets Warns if MongoDB is using more than 128 write tickets. MongoDB Write Tickets Generic Configuration mongodb_write_tickets_runtime Warns if MongoDB is using more than 128 write tickets during runtime. MongoDB - Configuration Write Ticket Check Replication Configuration mongodb_psa_architecture_check Raises an error if the replicaSet is utilizing a PSA (Primary-Secondary-Arbiter) architecture. MongoDB PSA Architecture Replication Configuration mongodb_replicaset_topology Warns if the Replica Set has less than three data-bearing nodes. MongoDB Replica Set Topology Resources Configuration mongodb_collection_fragmented Warns if the storage size exceeds the data size of a collection, indicating potential fragmentation. This suggests the need for compaction or an initial sync to reclaim disk space. MongoDB Collections Fragmented Resources Configuration mongodb_cpucores Warns if the number of CPU cores does not meet the minimum recommended requirements according to best practices. MongoDB CPU Cores Resources Configuration mongodb_dbpath_mount Warns if dbpath does not have a dedicated mount point. MongoDB - Separate Mount Point Other Than \u201c/\u201d Partition for dbpath. Resources Configuration mongodb_fcv_check Warns if there is a mismatch between the MongoDB version and the internal FCV (Feature Compatibility Version) parameter setting. MongoDB - FCV Mismatch Resources Configuration mongodb_maxsessions Warns if MongoDB is configured with a maxSessions value other than the default value of 1000000. MongoDB maxSessions Resources Configuration mongodb_swap_allocation Warns if there is no swap memory allocated to your instance. MongoDB - Allocate Swap Memory Resources Configuration mongodb_taskexecutor Warns if the count of MongoDB TaskExecutorPoolSize exceeds the number of available CPU cores. MongoDB TaskExecutorPoolSize High Resources Configuration mongodb_xfs_ftype Warns if dbpath is not using the XFS filesystem type. MongoDB - XFS Version Configuration mongodb_EOL Raises an error or a warning if your current PSMDB or MongoDB version has reached or is nearing its End-of-Life (EOL) status. MongoDB Version EOL Version Configuration mongodb_unsupported_version Raises an error if your current PSMDB or MongoDB version is not supported. MongoDB Unsupported Version Version Configuration mongodb_version Provides information on current MongoDB or Percona Server for MongoDB versions used in your environment. It also offers details on other available minor or major versions that you may consider for upgrades. MongoDB Version Check Generic Performance mongodb_multiple_services Warns if multiple mongod services are detected running on a single node. MongoDB - Multiple mongod Services Replication Performance mongodb_chunk_imbalance Warns if the distribution of chunks across shards is imbalanced. MongoDB Sharding - Chunk Imbalance Across Shards Replication Performance mongodb_oplog_size_recommendation Warns if the oplog window is below a 24-hour period and provides a recommended oplog size based on your instance. MongoDB - Oplog Recovery Window is Low Replication Performance mongodb_replication_lag Warns if the replica set member lags behind the primary by more than 10 seconds. MongoDB Replication Lag Index Query mongodb_shard_collection_inconsistent_indexes Warns if there are inconsistent indexes across shards for sharded collections. Missing or inconsistent indexes across shards can have a negative impact on performance. MongoDB Sharding - Inconsistent Indexes Across Shards Index Query mongodb_unused_index Warns if there are unused indexes on any database collection in your instance. This requires enabling the \u201cindexStats\u201d collector. MongoDB - Unused Indexes Authentication Security mongodb_auth Warns if MongoDB authentication is disabled. MongoDB Authentication Authentication Security mongodb_localhost_auth_bypass Warns if MongoDB localhost bypass is enabled. MongoDB localhost authentication bypass enabled Configuration Security mongodb_authmech_scramsha256 Warns if MongoDB is not using the default SHA-256 hashing function as its SCRAM authentication method. MongoDB Security AuthMech Check Connection Security mongodb_bindip Warns if the MongoDB network binding is not set as Recommended. MonogDB IP Bindings CVE Security mongodb_cve_version Shows an error if MongoDB or Percona Server for MongoDB version is older than the latest version containing CVE (Common Vulnerabilities and Exposures) fixes. MongoDB CVE Version"},{"location":"advisors/advisor-details.html#mysql","title":"MySQL","text":"Advisor Check Name Description Summary Connection Configuration mysql_configuration_max_connections_usage Checks the MySQL max_connections configuration option to ensure maximum utilization is achieved. Check Max Connections Usage Generic Configuration mysql_automatic_sp_privileges_enabled Checks if the automatic_sp_privileges configuration is ON. Checks if automatic_sp_privileges configuration is ON. Generic Configuration mysql_config_binlog_retention_period Checks whether binlogs are being rotated too frequently, which is not recommended, except in very specific cases. Binlogs Retention Check Generic Configuration mysql_config_binlog_row_image Advises when to set binlog_row_image=FULL. Binlogs Raw Image is Not Set to FULL Generic Configuration mysql_config_binlogs_checksummed Advises when to set binlog_checksum=CRC32 to improve consistency and reliability. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_general_log Checks whether the general log is enabled. General Log is Enabled Generic Configuration mysql_config_log_bin Checks whether the binlog is enabled or disabled. Binary Log is disabled Generic Configuration mysql_config_sql_mode Checks whether the server has specific values configured in sql_mode to ensure maximum data integrity. Server is Not Configured to Enforce Data Integrity Generic Configuration mysql_config_tmp_table_size_limit Checks whether the size of temporary tables exceeds the size of heap tables. Temp Table Size is Larger Than Heap Table Size Generic Configuration mysql_configuration_log_verbosity Checks whether warnings are being printed on the log. Check Log Verbosity Generic Configuration mysql_test_database Notifies if there are database named \u2018test\u2019 or \u2018test_%\u2019. MySQL Test Database Generic Configuration mysql_timezone Verifies whether the time zone is correctly loaded. MySQL configuration check InnoDB Configuration innodb_redo_logs_not_sized_correctly Reviews the InnoDB redo log size and provides suggestions if it is configured too low. InnoDB Redo Log Size is Not Configured Correctly. InnoDB Configuration mysql_ahi_efficiency_performance_basic_check Checks the efficiency and effectiveness of InnoDB\u2019s Adaptive Hash Index (AHI). InnoDB Adaptive Hash Index (AHI) Efficiency InnoDB Configuration mysql_config_innodb_redolog_disabled Warns when the MySQL InnoDB Redo log is set to OFF, which poses a significant security risk and compromises data integrity. The MySQL InnoDB Redo log is a crucial component for maintaining the ACID (Atomicity, Consistency, Isolation, Durability) properties in MySQL databases. Redo Log is Disabled in This Instance InnoDB Configuration mysql_configuration_innodb_file_format Verifies whether InnoDB is configured with the recommended file format. MySQL InnoDB File Format InnoDB Configuration mysql_configuration_innodb_file_maxlimit Checks whether InnoDB is configured with the recommended auto-extend settings. InnoDB Tablespace Size Has a Maximum Limit. InnoDB Configuration mysql_configuration_innodb_file_per_table_not_enabled Warns when innodb_file_per_table is not enabled. innodb_file_per_table Not Enabled InnoDB Configuration mysql_configuration_innodb_flush_method Checks whether InnoDB is configured with the recommended flush method. MySQL InnoDB Flush Method InnoDB Configuration mysql_configuration_innodb_strict_mode Warns about password lifetime. InnoDB strict mode Replication Configuration mysql_config_relay_log_purge Identifies whether a replica node has relay-logs purge set. Automatic Relay Log Purging is OFF Replication Configuration mysql_config_replication_bp1 Identifies whether a replica node is in read-only mode and if checksum is enabled. Checks Basic Best Practices When Setting Replica Node. Replication Configuration mysql_config_slave_parallel_workers Identifies whether replication is single-threaded. Replication is Single-Threaded Replication Configuration mysql_config_sync_binlog Checks whether the binlog is synchronized before a transaction is committed. Sync Binlog Disabled Replication Configuration mysql_log_replica_updates Checks if a replica is safely logging replicated transactions. MySQL Configuration Check Replication Configuration replica_running_skipping_errors_or_idempotent_mode Reviews replication status to check if it is configured to skip errors or if the slave_exec_mode is set to be idempotent. Replica is skipping errors or slave_exec_mode is Idempotent. Resources Configuration mysql_32binary_on_64system Notifies if version_compile_machine equals i686. Check if Binaries are 32 Bits Version Configuration mysql_unsupported_version_check Warns against an unsupported Mysql version. Checks Mysql Version Version Configuration mysql_version Warns if MySQL, Percona Server for MySQL, or MariaDB version is not the latest available one. MySQL Version Version Configuration mysql_version_eol_57 Checks if the server version is EOL. End Of Life Server Version (5.7). Index Query mysql_performance_temp_ondisk_table_high Warns if there are too many on-disk temporary tables being created due to unoptimized query execution. Too Many on Disk Temporary Tables Index Query mysql_tables_without_pk Checks tables without primary keys. MySQL check for a table without Primary Key Schema Design Query mysql_indexes_larger Check all the tables to see if any have indexes larger than data. This indicates a sub-optimal schema and should be reviewed. Tables With Index Sizes Larger Than Data Authentication Security mysql_automatic_expired_password Warns if the MySQL parameter for automatic password expiry is not active. MySQL Automatic User Expired Password Authentication Security mysql_security_anonymous_user Verifies if anonymous users are present, as this would contradict security best practices. Anonymous User (You Must Remove Any Anonymous User) Authentication Security mysql_security_open_to_world_host Checks whether host definitions are set as \u2018%\u2019 since this is overly permissive and could pose security risks. UserS Have Host Definition \u2018%\u2019 Which is Too Open Authentication Security mysql_security_root_not_local Checks whether the root user has a host definition that is not set to 127.0.0.1 or localhost. Root User Can Connect From Non-local Location Authentication Security mysql_security_user_ssl Reports users who are not using a secure SSL protocol to connect. Users Not Using Secure SSL Authentication Security mysql_security_user_super_not_local Reports users with super privileges who are not connecting from the local host or the host is not fully restricted (e.g., 192.168.%). Users have Super privileges With Remote and Too Open Access Authentication Security mysql_security_user_without_password Reports users without passwords. Users Without Password Configuration Security mysql_config_local_infile Checks if the \u201cLOAD DATA INFILE\u201d functionality is active. Load Data in File Active Configuration Security mysql_configuration_secure_file_priv_empty Warns when  secure_file_priv is empty as this enables users with FILE privilege to create files at any location where MySQL server has Write permission. secure_file_priv is Empty Configuration Security mysql_password_expiry Checks if MySQL user passwords are expired or expiring within the next 30 days. Check MySQL User Password Expiry Configuration Security mysql_require_secure_transport Checks the status of mysql_secure_transport_only. MySQL configuration check Configuration Security mysql_security_password_lifetime Warns about password lifetime. InnoDB Password Lifetime Configuration Security mysql_security_password_policy Checks for password policy. MySQL Security Check for Password Connection Security mysql_private_networks_only Notifies about MySQL accounts that are allowed to connect from public networks. MySQL Users With Granted Public Networks Access Replication Security mysql_replication_grants Checks if replication is configured on a node without user grants. MySQL Security Check for Replication User Replication Security mysql_security_replication_grants_mixed Checks if replication privileges are mixed with more elevated privileges. Replication Privileges"},{"location":"advisors/advisor-details.html#postgresql","title":"PostgreSQL","text":"Advisor Check Name Description Connection Configuration postgresql_max_connections_1 Notifies if the max_connections configuration option is set to a high value (above 300). PostgreSQL doesn\u2019t cope well with having many connections even if they are idle. The recommended value is below 300. Generic Configuration postgresql_archiver_failing_1 Verifies if the archiver has failed. Generic Configuration postgresql_fsync_1 Returns an error if the fsync configuration option is set to OFF, as this can lead to database corruptions. Generic Configuration postgresql_log_checkpoints_1 Notifies if the log_checkpoints configuration option is not enabled. It is recommended to enable the logging of checkpoint information, as that provides a lot of useful information with almost no drawbacks. Generic Configuration postgresql_logging_recommendation_checks Verifies whether the recommended minimum logging features are enabled. Generic Configuration postgresql_wal_retention_check Checks if there are too many WAL files retained in the WAL directory. Vacuum Configuration postgresql_log_autovacuum_min_duration_1 Notifies if the log_autovacuum_min_duration configuration option is set to -1 (disabled). It is recommended to enable the logging of autovacuum run information, as it provides a lot of useful information with almost no drawbacks. Vacuum Configuration postgresql_table_autovac_settings Returns tables where autovacuum parameters are specified along with the corresponding autovacuum settings. Vacuum Configuration postgresql_txid_wraparound_approaching Verifies the age of databases and alerts if the transaction ID wraparound issue is nearing. Vacuum Configuration postgresql_vacuum_sanity_check This performs a quick check of some vacuum parameters. Version Configuration postgresql_eol_check Checks if the currently installed PostgreSQL version has reached its EOL and is no longer supported. Version Configuration postgresql_extension_check Lists outdated extensions with newer versions available. Version Configuration postgresql_unsupported_check Verifies if the currently installed version is supported by Percona. Version Configuration postgresql_version_check Checks if the currently installed version is outdated for its release level. Generic Performance postgresql_cache_hit_ratio_1 Checks the hit ratio of one or more databases and raises a complaint when they are too low. Generic Performance postgresql_config_changes_need_restart_1 Warns if there are any settings or configurations that have been changed and require a server restart or reload. Generic Performance postgresql_tmpfiles_check Reports the number of temporary files and the number of bytes written to disk since the last statistics reset. Replication Performance postgresql_stale_replication_slot_1 Warns if there is a stale replication slot. Stale replication slots will lead to WAL file accumulation and can result in a database server outage. Vacuum Performance postgresql_table_bloat_bytes Verifies the size of the table bloat in bytes across all databases and raises alerts accordingly. Vacuum Performance postgresql_table_bloat_in_percentage Verifies the size of the table bloat in the percentage of the total table size and alerts accordingly. Index Query postgresql_number_of_index_check Lists relations with more than ten indexes. Index Query postgresql_sequential_scan_check Checks for tables with excessive sequential scans. Index Query postgresql_unused_index_check Lists relations with indexes that have not been used since the statistics were last reset. Authentication Security postgresql_super_role Notifies if there are users with Superuser role. Configuration Security postgresql_expiring_passwd_check Checks for passwords that are expiring and displays the time left before they expire. CVE Security postgresql_cve_check Checks if the currently installed version has reported security vulnerabilities."},{"location":"advisors/advisors.html","title":"Advisors","text":"<p>Percona Advisors provide automated insights and recommendations within Percona Monitoring and Management. These proactive insights help you uncover problems before they become larger issues: security risks, misconfigurations, poor performance, etc.</p> <p>Advisors are grouped by category: Security, Configuration, Performance and Query. Each Advisor category offers a set of automated checks, which investigate a specific range of possible issues. The list of Advisor checks available for your instance depends on whether your instance is connected to Percona Platform, and on your current subscription plan.</p>"},{"location":"advisors/advisors.html#prerequisites-for-accessing-advisor-checks","title":"Prerequisites for accessing Advisor checks","text":"<p>All checks are hosted on Percona Platform. PMM Server automatically downloads them from here when the Advisors and Telemetry options are enabled in PMM under Configuration &gt; Settings &gt; Advanced Settings. Both these options are enabled by default.</p>"},{"location":"advisors/advisors.html#highest-security-for-your-databases","title":"Highest security for your databases","text":"<p>Percona Platform communicates with PMM via secure channels, using the highest standards for privacy and security. Before downloading and running Advisor checks on your database, PMM verifies the content and integrity of all Advisor checks to confirm that every component originated from Percona Platform and that no one has altered them since the checks were digitally signed.</p>"},{"location":"advisors/advisors.html#advisor-check-tiers-and-platform-entitlements","title":"Advisor check tiers and Platform entitlements","text":"<p>Depending on the entitlements available for your Percona Account, the set of Advisor checks that PMM can download from the Percona Platform differs in terms of complexity and functionality.</p> <p>If your PMM instance is not connected to Percona Platform, PMM can only use the default Advisor checks. As soon as you connect your PMM instance to Percona Platform, has access to additional checks, available only for registered PMM instances.</p> <p>If you are a Percona customer with a Percona Customer Portal account, you also get access to Standard/Premium Advisor checks, which offer more advanced database health information.</p> <p>To see the complete list of available checks, see the Advisor Checks for PMM topic in the Percona Platform documentation.</p>"},{"location":"advisors/advisors.html#enabledisable","title":"Enable/Disable","text":"<p>To download the checks available for your Percona Account, the Advisors and Telemetry options have to be enabled under  Configuration &gt; Settings &gt; Advanced Settings.</p> <p>These options are enabled by default so that PMM can run automatic Advisor checks in the background. However, you can disable them at any time if you do not need to check the health and performance of your connected databases.</p>"},{"location":"advisors/advisors.html#automatic-checks","title":"Automatic checks","text":"<p>Advisor checks can be executed manually or automatically. By default, PMM runs all the checks available for your PMM instances every 24 hours.</p>"},{"location":"advisors/advisors.html#change-run-interval-for-automatic-advisors","title":"Change run interval for automatic advisors","text":"<p>You can change the standard 24-hour interval to a custom frequency for each Advisor check:</p> <ul> <li>Rare interval - 78 hours</li> <li>Standard interval (default) - 24 hours</li> <li>Frequent interval - 4 hours</li> </ul> <p>To change the frequency of an automatic check:</p> <ol> <li>Click  Advisors.</li> <li>Select the Advisor tab that contains the check for which you want to change the frequency.</li> <li> <p>Expand the relevant Advisor and scroll through the list to find your check. Alternatively, use the Filter section at the top of the table to search checks by Name, Description, Status, or Interval.</p> <p>Tip</p> <p>If you need to share filtered Advisor results with your team members, send them the PMM URL. This saves your search criteria and results.</p> <ol> <li>Click the  Interval icon in the Actions column, next to the check you want to update.</li> <li>Chose an interval and click Save.</li> </ol> </li> </ol>"},{"location":"advisors/advisors.html#manual-checks","title":"Manual checks","text":"<p>In addition to the automatic checks that run every 24 hours, you can also run checks manually, for ad-hoc assessments of your database health and performance.</p> <p>To run checks manually:</p> <ol> <li>Click  Advisors on the main menu.</li> <li>Select the Advisor tab that contains the checks which you want to run manually.</li> <li>Click Run checks to run all the available checks for this Advisor group, or expand an Advisor and click Run next to each check that you want to run individually. </li> </ol>"},{"location":"advisors/advisors.html#advisor-checks-results","title":"Advisor checks results","text":"<p>The results are sent to PMM Server where you can review any failed checks on the Home dashboard. The summary count of failed checks is classified as:</p> <ul> <li>Critical, which also includes checks tagged as Alert and Emergency</li> <li>Error</li> <li>Warning</li> <li>Notice, which also includes checks tagged as Info and Debug</li> </ul> <p></p> <p>To see more details about the available checks and any checks that failed, click the  Advisors icon on the main menu.</p> <p>Note: Check results always remain on the PMM Server. They are never sent as part of Telemetry.</p>"},{"location":"advisors/advisors.html#create-your-own-advisors","title":"Create your own Advisors","text":"<p>PMM Advisors offer a set of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>Developers can create custom checks to cover additional use cases, relevant to specific database infrastructure. For more information, see Develop Advisor checks.</p>"},{"location":"advisors/develop-advisor-checks.html","title":"Developing Advisor checks","text":"<p>PMM offers sets of checks that can detect common security threats, performance degradation, data loss and data corruption.</p> <p>As a developer, you can create custom checks to cover additional use cases, relevant to your specific database infrastructure.</p>"},{"location":"advisors/develop-advisor-checks.html#check-components","title":"Check components","text":"<p>A check is a combination of:</p> <ul> <li>A query for extracting data from the database.</li> <li>Python script for converting extracted data into check results. This is actually a Starlark script, which is a Python dialect that adds more imperative features than Python. The script\u2019s execution environment is sandboxed, and no I/O can be done from it.</li> </ul> <p>All checks are self-contained in the first phase, as well as in most of the planned phases.</p> <p>This means that extracted data is processed on the PMM side and not sent back to Percona Platform.</p>"},{"location":"advisors/develop-advisor-checks.html#backend","title":"Backend","text":"<p>At the backend, pmm-managed does the following:</p> <ol> <li>pmm-managed checks that the installation is opted-in for checks.</li> <li>pmm-managed downloads files with checks from Percona Platform.</li> <li>pmm-managed verifies file signatures using a list of hard-coded public keys. At least one signature should be correct.</li> <li>pmm-managed sends queries to pmm-agent and gathers results.</li> <li>pmm-managed executes check scripts that produce alert information.</li> <li>pmm-managed sends alerts to Alertmanager.</li> <li>Due to Alertmanager design, pmm-managed has to send and re-send alerts to it much more often than the frequency with which checks are executed. This expected behavior is not important for using checks but is important for understanding how checks work.</li> <li>Currently, Prometheus is not involved.</li> </ol> <p></p>"},{"location":"advisors/develop-advisor-checks.html#frontend","title":"Frontend","text":"<p>PMM uses Alertmanager API to get information about failed checks and show them on the UI:</p> <p></p>"},{"location":"advisors/develop-advisor-checks.html#format-for-checks","title":"Format for checks","text":"<p>Advisor checks use the following format:</p> Checks format <pre><code>---\nchecks:\n  - version: 2\n    name: exampleV2\n    summary: Check format V2\n    description: Checks something important\n    interval: standard\n    family: MYSQL\n    category: configuration ## Deprecated since PMM 2.36\n    advisor: dev            ## Required since PMM 2.36\n    queries:\n      - type: MYSQL_SHOW\n        query: VARIABLES\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n\n      - type: METRICS_INSTANT\n        query: mysql_global_status_uptime{service_name=~\"{{.ServiceName}}\"}\n        parameters:\n          lookback: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          range: 15m\n          step: 5m\n\n      - type: METRICS_RANGE\n        query: avg by (node_name) (avg_over_time(node_load1{node_name=~\"{{.NodeName}}\"}[5m]))\n        parameters:\n          lookback: 5m\n          range: 15m\n          step: 5m\n\n    script: |\n      def check_context(docs, context):\n          # `docs` is a frozen (deeply immutable) list where each item represents single query results. Order of results\n          # matches order of queries in check file. Each query result is list of dicts where each item where each dict\n          # represents a single document in result set.\n          #\n          # `context` is a dict with additional functions.\n          #\n          # Global `print` and `fail` functions are available.\n          #\n          # `check_context` function is expected to return a list of dicts that are then converted to alerts;\n          # in particular, that list can be empty.\n          # Any other value (for example, string) is treated as a script execution failure\n          # (Starlark does not support Python exceptions);\n          # it is recommended to use global function `fail` for that instead.\n\n          results = []\n\n          for row in docs[0]:\n              name, value = row[\"Variable_name\"], row[\"Value\"]\n              if name == \"version\":\n                  results.append({\n                      \"summary\": \"MySQL has version {}\".format(value),\n                      \"description\": \"Current version is {}\".format(value),\n                      \"read_more_url\": \"\",\n                      \"severity\": \"warning\",\n                      \"labels\": {},\n                  })\n\n          uptimeNow = int(int(docs[1][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime {} min\".format(uptimeNow),\n              \"description\": \"Current uptime is {} min\".format(uptimeNow),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          uptimeFiveMinAgo = int(int(docs[2][0][\"value\"][1])/60)\n          results.append({\n              \"summary\": \"MySQL uptime 5 min ago was {} min\".format(uptimeFiveMinAgo),\n              \"description\": \"5 min ago uptime was {} min\".format(uptimeFiveMinAgo),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[3][0][\"values\"]:\n            dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Node has load average for last 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          dataPoints = []\n          for row in docs[4][0][\"values\"]:\n              dataPoints.append(row[1])\n\n          results.append({\n              \"summary\": \"Five minutes ago node had load average for 15 minutes {}\".format(dataPoints),\n              \"description\": \"Data points {}\".format(dataPoints),\n              \"read_more_url\": \"\",\n              \"severity\": \"warning\",\n              \"labels\": {},\n          })\n\n          return results\n</code></pre>"},{"location":"advisors/develop-advisor-checks.html#checks-script","title":"Checks script","text":"<p>The check script assumes that there is a function with <code>check_context</code>, that accepts a list where each item represents the result of a single query specified in the check. Each result itself is a list of docs containing returned rows for SQL databases and documents for MongoDB. It returns zero, one, or several check results that are then converted to alerts.</p>"},{"location":"advisors/develop-advisor-checks.html#check-severity-levels","title":"Check severity levels","text":"<p>You can label your advisor checks with one of the following available severity levels: Emergency, Alert, Critical, Error, Warning, Notice, Info, Debug. PMM groups failed checks by their severity, and displays them under Advisors Checks &gt; Failed Checks.</p>"},{"location":"advisors/develop-advisor-checks.html#check-fields","title":"Check fields","text":"<p>Checks can include the following fields:</p> <ul> <li>Version (integer, required): defines what other properties are expected, what types are supported, what is expected from the script and what it can expect from the execution environment, etc.</li> <li>Name (string, required): defines machine-readable name (ID).</li> <li>Summary (string, required): defines short human-readable description.</li> <li>Description (string, required): defines long human-readable description.</li> <li>Family (string, required): specifies one of the supported database families: MYSQL, POSTGRESQL, MONGODB. This field is only available for Advisor checks v.2.</li> <li>Advisor (string, required): specifies the advisor to which this check belongs. For local environments, specify dev.</li> <li>Interval (string/enum, optional): defines running interval. Can be one of the predefined intervals in the UI: Standard, Frequent, Rare.</li> <li>Queries (array, required): contains items that specify queries.<ul> <li>Type (string/enum, required): defines the query type. Check the list of available types in the table below.</li> <li>Query (string, can be absent if the type defines the whole query by itself): The query is executed on the PMM Client side and can contain multiple queries specific to the target DBMS.</li> <li>Parameters (key-value, can be absent if query doesn\u2019t have required parameters)</li> </ul> </li> <li>Script (string, required): contains a small Starlark script that processes query results, and returns check results. It is executed on the PMM Server side.</li> </ul>"},{"location":"advisors/develop-advisor-checks.html#query-types","title":"Query types","text":"<p>Expand the table below for the list of checks types that you can use to define your query type and the PMM Service type for which the check will run.</p> Check types Check type Description \u201cquery\u201d required (must be empty if \u201cNo\u201d) MYSQL_SHOW Executes \u2018SHOW \u2026\u2019 clause against MySQL database. Yes MYSQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against MySQL database. Yes POSTGRESQL_SHOW Executes \u2018SHOW ALL\u2019 command against PosgreSQL database. No POSTGRESQL_SELECT Executes \u2018SELECT \u2026\u2019 clause against PosgreSQL database. Yes MONGODB_GETPARAMETER Executes db.adminCommand( { getParameter: \u201c*\u201d } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getParameter No MONGODB_BUILDINFO Executes db.adminCommand( { buildInfo:  1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see buildInfo No MONGODB_GETCMDLINEOPTS Executes db.adminCommand( { getCmdLineOpts: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see getCmdLineOpts No MONGODB_REPLSETGETSTATUS Executes db.adminCommand( { replSetGetStatus: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see  replSetGetStatus No MONGODB_GETDIAGNOSTICDATA Executes db.adminCommand( { getDiagnosticData: 1 } ) against MongoDB\u2019s \u201cadmin\u201d database. For more information, see MongoDB Performance No METRICS_INSTANT Executes instant MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about instant queries, check out the Prometheus docs. Yes METRICS_RANGE Executes range MetricsQL query. Query can use placeholders in query string  {{.NodeName}} and {{.ServiceName}}  . Both match target service/node names. To read more about range queries, check out the Prometheus docs. Yes CLICKHOUSE_SELECT Executes \u2018SELECT \u2026\u2019 statements against PMM\u2019s Query Analytics ClickHouse database. Queries can use the  {{.ServiceName}} and {{.ServiceID}}   placeholders in query string. They match the target service name and service ID respectively. Yes"},{"location":"advisors/develop-advisor-checks.html#query-parameters","title":"Query parameters","text":"<ul> <li><code>METRICS_INSTANT</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> </ul> </li> <li><code>METRICS_RANGE</code><ul> <li>lookback (duration, optional): specifies how far in past to look back to metrics history. If this parameter is not specified, then query executed on the latest data. Example values: <code>30s</code>, <code>5m</code>, <code>8h</code>.</li> <li>range (duration, required): specifies time window of the query. This parameter is equal to Prometheus API.</li> <li>step (duration, required): query resolution. This parameter is equal to Prometheus API.</li> </ul> </li> <li><code>POSTGRESQL_SELECT</code><ul> <li>all_dbs (boolean, optional): execute query on all available databases in PostgreSQL instance. If this parameter is not specified, then query executed on the default database (the one that was specified when service was added to PMM).</li> </ul> </li> </ul>"},{"location":"advisors/develop-advisor-checks.html#develop-checks","title":"Develop checks","text":"<p>Development/debugging only</p> <p>Note that check development in PMM is currently for debugging only and NOT for production use!  Future releases plan to include the option to run custom local checks in addition to hosted Percona Platform checks.</p> <p>To develop custom checks for PMM:</p> <ol> <li>Install the latest PMM Server and PMM Client builds following the installation instructions.</li> <li> <p>Run PMM Server with special environment variables:</p> <ul> <li><code>PMM_DEV_ADVISOR_CHECKS_FILE=/srv/custom-checks.yml</code> to use checks from the local files instead of downloading them from Percona Platform.</li> <li><code>PMM_ADVISORS_CHECKS_DISABLE_START_DELAY=true</code> to disable the default check execution start delay. This is currently set to one minute, so that checks run upon system start.</li> </ul> <pre><code>docker run -p 443:8443 --name pmm-server \\\n-e PMM_DEV_ADVISOR_CHECKS_FILE=/srv/custom-checks.yml \\\n-e PMM_ADVISORS_CHECKS_DISABLE_START_DELAY=true \\\nperconalab/pmm-server:3-dev-container\n</code></pre> </li> <li> <p>Log into Grafana with credentials admin/admin.</p> </li> <li> <p>Go to PMM Configuration &gt; Settings &gt; Advanced Settings and make sure the Advisors option is enabled.</p> </li> <li> <p>Create <code>/srv/custom-checks.yml</code> inside the <code>pmm-server</code> container with the content of your check. Specify dev advisor in your check.</p> </li> <li> <p>The checks will run according to the time interval defined on the UI. You can see the result of running the check on the home dashboard:</p> <p></p> </li> <li> <p>Click on the number of failed checks to open the Failed Checks dashboard:</p> <p></p> </li> <li> <p>Check out pmm-managed logs:     <pre><code>docker exec -it pmm-server supervisorctl tail -f pmm-managed\n</code></pre></p> </li> </ol>"},{"location":"advisors/develop-advisor-checks.html#troubleshooting-and-tips","title":"Troubleshooting and tips","text":"<p>When developing checks for PMM, you may encounter various issues. Here are solutions for common problems:</p>"},{"location":"advisors/develop-advisor-checks.html#managing-debug-output","title":"Managing debug output","text":"<p>Debug mode generates excessive information in log files that can obscure important data. To disable debug logging, use <code>PMM_DEBUG=0</code>.</p>"},{"location":"advisors/develop-advisor-checks.html#filtering-logs","title":"Filtering logs","text":"<p>All check subsystem logs include the component=checks tag. Filter relevant logs with: <code>grep \"component=checks\" /path/to/pmm-managed.log</code>.</p>"},{"location":"advisors/develop-advisor-checks.html#development-tab-issues","title":"Development tab issues","text":"<p>If your Development tab isn\u2019t appearing on the Advisors page:</p> <ol> <li>Verify your check file links to the development advisor: <code>advisor: dev</code>.</li> <li>If the Development tab still doesn\u2019t appear, check for YAML formatting issues in your check file. Examine <code>pmm-managed</code> logs for parsing errors or validation failures.</li> </ol>"},{"location":"advisors/develop-advisor-checks.html#reloading-check-files","title":"Reloading check files","text":"<p>There are two ways to reload your check file after making changes:</p> <ul> <li>Using the UI (when available): click the Run check button on the Advisors page.</li> <li>From command line (always works): SSH into PMM Server and execute: <code>supervisorctl restart pmm-managed</code>.</li> </ul>"},{"location":"advisors/develop-advisor-checks.html#submit-feedback","title":"Submit feedback","text":"<p>We welcome your feedback on the current process for developing and debugging checks. Send us your comments or post a question on the Percona Forums.</p>"},{"location":"alert/index.html","title":"About Percona Alerting","text":"<p>Alerting notifies of important or unusual activity in your database environments so that you can identify and resolve problems quickly. When something needs your attention, Percona Alerting can be configured to automatically send you a notification through your specified contact points.</p> <p>Percona Alerting is enabled by default in the PMM Settings. This feature adds the Alert rule templates option on the main menu and alert template options on the Alerting page.</p> <p>These options enable you to create alerts based on a set of Percona-supplied templates with common events and expressions for alerting. </p>"},{"location":"alert/index.html#alert-types","title":"Alert types","text":"<p>Percona Alerting is powered by Grafana infrastructure. It leverages Grafana\u2019s advanced alerting capabilities and provides pre-configured Alert Rule Templates that simplify creating powerful alerting rules.</p> <p>Depending on the datasources that you want to query, and the complexity of your required evaluation criteria, Percona Alerting enables you to create the following types of alerts:</p> <ul> <li>Percona templated alerts: alerts based on a set of Percona-supplied templates with common events and expressions for alerting. If you want to use custom expressions in alert rules, you can create your own alert rule templates.</li> <li>Grafana managed alerts: alerts that handle complex conditions and can span multiple different data sources like SQL, Prometheus, InfluxDB, etc. These alerts are stored and executed by Grafana.</li> </ul>"},{"location":"alert/alert_rules.html","title":"Alert rules and alert templates","text":"<p>Alert rules describe the circumstances under which you want to be alerted. The evaluation criteria that you define determine whether an alert will fire. </p> <p>An alert rule consists of one or more queries and expressions, a condition, the frequency of evaluation, and the duration over which the condition is met. For example, you might configure an alert to fire and trigger a notification when MongoDB is down.</p> <p></p> <p>An alert rule can be in three possible states:</p> <ul> <li>Normal: Everything is working correctly and the conditions specified in the rule has not been met. This is the default state for newly created rules.</li> <li>Pending: The conditions specified in the alert rule has been met, but for a time that is less than the configured duration.</li> <li>Firing: Both the conditions and the duration specified in the alert rule have both been met.</li> </ul> <p>It takes at least one evaluation cycle for an alert rule to transition from one state to another (e.g., from <code>Normal</code> to <code>Pending</code>).</p>"},{"location":"alert/alert_rules.html#alert-rules-templates","title":"Alert rules templates","text":"<p>PMM provides a set of Alert Rule templates with common events and expressions for alerting. These templates can be used as a basis for creating Alert Rules. You can also create your own templates if you need custom expressions.</p> <p>You can check the alert templates available for your account under Alerting &gt; Alert rule templates tab. PMM lists here the following types of templates:</p> <ul> <li>Built-in templates, available out-of-the-box with PMM.</li> <li>Templates downloaded from Percona Platform.</li> <li>Custom templates created or uploaded on the Alerting page &gt; Alert Templates tab. You can also store your custom template files in your <code>/srv/alerting/templates</code> directory and PMM will load them during startup.</li> </ul>"},{"location":"alert/alert_rules.html#accessing-alert-templates","title":"Accessing alert templates","text":"<p>To check the alert templates for your PMM instance, go to PMM &gt; Alerting &gt; Alert Rule Templates tab.</p> <p>To check the full list of available PMM templates, see the List of available alert templates topic</p>"},{"location":"alert/alert_rules.html#create-alert-rules-from-alert-rule-templates","title":"Create alert rules from alert rule templates","text":"<p>This section focuses on creating an alert rule based on PMM templates. For information on working with the other alert types, check the Grafana documentation on Grafana Labs.</p>"},{"location":"alert/alert_rules.html#provision-alert-resources","title":"Provision alert resources","text":"<p>Before creating PMM alert rules, configure the required alert resources:</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced Settings and ensure that the Percona Alerting option is enabled. When this is disabled, the Alerting page displays only Grafana-managed alert rules. This means that you will not be able to create alerts based on PMM templates.</li> <li>Go to Dashboards and check the folders available for storing alert rules. If none of the available folders are relevant for your future alert rules, click New &gt; New Folder and create a custom one.</li> <li>Go to Alerting &gt; Alert rule templates and check the default PMM templates. If none of the templates include a relevant expression for the type of alerts that you want to create, click Add template to create a custom template instead.</li> </ol>"},{"location":"alert/alert_rules.html#configure-alert-templates","title":"Configure alert templates","text":"<p>Alerts templates are YAML files that provide the source framework for alert rules. Alert templates contain general template details and an alert expression defined in MetricsQL. This query language is backward compatible with PromQL.</p>"},{"location":"alert/alert_rules.html#create-custom-templates","title":"Create custom templates","text":"<p>If none of the default PMM templates contain a relevant expression for the alert rule that you need, you can create a custom template instead.</p> <p>You can base multiple alert rules on the same template. For example, you can create a <code>pmm_node_high_cpu_load</code> template that can be used as the source for alert rules for production versus staging, warning versus critical, etc.</p>"},{"location":"alert/alert_rules.html#template-format","title":"Template format","text":"<p>When creating custom templates, make sure to use the required template format below:</p> <ul> <li>name (required): uniquely identifies template. Spaces and special characters are not allowed.</li> <li>version (required): defines the template format version.</li> <li>summary (required): a template description.</li> <li>expr (required): a MetricsQL query string with parameter placeholders.</li> <li>params: contains parameter definitions required for the query. Each parameter has a name, type, and summary. It also may have a unit, available range, and default value.<ul> <li>name (required): the name of the parameter. Spaces and special characters are not allowed.</li> <li>summary (required): a short description of what this parameter represents.</li> <li>unit (optional): PMM currently supports either s (seconds) or % (percentage).</li> <li>type (required): PMM currently supports the <code>float</code> type. <code>string</code>, <code>bool</code>, and other types will be available in a future release.</li> <li>range (optional): defines the boundaries for the value of a  float parameter</li> </ul> </li> <li>value (optional): default parameter value. Value strings must not include any of these special characters: <code>&lt; &gt; ! @ # $ % ^ &amp; * ( ) _ / \\ ' + - = (space)</code></li> <li>for (required): specifies the duration of time that the expression must be met before the alert will be fired</li> <li>severity (required): specifies default alert severity level</li> <li> <p>labels (optional): are additional labels to be added to generated alerts</p> </li> <li> <p>annotations (optional): are additional annotations to be added to generated alerts.</p> </li> </ul> Template example <pre><code>---\ntemplates:\n  - name: pmm_node_high_cpu_load\n    version: 1\n    summary: Node high CPU load\n    expr: |-\n      (1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])))\n      * 100\n      &gt; bool [[ .threshold ]]\n    params:\n      - name: threshold\n        summary: A percentage from configured maximum\n        unit: \"%\"\n        type: float\n        range: [0, 100]\n        value: 80\n    for: 5m\n    severity: warning\n    annotations:\n      summary: Node high CPU load ({{ $labels.node_name }})\n      description: |-\n        {{ $labels.node_name }} CPU load is more than [[ .threshold ]]%.\n</code></pre>"},{"location":"alert/alert_rules.html#test-alert-expressions","title":"Test alert expressions","text":"<p>If you want to create custom templates, you can test the MetricsQL expressions for your custom template in the Explore section of PMM. Here you can also query any PMM internal database.</p> <p>To test expressions for custom templates:</p> <ol> <li>On the main menu in PMM, choose Explore &gt; Metrics.</li> <li>Enter your expression in the Metrics field and click Run query.</li> </ol> <p>For example, to check the CPU usage, Go to Explore &gt; Metrics in your PMM dashboard and run the query expression below: <pre><code>(1 - avg by(node_name) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m]))) * 100\n</code></pre> </p> <p>Note that to paste the query above, Explore must be in <code>Code</code> mode, and not in <code>Builder</code> mode.</p>"},{"location":"alert/alert_rules.html#add-an-alert-rule-based-on-a-template","title":"Add an alert rule based on a template","text":"<p>After provisioning the resources required for creating Percona templated alerts, you are now ready to create your alert rule based on a Percona template. </p> <p>If you want to learn about creating Grafana alerts instead, check out Grafana\u2019s documentation:</p> <ol> <li>Go to Alerting &gt; Alert Rules, and click New alert rule from template.</li> <li>On the Create alert rule from template page, choose the template on which you want to base the new alert rule. This automatically populates the Name, Duration, and Severity fields with information from the template. You can change these values if you want to override the default specifications in the template.</li> <li>From the Folder drop-down menu, select the location where you want to store the rule.</li> <li> <p>In the Filters section, specify if you want the alert rule to apply only to specific services or nodes. For example: <code>service_name=ps5.7</code>. When creating alert rule filters, consider the following:</p> <ul> <li>Filters use conjunction semantics. This means that if you add more than one filter, PMM will combine their conditions to search for matches: filter 1 AND filter 2 AND filter 3.</li> <li>Label must be an exact match. You can find a complete list of labels using the  Explore menu in PMM.</li> </ul> </li> <li> <p>Click Save and Exit to close the page and go to the Alert Rules tab where you can review, edit and silence your new alert.</p> </li> </ol>"},{"location":"alert/contact_points.html","title":"Contact points","text":"<p>Contact points specify where Percona Alerting should deliver notifications for alerts. PMM can be configured via a Notification policy to send a notification to specified contact points whenever an alert is fired.</p> <p>Depending on the severity of an alert, you might want to send different alert notifications to different channels. For example, you can deliver common notifications via a Slack channel, but send an email notification for potentially critical issues.  </p> <p>Percona Alerting uses email as the default contact point but you can choose from a variety of other contact points, including Slack, Webhooks, PagerDuty, and more.</p> <p>Before Percona Alerting can send out email notifications via email contact points, you will need to:</p> <ol> <li>Configure Email (SMTP) server settings.</li> <li>Configure a contact point to define the email delivery options</li> </ol> <p>Contact points with invalid settings show a No Attempts status under  Alerting &gt; Contact points.</p>"},{"location":"alert/contact_points.html#configure-email-smtp-server-settings","title":"Configure Email (SMTP) server settings","text":"<p>To use SMTP with a PMM Docker installation:</p> <ol> <li> <p>Create an <code>.env</code> file and populate it with your SMTP credentials (and other environment variables) as follows:</p> <p><pre><code>GF_SMTP_ENABLED=true  \nGF_SMTP_HOST=smtp.gmail.com:587\nGF_SMTP_USER=email@domain.com\nGF_SMTP_PASSWORD=&lt;YOUR_SMTP_PASSWORD&gt;\nGF_SMTP_SKIP_VERIFY=false\nGF_SMTP_FROM_ADDRESS=email@domain.com\nGF_SMTP_FROM_NAME=Percona Alerting\n</code></pre> Below is a summary of each environment variable above: </p> <ul> <li><code>GF_SMTP_ENABLED</code>: When true, enables Grafana to send emails.</li> <li><code>GF_SMTP_HOST</code>: Host address of your SMTP server.</li> <li><code>GF_SMTP_USER</code>: Username for SMTP authentication.</li> <li><code>GF_SMTP_PASSWORD</code>: Password for SMTP authentication</li> <li><code>GF_SMTP_SKIP_VERIFY</code>: When true, verifies SSL for the SMTP server.</li> <li><code>GF_SMTP_FROM_ADDRESS</code>: Email address to be used when sending out emails.</li> <li><code>GF_SMTP_FROM_NAME</code>: Name to be used when sending out emails.</li> </ul> <p>NB: If you are using your Gmail\u2019s SMTP credentials as shown above, you will have to generate an app password and fill it in as the value of your $GF_SMTP_PASSWORD variable.</p> </li> <li> <p>Pass in the <code>.env</code> file to Docker run using the <code>--env-file</code> flag:     <pre><code>docker run --env-file=.env -p 443:8443 percona/pmm-server:3\n</code></pre>     This command starts a docker container and will keep running as long as the container is also running. Stopping the command (e.g with Ctrl+C) will stop the container hence, subsequent commands should be run in a new terminal.</p> </li> </ol>"},{"location":"alert/contact_points.html#restore-smtp-settings-following-an-upgrade","title":"Restore SMTP settings following an upgrade","text":"<p>If you configured PMM to use SMTP settings via environment variables, you do not need to do anything after an upgrade as your settings will be transferred.</p>"},{"location":"alert/contact_points.html#configure-an-email-contact-point","title":"Configure an Email contact point","text":"<p>After configuring the SMTP settings, specify email delivery options for an Email contact point:</p> <ol> <li>Go to Alerting &gt; Contact points.</li> <li>Click the edit button next to the grafana-default-email to update PMM\u2019s default Email contact point, or click Add contact point to create a custom one.</li> <li>Enter a contact point name, and add the email addresses for the recipients of the email notifications.</li> <li> <p>Expand Optional Email settings and fill in any other relevant settings:</p> <ul> <li>Enable the Single email option to send a single email to the recipients containing alerts that are firing. For example, if an alert fires for three nodes, this would send only one email listing all three alerts.</li> <li>Add an optional message to include with the email notifications.</li> <li>Edit the email subject for the notifications. The default subject line uses the following format: [FIRING: number of alerts firing for the alert rule] (Name of alert rule and instance).    </li> </ul> </li> <li> <p>If you do not want to be notified when an alert resolves, expand Notification settings, and tick the Disable Resolved Message checkbox.</p> </li> <li>If you want your contact point to notify via multiple channels, for example, both via Email and Teams, click New contact point type and fill out additional contact point type details.</li> <li>Click the Test button to send a test email and make sure your contact point works as expected.     </li> <li>Click the Save contact point button at the bottom of the page. The contact point is now listed under Alerting &gt; Contact points.</li> </ol>"},{"location":"alert/contact_points.html#create-additional-contact-points","title":"Create additional contact points","text":"<p>In addition to Email contact points, you can add a variety of other contact points, including Slack, email, webhooks, PagerDuty, and more.</p> <p>Follow the steps above to create additional contact points. Different contact points require different configuration information. For example, for Slack, PMM requires the recipient information, the API token and the webhook URL, which you can get from your Slack administrator.</p>"},{"location":"alert/contact_points.html#notification-policies","title":"Notification policies","text":"<p>Notification policies determine how notifications (triggered by alerts) are routed to contact points by defining where, when, and how to send notifications.</p> <p>For example, you might specify a limit for the number of times a notification is sent during a certain period. This helps ensure that you don\u2019t spam your Slack channel with too many notifications about the same issue.</p>"},{"location":"alert/contact_points.html#root-notification-policy","title":"Root notification policy","text":"<p>Percona Alerting comes pre-configured with a Notification Root Policy, which is the default notification policy. It uses the grafana-default-email contact point and is applied to all alerts that don\u2019t have a custom notification policy assigned to them.</p>"},{"location":"alert/contact_points.html#how-matching-works","title":"How matching works","text":"<p>Policies can have one or more child policies. An alert matches if the alert\u2019s labels match all the Matching Labels specified on the policy.</p> <p>Alerts that don\u2019t match any specific policies are handled by the root policy. The root policy also handles any alert rules for which the assigned custom notification policy has been deleted, to ensure notifications for existing alerts continue to be delivered.</p>"},{"location":"alert/contact_points.html#edit-the-root-notification-policy","title":"Edit the root notification policy","text":"<p>To edit the root notification policy:</p> <ol> <li>Go to  Alerting &gt; Notification policies tab.</li> <li>Click the ellipsis button next to the root policy box and select the Edit option.</li> <li>Choose whether to keep the default Email contact point, select a new available contact point or create a new one.</li> <li>In the Group by field, specify how alert rules should be processed into notifications. If multiple alerts are matched for this policy, they will be grouped based on the labels you specify, and a notification will be sent per group.</li> <li>Expand the Timing options section and specify how notification wait times should be processed. These are short pauses the system can take to efficiently process multiple sets of alerts for notifications:<ul> <li>Group wait: The default is to wait 30 seconds to buffer alerts of the same group before sending a notification initially.</li> <li>Group interval: The default is to wait five minutes before sending a batch of new alerts after the first notification was sent.</li> <li>Repeat interval: The default is to wait four hours before resending an alert.</li> </ul> </li> <li>Click Save to save your changes.</li> </ol>"},{"location":"alert/contact_points.html#create-a-new-notification-policy","title":"Create a new notification policy","text":"<p>To create a new notification policy:</p> <ol> <li> <p>Go to  Alerting &gt; Notification policies tab. </p> </li> <li> <p>Click New nested policy.</p> </li> <li>The Matching labels section defines the rules for matching alert labels. The matching label is a combination of label name, operator and label value, where the label name is any valid label in your environment. For example:  <code>node_name</code>, <code>cluster</code>, etc. A policy will match an alert if the alert\u2019s labels match all the matching labels specified on the policy. If there are no matchers, the policy will handle all the alert instances. For example, you could add a node_name=pmm-server matcher to send out notifications only for this node.</li> <li>Select an existing contact point for the policy.</li> <li>Enable Continue matching subsequent sibling nodes to continue matching subsequent siblings of the policy after an alert matched the parent policy. This can be useful, for example, when you want to send notifications to a catch-all contact point as well as to one of more specific contact points handled by subsequent policies.</li> <li>Toggle Override grouping if you do not want to use root policy grouping.</li> <li>Toggle Override general timings to specify how often you want to wait until the initial notification is sent for a new group. When this is disabled, PMM uses root policy group timings instead.</li> <li> <p>Add a mute timing if you want to mute notifications or this policy for a specific, regular interval. For example, you can create a mute to suppress trivial notifications during weekends. Mute timings are different from silences in the sense that they are recurring, while silences have a fixed start and end time.</p> <p>Important</p> <p>Time specified in mute timing must be in UTC format, i.e. 14:00, not 2:00 PM.</p> </li> </ol>"},{"location":"alert/disable_alerts.html","title":"Disable Percona Alerting","text":"<p>Percona Alerting is enabled by default in the PMM Settings. This feature adds the Percona templated alerts option on the Alerting menu.</p> <p>If for some reason you want to disable PMM Alert templates and keep only Grafana-managed alerts:</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced settings.</li> <li>Disable the Alerting option. The Alerting menu will now display only Grafana-managed alert rules.</li> </ol>"},{"location":"alert/silence_alerts.html","title":"Silence alerts","text":"<p>Create a silence when you want to suppress/stop alerts and their associated notifications for a very specific amount of time.  Silences default to today\u2019s current date and have a default duration of two hours.</p> <p>You can also schedule a silence for a future date and time. This is referred to as a <code>Pending</code> silence, which can be observed on the Silences page.</p> <p>During a silence, PMM continues to track metrics but does not trigger alerts or send notifications to any specified contact points. Once the silence expires alerts and notifications will resume.</p> <p>Silenced alerts are still recorded under Alerting &gt; Fired Alerts so that you can review them later. Silenced alerts show up as Suppressed and are disabled for as long as it\u2019s specified in the Silence Duration, or until you remove a silence.</p>"},{"location":"alert/silence_alerts.html#using-silences","title":"Using silences","text":"<p>You can silence an alert by creating a silence from the Silences page.  Here you define labels that match the alert that you want to silence.</p> <p>To create a new silence:</p> <ol> <li>Click the Create silence button.</li> <li>Select the start and end date to indicate when the silence should go into effect and expire.</li> <li>Optionally, update the duration to alter the time for the end of silence in the previous step to correspond to the start plus the duration.</li> <li>Enter one or more matching labels by filling out the Name and Value fields. Matchers determine which rules the silence will apply to. Note that all labels specified here must be matched by an alert for it to be silenced.</li> <li>Enter any additional comments you would like about this silence - by default, the date the silence was created is placed here.</li> <li>Review the affected alert instances that will be silenced.</li> <li>Click Save silece.</li> </ol> <p>For more information on working with silences, see About alerting silences in the Grafana documentation.</p>"},{"location":"alert/silence_alerts.html#alerting-compatibility","title":"Alerting compatibility","text":""},{"location":"alert/silence_alerts.html#template-compatibility-with-pmm-2","title":"Template compatibility with PMM 2","text":"<p>After upgrading from the latest PMM 2 version to PMM 3, you will find all your alert templates under Alerting &gt; Alert rule templates.</p> <p>If you have any templates available in the  <code>/srv/ia/templates</code> folder, make sure to transfer them to <code>/srv/alerting/templates</code> as PMM 3 will look for custom templates in this location.</p>"},{"location":"alert/silence_alerts.html#template-compatibility-with-other-alerting-tools","title":"Template compatibility with other alerting tools","text":"<p>If you have existing YAML alert templates that you want to leverage in Percona Alerting:</p> <ol> <li>Go to Alerting &gt; Alert rule templates tab and click Add template at the top right-hand side of the table.</li> <li>Upload a local .yaml file that contains the definition of one or more alert templates then click Add. Alert templates added in bulk will be displayed individually on Alert rule templates page.</li> </ol>"},{"location":"alert/silence_alerts.html#script-commands","title":"Script commands","text":"<p>The default command for migrating rules is: <pre><code>python3 ia_migration.py -u admin -p admin\n</code></pre> To see all the available options, check the scrip help using <code>ia_migration.py -h</code></p>"},{"location":"alert/silence_alerts.html#script-prerequisites","title":"Script prerequisites","text":"<ul> <li>Python version 3.x, which you can download from Python Downloads centre.</li> <li>Requests library, which you can install with the following command: <code>pip3 install requests</code>.</li> </ul> <p>Important</p> <p>The script sets all migrated alert rules to Active. Make sure to silence any alerts that should not be firing.</p> <p>For more information about the script and advanced migration options, check out the help information embedded in the script.</p>"},{"location":"alert/templates_list.html","title":"List of available alert templates","text":"<p>The table below lists all the alert templates available in Percona Monitoring and Management (PMM). This list includes both built-in templates (accessible to all PMM users), and customer-only templates.</p> <p>To access the customer-only templates, you must be a Percona customer and connect PMM to Percona Platform using a Percona Account.</p>"},{"location":"alert/templates_list.html#template-catalog","title":"Template catalog","text":"<ul> <li>Operating System templates</li> <li>PMM templates</li> <li>MongoDB templates</li> <li>PBM templates</li> <li>MySQL templates</li> <li>PostgreSQL templates</li> <li>ProxySQL templates</li> </ul>"},{"location":"alert/templates_list.html#operating-system-os-templates","title":"Operating System (OS) templates","text":"Area Template name Description Available for Database technology OS Node high CPU load Monitors node CPU usage and alerts when it surpasses 80% (default threshold). Provides details about specific nodes experiencing high CPU load, indicating potential performance issues or scaling needs. All users MySQL, MongoDB, PostgreSQL OS Memory available less than a threshold Tracks available memory on nodes and alerts when free memory drops below 20% (default threshold). Helps prevent system instability due to memory constraints. All users MySQL, MongoDB, PostgreSQL OS Node high swap filling up Monitors node swap usage and alerts when it exceeds 80% (default threshold). Indicates potential memory pressure and performance degradation, allowing for timely intervention. All users MySQL, MongoDB, PostgreSQL"},{"location":"alert/templates_list.html#pmm-templates","title":"PMM templates","text":"Area Template name Description Available for Database technology PMM PMM agent down Monitors PMM Agent status and alerts when an agent becomes unreachable, indicating potential host or agent issues. All users MySQL, MongoDB, PostgreSQL, ProxySQL PMM Backup failed [Technical Preview] Monitors backup processes and alerts on failures, providing details about the failed backup artifact and service. Helps maintain data safety and recovery readiness. This template is currently in Technical Preview status and should be used for testing purposes only as it is subject to change. All users MySQL, MongoDB, PostgreSQL, ProxySQL"},{"location":"alert/templates_list.html#mongodb-templates","title":"MongoDB templates","text":"Area Template name Description Available for Database technology MongoDB MongoDB down Detects when a MongoDB instance becomes unavailable, enabling rapid response to maintain database accessibility. When monitoring MongoDB sharded clusters, alerts using this template detect outages in any cluster component (configuration servers, Mongos routers, data-bearing nodes, and arbiters). All users MongoDB MongoDB Memory used by MongoDB connections Tracks MongoDB connection memory usage and alerts when it exceeds configurable thresholds. Helps identify and address potential performance issues caused by high memory consumption. All users MongoDB MongoDB Memory used by MongoDB Monitors overall MongoDB memory usage and alerts when it exceeds 80% of total system memory. Provides details about specific MongoDB services and nodes experiencing high memory consumption, aiding in resource optimization. All users MongoDB MongoDB MongoDB restarted Detects recent MongoDB restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Facilitates investigation of unexpected downtime and potential issues. All users MongoDB MongoDB MongoDB DBPath disk space utilization Monitors disk space usage in MongoDB\u2019s data directory and alerts when it exceeds set thresholds. Helps prevent storage-related issues and ensures adequate space for database operations. Customers-only MongoDB MongoDB MongoDB host SSL certificate expiry Tracks SSL certificate expiration dates for MongoDB hosts and alerts when certificates are approaching expiry. Enables timely certificate renewal to maintain secure connections. Customers-only MongoDB MongoDB MongoDB oplog window Monitors the oplog window size and alerts when it falls below the recommended threshold (typically 24-48 hours). Ensures sufficient time for secondary nodes to replicate data and maintain cluster consistency. Customers-only MongoDB MongoDB MongoDB read tickets Tracks read ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Helps optimize read performance and identify potential bottlenecks. Customers-only MongoDB MongoDB MongoDB replication lag is high Monitors replication lag and alerts when it exceeds acceptable thresholds. Crucial for maintaining data consistency across replicas and identifying synchronization issues. Customers-only MongoDB MongoDB MongoDB ReplicaSet has no primary Detects when a replica set loses its primary node and alerts users. Indicates that the cluster is in read-only mode, potentially affecting write operations and overall database functionality. Customers-only MongoDB MongoDB MongoDB member is in unusual state Identifies and alerts when replica set members enter unusual states such as Recovering, Startup, or Rollback. Helps maintain cluster health and performance by enabling quick intervention. Customers-only MongoDB MongoDB MongoDB write tickets Monitors write ticket availability in the WiredTiger storage engine and alerts when it falls below set thresholds. Aids in optimizing write performance and identifying potential bottlenecks. Customers-only MongoDB MongoDB MongoDB too many chunk migrations Monitors amount of chunk migrations in a MongoDB sharded cluster and alerts if they are more than set thresholds. Customers-only MongoDB"},{"location":"alert/templates_list.html#pbm-percona-backup-for-mongodb-templates","title":"PBM (Percona Backup for MongoDB) templates","text":"Area Template name Description Available for Database technology PBM MongoDB PBM Agent down Monitors the status of Percona Backup for MongoDB (PBM) Agents and alerts when an Agent becomes unresponsive. This indicates potential issues with the host system or with the PBM Agent itself. All users MongoDB PBM MongoDB PBM backup duration Monitors the time taken to complete a backup and alerts when it exceeds set thresholds. If the backup did not complete, no alerts are sent. All users MongoDB PBM MongoDB PBM backup size Monitors the amount of disk space taken by a completed backup and alerts when it exceeds set thresholds. If the backup did not complete, no alerts are sent. All users MongoDB PBM MongoDB Stale PBM backup Monitors the time of the last successful backup. If it is older than the configured threshold, it sends an alert. All users MongoDB"},{"location":"alert/templates_list.html#mysql-templates","title":"MySQL templates","text":"Area Template name Description Available for Database technology MySQL MySQL down Monitors MySQL instance availability and alerts when any MySQL service becomes unreachable. Enables quick response to maintain database services. All users MySQL MySQL MySQL replication running IO Tracks MySQL replication I/O thread status and alerts if it stops running on a replica. Crucial for ensuring data is being received from the primary server. All users MySQL MySQL MySQL replication running SQL Monitors MySQL replication SQL thread status and alerts if it stops running on a replica. Essential for verifying that received data is being applied correctly to maintain data consistency. All users MySQL MySQL MySQL restarted Detects recent MySQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. All users MySQL MySQL MySQL connections in use Tracks MySQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to connection overload. All users MySQL"},{"location":"alert/templates_list.html#postgresql-templates","title":"PostgreSQL templates","text":"Area Template name Description Available for Database technology PostgreSQL PostgreSQL down Detects when PostgreSQL instances become unavailable, enabling quick response to maintain database services. Provides details about affected services and nodes. All users PostgreSQL PostgreSQL PostgreSQL restarted Identifies recent PostgreSQL restarts, alerting if an instance has been restarted within the last 5 minutes (default threshold). Aids in investigating unexpected downtime and potential issues. All users PostgreSQL PostgreSQL PostgreSQL connections in use Monitors PostgreSQL connection usage and alerts when the percentage of active connections exceeds 80% of the maximum allowed (default threshold). Helps prevent performance degradation due to excessive connections. All users PostgreSQL PostgreSQL PostgreSQL index bloat is high Detects excessive index bloat and alerts users. Helps identify performance degradation due to bloated indexes, enabling timely maintenance to improve query performance. Customers-only PostgreSQL PostgreSQL PostgreSQL high number of dead tuples Monitors the accumulation of dead tuples in relations and alerts when they exceed set thresholds. Indicates potential issues with vacuum settings and helps optimize storage and query performance. Customers-only PostgreSQL PostgreSQL PostgreSQL has a high number of statement timeouts Tracks and alerts on frequent query cancellations due to statement timeouts. Helps identify various issues such as high load, poorly written queries, or inadequate resource allocation. Customers-only PostgreSQL PostgreSQL PostgreSQL table bloat is high Detects excessive table bloat and alerts users. Indicates a need to adjust vacuum settings for specific relations or globally, helping to maintain optimal query performance and storage efficiency. Customers-only PostgreSQL PostgreSQL PostgreSQL high rate of transaction rollbacks Monitors the ratio of transaction rollbacks to commits and alerts on high rates. Helps identify potential application or database issues leading to frequent transaction failures. Customers-only PostgreSQL PostgreSQL PostgreSQL tables not auto analyzed Identifies tables that are not being auto-analyzed and alerts users. Crucial for maintaining accurate statistics and generating proper query execution plans. Customers-only PostgreSQL PostgreSQL PostgreSQL tables not auto vacuumed Detects tables that are not being auto-vacuumed and alerts users. Essential for managing bloat, optimizing storage, and maintaining overall database health. Customers-only PostgreSQL PostgreSQL PostgreSQL unused replication slot Identifies and alerts on unused replication slots. Helps prevent excessive WAL retention and potential disk space issues, especially when replicas are offline. Customers-only PostgreSQL"},{"location":"alert/templates_list.html#proxysql-templates","title":"ProxySQL templates","text":"Area Template name Description Available for Database technology ProxySQL ProxySQL server status Monitors ProxySQL server status and alerts when a server transitions to OFFLINE_SOFT (3) or OFFLINE_HARD (4) state. Includes critical details such as server endpoint, hostgroup, and associated ProxySQL service. This alert is essential for maintaining high availability and preventing database access disruptions. All users ProxySQL"},{"location":"api/index.html","title":"About PMM API","text":"<p>PMM Server provides a comprehensive REST API that enables you to monitor databases, manage resources, collect metrics, and automate PMM operations programmatically. The API supports endpoints for managing nodes, services, agents, alerting, backups, and other PMM components. </p> <p>The complete API documentation on Readme.io includes detailed endpoint specifications, authentication methods, example requests, and response schemas.</p>"},{"location":"api/index.html#interactive-api-documentation","title":"Interactive API documentation","text":"<p>You can explore and test the API using the built-in Swagger UI, accessible at the <code>/swagger/</code> endpoint of your PMM Server. The Swagger interface allows you to:</p> <ul> <li>browse available API endpoints</li> <li>view detailed request and response schemas</li> <li>execute API requests directly from the browser</li> <li>test different parameters and see live responses</li> </ul> <p></p>"},{"location":"api/index.html#core-api-resources","title":"Core API resources","text":"<p>The PMM API organizes resources into Nodes, Services and Agents. </p>"},{"location":"api/index.html#nodes","title":"Nodes","text":"<p>A Node represents a hosting environment where your services run and monitoring takes place. This can include bare metal servers, virtual machines, Docker containers, or cloud instances like Amazon RDS.</p> <p>Each Node can:</p> <ul> <li>host multiple Services and Agents</li> <li>receive insights from zero or more Agents</li> <li>be monitored independently of other components</li> </ul>"},{"location":"api/index.html#services","title":"Services","text":"<p>A Service represents a monitored database or application instance in your infrastructure. These include database systems like MySQL, MongoDB, Amazon Aurora, PostgreSQL, and other supported database types.</p> <p>Services can:</p> <ul> <li>run on zero nodes (serverless configurations)</li> <li>run on a single node (standalone installations)</li> <li>span multiple nodes (distributed systems like Percona XtraDB Cluster)</li> <li>receive monitoring insights from multiple Agents</li> </ul>"},{"location":"api/index.html#agents","title":"Agents","text":"<p>Agents are the monitoring components that:</p> <ul> <li>collect metrics, query data, and system information</li> <li>run on specific Nodes</li> <li>monitor multiple Services and/or Nodes</li> <li>include both internal PMM agents and External Exporters</li> </ul>"},{"location":"api/index.html#resource-types-and-management","title":"Resource types and management","text":"<p>All resources (Nodes, Services, and Agents) have specific Types which define their properties and operational logic. These Types determine how each resource behaves and what properties it can have within PMM.</p> <p>The management of these resources follows specific patterns:</p> <ul> <li>Nodes and Services: These are inherently external resources. PMM does not manage their actual creation or deletion. Instead, PMM maintains an inventory of these resources within PMM Server, allowing you to add them to or remove them from the inventory as needed.</li> <li>Agents: Most Agents are initiated and halted by pmm-agent. The exception is the External Exporter Type, which is initiated externally. Agents are responsible for collecting and reporting monitoring data about Nodes and Services.</li> </ul>"},{"location":"api/index.html#authentication","title":"Authentication","text":"<p>API access requires authentication using service account tokens. </p> <p>For details about controlling access to the PMM Server components and resources, see Authentication with service accounts topic.</p>"},{"location":"api/authentication.html","title":"Service accounts authentication","text":"<p>Deprecation notice</p> <p>Starting with version 3, PMM no longer uses API keys as the primary method for controlling access to the PMM Server components and resources. Instead, PMM is now leveraging Grafana service accounts, which have limited scopes and offer enhanced security compared to API keys.</p>"},{"location":"api/authentication.html#automatic-migration-of-api-keys","title":"Automatic migration of API keys","text":"<p>When you install PMM v3.x, any existing API keys will be seamlessly converted to service accounts with corresponding service tokens. For more information about the migration, see Migrate PMM 2 to PMM 3.</p> <p>Service accounts in PMM provide a secure and efficient way to manage access to the PMM Server and its resources. They serve as a replacement for the basic authentication and API keys used in previous versions of PMM (v.2 and earlier).</p> <p>With service accounts, you can:</p> <ul> <li>control access to PMM Server components and resources.</li> <li>define granular permissions for various actions.</li> <li>create and manage multiple access tokens for a single service account.</li> </ul> <p>Creating multiple tokens for the same service account is beneficial in the following scenarios:</p> <ul> <li>when multiple applications require the same permissions but need to be audited or managed separately. By assigning each application its own token, you can track and control their actions individually.</li> <li>when a token becomes compromised and needs to be replaced. Instead of revoking the entire service account, you can rotate or replace the affected token without disrupting other applications using the same service account.</li> <li>when you want to implement token lifecycle management. You can set expiration dates for individual tokens, ensuring that they are regularly rotated and reducing the risk of unauthorized access.</li> </ul>"},{"location":"api/authentication.html#service-account-name-management","title":"Service Account name management","text":"<p>To prevent node registration failures, PMM automatically manages service account names that exceed 200 characters using a <code>{prefix}_{hash}</code> pattern. For example, a very long service account name will be automatically shortened while maintaining uniqueness:</p> <ul> <li>original: <code>very_long_mysql_database_server_in_production_environment_with_specific_location_details...</code></li> <li>shortened: <code>very_long_mysql_database_server_in_prod_4a7b3f9d</code></li> </ul>"},{"location":"api/authentication.html#generate-a-service-account-and-token","title":"Generate a service account and token","text":"<p>PMM uses Grafana service account tokens for authentication. These tokens are randomly generated strings that serve as alternatives to API keys or basic authentication passwords.</p> <p>Here\u2019s how to generate a service account token:</p> <ol> <li>Log into PMM.</li> <li>From the side menu, click Administration &gt; Users and access.</li> <li>Click on the Service accounts card.</li> <li>Click Add service account. Specify a unique name for your service account, select a role from the drop-down menu, and click Create to display your newly created service account.</li> <li>Click Add service account token.</li> <li>In the pop-up dialog, provide a name for the new service token, or leave the field empty to generate an automatic name.</li> <li>Optionally, set an expiration date for the service account token. PMM cannot automatically rotate expired tokens, which means and you will need to manually update the PMM-agent configuration file with a new service account token. Permanent tokens, on the other hand, remain valid indefinitely unless specifically revoked.</li> <li>Click Generate Token. A pop-up window will display the new token, which usually has a glsa_ prefix.</li> <li>Copy your service token to the clipboard and store it securely. Now you can use your new service token for authentication in PMM API calls or in your pmm-agent configuration.</li> </ol>"},{"location":"api/authentication.html#authenticate","title":"Authenticate","text":"<p>You can authenticate your request using the HTTPS header.</p> <p>Important</p> <p>Use the <code>-k</code> or <code>--insecure</code> parameter to force cURL to ignore invalid and self-signed SSL certificate errors. The option will skip the SSL verification process, and you can bypass any SSL errors while still having SSL-encrypted communication. However, using the <code>--insecure</code>  parameter is not recommended. Although the data transfer is encrypted, it is not entirely secure. For enhanced security of your PMM installation, you need valid SSL certificates. For information on validating SSL certificates, see SSL certificates.</p> <pre><code>curl -H \"Authorization: Bearer &lt;service_token&gt;\" https://127.0.0.1/v1/version\n</code></pre>"},{"location":"api/authentication.html#use-a-service-token-in-basic-authentication","title":"Use a service token in basic authentication","text":"<p>You can include the service token as a query parameter in a REST API call using the following format. Replace YOUR_SERVICE_TOKEN with the actual service token you obtained in step 9.</p> <p>Example <pre><code>curl -X GET https://service_token:SERVICE_TOKEN@localhost/v1/version\n</code></pre></p>"},{"location":"api/authentication.html#use-a-service-token-in-bearer-authentication-http-header","title":"Use a service token in Bearer authentication (HTTP header)","text":"<p>You can also include the service token in the header of an HTTP request for authentication. To do this, replace <code>SERVICE_TOKEN</code> with the actual service token you obtained in step 9.</p> <p>Example <pre><code>curl -X GET -H 'Authorization: Bearer SERVICE_TOKEN' \\\n  -H 'Content-Type: application/json' https://127.0.0.1/v1/version\n</code></pre></p>"},{"location":"backup/index.html","title":"Back up and restore","text":"<p>Losing your data can destroy your business. This is why backing up data is critical for all database operations. Even more important than backing up data, is the ability to restore it in the event of data loss. PMM enables you to do all this with zero downtime and minimal performance impact.</p> <ul> <li>MongoDB (Generally Available)</li> <li>MySQL (in Technical Preview)</li> </ul> <p>Enable the Backup Management option in PMM\u2019s Advanced Settings to activate the Backup page from where you can: </p> <ul> <li>Create and restore MongoDB and MySQL backups </li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"backup/index.html#supported-setups","title":"Supported setups","text":"<p>For MySQL databases, you can create and restore on-demand and scheduled physical backups. For MongoDB, you can create and restore physical, logical and Point-in-Time-Recovery (PITR) backups, both on-demand and scheduled.</p>"},{"location":"backup/index.html#sharded-mongodb-cluster-configurations","title":"Sharded MongoDB cluster configurations","text":"<p>PMM 3 supports creating backups of sharded MongoDB clusters. However, the restoring process is not handled end-to-end, and requires you to manually restore the artifacts using the CLI in Percona Backup for MongoDB.</p>"},{"location":"backup/index.html#start-here","title":"Start here","text":"<p>To learn how to create and restore backups, check out subtopics below:</p> <ul> <li>Prepare a storage location</li> <li> MongoDB  backups</li> <li> MySQL backups </li> </ul> Additional resources <p>Here are some external resources for learning more about databases backups:</p> <ul> <li>Amazon Web Services S3</li> <li>Percona Backup for MongoDB</li> <li>PERCONA_QPRESS</li> <li>PERCONA_XBCLOUD</li> <li>PERCONA_XBSTREAM</li> <li>PERCONA_XTRABACKUP</li> <li>oplog slices</li> <li>Percona Server for MongoDB</li> <li>MongoDB Replication</li> </ul>"},{"location":"backup/delete_a_backup.html","title":"Delete a backup","text":"<p>You can only delete backup artifacts stored on Amazon S3-compatible. Local backups must be removed manually.</p> <p>To delete a backup:</p> <ol> <li>Go to   Backup &gt; All Backups and find the row with the backup you want to delete.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  &gt; Delete backup.</li> <li>In the Delete backup artifact dialog box, enable Delete from storage if you also want to delete the actual backup content besides just the backup register.</li> <li>Click Delete.</li> </ol>"},{"location":"backup/edit_scheduled.html","title":"Edit a scheduled backup","text":"<p>To edit a scheduled backup:</p> <ol> <li>Go to Backup &gt; Scheduled Backup Jobs.</li> <li>In the Actions column:<ul> <li>Click the switch  to enable or disable the backup.</li> <li>Click  to edit, delete or create a (by default, disabled) copy of the backup schedule.</li> </ul> </li> </ol> <p></p>"},{"location":"backup/prepare_storage_location.html","title":"Prepare a storage location","text":"<p>Prepare a storage location as a backup destination for creating and storing your backup artifacts.</p> <p>PMM supports the following types of storage:</p> <ul> <li>Amazon S3-compatible: enables you to use not only AWS S3, but also other storage solutions that support S3 API, like min.io.</li> <li>Local storage: currently only available for MongoDB backups.</li> </ul>"},{"location":"backup/prepare_storage_location.html#prepare-a-location-for-local-backups","title":"Prepare a location for local backups","text":"<p>If you prefer storing your MongoDB backup artifacts on a remote filesystem, make sure that you\u2019ve mounted the remote folder to all the mongoDB nodes on the same path, and that PBM tool has Write permissions on the path you define.</p> <p>For more information, see the Percona Backup for MongoDB (PBM) documentation.</p>"},{"location":"backup/prepare_storage_location.html#prepare-a-location-for-s3-compatible-storage","title":"Prepare a location for S3-compatible storage","text":"<p>If you want to store backup artifacts in S3-compatible storage, you can use Amazon S3, Min.io or any other storage solution with S3-compatible API.</p> <p>Before creating a cloud storage location for our future backups, make sure you have your S3-compatible storage ready. In addition to bucket location details, you will also need to ensure proper S3 permissions.</p> <p>The general minimum permissions are LIST/PUT/GET/DELETE. A sample IAM policy is:</p> <pre><code>    ```json\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:ListBucket\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing\"\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:PutObject\",\n                    \"s3:PutObjectAcl\",\n                    \"s3:GetObject\",\n                    \"s3:GetObjectAcl\",\n                    \"s3:DeleteObject\"\n                ],\n                \"Resource\": \"arn:aws:s3:::pmm-backup-testing/*\"\n            }\n        ]\n    }\n    ```\n</code></pre>"},{"location":"backup/prepare_storage_location.html#create-the-storage-location","title":"Create the storage location","text":"<ol> <li> <p>Go to Backup &gt; Storage Locations:</p> <p></p> </li> <li> <p>Click Add storage location and fill in a name and description for this new location.</p> </li> <li> <p>Choose the type of storage location you are creating:</p> <ul> <li>S3: Specify the S3-compatible backup location endpoint (URL), bucket name, and connection details. </li> <li>Local Client: specify the path on your local client for files to be backed up to.</li> </ul> </li> <li> <p>Optionally, for S3-compatible storages, you can click Test to check the connection.</p> </li> <li> <p>Click Add to create the location.</p> </li> </ol>"},{"location":"backup/prepare_storage_location.html#specific-target-directories-for-backups","title":"Specific target directories for backups","text":"<p>During backup creation, PMM enables you to set a specific folder within the local or S3-compatible location that you prepared following the instructions above. Organizing backups in folders not only makes it easier to group backups for an entire cluster, but also improves PMM-PBM (Percona Backup for MongoDB) integration workflows. </p> <p>The Folder field on the Create Backup pages is automatically populated with the value of the cluster label. You can change this default folder from PMM\u2019s Advanced Settings, but make sure you understand how your custom folder will impact PBM integration workflows.</p>"},{"location":"backup/mongodb-backup/backup_mongo.html","title":"Supported setups for MongoDB backups","text":"<p>PMM supports the following actions for MongoDB backups: </p> <p>Docker limitations</p> <p>MongoDB instances running in Docker containers are not supported for backup operations.</p>"},{"location":"backup/mongodb-backup/backup_mongo.html#replica-set-setups","title":"Replica set setups","text":"<p>The following backup operations are supported for replica sets:</p> <ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating and restoring Logical snapshot backups</li> <li>Creating and restoring Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage. Restoring logical PITR backups from S3-compatible object storage.</li> </ul>"},{"location":"backup/mongodb-backup/backup_mongo.html#sharded-clusters","title":"Sharded clusters","text":"<p>PMM 3 supports backing up sharded clusters. However, restoring for sharded cluster configurations is only supported from the CLI, and is handled via Percona Backup for MongoDB.</p> <ul> <li>Storing backups on Amazon S3-compatible object storage, and on mounted filesystem</li> <li>Creating Logical snapshot backups</li> <li>Creating Physical snapshot backups</li> <li>Creating logical PITR backups both locally and on S3-compatible object storage</li> </ul> <p>For a detailed overview of the supported setups for MongoDB, check out the Support matrix.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html","title":"Create MongoDB PITR backups","text":"<p>Point-in-Time Recovery (PITR) restores databases up to a specific moment in time. PITR includes restoring the data from a backup snapshot and replaying all events that occurred to this data up to a specified moment from oplog slices.</p> <p>Point-in-Time Recovery helps you prevent data loss during a disaster such as crashed database, accidental data deletion or drop of tables, or unwanted update of multiple fields instead of a single one.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#compatibility-with-percona-backup-for-mongodb","title":"Compatibility with Percona Backup for MongoDB","text":"<p>PMM introduced the option to create PITR Backups for MongoDB in version 2.23, as part of the larger Backup Management feature. This implementation in PMM uses Percona Backup for MongoDB (pbm) behind the scenes.</p> <p>Percona Backup for MongoDB is a distributed, low-impact solution for achieving consistent backups of MongoDB sharded clusters and replica sets. Restoring PITR backups is available for backups based on pbm \u2264 2.0.1. To restore PITR backups, make sure you have pbm \u2265 2.0.1 installed.</p> <p>Percona Backup for MongoDB supports Percona Server for MongoDB and MongoDB Community \u2264 3.6, with MongoDB Replication enabled. For more information, see the Percona Backup for MongoDB documentation.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#how-does-it-work","title":"How does it work?","text":"<p>When point-in-time recovery (PITR) is enabled, pbm-agent periodically saves consecutive slices of the oplog.</p> <p>To start saving oplog, PBM requires a backup snapshot. Such snapshots are created when you activate a PITR-scheduled task in PMM.</p> <p>Since PBM saves oplog slices and streams them into your storage between scheduled task runs, scheduling frequent PITR backups is not necessary. You can use the available oplog slices in your storage to restore a backup to any moment between snapshots.</p> <p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Select the Schedule Backup option in the Create Scheduled backup window.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select Logical as this is the only data model that currently supports PITR backups.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage.     However, restoring from local storage is not supported yet.     If no options are available here, see the Create a storage location topic.</li> <li>Specify the backup type and the schedule for your backup:<ul> <li>Backup Type: select the  PITR option.</li> <li>Schedule: configure the frequency and the start time for this backup.  </li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is not available for PITR backups. Currently, retention policies can only be specified for Snapshot backups stored on Amazon S3-compatible storage.</li> </ul> </li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual).      Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li> <p>In the Folder field, check the target directory available for the specified service and location. By default, this field comes prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre></p> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> </li> <li> <p>Click Schedule to start creating the backup artifact.</p> </li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis icon  shows that a backup is currently being created.</li> </ol> <p></p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#failed-backup-alerts","title":"Failed backup alerts","text":"<p>If you want to be notified of any MongoDB backups that fail, you can create an alert based on the Backup Failed alert template. For information on working with alert templates, see the Percona Alerting topic.</p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#pitr-artifacts","title":"PITR artifacts","text":"<p>The PITR oplog is available a few minutes (10 by default) after your PITR job has run for the first time. To see the corresponding PITR artifact, check out the list under Backup &gt; All Backups.</p> <p></p>"},{"location":"backup/mongodb-backup/create_PITR_mongo.html#pitr-and-other-scheduled-backups","title":"PITR and other scheduled backups","text":"<p>Make sure to disable any other scheduled backup jobs before creating a PITR backup. PMM displays an error message if you try to enable PITR while other scheduled backup jobs are active:</p> <p></p> <p>This constraint applies at the service level. You can still have PITR enabled for one service while having regular scheduled backup jobs for other services.</p>"},{"location":"backup/mongodb-backup/create_mongo_on_demand.html","title":"Create MongoDB on-demand and scheduled backups","text":"<p>Before creating a backup, make sure to check the MongoDB backup prerequisites.</p> <p>To schedule or create an on-demand backup, check the instructions below. If you want to create a Point-in-time-recovery (PITR) backup instead, see Create MongoDB PITR backups.</p> <ol> <li>Go to  Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>In the Create Scheduled backup window, select whether you want to create an On Demand or a Schedule Backup.</li> <li>Enter a unique name for the backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field.</li> <li>Select whether you want to create a Physical or Logical backup of your data, depending on your use case and requirements.</li> <li>Choose a storage location for the backup. MongoDB supports both Amazon S3-compatible and local storage. If no options are available here, see the Create a storage location topic.</li> <li> <p>Specify the backup type, the schedule, and a retention policy for your backup:</p> <ul> <li>Backup Type: select Full. If you want to create a PITR backup instead, see the Create MongoDB PITR backups topic</li> <li>Schedule: if you\u2019re creating a scheduled backup, configure its frequency and start time.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for snapshot backups stored on S3-compatible storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto-retry mode enables you to select up to ten retries and an interval of up to eight hours between retries. </li> <li> <p>In the Folder field, check the target directory available for the specified service and location. By default, this field is prefilled with the cluster label to ensure that all the backups for a cluster are stored in the same directory. If the field is not automatically populated, the service you have specified is not member of a cluster and should be re-added using the following set of commands:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre> </p> <p>Important</p> <p>Unless you are using verified custom workflows, make sure to keep the default Folder value coming from the cluster name. Editing this field will impact PMM-PBM integration workflows.</p> </li> </ul> </li> <li> <p>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</p> </li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis icon  shows that a backup is currently being created.</li> </ol>"},{"location":"backup/mongodb-backup/mongo_prerequisites.html","title":"MongoDB backup prerequisites","text":"<p>Before creating MongoDB backups, make sure to:</p> <ol> <li>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Management has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management  then click Apply changes.</li> <li>Prepare and create a storage location for your backups.</li> <li>Check that PMM Client is installed and running on all MongoDB nodes in the cluster.</li> <li>Check that Percona Backup for MongoDB (PBM) is installed and <code>pbm-agent</code> is running on all MongoDB nodes in the replica set. Make sure to configure the MongoDB connection URI for pbm-agent on all nodes.</li> <li>Check that installed mongod binary is added to PATH variable of the user under which PMM client is running, and that mongod is controlled as a service by systemctl. PMM only works with a single mongod installed on a node.</li> <li> <p>Check that your MongoDB Services are managed as clusters in PMM. Go to PMM Inventory &gt; Services page, expand the Details section  on the Options column, and make sure that all the services in the table specify a cluster name. Services that do not specify a cluster name should be removed and re-added using commands like the following:   <pre><code>pmm-admin add mongodb \\\n   --username=pmm_mongodb --password=password \\\n   query-source=profiler --cluster=mycluster</code></pre> </p> </li> <li> <p>Check that MongoDB nodes are members of replica set.</p> </li> <li>Check that you set the required permissions for creating and restoring MongoDB backups.</li> <li>Verify the MongoDB supported configurations and limitations.</li> </ol> <p>Important</p> <p>Use <code>pbm</code> in manual mode only for restoring sharded cluster backups or other operations that can only be completed via the PBM CLI! Since PMM takes care of the PBM configuration, any unnecessary manual intervention can break the state.</p> <p>PMM 3 and later require PBM 2.0.1 or newer.</p>"},{"location":"backup/mongodb-backup/mongodb_limitations.html","title":"MongoDB Backup and Restore support matrix","text":"<p>Creating and restoring MongoDB backups in PMM currently has the following limitations and requirements:</p> <ul> <li>Physical backups and restores are supported only for Percona Server for MongoDB.</li> <li>Physical restores are not supported for deployments with arbiter nodes. For more information, see the Percona Backup for MongoDB documentation.</li> <li>Creating backups for sharded clusters is available straight from the UI. However, restoring these backup artifacts is only possible via the CLI, using Percona Backup for MongoDB. For information on restoring sharded backups, check the PBM documentation.</li> <li>Retention policy is supported only for snapshot types of scheduled backups and for the S3-compatible storage type.</li> <li>Before restoring, make sure to prevent clients from accessing the database.</li> </ul>"},{"location":"backup/mongodb-backup/mongodb_limitations.html#support-matrix","title":"Support matrix","text":""},{"location":"backup/mongodb-backup/mongodb_limitations.html#backup-logical","title":"Backup: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local Full Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#backup-physical","title":"Backup: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#restore-logical","title":"Restore: Logical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 Full PITR Local No Full S3 Full Full Local Full"},{"location":"backup/mongodb-backup/mongodb_limitations.html#restore-physical","title":"Restore: Physical","text":"Full or PITR Storage type (S3 or Local) Support level PITR S3 No PITR Local No Full S3 Partial* Full Local Partial* <p>* Partial support for non-containerized deployments and NO support for containerized deployments.                             </p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html","title":"Restore a MongoDB backup","text":"<p>MongoDB backups can only be restored to the same service they were created from.</p> <p>To restore a backup:</p> <ol> <li>Go to  Backup &gt; All backups and find the backup that you want to restore.</li> <li>Click the arrow in the Actions column to check all the information for the backup, then click  Restore from backup. This opens the Restore from backup dialog, with the Same service option automatically preselected. This is because, currently, MongoDB backups can only be restored to a service with identical properties.</li> <li>If you are restoring a PITR backup, select the point for the date and time that you want to restore the database to.</li> <li>Click Restore then go to the Restores tab to check the status of the restored backup.</li> </ol> <p>Important</p> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html#restore-to-a-new-cluster-manually","title":"Restore to a new cluster manually","text":"<p>To restore to a new cluster manually:</p> <ol> <li>Install MongoDB and Percona Backup for MongoDB. Pay attention to the versions. To minimize potential incompatibility, use the same versions that were used for taking backups.    For instructions, see the PBM install documentation.</li> <li> <p>Configure your environment:</p> <ul> <li>to restore to a new environment with the same replica set name, make sure that the replica set name in your new destination cluster use the same name as that in the cluster that was backed up.   For more information, see Restoring a backup into a new-environment in the PBM documentation.  </li> <li> <p>to restore logical backups to a new environment that has a different replica set name, configure the name mapping between the source and target environments.    For the new environment, you can either set the PBM_REPLSET_REMAPPING environment variable for pbm CLI, or use the <code>--replset-remapping</code> flag for PBM commands.</p> <p>The mapping format is <code>&lt;rsTarget&gt;=&lt;rsSource&gt;</code>.</p> <p>For example:</p> <p><code>$ export PBM_REPLSET_REMAPPING=\"targetRS=sourceRS\"</code></p> <p>OR </p> <p><code>$ pbm restore &lt;timestamp&gt; --replset-remapping=\"targetRS=sourceRS\"</code></p> <p>For more information, see Restoring into a replica set with a different name in the PBM documentation.</p> </li> </ul> </li> <li> <p>Make sure that Percona Backup for MongoDB configuration in the new environment points to the remote storage defined for the original environment, including the authentication credentials for object stores.</p> <p>The easiest way to configure it is to create a config file, called, for example, <code>pbm_config.yaml</code>.</p> <p>For this, you can either copy the config from the source host or create a new one.</p> <p>To redirect the config output from the existing environment, use: <pre><code>  pbm config &gt;&gt; pbm_config.yaml\n</code></pre> then copy the resulting file to the new environment.</p> <p>Here\u2019s an example of config file content for AWS S3-compatible storage:</p> <p><pre><code>storage:\n  type: s3\n  s3:\n    region: us-west-2\n    bucket: pbm-test-bucket\n    prefix: backup_name_from_pmm\n    credentials:\n      access-key-id: &lt;your-access-key-id-here&gt;\n      secret-access-key: &lt;your-secret-key-here&gt; \n</code></pre> The prefix name is the artifact name that appears in the Backup name column, under  Backup &gt; All Backups page:</p> <p> </p> <p>To implement the config, use the following command:     <pre><code>pbm config --file pbm_config.yaml\n</code></pre></p> <p>For more information, see Restoring a backup into a new-environment in the PBM documentation.  </p> </li> <li> <p>Run <code>pbm list</code> to check if pbm is ready to perform the restore procedure.</p> </li> <li> <p>Once all the backups made from the original environment are available, run the restore command:</p> <ul> <li> <p>For snapshot backups:</p> <p>a) run the following command:</p> <p><pre><code>pbm list\n  Backup snapshots: 2022-11-23T19:40:06Z [restore_to_time: 2021-01-13T15:53:40Z]\n</code></pre> b) provide the timestamp of the backup to the <code>pbm</code> command:</p> <p><code>pbm restore 2022-11-23T19:40:06Z</code></p> <p>For more information, see Restore a backup topic in the PBM documentation.</p> </li> <li> <p>For PITR backups:</p> <p>a) run the following command:</p> <p><pre><code>  pbm list\n  Backup snapshots:\n    2022-11-23T19:40:06Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:40:25Z]\n    2022-11-23T19:45:07Z &lt;logical&gt; [restore_to_time: 2022-11-23T19:45:22Z]\n  PITR &lt;on&gt;:\n    2022-11-23T19:40:26Z - 2022-11-23T19:45:22Z\n</code></pre>     b) provide the timestamp from one of the PITR ranges to the <code>pbm</code> command:</p> <p><code>pbm restore --time=\"2022-11-23T19:40:26</code></p> </li> </ul> <p>For more information, see the Point-in-time Recovery topic in the PBM documentation.</p> </li> <li> <p>Check the progress of the restore operation, using one of the commands below:</p> <ul> <li> <p>For logical restores: <code>pbm describe-restore &lt;restore_name&gt;</code></p> </li> <li> <p>For physical restores: <code>pbm describe-restore --config=/path/to/pbm_config.yaml &lt;restore_name&gt;</code></p> </li> </ul> <p>Required arguments:</p> <ul> <li>PBM generates the <code>&lt;restore_name&gt;</code> information after you start the restoring.</li> <li>The pbm_config.yaml file required for physical restores is the PBM config file that you provided for step 3.</li> </ul> </li> </ol> <p>Important</p> <p>Make sure not to run pbm backup from the new environment while the Percona Backup for MongoDB config is pointing to the remote storage location of the original environment.</p>"},{"location":"backup/mongodb-backup/restore_MongoDB_backups.html#restoring-from-a-sharded-cluster","title":"Restoring from a sharded cluster","text":"<p>Sharded cluster backups are supported and PMM handles the backup process end-to-end. However, restoring such artifacts is currently possible only via the CLI, using Percona Backup for MongoDB.</p> <p>For information on restoring sharded backups, check the PBM documentation</p>"},{"location":"backup/mysql-backup/backup_mysql.html","title":"Supported setups for MySQL backups","text":"<p>Important</p> <p>MySQL backup functionality is still in Technical Preview.</p> <p>PMM supports MySQL database server for:</p> <ul> <li>Creating and restoring physical backups</li> <li>Storing backups to Amazon S3-compatible object storage  </li> </ul>"},{"location":"backup/mysql-backup/backup_mysql.html#backing-up-mysql-databases-hosted-in-docker-container","title":"Backing up MySQL databases hosted in Docker container","text":"<p>To ensure PMM can correctly backup and restore databases from a MySQL Docker container, make sure that the container is compatible with systemd.</p>"},{"location":"backup/mysql-backup/create_mysql_backup.html","title":"Create a MySQL backup","text":"<p>Before creating a backup, make sure to check the MySQL backup prerequisites.</p> <p>To create a backup:</p> <ol> <li>Go to   Backup &gt; All Backups.</li> <li>Click  Create Backup.</li> <li>Specify the type of backup that you want to create: On Demand or Schedule Backup.</li> <li>Enter a unique name for this backup.</li> <li>Choose the service to back up from the Service name drop-down menu. This automatically populates the DB Technology field and selects the Physical data model, as this is the only model available for MySQL backups.</li> <li>Choose a storage location for the backup. MySQL currently only supports storing backups to Amazon S3. If no options are available here, see the Create a storage location topic section above.</li> <li>If you\u2019re creating scheduled backups, also specify the backup type, the schedule, and a retention policy for your backup:<ul> <li>Backup Type: currently, PMM only supports Full backup types for MySQL.</li> <li>Schedule: configure the frequency and the start time for this backup.</li> </ul> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also check that your specified schedule does not overlap with production hours.</p> <ul> <li>Retention: this option is only available for Snapshot backups stored on S3-compatible object storage. If you want to keep an unlimited number of backup artifacts, type <code>0</code>.</li> </ul> </li> <li>Leave the Folder field as is. This field is relevant for MongoDB backups to ensure compatibility with PBM wokflows and comes prefilled with the cluster label.</li> <li>Expand Advanced Settings to specify the settings for retrying the backup in case of any issues. You can either let PMM retry the backup again (Auto), or do it again yourself (Manual). Auto retry mode enables you to select up to ten retries and an interval of up to eight hours between retries.</li> <li>To start creating the backup artifact, click Backup or Schedule at the top of the window, depending on whether you are creating a scheduled or an on-demand backup.</li> <li>Go to the All Backups tab, and check the Status column. An animated ellipsis icon  shows that a backup is currently being created.</li> </ol>"},{"location":"backup/mysql-backup/mysql_prerequisites.html","title":"MySQL backup prerequisites","text":"<p>Before creating MySQL backups, make sure to:</p> <ol> <li> <p>Check that Backup Management is enabled and the  Backup option is available on the side menu. If Backup Managemt has been disabled on your instance, go to  Configuration &gt; PMM Settings &gt; Advanced Settings, re-enable Backup Management then click Apply changes.    !!! caution alert alert-warning \u201cImportant\u201d     If PMM Server runs as a Docker container, enable backup features at container creation time by adding <code>-e ENABLE_BACKUP_MANAGEMENT=1</code> to your <code>docker run</code> command.</p> </li> <li> <p>Check that the PMM Client is installed and running on the node.</p> </li> <li> <p>To enable Xtrabackup for MySQL 8.0+, check that pmm-agent connects to MySQL with a user that has BACKUP_ADMIN privilege.</p> </li> <li> <p>Check that there is only one MySQL instance running on the node.</p> </li> <li> <p>Verify that MySQL is running:</p> <ul> <li> <p>as a service via <code>systemd</code>;</p> </li> <li> <p>with the name <code>mysql</code> or <code>mysqld</code> (to confirm, use <code>systemctl status mysql</code> or <code>systemctl status mysqld</code> respectively);</p> </li> <li> <p>from a <code>mysql</code> system user account.</p> </li> </ul> </li> <li> <p>Make sure that there is a <code>mysql</code> system group.</p> </li> <li> <p>Check that MySQL is using the <code>/var/lib/mysql</code> directory for database storage.</p> </li> <li> <p>Make sure that <code>pmm-agent</code> has read/write permissions to the <code>/var/lib/mysql</code> directory.</p> </li> <li> <p>Check that the latest versions of the following packages are installed and included in the <code>$PATH</code> environment variable:</p> <ul> <li> <p><code>xtrabackup</code>, which includes:</p> <ul> <li> <p><code>xbcloud</code></p> </li> <li> <p><code>xbstream</code></p> </li> </ul> </li> <li> <p>[<code>qpress</code>][PERCONA_QPRESS].</p> </li> </ul> </li> </ol> <p>Important</p> <p>The versions of each must be compatible with the installed version of MySQL.</p>"},{"location":"backup/mysql-backup/restore_mysql_backup.html","title":"Restore a MySQL backup","text":""},{"location":"backup/mysql-backup/restore_mysql_backup.html#restore-compatibility","title":"Restore compatibility","text":"<p>MySQL backups can be restored to the same service it was created from, or to a compatible one. </p> <p>To restore a backup:</p> <ol> <li>Go to  Backup &gt; All backups and find the backup that you want to restore.</li> <li>Click the three dots  in the Actions column to check all the information for the backup, then click  Restore from backup.</li> <li>In the Restore from backup dialog, select Same service to restore to a service with identical properties or Compatible services to restore to a compatible service.</li> <li>Select one of the available service names from the drop-down menu.</li> <li>Check the values, then click Restore.</li> <li>Go to the Restores tab to check the status of the restored backup.</li> </ol> <p>During restoring, PMM disables all the scheduled backup tasks for the current service. Remember to re-enable them manually after the restore.</p>"},{"location":"configure-pmm/advanced_settings.html","title":"Advanced PMM settings","text":""},{"location":"configure-pmm/advanced_settings.html#data-retention","title":"Data retention","text":"<p>Data retention specifies how long data is stored by PMM Server. By default, time-series data is stored for 30 days. You can adjust the data retention time to balance your system\u2019s available disk space with your metrics history requirements.</p>"},{"location":"configure-pmm/advanced_settings.html#telemetry","title":"Telemetry","text":"<p>The Telemetry switch enables gathering and sending basic anonymous data to Percona, which helps us to determine where to focus the development and what is the uptake for each release of PMM.  Specifically, gathering this information helps determine if we need to release patches to legacy versions beyond support, determine when supporting a particular version is no longer necessary, and understand the best frequency of releases.</p> <p>PMM Telemetry is based on data collected by various PMM components and stored inside PMM Server </p> <p>When PMM is installed, telemetry is not sent immediately. Before the first telemetry report is generated, PMM provides users with a 24-hour grace period to disable telemetry.</p> <p>To see the metrics being collected by telemetry, from the main menu navigate to PMM Configuration &gt;  Settings &gt; Advanced Settings &gt; Telemetry and hover over the exclamation mark.</p> <p></p> <p>We do not gather anything that can identify your system, but consider the following:</p> <ol> <li> <p>The Country Code is evaluated from the submitting IP address before being discarded.</p> </li> <li> <p>We do create an \u201cinstance ID\u201d - a random string generated using UUID v4.  This instance ID is generated to distinguish new instances from existing ones, for figuring out instance upgrades.</p> </li> </ol> <p>The first telemetry reporting of a new PMM Server instance is delayed by 24 hours to allow enough time to disable the service for those that do not wish to share any information.</p> <p>The landing page for this service, check.percona.com, explains what this service is.</p> <p>Grafana\u2019s anonymous usage statistics is not managed by PMM. To activate it, you must change the PMM Server container configuration after each update.</p> <p>As well as via the PMM Settings page, you can also disable telemetry with the <code>-e DISABLE_TELEMETRY=1</code> option in your docker run statement for the PMM Server.</p> <p>For information on the various config parameters for telemetry, see the config file.</p>"},{"location":"configure-pmm/advanced_settings.html#check-for-updates","title":"Check for updates","text":"<p>When active, PMM will automatically check for updates and put a notification in the home page Updates dashboard if any are available.</p>"},{"location":"configure-pmm/advanced_settings.html#advisors","title":"Advisors","text":"<p>Advisors are sets of checks grouped by functionality that run a range of database health checks on a registered PMM instance.</p> <p>The findings are reported on the Advisors &gt; Advisor Insights page, and an overview is displayed on the Home dashboard.</p> <p>The Advisors option is enabled by default. Checks are re-fetched and rerun at intervals.</p> <p>See Working with Advisor checks.</p>"},{"location":"configure-pmm/advanced_settings.html#percona-alerting","title":"Percona Alerting","text":"<p>Enables Percona Alerting and reveals the Percona templated alerts option on the Alerting page.</p>"},{"location":"configure-pmm/advanced_settings.html#backup-management","title":"Backup Management","text":"<p>Enables Backup Management option and reveals the Backup page from where you can:</p> <ul> <li>Create and restore MongoDB and MySQL backups</li> <li>Automate backup scheduling</li> <li>Set retention policies</li> <li>Monitor your backup and restore activity</li> </ul>"},{"location":"configure-pmm/advanced_settings.html#public-address","title":"Public Address","text":"<p>The address or hostname PMM Server will be accessible at. Click Get from browser to have your browser detect and populate this field automatically.</p>"},{"location":"configure-pmm/advanced_settings.html#microsoft-azure-monitoring","title":"Microsoft Azure monitoring","text":"<p>Caution</p> <p>This is a technical preview feature.</p> <p>Activates Microsoft Azure monitoring.</p>"},{"location":"configure-pmm/configure.html","title":"Configure PMM","text":"<p>This section provides the instructions to configure your PMM instance after you have installed PMM.</p> <p>The PMM Configuration page gives you access to PMM setup\u2019s settings and inventory options:</p> <ul> <li>Metrics resolution</li> <li>Advanced Settings<ul> <li>Data retention</li> <li>Telemetry</li> <li>Check for updates</li> <li>Advisors</li> </ul> </li> <li>Public address<ul> <li>Alerting</li> <li>Microsoft Azure Monitoring</li> </ul> </li> <li>SSH Key</li> <li>Percona Portal<ul> <li>Check Percona Portal account information</li> <li>Connect PMM to Percona Platform</li> </ul> </li> </ul> <p>You can also use the Administration page to manage Grafana-related configurations and account settings.</p>"},{"location":"configure-pmm/metrics_res.html","title":"Metrics resolution","text":"<p>Metrics are collected at three intervals representing low, medium and high resolutions.</p> <p>The Metrics Resolution settings tab contains three fixed presets (Rare, Standard and Frequent) and an editable custom preset (Custom). Each preset is a group of low, medium and high resolutions. The values are in seconds.</p> <p></p> <p>Time intervals and resolutions</p> <p>Short time intervals are high resolution metrics. Longer time intervals are low resolution. So:</p> <ul> <li>A low resolution interval increases the time between collection, resulting in low-resolution metrics and lower disk usage.</li> <li>A high resolution interval decreases the time between collection, resulting in high-resolution metrics and higher disk usage.</li> </ul> <p>The default values (in seconds) for the fixed presets and their resolution names are:</p> Editable? Preset Low Medium High No Rare 300 180 60 No Standard 60 10 5 No Frequent 30 5 1 Yes Custom (defaults) 60 10 5 <p>Values for the Custom preset can be entered as values, or changed with the arrows.</p> <p>Note</p> <p>If there is poor network connectivity between PMM Server and PMM Client, or between PMM Client and the database server being monitored, scraping every second may not be possible when the network latency is greater than 1 second.</p>"},{"location":"configure-pmm/ssh.html","title":"SSH Key","text":"<p>This section enables you to upload your public SSH key for SSH access to the PMM Server, such as when accessing it as a virtual appliance.</p> <p></p> <p>Enter your public key in the SSH Key field and click Apply SSH Key.</p>"},{"location":"configure-pmm/percona_platform/account-info.html","title":"Check Percona Portal account information","text":"<p>When you connect your PMM instances to Percona Platform, PMM gets access to:</p> <ul> <li>more alert templates</li> <li>Registered Advisor Checks for additional database checks</li> <li>Paid Advisor Checks for more advanced database health checks. </li> </ul> <p>Paid checks are available when you connect to Percona Platform with a customer account.</p> <p>You can check the list of available Paid Advisor checks on the Advisors details page.</p> <p>When you connect with a customer account, PMM  reveals two new tabs on the main menu, where you can check all the information available for your customer accounts:  Entitlements and Support tickets:</p> <p></p> <p></p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html","title":"Connect PMM to Percona Platform","text":"<p>To connect your PMM Server to Percona Platform, copy your personal access token from Platform Portal and paste it into PMM. You will find your access token in Platform Portal as part of your user profile page.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#token-validity","title":"Token validity","text":"<p>For security reasons, access tokens expire after 30 minutes. Make sure to paste the code before that, or generate a new one if it expires.</p> <p>To connect your PMM Server to Percona Platform:</p> <ol> <li> <p>In PMM, go to PMM Configuration &gt; Settings &gt; Percona Platform tab to fill in the Connect PMM to Percona Portal form: </p> </li> <li> <p>The PMM Server ID field is automatically populated with the ID identified for your PMM instance. Enter the name of your PMM instance and click Get token to go to Percona Platform Portal and generate your access token.</p> </li> <li>Log into Percona Platform using your Percona Account (if you don\u2019t have an active current session).</li> <li>On the Profile Settings page, copy the code from the Percona Platform Access Token field.</li> <li>Back into PMM, paste the Access Token into the Percona Platform Access Token field, and click  Connect.</li> </ol> <p>To confirm that you have successfully connected the server and check the list of all servers currently connected to an organization, go to Percona Platform &gt; Dashboard tab and click View Instances next to the Connect your PMM step.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#check-percona-portal-entitlements","title":"Check Percona Portal entitlements","text":"<p>After connecting to the Percona Platform, PMM has access to additional alert templates, Advisor checks, and account information. See Check Percona Portal account information.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#disconnect-a-pmm-instance","title":"Disconnect a PMM instance","text":"<p>Disconnect a PMM instance when you want to unlink it from your Percona Platform organization or stop monitoring it there.</p> <p>To disconnect a PMM Server, go to  Configuration &gt; Settings &gt; Percona Platform and click Disconnect.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#disconnecting-instances-as-an-admin","title":"Disconnecting instances as an Admin","text":"<p>In situations where you are not able to disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you cannot disconnect servers yourself, ask your PMM Admin to disconnect the server for you. For example, you may not be able to disconnect servers when PMM is moved to a network segment without outbound connections to public networks.</p> <p>If you are a PMM Admin, you can terminate any connections to Percona Platform, even if you are not logged into PMM with a Percona Account. However, we recommend logging in with a Percona Account before disconnecting servers, as this will automatically remove the disconnected servers from Percona Platform as well. </p> <p>If you do disconnect servers without being connected with a Percona Account, you\u2019ll have to manually remove the unavailable servers from Percona Platform. This ensures that your list of connected PMM instances stays up-to-date in Percona Platform. </p> <p>To do this, go to PMM instances, and remove any servers that you have already disconnected from PMM.</p>"},{"location":"configure-pmm/percona_platform/check_percona_platform.html#sign-into-pmm-with-your-percona-account","title":"Sign into PMM with your Percona Account","text":"<p>Once you\u2019ve successfully connected your PMM instance to the Percona Platform, you can also sign into PMM using your Percona Account:</p> <ol> <li>Log out of your existing PMM session.</li> <li>On the PMM login screen, click Sign in with Percona Account.  If you have an active Percona Account session on the same browser, PMM will log you in automatically. Otherwise, enter your Percona Account credentials to start a new session.</li> </ol>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html","title":"Integrate PMM with Percona Platform","text":"<p>Percona Platform brings together database distributions, support expertise, services, management, and automated insights.</p> <p>Connect your PMM Servers to Percona Platform to boost the monitoring capabilities of your PMM installations and manage database deployments easier. In addition, you get access to PMM updates, automated insights, advanced advisor checks and more alert rule templates.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#connect-pmm-to-percona-platform","title":"Connect PMM to Percona Platform","text":"<p>You can connect to Percona Platform with a Percona Account or via Google or GitHub authentication. If Percona Support has enabled a custom identity provider for your account, you can also log in using your company\u2019s credentials.</p> <p>We recommend that you connect with a Percona Account, as this gives you access to other Percona services, including Percona Platform, Percona Customer Portal, and Community Forum. If you don\u2019t have a Percona Account, you can create one on the Percona Platform homepage using the Don\u2019t have an account? Create one? link.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#prerequisites","title":"Prerequisites","text":"<p>To ensure that PMM can establish a connection to Percona Platform:</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#check-that-you-are-a-member-of-an-existing-platform-organization","title":"Check that you are a member of an existing Platform organization","text":"<p>To check whether you are a member of an existing Platform organization:</p> <ol> <li> <p>Log in to Percona Platform using your Percona Account. If you are connecting via GitHub, make sure you set your email address as public in your GitHub account. If your email address is private instead, Percona Platform cannot access it to authenticate you.</p> </li> <li> <p>On the Getting Started page, check that the Create organization step shows an option to view your organization.</p> </li> </ol> <p>Contact your account administrator or create a new organization for your Percona Account if this is the case.</p>"},{"location":"configure-pmm/percona_platform/integrate_with_percona_platform.html#set-the-public-address-of-your-pmm-server","title":"Set the public address of your PMM Server","text":"<p>PMM automatically detects and populates the public address of the PMM Server when this is not set up.  If you need to set it differently, go to Settings &gt; Advanced Settings and edit the  Public Address field.</p>"},{"location":"discover-pmm/features.html","title":"Key features","text":"<p>The following features make Percona Monitoring and Management a powerful tool for database administrators and DevOps teams to monitor, analyze, and optimize the performance of their database infrastructure:</p> <ul> <li> <p>Query Analytics: PMM provides insights into database query performance and enables you to identify slow queries, analyze query execution plans, and optimize them.</p> </li> <li> <p>Monitoring: PMM comprehensively monitors the key performance metrics such as CPU usage, memory, disk I/O, network traffic, and other database-specific metrics. In addition to understanding the health of your database infrastructure, these metrics help you discover new patterns in database behavior and identify performance bottlenecks, regardless of where they are located or deployed.</p> </li> <li> <p>User-friendly dashboards: PMM provides an intuitive graphical user interface with customizable dashboards that enable you to visualize and analyze your database\u2019s performance.</p> </li> <li> <p>Alerting: PMM enables setting up alerts based on predefined thresholds for various metrics. When these thresholds are exceeded, PMM sends notifications via email or other channels, facilitating proactive management and quick resolution.</p> </li> <li> <p>Percona Advisors: Built-in Advisors run regular checks on the databases connected to PMM. The checks identify and alert you of potential security threats, performance degradation, data loss, and data corruption.</p> </li> <li> <p>Backup and restore: PMM enables you to back up critical data with zero downtime and minimal performance impact. Furthermore, you can schedule various backups (hot, incremental, physical) and restore databases up to a specific moment with the Point-in-Time-Recovery feature.</p> </li> </ul>"},{"location":"discover-pmm/why-pmm.html","title":"Why PMM?","text":"<p>Percona Monitoring and Management (PMM) delivers:</p> <ul> <li>Comprehensive monitoring of MySQL, MariaDB, MongoDB, and PostgreSQL databases</li> <li>Query performance insights to identify and optimize slow queries for improved system efficiency</li> <li>Database-specific features tailored for deep monitoring of different database engines</li> <li>Built-in security with SSL encryption and robust authentication</li> <li>Flexible customization through custom dashboards, metrics, and exporters</li> <li>Centralized management of multiple database instances across different hosts</li> <li>Active community support with regular updates and improvements</li> </ul> <p></p>"},{"location":"install-pmm/index.html","title":"PMM installation overview","text":"<p>Installing Percona Monitoring and Management (PMM) involves setting up a central PMM Server and distributed PMM Clients that work together to monitor your database environment. </p> <p>PMM Server provides the web interface with dashboards and analytics, while PMM Clients collect data from your databases with minimal performance impact and send it back to PMM Server for analysis and visualization.</p>"},{"location":"install-pmm/index.html#what-the-installation-involves","title":"What the installation involves","text":"<p>The PMM installation consists of three main steps that need to be completed in sequence: </p> <ol> <li>Install PMM Server: centralized platform that collects, analyzes, and visualizes your monitoring data</li> <li>Install PMM Clients: lightweight agents on each database host that collect metrics without impacting performance</li> <li>Configure monitoring services: connect PMM to your database instances, select which metrics to collect, and customize monitoring parameters</li> </ol>"},{"location":"install-pmm/index.html#plan-the-installation","title":"Plan the installation","text":"<p>Before ou install PMM, ensure your environment is properly prepared:</p> <ul> <li>Choose a deployment strategy based on your environment needs.</li> <li>Verify hardware requirements to ensure your system meets the necessary specifications.</li> <li>Configure your network for the required connections.</li> </ul>"},{"location":"install-pmm/index.html#pmm-server-deployment-options","title":"PMM Server deployment options","text":"<p>Compare the available deployment methods to choose what works best for your setup. For a fast evaluation setup, Docker is the quickest option. For production environments, consider your existing infrastructure stack and operational preferences when choosing between Docker, Kubernetes (Helm), or Virtual Appliance deployments:</p> Deployment Method Best for Advantages Considerations Docker Quick setup, development environments \u2022 Fast deployment\u2022 Easy to manage\u2022 Runs without root privileges\u2022 Minimal resource overhead \u2022 Requires Docker knowledge\u2022 May need additional network configuration Podman Security-conscious environments \u2022 Rootless by default\u2022 Enhanced security\u2022 Docker-compatible commands\u2022 No daemon required \u2022 Requires Podman installation\u2022 Less common than Docker Helm Kubernetes environments \u2022 Native Kubernetes deployment\u2022 Scalable and orchestrated\u2022 ConfigMap and Secret management\u2022 Ingress controller support \u2022 Requires Kubernetes cluster\u2022 Helm knowledge needed\u2022 More complex setup Virtual Appliance Traditional VM environments \u2022 Pre-configured virtual machine\u2022 Works with VMware, VirtualBox\u2022 No container knowledge required\u2022 Isolated environment \u2022 Larger resource footprint\u2022 VM management overhead\u2022 Less flexible than containers Amazon AWS AWS cloud deployments \u2022 Wizard-driven install\u2022 Rootless deployment\u2022 Integrated with AWS services \u2022 Paid service, incurs infrastructure costs\u2022 AWS-specific deployment"},{"location":"install-pmm/index.html#installation-steps","title":"Installation steps","text":""},{"location":"install-pmm/index.html#1-install-pmm-server","title":"1. Install PMM Server","text":"<p>Install and run at least one PMM Server using one of the following deployment methods. If you\u2019re not sure which deployment method is best for your environment, check out this Choose a PMM deployment strategy topic for a comparison of your options.</p>  Docker Podman Helm Virtual Appliance AWS Marketplace <p>Run PMM Server as a Docker container</p> <p>Get started with Docker deployment </p> <p>Run PMM Server as a rootless Podman container</p> <p>Get started with Podman deployment </p> <p>Deploy PMM Server on a Kubernetes cluster</p> <p>Get started with Kubernetes deployment </p> <p>Run PMM Server as a pre-configured virtual machine</p> <p>Get started with Virtual Appliance </p> <p>Deploy PMM Server from AWS Marketplace</p> <p>Get started with AWS deployment .</p>"},{"location":"install-pmm/index.html#2-install-pmm-client","title":"2. Install PMM Client","text":"<p>Install and run PMM Client on every node where there is a service you want to monitor. Choose the installation method that best fits your environment:</p>"},{"location":"install-pmm/index.html#client-installation-options","title":"Client installation options","text":"With package manager With binary package With Docker <p>Linux package: Use <code>apt</code>, <code>apt-get</code>, <code>dnf</code>, <code>yum</code>.  The package manager automatically selects the correct version for your architecture.</p> <p>Binary package: Download the appropriate <code>.tar.gz</code> file for your architecture (x86_64 or ARM64).</p> <p>Running PMM Client as a Docker container simplifies deployment across different architectures and automatically selects the appropriate image for your architecture (x86_64 or ARM64).</p>"},{"location":"install-pmm/index.html#3-add-services-for-monitoring","title":"3. Add services for monitoring","text":"<p>After installing PMM Client, configure the nodes and services you want to monitor. </p> <p>PMM supports monitoring across the following database technologies, cloud services, proxy services, and system metrics:</p>  Database services Cloud services System &amp; infrastructure Proxy services <p>Monitor relational and NoSQL database instances:</p> <ul> <li>MySQL and variants (Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> </ul> <p>Monitor cloud-hosted database services and platforms:</p> <ul> <li>Microsoft Azure</li> <li>Google Cloud Platform</li> <li>Amazon RDS </li> </ul> <p>Monitor system resources and infrastructure components:</p> <ul> <li>Linux systems</li> <li>Remote instances</li> <li>External services</li> </ul> <p>Monitor database proxy and load balancing services:</p> <ul> <li>ProxySQL</li> <li>HAProxy</li> </ul>"},{"location":"install-pmm/HA.html","title":"Install PMM in High Availability (HA) mode","text":"<p>When your database monitoring goes down, you lose visibility into critical performance issues just when you need it most. HA ensures your PMM monitoring stays online even when servers fail, networks disconnect, or hardware breaks.</p> <p>Implement HA to build a resilient PMM deployment that keeps monitoring your databases no matter what happens to individual components.</p>"},{"location":"install-pmm/HA.html#understand-what-pmm-ha-can-and-cant-do","title":"Understand what PMM HA can and can\u2019t do","text":"<p>Before you invest time in setting up HA for PMM, evaluate whether its benefits justify the added complexity for your specific use case.</p> <p>Critical systems requiring sub-second failover gain the most value from PMM HA, while environments that can tolerate brief monitoring gaps (seconds to minutes) may find simpler solutions more appropriate. Consider your RTO requirements and incident response processes when deciding whether HA justifies the operational investment:</p>"},{"location":"install-pmm/HA.html#what-pmm-ha-provides","title":"What PMM HA provides","text":"<ul> <li>Continuous monitoring visibility during server failures, preventing blind spots when you need observability most.</li> <li>Automatic failover that restarts services or switches to backup systems without manual intervention.</li> <li>Zero metric loss during brief outages, thanks to PMM\u2019s client-side caching that preserves data until connectivity resumes.</li> <li>Reduced operational risk by maintaining monitoring coverage during critical incidents.</li> </ul>"},{"location":"install-pmm/HA.html#what-pmm-ha-cannot-solve","title":"What PMM HA cannot solve","text":"<ul> <li>Even with perfect HA, you\u2019ll still only detect issues after PMM\u2019s minimum one-minute alerting interval.</li> <li>Complete network partitions that isolate entire segments of your infrastructure from monitoring.</li> <li>Increased operational overhead since HA introduces additional complexity in deployment, maintenance, and troubleshooting.</li> </ul>"},{"location":"install-pmm/HA.html#ha-deployment-options","title":"HA deployment options","text":"<p>Choose the option that best fits your infrastructure and requirements:</p> Docker (basic)Kubernetes (production)Clustered (future)Manual setup (advanced) <p>Best for: Development environments, single-server deployments, teams wanting basic restart capabilities without true HA.</p> <p>Docker\u2019s built-in restart capabilities combined with PMM\u2019s client-side data buffering provide basic availability improvements, but this is not a true high availability solution. This approach leverages Docker\u2019s automatic container recovery:</p> <ul> <li>Docker automatically restarts the PMM Server container after crashes or system reboots.</li> <li>PMM Clients buffer metrics locally when the server is unavailable, preventing data loss during outages.</li> </ul> <p>To increase PMM availability and ensure the PMM Server automatically restarts after minor issues, launch the PMM Server in Docker with the <code>--restart=always</code> flag.</p> <p>When the PMM Server becomes unavailable, PMM Clients automatically:</p> <ul> <li>detect the connection failure</li> <li>begin caching metrics data locally</li> <li>continue attempting to reconnect</li> <li>transfer all cached data once the connection is restored</li> </ul> <p>This solution works well for environments where brief interruptions are acceptable and post-incident analysis is more important than real-time availability. For mission-critical deployments requiring higher availability, consider the more advanced options described in the following sections.</p> <p>For deployment instructions, see Install PMM Server with Docker.</p> <p>Best for: Production environments, cloud-native architectures, teams with existing Kubernetes infrastructure.</p> <p>Kubernetes provides enterprise-grade high availability through automated container orchestration, self-healing capabilities, and intelligent workload distribution across multiple nodes. This leverages Kubernetes pod management and PMM\u2019s data persistence:</p> <ul> <li>Kubernetes automatically restarts failed pods and reschedules them to healthy nodes.</li> <li>persistent volumes preserve all PMM data, configurations, and dashboards across pod restarts.</li> <li>health probes ensure only healthy instances receive traffic.</li> <li>PMM Clients cache metrics locally during server unavailability.</li> </ul> <p>When infrastructure issues occur, Kubernetes automatically:</p> <ul> <li>detects pod or node failures through health checks (within 30 seconds)</li> <li>marks failed resources as unavailable</li> <li>reschedules the PMM pod to a healthy node</li> <li>mounts the existing persistent volume to restore state</li> <li>routes traffic once readiness checks pass</li> </ul> <p>During failover (typically 2-5 minutes), data integrity is maintained through:</p> <ul> <li>PMM Client-side caching of up to 24 hours of metrics.</li> <li>persistentVolumeClaims that retain all historical data.</li> <li>automatic metric synchronization once connection restores.</li> <li>preservation of all configurations and custom dashboards.</li> </ul> <p>This solution works well for production environments that can tolerate brief monitoring interruptions during automatic failover. </p> <p>The trade-off between operational simplicity and high availability makes it ideal for most production workloads. For zero-downtime requirements or multi-region deployments, consider the advanced clustering options in the following sections.</p> <p>For deployment instructions, see Install PMM Server with Helm on Kubernetes clusters.</p> <p>Best for: Large enterprises, geographically distributed teams, maximum resilience requirements.</p> <p>A fully clustered PMM deployment is under development to provide true high availability with zero downtime and horizontal scalability. This enterprise-grade architecture will leverage Kubernetes orchestration and distributed database technologies:</p> <ul> <li>multiple active PMM instances with automatic leader election via Raft consensus</li> <li>clustered databases ensure no single point of failure across all data stores</li> <li>geographic distribution support for multi-region deployments</li> <li>automatic failover with zero data loss and minimal service interruption</li> </ul> <p>The clustered architecture will include:</p> <ul> <li>PMM instances: multiple servers in active-passive configuration with automatic leader election.</li> <li>PostgreSQL cluster: replicated metadata and configuration storage with automatic failover.</li> <li>ClickHouse cluster: distributed query analytics data across multiple shards and replicas.</li> <li>VictoriaMetrics cluster: horizontally scaled metrics storage with configurable replication factor.</li> <li>HAProxy: intelligent load balancing and automatic routing to the current leader.</li> </ul> <p>This solution will address enterprise requirements for mission-critical monitoring infrastructure where any downtime is unacceptable. It will support complex scenarios including disaster recovery, multi-datacenter deployments, and regulatory compliance requiring data residency.</p> <p>This feature is currently in development. For immediate high availability needs, consider the Kubernetes deployment option described above, which provides robust automatic recovery suitable for most production environments.</p> <p>Best for: Custom requirements that other options don\u2019t meet, integration with existing infrastructure, granular control over individual components.</p> <p>Availability status</p> <p>This feature is currently in Technical Preview. Early adopters should use this feature for testing purposes only as it is subject to change.</p> <p>Manual setup provides complete control over PMM\u2019s HA architecture by deploying each component separately. This approach leverages distributed consensus protocols and external clustered databases:</p> <ul> <li>Gossip protocol enables PMM servers to discover and share information about their states. It is used for managing the PMM server list and failure detection, ensuring that all instances are aware of the current state of the cluster.</li> <li>Raft consensus ensures that PMM servers agree on a leader and that logs are replicated among all machines to maintain data consistency.</li> <li>External clustered databases eliminate single points of failure for all data stores.</li> <li>Three PMM instances with one leader, two followers. The leader server handles all client requests. If the leader fails, the followers take over, minimizing downtime.</li> </ul> <p>These protocols work in tandem to ensure that the PMM Server instances can effectively store and manage the data collected from your monitored databases and systems.</p> <p>The architecture separates critical services to eliminate single points of failure and provide better Service Level Agreements (SLAs):</p> <ul> <li>ClickHouse cluster stores Query Analytics (QAN) metrics. This ensures that QAN data remains highly available and can be accessed even if one of the ClickHouse nodes fails.</li> <li>VictoriaMetrics cluster stores Prometheus metrics. This provides a highly available and scalable solution for storing and querying metrics data.</li> <li>PostgreSQL cluster stores PMM data, such as inventory and settings. This ensures that PMM\u2019s configuration and metadata remain highly available and can be accessed by all PMM Server instances.</li> <li>HAProxy routes traffic to the current leader based on health checks.</li> </ul> <p>When the leader fails, the remaining instances:</p> <ul> <li>detect the failure through Raft consensus</li> <li>elect a new leader from the followers</li> <li>update HAProxy routing automatically</li> <li>maintain service availability with minimal interruption</li> <li>preserve all data through external clustered storage</li> </ul>"},{"location":"install-pmm/HA.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin:</p> <ul> <li>Install and configure Docker.</li> <li>Prepare your environment:<ul> <li>for testing &gt; run services on a single machine.</li> <li>for production &gt; deploy services on separate instances and use clustered versions of PostgreSQL, VictoriaMetrics, and ClickHouse. Keep in mind that running all services on a single machine is not recommended for production. Use separate instances and clustered components for better reliability.</li> </ul> </li> </ul>"},{"location":"install-pmm/HA.html#step-1-define-environment-variables","title":"Step 1: Define environment variables","text":"<p>Before you start, define the necessary environment variables on each instance where the services will be running. You will need these variables for the subsequent commands.</p> <p>For all IP addresses, use the format <code>17.10.1.x</code>, and for all usernames and passwords, use a string format like <code>example</code>.</p> Variable Description <code>CH_HOST_IP</code> The IP address of the instance where the ClickHouse service is running or the desired IP address for the ClickHouse container within the Docker network, depending on your setup.Example: <code>17.10.1.2</code> <code>VM_HOST_IP</code> The IP address of the instance where the VictoriaMetrics service is running or the desired IP address for the VictoriaMetrics container within the Docker network, depending on your setup.Example: <code>17.10.1.3</code> <code>PG_HOST_IP</code> The IP address of the instance where the PostgreSQL service is running or the desired IP address for the PostgreSQL container within the Docker network, depending on your setup. Example: <code>17.10.1.4</code> <code>PG_USERNAME</code> The username for your PostgreSQL server. Example: <code>pmmuser</code> <code>PG_PASSWORD</code> The password for your PostgreSQL server.Example: <code>pgpassword</code> <code>GF_USERNAME</code> The username for your Grafana database user.Example: <code>gfuser</code> <code>GF_PASSWORD</code> The password for your Grafana database user.Example: <code>gfpassword</code> <code>PMM_ACTIVE_IP</code> The IP address of the instance where the active PMM server is running or the desired IP address for your active PMM server container within the Docker network, depending on your setup.Example: <code>17.10.1.5</code> <code>PMM_ACTIVE_NODE_ID</code> The unique ID for your active PMM server node.Example: <code>pmm-server-active</code> <code>PMM_PASSIVE_IP</code> The IP address of the instance where the first passive PMM server is running or the desired IP address for your first passive PMM server container within the Docker network, depending on your setup.Example: <code>17.10.1.6</code> <code>PMM_PASSIVE_NODE_ID</code> The unique ID for your first passive PMM server node.Example: <code>pmm-server-passive</code> <code>PMM_PASSIVE2_IP</code> The IP address of the instance where the second passive PMM server is running or the desired IP address for your second passive PMM server container within the Docker network, depending on your setup.Example: <code>17.10.1.7</code> <code>PMM_PASSIVE2_NODE_ID</code> The unique ID for your second passive PMM server node.Example: <code>pmm-server-passive2</code> <code>PMM_DOCKER_IMAGE</code> The specific PMM Server Docker image for this guide.Example: <code>percona/pmm-server:3</code> Expected output <pre><code>export CH_HOST_IP=17.10.1.2\nexport VM_HOST_IP=17.10.1.3\nexport PG_HOST_IP=17.10.1.4\nexport PG_USERNAME=pmmuser\nexport PG_PASSWORD=pgpassword\nexport GF_USERNAME=gfuser\nexport GF_PASSWORD=gfpassword\nexport PMM_ACTIVE_IP=17.10.1.5\nexport PMM_ACTIVE_NODE_ID=pmm-server-active\nexport PMM_PASSIVE_IP=17.10.1.6\nexport PMM_PASSIVE_NODE_ID=pmm-server-passive\nexport PMM_PASSIVE2_IP=17.10.1.7\nexport PMM_PASSIVE2_NODE_ID=pmm-server-passive2\nexport PMM_DOCKER_IMAGE=percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/HA.html#step-2-create-docker-network-optional","title":"Step 2: Create Docker network (optional)","text":"<p>Create a dedicated network if you plan to run multiple PMM services on the same instance. This ensures proper communication between containers, especially for High Availability mode:</p> <ol> <li> <p>Set up a Docker network for PMM services if you plan to run all the services on the same instance. As a result of this Docker network, your containers will be able to communicate with each other, which is essential for the High Availability (HA) mode to function properly in PMM. This step may be optional if you run your services on separate instances.</p> </li> <li> <p>Run the following command to create a Docker network:</p> <pre><code>docker network create pmm-network --subnet=17.10.1.0/16\n</code></pre> </li> </ol>"},{"location":"install-pmm/HA.html#step-3-set-up-clickhouse","title":"Step 3: Set up ClickHouse","text":"<p>ClickHouse is an open-source column-oriented database management system. In PMM, ClickHouse stores Query Analytics (QAN) metrics, which provide detailed information about your queries.</p> <p>To set up ClickHouse:</p> <ol> <li> <p>Pull the ClickHouse Docker image:</p> <pre><code>docker pull clickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> </li> <li> <p>Create a Docker volume for ClickHouse data:</p> <pre><code>docker volume create ch_data\n</code></pre> </li> <li> <p>Run the ClickHouse container:</p> Run services on the same instanceRun services on a separate instance <pre><code>docker run -d \\\n--name ch \\\n--network pmm-network \\\n--ip ${CH_HOST_IP} \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <p>The <code>--network</code> and <code>--ip</code> flags assign a specific IP address within the Docker network created in Step 2.</p> <pre><code>docker run -d \\\n--name ch \\\n-p 9000:9000 \\\n-v ch_data:/var/lib/clickhouse \\\nclickhouse/clickhouse-server:23.8.2.7-alpine\n</code></pre> <p>When running on separate instances, ClickHouse binds to the default network interface.</p> </li> </ol>"},{"location":"install-pmm/HA.html#step-4-set-up-victoriametrics","title":"Step 4: Set up VictoriaMetrics","text":"<p>VictoriaMetrics provides a long-term storage solution for your time-series data. In PMM, it is used to store Prometheus metrics.</p> <p>To set up VictoriaMetrics:</p> <ol> <li> <p>Pull the VictoriaMetrics Docker image:</p> <pre><code>docker pull victoriametrics/victoria-metrics:v1.93.4\n</code></pre> </li> <li> <p>Create a Docker volume for VictoriaMetrics data:</p> <pre><code>docker volume create vm_data\n</code></pre> </li> <li> <p>Run the VictoriaMetrics container:</p> Run services on the same instanceRun services on a separate instance <pre><code>docker run -d \\\n--name vm \\\n--network pmm-network \\\n--ip ${VM_HOST_IP} \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <p>The <code>--network</code> and <code>--ip</code> flags assign a specific IP address within the Docker network created in Step 2.</p> <pre><code>docker run -d \\\n--name vm \\\n-p 8428:8428 \\\n-p 8089:8089 \\\n-p 8089:8089/udp \\\n-p 2003:2003 \\\n-p 2003:2003/udp \\\n-p 4242:4242 \\\n-v vm_data:/storage \\\nvictoriametrics/victoria-metrics:v1.93.4 \\\n--storageDataPath=/storage \\\n--graphiteListenAddr=:2003 \\\n--opentsdbListenAddr=:4242 \\\n--httpListenAddr=:8428 \\\n--influxListenAddr=:8089\n</code></pre> <p>When running on separate instances, VictoriaMetrics binds to the default network interface.</p> </li> </ol>"},{"location":"install-pmm/HA.html#step-5-set-up-postgresql","title":"Step 5: Set up PostgreSQL","text":"<p>PostgreSQL is a powerful, open-source object-relational database system. PMM uses it to store data related to inventory, settings, and other features.</p> <p>To set up PostgreSQL:</p> <ol> <li> <p>Pull the PostgreSQL Docker image:</p> <pre><code>docker pull postgres:14\n</code></pre> </li> <li> <p>Create a Docker volume for PostgreSQL data:</p> <pre><code>docker volume create pg_data\n</code></pre> </li> <li> <p>Create a directory to store initialization SQL queries:</p> <pre><code>mkdir -p /path/to/queries\n</code></pre> <p>Replace <code>/path/to/queries</code> with your desired absolute path (e.g., <code>/opt/pmm/postgres-init</code>).</p> </li> <li> <p>Create an <code>init.sql.template</code> file in the newly created directory with the following content:</p> <pre><code>CREATE DATABASE \"pmm-managed\";\nCREATE USER &lt;YOUR_PG_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_PG_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE \"pmm-managed\" TO &lt;YOUR_PG_USERNAME&gt;;\nCREATE DATABASE grafana;\nCREATE USER &lt;YOUR_GF_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_GF_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE grafana TO &lt;YOUR_GF_USERNAME&gt;;\n\n\\c pmm-managed\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n</code></pre> </li> <li> <p>Use <code>sed</code> to replace the placeholders with the environment variables and write the output to <code>init.sql</code>:</p> <pre><code>sed -e 's/&lt;YOUR_PG_USERNAME&gt;/'\"$PG_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_PG_PASSWORD&gt;/'\"$PG_PASSWORD\"'/g' \\\n    -e 's/&lt;YOUR_GF_USERNAME&gt;/'\"$GF_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_GF_PASSWORD&gt;/'\"$GF_PASSWORD\"'/g' \\\n    init.sql.template &gt; init.sql\n</code></pre> </li> <li> <p>Run the PostgreSQL container based on your deployment architecture:</p> Run services on the same instanceRun services on a separate instance <pre><code>docker run -d \\\n    --name pg \\\n    --network pmm-network \\\n    --ip ${PG_HOST_IP} \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d/ \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <p>The <code>--network</code> and <code>--ip</code> flags assign a specific IP address within the Docker network created in Step 2.</p> <pre><code>docker run -d \\\n    --name pg \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n    -v /path/to/queries:/docker-entrypoint-initdb.d \\\n    -v pg_data:/var/lib/postgresql/data \\\n    postgres:14 \\\n    postgres -c shared_preload_libraries=pg_stat_statements\n</code></pre> <p>When running on separate instances, PostgreSQL binds to the default network interface.</p> <p>Path requirements</p> <ul> <li>Always use absolute paths for volume mounts (e.g., <code>/opt/pmm/postgres-init</code> instead of <code>./queries</code>).</li> <li>The init SQL file in <code>/docker-entrypoint-initdb.d</code> executes automatically on first container startup.</li> <li>Ensure the postgres user has read permissions on the mounted directory.</li> </ul> </li> </ol>"},{"location":"install-pmm/HA.html#step-6-running-pmm-services","title":"Step 6: Running PMM services","text":"<p>The PMM server orchestrates the collection, storage, and visualization of metrics. In our high-availability setup, we\u2019ll have one active PMM server and two passive PMM servers:</p> <ol> <li>Check that environment variables from Step 1 are set on each instance where you run these commands.</li> <li> <p>Pull the PMM Server Docker image:</p> <pre><code>docker pull ${PMM_DOCKER_IMAGE}\n</code></pre> </li> <li> <p>Create Docker volumes for PMM-Server data:</p> <pre><code>docker volume create pmm-server-active_data\ndocker volume create pmm-server-passive_data\ndocker volume create pmm-server-passive-2_data\n</code></pre> </li> <li> <p>Run the active PMM managed server. This server will serve as the primary monitoring server.</p> Run services on same instanceRun services on a separate instance <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n--hostname ${PMM_ACTIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_ACTIVE_IP} \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\            \n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on the same instance, omit <code>-p</code> port flags and use <code>--network</code> and <code>--ip</code> for internal communication.</p> <pre><code>docker run -d \\\n--name ${PMM_ACTIVE_NODE_ID} \\\n-p 80:8080 \\\n-p 443:8443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=1 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_ACTIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_ACTIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-active_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on separate instances, include <code>-p</code> port mappings and omit <code>--network</code> and <code>--ip</code> flags.</p> </li> <li> <p>Run the first passive PMM-managed server. This server will act as a standby server, ready to take over if the active server fails.</p> Run services on the same instanceRun services on a separate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n--hostname ${PMM_PASSIVE_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE_IP} \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\            \n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on the same instance, omit <code>-p</code> port flags and use <code>--network</code> and <code>--ip</code> for internal communication.</p> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE_NODE_ID} \\\n-p 80:8080 \\\n-p 443:8443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\            \n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on separate instances, include <code>-p</code> port mappings and omit <code>--network</code> and <code>--ip</code> flags.</p> </li> <li> <p>Run the second passive PMM-managed server. Like the first passive server, this server will also act as a standby server.</p> Run services on the same instanceRun services on a separate instance <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n--hostname ${PMM_PASSIVE2_NODE_ID} \\\n--network pmm-network \\\n--ip ${PMM_PASSIVE2_IP} \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\            \n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive-2_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on the same instance, omit <code>-p</code> port flags and use <code>--network</code> and <code>--ip</code> for internal communication.</p> <pre><code>docker run -d \\\n--name ${PMM_PASSIVE2_NODE_ID} \\\n-p 80:8080 \\\n-p 443:8443 \\\n-p 9094:9094 \\\n-p 9096:9096 \\\n-p 9094:9094/udp \\\n-p 9096:9096/udp \\\n-p 9097:9097 \\\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1 \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n-e PMM_CLICKHOUSE_ADDR=${CH_HOST_IP}:9000 \\\n-e PMM_CLICKHOUSE_DATABASE=pmm \\\n-e PMM_POSTGRES_ADDR=${PG_HOST_IP}:5432 \\\n-e PMM_POSTGRES_USERNAME=${PG_USERNAME} \\\n-e PMM_POSTGRES_DBPASSWORD=${PG_PASSWORD} \\\n-e GF_DATABASE_USER=${GF_USERNAME} \\\n-e GF_DATABASE_PASSWORD=${GF_PASSWORD} \\\n-e GF_DATABASE_HOST=${PG_HOST_IP} \\\n-e GF_DATABASE_PORT=5432 \\\n-e GF_DATABASE_NAME=grafana \\\n-e PMM_VM_URL=http://${VM_HOST_IP}:8428 \\\n-e PMM_TEST_HA_ENABLE=1 \\\n-e PMM_TEST_HA_BOOTSTRAP=0 \\\n-e PMM_TEST_HA_NODE_ID=${PMM_PASSIVE2_NODE_ID} \\\n-e PMM_TEST_HA_ADVERTISE_ADDRESS=${PMM_PASSIVE2_IP} \\\n-e PMM_TEST_HA_GOSSIP_PORT=9096 \\\n-e PMM_TEST_HA_RAFT_PORT=9097 \\\n-e PMM_TEST_HA_GRAFANA_GOSSIP_PORT=9094 \\\n-e PMM_TEST_HA_PEERS=${PMM_ACTIVE_IP},${PMM_PASSIVE_IP},${PMM_PASSIVE2_IP} \\\n-v pmm-server-passive-2_data:/srv \\\n${PMM_DOCKER_IMAGE}\n</code></pre> <p>When running on separate instances, include <code>-p</code> port mappings and omit <code>--network</code> and <code>--ip</code> flags.</p> </li> </ol>"},{"location":"install-pmm/HA.html#step-7-set-up-haproxy","title":"Step 7: Set up HAProxy","text":"<p>HAProxy provides high availability for your PMM setup by directing traffic to the current leader server via the <code>/v1/leaderHealthCheck</code> endpoint:</p> <ol> <li> <p>Pull the HAProxy Docker image:</p> <pre><code>docker pull haproxy:2.4.2-alpine\n</code></pre> </li> <li> <p>Create a directory to store the SSL certificate:</p> <pre><code>mkdir -p /path/to/certs\n</code></pre> <p>Replace <code>/path/to/certs</code> with the path where you want to store your SSL certificates.</p> </li> <li> <p>Navigate to this directory and generate a new private key:</p> <pre><code>openssl genrsa -out pmm.key 2048\n</code></pre> <p>This command generates a 2048-bit RSA private key and saves it to a file named <code>pmm.key</code>.</p> </li> <li> <p>Using the private key, generate a self-signed certificate:</p> <pre><code>openssl req -new -x509 -key pmm.key -out pmm.crt -days 365\n</code></pre> <p>Enter country, state, organization name, etc. when asked. Use <code>-days 365</code> option for 365-day certificate validity.</p> </li> <li> <p>Copy your SSL certificate and private key to the directory you created in step 2. Ensure that the certificate file is named <code>pmm.crt</code> and the private key file is named <code>pmm.key</code>.</p> <p>Concatenate these two files to create a PEM file:</p> <pre><code>cat pmm.crt pmm.key &gt; pmm.pem\n</code></pre> </li> <li> <p>Create a directory to store HAProxy configuration:</p> <pre><code>mkdir -p /path/to/haproxy-config\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path where you want to store your HAProxy configuration.</p> </li> <li> <p>Create an HAProxy configuration file named <code>haproxy.cfg.template</code> in that directory. This configuration tells HAProxy to use the <code>/v1/leaderHealthCheck</code> endpoint of each PMM server to identify the leader:</p> <pre><code>global\n    log stdout    local0 debug\n    log stdout    local1 info\n    log stdout    local2 info\n    daemon\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend http_front\n    bind *:80\n    default_backend http_back\n\nfrontend https_front\n    bind *:443 ssl crt /etc/haproxy/certs/pmm.pem\n    default_backend https_back\n\nbackend http_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-http PMM_ACTIVE_IP:8080 check\n    server pmm-server-passive-http PMM_PASSIVE_IP:8080 check backup\n    server pmm-server-passive-2-http PMM_PASSIVE2_IP:8080 check backup\n\nbackend https_back\n    option httpchk\n    http-check send meth POST uri /v1/leaderHealthCheck ver HTTP/1.1 hdr Host www\n    http-check expect status 200\n    server pmm-server-active-https PMM_ACTIVE_IP:8443 check ssl verify none\n    server pmm-server-passive-https PMM_PASSIVE_IP:8443 check ssl verify none\n    server pmm-server-passive-2-https PMM_PASSIVE2_IP:8443 check ssl verify none\n</code></pre> </li> <li> <p>Before starting the HAProxy container, use <code>sed</code> to replace the placeholders in <code>haproxy.cfg.template</code> with the environment variables, and write the output to <code>haproxy.cfg</code>:</p> <pre><code>sed -e \"s/PMM_ACTIVE_IP/$PMM_ACTIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE_IP/$PMM_PASSIVE_IP/g\" \\\n    -e \"s/PMM_PASSIVE2_IP/$PMM_PASSIVE2_IP/g\" \\\n    /path/to/haproxy.cfg.template &gt; /path/to/haproxy.cfg\n</code></pre> </li> <li> <p>Run the HAProxy container, using absolute paths for all volume mounts. If running services on separate instances, remove the <code>--network</code> flag:</p> <pre><code>docker run -d \\\n--name haproxy \\\n--network pmm-network \\\n-p 80:80 \\\n-p 443:443 \\\n-v /path/to/haproxy-config:/usr/local/etc/haproxy \\\n-v /path/to/certs:/etc/haproxy/certs \\\nhaproxy:2.4.2-alpine\n</code></pre> <p>Replace <code>/path/to/haproxy-config</code> with the path to the <code>haproxy.cfg</code> file you created in step 6, and <code>/path/to/certs</code> with the path.</p> </li> </ol> <p>HAProxy is now configured to redirect traffic to the leader PMM managed server. This ensures highly reliable service by redirecting requests to the remaining servers in the event that the leader server goes down.</p>"},{"location":"install-pmm/HA.html#step-8-access-pmm-and-verify-the-setup","title":"Step 8: Access PMM and verify the setup","text":"<p>Once all components are running, access PMM through HAProxy and verify your high availability configuration:</p> <ol> <li>Access the PMM services by navigating to <code>https://&lt;HAProxy_IP&gt;</code> in your web browser. Replace <code>&lt;HAProxy_IP&gt;</code> with the IP address or hostname of the machine running the HAProxy container. HAProxy will automatically route your connection to the current leader PMM instance.</li> <li>Use the default credentials (<code>admin</code>/<code>admin</code>) unless changed during setup. PMM will prompt you to set a new password on first login.</li> <li>Verify HA status to check that your HA setup is functioning correctly. You can use <code>docker ps</code> to check the status of your Docker containers. If a container is not running, you can view its logs using the command <code>docker logs &lt;container_name&gt;</code> to investigate the issue.</li> <li>Register PMM Clients. When adding monitored nodes, always use the HAProxy address (or hostname) instead of individual PMM server IPs.</li> </ol> <p>Your PMM environment is now running in high availability mode with automatic failover capabilities. The setup provides resilience against single node failures and maintains continuous monitoring coverage.</p>"},{"location":"install-pmm/install-pmm-client/index.html","title":"PMM Client installation overview","text":"<p>PMM Client is the component of Percona Monitoring and Management (PMM) that collects metrics from your database servers and sends them to PMM Server for analysis and visualization.</p> Common installation process at a glance <p>While specific steps vary by deployment method, the general installation process includes:</p> <ol> <li>Install PMM Client using your preferred method and register the Client node with your PMM Server.</li> <li>Add database services for monitoring.</li> <li>Verify monitoring data in the PMM web interface.</li> </ol>"},{"location":"install-pmm/install-pmm-client/index.html#prerequisites","title":"Prerequisites","text":"<p>Complete these steps to prepare your system for PMM installation:</p> <ul> <li> <p>Check system requirements to ensure your environment meets the minimum criteria.</p> </li> <li> <p>Install and configure PMM Server using your preferred deployment method. You\u2019ll need PMM Server\u2019s IP address or hostname to configure PMM Client.</p> </li> <li> <p>Set up firewall rules to allow communication between PMM Client and PMM Server.</p> </li> <li> <p>Create monitoring users with necessary permissions for your database</p> </li> <li> <p>Check that you have administrator access to install PMM Client</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/index.html#deployment-options","title":"Deployment options","text":"<p>Install PMM Client using one of the following deployment methods:</p> Your setup Recommended deployment Production environments on supported Linux distributions Package Manager \u2192 Unsupported Linux distributions or non-root installation Binary Package \u2192 Containerized environments or testing Docker \u2192"},{"location":"install-pmm/install-pmm-client/index.html#connect-services","title":"Connect services","text":"<p>Each database service requires specific configuration parameters. Configure your service according to its service type:</p> <ul> <li>MySQL (and variants Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> <li>ProxySQL</li> <li>Amazon RDS</li> <li>Microsoft Azure</li> <li>Google Cloud Platform (MySQL and PostgreSQL)</li> <li>Linux</li> <li>External services</li> <li>HAProxy</li> <li>Remote instances</li> </ul>"},{"location":"install-pmm/install-pmm-client/index.html#modifying-service-configurations","title":"Modifying service configurations","text":"<p>If you need to modify the configuration of a service you\u2019ve already added, you\u2019ll need to remove the service and re-add it with the new parameters.</p>"},{"location":"install-pmm/install-pmm-client/index.html#next-steps","title":"Next steps","text":"<ul> <li>Connect database services for monitoring</li> <li>Configure optimization settings for specific database types</li> </ul>"},{"location":"install-pmm/install-pmm-client/binary_package.html","title":"Install PMM Client manually using binaries","text":"<p>This method allows you to install PMM Client using pre-compiled binary packages on a wide range of Linux distributions, for both x86_64 and ARM64 architectures.</p> <p>Installing from binaries offers these advantages:</p> <ul> <li>supports Linux distributions not covered by package managers</li> <li>doesn\u2019t require package managers</li> <li>allows installation without root permissions (unique to this method)</li> <li>provides complete control over the installation location</li> </ul> <p>Tip for quick installation</p> <p>For a quick installation:</p> <ul> <li>Download the PMM Client tar.gz file</li> <li>Extract it</li> <li>Run <code>./install_tarball</code> (or with <code>-u</code> flag to preserve existing config during upgrades)</li> </ul>"},{"location":"install-pmm/install-pmm-client/binary_package.html#prerequisites","title":"Prerequisites","text":"<p>Complete these essential steps before installation:</p> <ol> <li> <p>Check system requirements to ensure your environment meets the minimum criteria.</p> </li> <li> <p>Install and configure PMM Server as you\u2019ll its IP address or hostname to configure the Client.</p> </li> <li> <p>Set up firewall rules to allow communication between PMM Client and PMM Server.</p> </li> <li> <p>Create database monitoring users with appropriate permissions for the databases you plan to monitor.</p> </li> <li> <p>Check that you have root or sudo privileges to install PMM Client. Alternatively, use binary installation for non-root environments.</p> </li> </ol> <p>Version information</p> <p>The commands below are for the latest PMM release. If you want to install a different release, make sure to update the commands with your required version number.</p>"},{"location":"install-pmm/install-pmm-client/binary_package.html#choose-your-installation-path","title":"Choose your installation path","text":"<p>Select the appropriate instructions based on your access level:</p> With root permissionsWithout root permissions <p>To install with root/administrator privileges:</p> <ol> <li> <p>Download the PMM Client package for your architecture:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-x86_64.tar.gz\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-aarch64.tar.gz\n</code></pre> </li> <li> <p>Download the corresponding checksum file to verify integrity:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Verify the download:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>sha256sum -c pmm-client-3.3.1-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>sha256sum -c pmm-client-3.3.1-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Unpack the package and move into the directory:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>tar xfz pmm-client-3.3.1-x86_64.tar.gz &amp;&amp; cd pmm-client-3.3.1\n</code></pre> <pre><code>tar xfz pmm-client-3.3.1-aarch64.tar.gz &amp;&amp; cd pmm-client-3.3.1\n</code></pre> </li> <li> <p>Set the installation directory:</p> <pre><code>export PMM_DIR=/usr/local/percona/pmm\n</code></pre> </li> <li> <p>Run the installer:</p> <pre><code>sudo ./install_tarball\n</code></pre> </li> <li> <p>Update your PATH:</p> <pre><code>PATH=$PATH:$PMM_DIR/bin\n</code></pre> </li> <li> <p>Create symbolic links to make PMM commands available system-wide:</p> <pre><code>sudo ln -s /usr/local/percona/pmm/bin/pmm-agent /usr/local/bin/pmm-agent\nsudo ln -s /usr/local/percona/pmm/bin/pmm-admin /usr/local/bin/pmm-admin\n</code></pre> </li> <li> <p>Set up the agent:</p> <pre><code>sudo pmm-agent setup --config-file=/usr/local/percona/pmm/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin\n</code></pre> </li> <li> <p>Run the agent:</p> <pre><code>sudo pmm-agent --config-file=${PMM_DIR}/config/pmm-agent.yaml\n</code></pre> </li> <li> <p>Register your nodes to be monitored by PMM Server using the PMM Client:</p> <pre><code>sudo pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <p>where: </p> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server</li> <li><code>443</code> is the default port number</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>HTTPS connection required</p> <p>Nodes must be registered with the PMM Server using a secure HTTPS connection. If you try to use HTTP in your server URL, PMM will automatically attempt to establish an HTTPS connection on port 443. If a TLS connection cannot be established, you will receive an error message and must explicitly use HTTPS with the appropriate secure port.</p> Registration example <p>Register a node with IP address 192.168.33.23, type generic, and name mynode on a PMM Server with IP address 192.168.33.14:</p> <pre><code>sudo pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre> </li> <li> <p>Verify the installation in a new terminal:</p> <pre><code>sudo pmm-admin status\n</code></pre> </li> </ol> <p>Follow these steps for environments where you don\u2019t have root access:</p> <ol> <li> <p>Download the PMM Client package for your architecture:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-x86_64.tar.gz\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-aarch64.tar.gz\n</code></pre> </li> <li> <p>Download the corresponding checksum file to verify integrity:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>wget https://downloads.percona.com/downloads/pmm3/3.3.1/binary/tarball/pmm-client-3.3.1-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Verify the download:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>sha256sum -c pmm-client-3.3.1-x86_64.tar.gz.sha256sum\n</code></pre> <pre><code>sha256sum -c pmm-client-3.3.1-aarch64.tar.gz.sha256sum\n</code></pre> </li> <li> <p>Unpack the package and move into the directory:</p> For x86_64 (AMD64)For ARM64 (aarch64) <pre><code>tar xfz pmm-client-3.3.1-x86_64.tar.gz &amp;&amp; cd pmm-client-3.3.1\n</code></pre> <pre><code>tar xfz pmm-client-3.3.1-aarch64.tar.gz &amp;&amp; cd pmm-client-3.3.1\n</code></pre> </li> <li> <p>Set the installation directory:</p> <pre><code>export PMM_DIR=YOURPATH\n</code></pre> <p>Replace YOURPATH with a path where you have required access.</p> </li> <li> <p>Run the installer:</p> <pre><code>./install_tarball\n</code></pre> </li> <li> <p>Update your PATH:</p> <pre><code>PATH=$PATH:$PMM_DIR/bin\n</code></pre> </li> <li> <p>Set up the agent:</p> <pre><code>pmm-agent setup --config-file=${PMM_DIR}/config/pmm-agent.yaml --server-address=192.168.1.123 --server-insecure-tls --server-username=admin --server-password=admin --paths-tempdir=${PMM_DIR}/tmp --paths-base=${PMM_DIR}\n</code></pre> </li> <li> <p>Run the agent:</p> <pre><code>pmm-agent --config-file=${PMM_DIR}/config/pmm-agent.yaml\n</code></pre> </li> <li> <p>Register your nodes to be monitored by PMM Server using the PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <p>where: </p> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server</li> <li><code>443</code> is the default port number</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>HTTPS connection required</p> <p>Nodes must be registered with the PMM Server using a secure HTTPS connection. If you try to use HTTP in your server URL, PMM will automatically attempt to establish an HTTPS connection on port 443. If a TLS connection cannot be established, you will receive an error message and must explicitly use HTTPS with the appropriate secure port.</p> Registration example <p>Register a node with IP address 192.168.33.23, type generic, and name mynode on a PMM Server with IP address 192.168.33.14:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre> </li> <li> <p>Open a new terminal and verify the installation:</p> <pre><code>pmm-admin status\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/binary_package.html#related-topics","title":"Related topics","text":"<ul> <li>Prerequisites for PMM Client</li> <li>Connect databases for monitoring</li> <li>Uninstall PMM Client</li> <li>Docker installation option </li> <li>Package manager installation </li> </ul>"},{"location":"install-pmm/install-pmm-client/docker.html","title":"Run PMM Client as a Docker container","text":"<p>The PMM Client Docker image provides a convenient way to run PMM Client as a pre-configured container without installing software directly on your host system.</p> <p>Using the Docker container approach offers several advantages:</p> <ul> <li>no need to install PMM Client directly on your host system</li> <li>consistent environment across different operating systems</li> <li>simplified setup and configuration process</li> <li>automatic architecture detection (x86_64/ARM64)</li> </ul>"},{"location":"install-pmm/install-pmm-client/docker.html#prerequisites","title":"Prerequisites","text":"<p>Complete these essential steps before installation:</p> <ol> <li> <p>Install Docker Engine</p> </li> <li> <p>Check system requirements to ensure your environment meets the minimum criteria.</p> </li> <li> <p>Install and configure PMM Server as you\u2019ll need its IP address or hostname to configure the Client.</p> </li> <li> <p>Set up firewall rules to allow communication between PMM Client and PMM Server.</p> </li> <li> <p>Create database monitoring users with appropriate permissions for the databases you plan to monitor.</p> </li> <li> <p>Check that you have root or sudo privileges to install PMM Client. Alternatively, use binary installation for non-root environments.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/docker.html#installation-and-setup","title":"Installation and setup","text":"<p>Follow these steps to deploy PMM Client using Docker:</p> <ol> <li> <p>Pull the PMM Client Docker image:</p> <pre><code>docker pull percona/pmm-client:3\n</code></pre> </li> <li> <p>Create a persistent Docker volume to store PMM Client data between container restarts:</p> <pre><code>docker volume create pmm-client-data\n</code></pre> </li> <li> <p>Start the PMM Client container and configure the pmm-agent in Setup mode to connect to PMM Server. Replace <code>X.X.X.X</code> with the IP address of your PMM Server and update <code>PMM_AGENT_SERVER_PASSWORD</code> value if you changed the default <code>admin</code> password during setup:</p> <pre><code> docker run \\\n --name pmm-client \\\n -e PMM_AGENT_SERVER_ADDRESS=X.X.X.X:443 \\\n -e PMM_AGENT_SERVER_USERNAME=admin \\\n -e PMM_AGENT_SERVER_PASSWORD=admin \\\n -e PMM_AGENT_SERVER_INSECURE_TLS=1 \\\n -e PMM_AGENT_SETUP=1 \\\n -e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n -e PMM_AGENT_SETUP_FORCE=1 \\\n -v pmm-client-data:/usr/local/percona/pmm/tmp \\\n percona/pmm-client:3\n</code></pre> <p>Important</p> <ul> <li>Do not use the <code>docker --detach</code> option with this command. The pmm-agent outputs logs directly to the console, and detaching would prevent you from seeing important setup information and potential errors.</li> <li>You can find a complete list of compatible environment variables here.</li> <li>If you get <code>Failed to register pmm-agent on PMM Server: connection refused</code>, this typically means that the IP address is incorrect or the PMM Server is unreachable.</li> </ul> </li> <li> <p>After the setup is complete, start the pmm-agent in normal mode:</p> <pre><code>docker run \\\n  --detach \\\n  --name pmm-client \\\n  -e PMM_AGENT_SETUP=0 \\\n  -e PMM_AGENT_CONFIG_FILE=config/pmm-agent.yaml \\\n  -v pmm-client-data:/usr/local/percona/pmm/tmp \\\n  percona/pmm-client:3\n</code></pre> </li> <li> <p>Register your nodes to be monitored by PMM Server using the PMM Client:</p> <pre><code>docker exec pmm-client pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <p>where: </p> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server</li> <li><code>443</code> is the default port number</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>HTTPS connection required</p> <p>Nodes must be registered with the PMM Server using a secure HTTPS connection. If you try to use HTTP in your server URL, PMM will automatically attempt to establish an HTTPS connection on port 443. If a TLS connection cannot be established, you will receive an error message and must explicitly use HTTPS with the appropriate secure port.</p> Registration example <p>Register a node with IP address 192.168.33.23, type generic, and name mynode on a PMM Server with IP address 192.168.33.14:</p> <pre><code>docker exec pmm-client pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre> </li> <li> <p>Verify the PMM Client status. If the connection is successful, you should also see an increased number of monitored nodes in the PMM user interface:</p> <pre><code>docker exec -t pmm-client pmm-admin status\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/docker.html#add-monitoring-services","title":"Add monitoring services","text":"<p>After installing PMM Client, you can add database services to monitor with <code>pmm-admin</code>. </p> <p>When running PMM in Docker, prefix all pmm-admin commands with <code>docker exec pmm-client</code>.</p> <p>Tips for Docker configuration</p> <ul> <li>Ensure your host\u2019s firewall and routing rules are configured to allow Docker communications. This is crucial for Docker containers to communicate properly. For more details, see to the troubleshooting checklist.</li> <li>If you need assistance with PMM Client, run: <code>docker run --rm percona/pmm-client:3 --help</code>.</li> </ul>"},{"location":"install-pmm/install-pmm-client/docker.html#view-your-monitored-node","title":"View your monitored node","text":"<p>To confirm your node is being monitored:</p> <ol> <li> <p>Go to the main menu and select Operating System (OS) &gt; Overview.</p> </li> <li> <p>In the Node Names drop-down menu, select the node you recently registered.</p> </li> <li> <p>Modify the time range to view the relevant data for your selected node.</p> </li> </ol> <p>Danger</p> <p><code>pmm-agent.yaml</code> contains sensitive credentials and should not be shared.</p>"},{"location":"install-pmm/install-pmm-client/package_manager.html","title":"Install PMM Client with Package Manager","text":"<p>Percona Monitoring and Management (PMM) Client can be installed using standard Linux package managers. You can choose between automated repository setup or manual package download options.</p>"},{"location":"install-pmm/install-pmm-client/package_manager.html#prerequisites","title":"Prerequisites","text":"<p>Complete these essential steps before installation:</p> <ol> <li> <p>Check system requirements to ensure your environment meets the minimum criteria.</p> </li> <li> <p>Install and configure PMM Server as you\u2019ll its IP address or hostname to configure the Client.</p> </li> <li> <p>Set up firewall rules to allow communication between PMM Client and PMM Server.</p> </li> <li> <p>Create database monitoring users with appropriate permissions for the databases you plan to monitor.</p> </li> <li> <p>Check that you have root or sudo privileges to install PMM Client. Alternatively, use binary installation for non-root environments.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/package_manager.html#supported-architectures-and-platforms","title":"Supported architectures and platforms","text":"<p>PMM Client supports:</p> <ul> <li>Architectures: x86_64 (AMD64) and ARM64 (aarch64)</li> <li> <p>Operating systems:</p> <ul> <li>Red Hat/CentOS/Oracle Linux 8 and 9</li> <li>Debian 11 (Bullseye) and 12 (Bookworm)</li> <li>Ubuntu 22.04 (Jammy) and 24.04 (Noble)</li> <li>Amazon Linux 2023</li> </ul> </li> </ul> <p>The package manager will automatically select the appropriate version for your system architecture.</p>"},{"location":"install-pmm/install-pmm-client/package_manager.html#installation-process","title":"Installation process","text":""},{"location":"install-pmm/install-pmm-client/package_manager.html#step-1-configure-repositories","title":"Step 1: Configure repositories","text":"<p>Choose your preferred method to configure the Percona repositories:</p> Automatic (Recommended)Manual download <p>Use the <code>percona-release</code> utility to automatically configure repositories:</p> <p>Tip</p> <p>If you have used <code>percona-release</code> before, disable and re-enable the repository: <pre><code>percona-release disable all\npercona-release enable pmm3-client\n</code></pre></p> Debian-basedRed Hat-based <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\nsudo dpkg -i percona-release_latest.generic_all.deb\nsudo percona-release enable pmm3-client\n</code></pre> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\npercona-release enable pmm3-client\n</code></pre> <p>Download packages directly without configuring repositories:</p> <ol> <li>Visit the PMM download page.</li> <li>Select PMM 3 and choose specific version (usually the latest).</li> <li>Under Select Platform, select the item matching your software platform and architecture (x86_64 or ARM64).</li> <li>Download the package file or copy the link and use <code>wget</code> to download it.</li> </ol>"},{"location":"install-pmm/install-pmm-client/package_manager.html#step-2-install-pmm-client","title":"Step 2: Install PMM Client","text":"<p>Root permissions required</p> <p>The installation commands below require root privileges. Use <code>sudo</code> if you\u2019re not running as root.</p> From repositoryFrom downloaded package Debian-basedRed Hat-based <pre><code>sudo apt update\nsudo apt install -y pmm-client\n</code></pre> <pre><code>yum install -y pmm-client\n</code></pre> Debian-basedRed Hat-based <pre><code>sudo dpkg -i pmm-client_*.deb\n</code></pre> <pre><code>sudo dnf localinstall pmm-client-*.rpm\n</code></pre>"},{"location":"install-pmm/install-pmm-client/package_manager.html#step-3-verify-installation","title":"Step 3: Verify installation","text":"<p>Check that PMM Client installed correctly:</p> <pre><code>pmm-admin --version\n</code></pre>"},{"location":"install-pmm/install-pmm-client/package_manager.html#step-4-register-the-node","title":"Step 4: Register the node","text":"<p>Register your nodes to be monitored by PMM Server using the PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> <p>where: </p> <ul> <li><code>X.X.X.X</code> is the address of your PMM Server</li> <li><code>443</code> is the default port number</li> <li><code>admin</code>/<code>admin</code> is the default PMM username and password. This is the same account you use to log into the PMM user interface, which you had the option to change when first logging in.</li> </ul> <p>HTTPS connection required</p> <p>Nodes must be registered with the PMM Server using a secure HTTPS connection. If you try to use HTTP in your server URL, PMM will automatically attempt to establish an HTTPS connection on port 443. If a TLS connection cannot be established, you will receive an error message and must explicitly use HTTPS with the appropriate secure port.</p> Registration example <p>Register a node with IP address 192.168.33.23, type generic, and name mynode on a PMM Server with IP address 192.168.33.14:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@192.168.33.14:443 192.168.33.23 generic mynode\n</code></pre>"},{"location":"install-pmm/install-pmm-client/package_manager.html#step-5-verify-the-connection","title":"Step 5: Verify the connection","text":"<p>Check that PMM Client is properly connected and registered:</p> <pre><code>pmm-admin status\n</code></pre>"},{"location":"install-pmm/install-pmm-client/package_manager.html#related-topics","title":"Related topics","text":"<ul> <li>Install PMM Client using Docker </li> <li>Connect database services </li> <li>PMM Client command reference </li> <li>Upgrade PMM Client </li> <li>Uninstall PMM Client</li> <li>Unregister PMM Client</li> </ul>"},{"location":"install-pmm/install-pmm-client/prerequisites.html","title":"Prerequisites for PMM Client","text":"<p>Before installing PMM Client, ensure your environment meets these requirements.</p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#quick-requirements-checklist","title":"Quick requirements checklist","text":"<p>\u2713 Hardware: 64-bit system (x86_64 or ARM64) with at least 100 MB storage \u2713 OS: Modern 64-bit Linux (Debian, Ubuntu, RHEL, Oracle Linux, Amazon Linux 2023) \u2713 Network: Connectivity to PMM Server (ports 80/443) \u2713 Software: curl, gnupg, sudo, wget \u2713 Database: Appropriate monitoring user credentials  </p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#system-requirements","title":"System requirements","text":"<p>PMM Client is designed to be lightweight but requires:</p> <ul> <li>Architecture: x86_64 or ARM64</li> <li>RAM: Minimal (100-200 MB per monitored database instance)</li> <li> <p>Storage:</p> <ul> <li>100 MB for installation</li> <li>VM Agent reserves 1 GB for caching during network outages</li> </ul> </li> </ul> <p>For comprehensive hardware specifications, see Hardware and system requirements.</p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#network-connectivity","title":"Network connectivity","text":"<p>PMM Client requires these network connections:</p> Connection Port Purpose PMM Client &gt; PMM Server 443 (or 80) Metrics reporting and management PMM Client &gt; Database instances Varies by DB type Collection of monitoring data <p>For a complete list of ports and detailed network configuration options, see Network and firewall requirements.</p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#required-software","title":"Required software","text":"<ul> <li> <p>Ensure these packages are installed before proceeding: curl, gnupg, sudo, wget.</p> </li> <li> <p>For Docker-based deployment, you\u2019ll also need Docker Engine properly installed and configured. </p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#database-monitoring-requirements","title":"Database monitoring requirements","text":"<p>To ensure successful database monitoring with PMM, confirm the following:</p> <ul> <li>Monitoring users: Create database accounts with the required permissions  </li> <li>Log access: Enable file system access to database logs (where applicable)  </li> <li>Performance Schema: Recommended for enhanced MySQL monitoring  </li> </ul>  Core databases Cloud services Proxy services Additional services <ul> <li>MySQL monitoring requirements </li> <li>MongoDB monitoring requirements </li> <li>PostgreSQL monitoring requirements</li> </ul> <ul> <li>Amazon RDS / Aurora</li> <li>Microsoft Azure </li> <li>Google Cloud Platform</li> </ul> <ul> <li>ProxySQL monitoring requirements </li> <li>HAProxy monitoring requirements</li> </ul> <ul> <li>External services monitoring </li> <li>Remote instances monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during installation or setup, see the Troubleshooting checklist.</p>"},{"location":"install-pmm/install-pmm-client/prerequisites.html#next-steps","title":"Next steps","text":"<p>After confirming your environment meets these prerequisites:</p> <ul> <li>Install PMM Client using your preferred method</li> <li>Add database instances for monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/index.html","title":"Connect databases to PMM","text":"<p>Percona Monitoring and Management (PMM) supports monitoring for MySQL/MariaDB, PostgreSQL, MongoDB, and various cloud database services. </p>"},{"location":"install-pmm/install-pmm-client/connect-database/index.html#supported-database-technologies","title":"Supported database technologies","text":"<ul> <li>MySQL (and variants Percona Server for MySQL, Percona XtraDB Cluster, MariaDB)</li> <li>MongoDB</li> <li>PostgreSQL</li> <li>ProxySQL</li> <li>Amazon RDS</li> <li>Microsoft Azure</li> <li>Google Cloud Platform (MySQL and PostgreSQL)</li> <li>Linux</li> <li>External services</li> <li>HAProxy</li> <li>Remote instances</li> </ul> Database type Local monitoring Remote monitoring Query Analytics (QAN) Performance schema Backup integration MySQL/MariaDB \u2714 \u2714 \u2714 \u2714 \u2714 PostgreSQL \u2714 \u2714 \u2714 \u2714 \u2718 MongoDB \u2714 \u2714 \u2714 \u2714 \u2714 AWS RDS/Aurora \u2718 \u2714 \u2714 \u2714 \u2718 Azure Database \u2718 \u2714 \u2714 \u2714 \u2718 Google Cloud SQL \u2718 \u2714 \u2714 \u2714 \u2718 ProxySQL \u2714 \u2714 \u2718 \u2718 \u2718 HAProxy \u2714 \u2714 \u2718 \u2718 \u2718"},{"location":"install-pmm/install-pmm-client/connect-database/index.html#modify-existing-services","title":"Modify existing services","text":"<p>To change the parameters of a previously-added service, remove the service and re-add it with the new parameters.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/index.html#new-to-pmm","title":"New to PMM?","text":"<p>If you\u2019re setting up monitoring for the first time, follow the installation and setup instructions in the PMM installation overview.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html","title":"Connect Amazon RDS instance","text":""},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#required-settings","title":"Required settings","text":"<p>It is possible to use PMM for monitoring Amazon RDS. In this case, the PMM Client is not installed on the host where the database server is deployed. By using the PMM web interface, you connect to the Amazon RDS DB instance. You only need to provide the IAM user access key (or assign an IAM role) and PMM discovers the Amazon RDS DB instances available for monitoring.</p> <p>First of all, ensure that there is the minimal latency between PMM Server and the Amazon RDS instance.</p> <p>Network connectivity can become an issue for VictoriaMetrics to scrape metrics with 1 second resolution.  We strongly suggest that you run PMM Server on AWS (Amazon Web Services) in the same availability zone as Amazon RDS instances.</p> <p>It is crucial that enhanced monitoring be enabled for the Amazon RDS DB instances you intend to monitor.</p> <p>Set the Enable Enhanced Monitoring option in the settings of your Amazon RDS DB instance.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-user-with-permission-to-access-amazon-rds-db-instances","title":"Creating an IAM user with permission to access Amazon RDS DB instances","text":"<p>It is recommended that you use an IAM user account to access Amazon RDS DB instances instead of using your AWS account. This measure improves security as the permissions of an IAM user account can be limited so that this account only grants access to your Amazon RDS DB instances. On the other hand, you use your AWS account to access all AWS services.</p> <p>The procedure for creating IAM user accounts is well described in the Amazon RDS documentation. This section only goes through the essential steps and points out the steps required for using Amazon RDS with Percona Monitoring and Management.</p> <p>The first step is to define a policy which will hold all the necessary permissions. Then, you need to associate this policy with the IAM user or group. In this section, we will create a new user for this purpose.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-a-policy","title":"Creating a policy","text":"<p>A policy defines how AWS services can be accessed. Once defined it can be associated with an existing user or group.</p> <ol> <li> <p>Select the Policies option on the navigation panel and click the Create policy button.</p> <p></p> </li> <li> <p>On the Create policy page, select the JSON tab and replace the existing contents with the following JSON document.</p> JSON <pre><code>{ \"Version\": \"2012-10-17\",\n\"Statement\": [{ \"Sid\": \"Stmt1508404837000\",\n            \"Effect\": \"Allow\",\n            \"Action\": [ \"rds:DescribeDBInstances\",\n                        \"cloudwatch:GetMetricStatistics\",\n                        \"cloudwatch:ListMetrics\"],\n                        \"Resource\": [\"*\"] },\n            { \"Sid\": \"Stmt1508410723001\",\n            \"Effect\": \"Allow\",\n            \"Action\": [ \"logs:DescribeLogStreams\",\n                        \"logs:GetLogEvents\",\n                        \"logs:FilterLogEvents\" ],\n                        \"Resource\": [ \"arn:aws:logs:*:*:log-group:RDSOSMetrics:*\" ]}\n        ]\n}\n</code></pre> </li> <li> <p>Click Review policy and set a name to your policy, such as <code>AmazonRDSforPMMPolicy</code>. Then, click the Create policy button.</p> <p></p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-user","title":"Creating an IAM user","text":"<p>Policies are attached to existing IAM users or groups. To create a new IAM user, select Users on the Identity and Access Management page at AWS. Then click Add user and complete the following steps:</p> <ol> <li> <p>On the Add user page, set the user name and select the Programmatic access option under Select AWS access type. Set a custom password and then proceed to permissions by clicking the Permissions button.</p> <p></p> </li> <li> <p>On the Set permissions page, add the new user to one or more groups if necessary. Then, click Review.</p> </li> <li> <p>On the Add user page, click Create user.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-access-key-for-an-iam-user","title":"Creating an access key for an IAM user","text":"<p>To discover an Amazon RDS DB instance in PMM, you either need to use the access key and secret access key of an existing IAM user or an IAM role. To create an access key for use with PMM, open the IAM console and click Users on the navigation pane. Then, select your IAM user.</p> <p>To create the access key, open the Security credentials tab and click the Create access key button. The system automatically generates a new access key ID and a secret access key that you can provide on the PMM Add Instance dashboard to have your Amazon RDS DB instances discovered.</p> <p>In case, the PMM Server and Amazon RDS DB instance were created by using the same AWS account, you do not need create the access key ID and secret access key manually. PMM retrieves this information automatically and attempts to discover your Amazon RDS DB instances.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#attaching-a-policy-to-an-iam-user","title":"Attaching a policy to an IAM user","text":"<p>The last step before you are ready to create an Amazon RDS DB instance is to attach the policy with the required permissions to the IAM user.</p> <p>First, make sure that the Identity and Access Management page is open and open Users. Then, locate and open the IAM user that you plan to use with Amazon RDS DB instances. Complete the following steps, to apply the policy:</p> <ol> <li> <p>On the Permissions tab, click the Add permissions button.</p> </li> <li> <p>On the Add permissions page, click Attach existing policies directly.</p> </li> <li> <p>Using the Filter, locate the policy with the required permissions (such as <code>AmazonRDSforPMMPolicy</code>).</p> </li> <li> <p>Select a check-box next to the name of the policy and click Review.</p> </li> <li> <p>The selected policy appears on the Permissions summary page. Click Add permissions.</p> </li> </ol> <p>The <code>AmazonRDSforPMMPolicy</code> is now added to your IAM user.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#creating-an-iam-role","title":"Creating an IAM role","text":"<p>Instead of creating an IAM user you can create an IAM role for a service, to discover Amazon RDS DB instances automatically without the need for access and secret keys. (But this only works if you are running PMM through AWS.)</p> <p>To create an IAM role open the IAM console and click Roles on the navigation pane.</p> <ol> <li> <p>Click the Create role button.</p> </li> <li> <p>Select AWS service and select EC2 for the use case.</p> </li> <li> <p>Click the Next: Permissions button.</p> </li> <li> <p>Find the policy created previously and select it.</p> </li> <li> <p>Click the Next: Tags button.</p> </li> <li> <p>(Optional) Add a metadata tag to the role.</p> </li> <li> <p>Click the Next: Review button.</p> </li> <li> <p>Fill the role name and description.</p> </li> <li> <p>Click the Create role button.</p> </li> </ol> <p>After the role is created EC2 instances running PMM will have permissions to discover RDS DB instances.</p> <p>It\u2019s also possible to create an IAM role to delegate permissions to an IAM user or to add permissions to a user belonging to another AWS account. See the official AWS documentation on creating IAM roles.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#setting-up-the-amazon-rds-db-instance","title":"Setting up the Amazon RDS DB Instance","text":"<p>Query Analytics requires Configuring Performance Schema as the query source, because the slow query log is stored on the AWS (Amazon Web Services) side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Amazon RDS.</p> <p>Important</p> <p>Enabling Performance Schema on T2 instances is not recommended because it can easily run the T2 instance out of memory.</p> <p>When adding a monitoring instance for Amazon RDS, specify a unique name to distinguish it from the local instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Amazon RDS instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, UPDATE, DELETE, DROP ON performance_schema.* TO 'pmm'@'%';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#adding-an-amazon-rds-aurora-or-remote-instance","title":"Adding an Amazon RDS, Aurora or Remote Instance","text":"<p>Important</p> <p>It may take longer for PMM to discover Amazon RDS instances in the <code>creating</code> state. You must wait a bit longer until PMM discovers these instances.</p> <p>The preferred method of adding an Amazon RDS database instance to PMM is via the  PMM Configuration &gt; PMM Inventory &gt; Add Instance menu option.</p> <p>This method supports Amazon RDS database instances that use Amazon Aurora, MySQL, or MariaDB engines, as well as any remote PostgreSQL, ProxySQL, MySQL and MongoDB instances.</p> <p>The following steps are needed to add an Amazon RDS database instance to PMM:</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Instance &gt; Amazon RDS.</p> <p></p> </li> <li> <p>Enter the access key ID and the secret access key of your IAM user or leave these fields empty if an IAM role was created.</p> </li> <li> <p>Click the Discover button for PMM to retrieve the available Amazon RDS instances.</p> <p></p> </li> <li> <p>For the instance that you would like to monitor, select the Start monitoring button.</p> </li> <li> <p>You will see a new page with the number of fields. The list is divided into the following groups: Main details, RDS database, Labels, and Additional options. Some already known data, such as already entered AWS access key, are filled in automatically, and some fields are optional.</p> <p></p> <p>The Main details section allows you to specify the DNS hostname of your instance, the service name to use within PMM, the port your service is listening on, and the database user name and password.</p> <p></p> <p>The Labels section allows you to specify labels for the environment, the AWS region and availability zone to be used, the Replication set and Cluster names and also it allows you to set the list of custom labels in a key:value format.</p> <p></p> <p>The Additional options section contains specific flags which allow you to tune the RDS monitoring. They can allow you to skip connection check, to use TLS for the database connection, not to validate the TLS certificate and the hostname, as well as to disable basic and/or enhanced metrics collection for the RDS instance to reduce costs.</p> <p>Also this section contains a database-specific flag, which would allow Query Analytics for the selected remote database:</p> <ul> <li> <p>when adding some remote MySQL, AWS RDS MySQL or Aurora MySQL instance, you will be able to choose using performance schema for the database monitoring;</p> </li> <li> <p>when adding a PostgreSQL instance, you will be able to activate using <code>pg_stat_statements</code> extension;</p> </li> <li> <p>when adding a MongoDB instance, you will be able to choose using Query Analytics MongoDB profiler.</p> </li> </ul> </li> <li> <p>Finally press the Add service button to start monitoring your instance.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/aws.html#adding-an-amazon-rds-postgresql-instance","title":"Adding an Amazon RDS PostgreSQL instance","text":"<p>For PostgreSQL, use the same method described above.</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Instance &gt; Amazon RDS.</p> <p></p> </li> <li> <p>Follow steps 4 to 6 as in the previous section. Fill the form and remember to select <code>PG Stat Statement</code> to enable Query Analytics.</p> <p>To get queries for Query Analytics, you need to enable <code>pg_stat_statements</code> in <code>postgres</code> database of your instance by running:</p> <pre><code>CREATE EXTENSION pg_stat_statements SCHEMA public;\n</code></pre> <p> </p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html","title":"Connect Azure instance to PMM","text":"<p>Technical Preview</p> <p>Microsoft Azure functionality is currently in technical preview and is subject to change.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#activate-microsoft-azure","title":"Activate Microsoft Azure","text":"<p>The Microsoft Azure feature is turned off by default. To turn it on:</p> <ol> <li> <p>Go to  PMM Configuration &gt; Settings &gt; Advanced Settings.</p> </li> <li> <p>Click the  toggle in the Technical preview features section of the page.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#prerequisites","title":"Prerequisites","text":"<p>PMM can monitor Azure database instances similar to other remote instances. In this case, the PMM Client is not installed on the host where the database server is deployed. </p> <p>By using the PMM web interface, you connect to the Azure DB instance. Discovery is not yet implemented in PMM but it is possible to add known instances by providing the connection parameters.</p> <ol> <li>Minimize network latency between PMM Server and the Azure instance.</li> <li>Configure firewall rules to allow PMM Server access to your Azure database:</li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#setting-up-a-mysql-instance","title":"Setting up a MySQL instance","text":"<p>Query Analytics requires you to configure Performance Schema as the query source, because the slow query log is stored on the Azure side, and QAN agent is not able to read it.  Enable the <code>performance_schema</code> option under <code>Parameter Groups</code> in Azure MySQL databases.</p> <p>When adding a monitoring instance for Azure, specify a unique name to distinguish it from the local MySQL instance.  If you do not specify a name, it will use the client\u2019s host name.</p> <p>Create the <code>pmm</code> user with the following privileges on the Azure MySQL database instance that you want to monitor:</p> <pre><code>CREATE USER 'pmm'@'%' IDENTIFIED BY 'pass';\nGRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO 'pmm'@'%';\nALTER USER 'pmm'@'%' WITH MAX_USER_CONNECTIONS 10;\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#adding-an-azure-instance","title":"Adding an Azure instance","text":"<p>Follow the instructions for remotes instances explained here, Azure MySQL databases are similar to AWS RDS databases.</p> <p>Example:</p> <p></p> <p>and be sure to set Performance Schema as the query collection method for Query Analytics.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#mariadb","title":"MariaDB","text":"<p>MariaDB up to version 10.2 works out of the box but starting with MariaDB 10.3 instrumentation is disabled by default and cannot be enabled since there is no SUPER role in Azure-MariaDB. So, it is not possible to run the required queries to enable instrumentation. Monitoring will work but Query Analytics won\u2019t receive any query data.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#postgresql","title":"PostgreSQL","text":"<p>For PostgreSQL follow the same methods used for MySQL and MariaDB and enable <code>track_io_timing</code> in the instance configuration to enable Query Analytics.</p> <p></p> <p>For Query Analytics, set the server parameter:</p> <pre><code>pg_stat_statements.track = all\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#to-discover-databases-on-azure","title":"To discover databases on Azure","text":"<p>You need to get the Client ID, Client Secret, Tenant ID and Subscription ID.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#get-the-subscription-id","title":"Get the subscription ID","text":"<p>To get a subscription ID:</p> <ol> <li> <p>Search Subscriptions, click on your subscription name </p> </li> <li> <p>Copy the subscription ID</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#create-a-new-application-to-get-the-tenant-id-client-id-and-the-client-secret","title":"Create a new application to get the tenant ID, client ID and the client secret","text":"<p>To get the tenant ID, client ID and the client secret:</p> <ol> <li> <p>Search for Azure Active Directory </p> </li> <li> <p>Register a new application  </p> </li> <li> <p>At this point you can copy the client and tenant IDs. </p> </li> <li> <p>Create an application secret.  </p> </li> <li> <p>Copy the value of the application secret. Once you leave this page you won\u2019t be able to see the secret again and you will have to generate a new    one. </p> </li> <li> <p>Give API access permissions to your application.</p> <ul> <li> <p>Search for Subscriptions like in step 1.</p> </li> <li> <p>Select your application and grant Monitor Reader permissions. This might require you to have admin permissions in your Azure account.</p> </li> </ul> </li> </ol> <p> </p> <p>When you fill in all fields press the Discover button and you will see a list of available databases for monitoring.</p> <p></p> <p>You can monitor 6 types of databases:</p> <ul> <li><code>Microsoft.DBforMySQL/servers</code></li> <li><code>Microsoft.DBforMySQL/flexibleServers</code></li> <li><code>Microsoft.DBforMariaDB/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/servers</code></li> <li><code>Microsoft.DBforPostgreSQL/flexibleServers</code></li> <li><code>Microsoft.DBforPostgreSQL/serversv2</code></li> </ul> <p>You can find more details on how to create DB on Azure at:</p> <ul> <li>https://docs.microsoft.com/en-us/azure/postgresql/</li> <li>https://docs.microsoft.com/en-us/azure/mysql/</li> </ul> <p>Tip</p> <p>You must set <code>pg_stat_statements.track = all</code> in your PostgreSQL Server settings to use PMM Query Analytics. [Read more](../connect-database/postgresql.md#configure-monitoring-extension.</p> <p></p> <p>In the list of databases on the Discovery page click Start Monitoring to add the selected Azure Database to PMM.</p> <p>Fill in all required fields and click Add service.</p> <p>PMM can use 3 exporters to collect metrics:</p> <ul> <li> <p>Azure Metrics Exporter \u2013 collect \u201csystem\u201d metrics related to DB.</p> <ul> <li><code>node_cpu_average</code></li> <li><code>azure_resource_info</code></li> <li><code>node_filesystem_size_bytes</code></li> <li><code>azure_memory_percent_average</code></li> <li><code>azure_storage_percent_average</code></li> <li><code>azure_storage_used_bytes_average</code></li> <li><code>node_network_receive_bytes_total</code></li> <li><code>node_network_transmit_bytes_total</code></li> </ul> </li> <li> <p><code>mysql_exporter</code> or <code>postgres_exporter</code> \u2013 to collect database related metrics.</p> </li> <li> <p>pmm-agent to collect queries related metrics using <code>pg_stat_statements</code> for PostgreSQL or Performance Schema for MySQL (MariaDB)</p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/azure.html#adding-an-azure-instance-on-pmm-client-side","title":"Adding an Azure Instance on PMM Client side","text":"<p>TLS/SSL is enforced on the server by default. So please download the certificate needed to communicate over SSL with your Azure Database. It can be done on Networking tab for your Azure Database instance.</p> <p>Also enforced TLS/SSL connection option can be disabled on server side.</p> <p></p> <p>Command for adding an azure database service for monitoring without TLS/SSL.</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema\n</code></pre> <p>Downloaded certificate is named <code>DigiCertGlobalRootCA.crt.pem</code>.</p> <p>An example of the command for adding an Azure database service for monitoring with TLS/SSL would be:</p> <pre><code>pmm-admin add mysql --username=azureuser --password=secure --host=azuremysql.mysql.database.azure.com --service-name=azure1 --query-source=perfschema --tls --tls-ca=DigiCertGlobalRootCA.crt.pem --tls-cert=client-cert.pem --tls-key=client-key.pem --tls-skip-verify\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html","title":"Connect an external instance to PMM","text":""},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-general-external-services","title":"Add general external services","text":"<p>You can collect metrics from an external (custom) exporter on a node when:</p> <ul> <li>there is already a pmm-agent instance running and,</li> <li>this node has been configured using the <code>pmm-admin config</code> command.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#usage","title":"Usage","text":"<pre><code>pmm-admin add external --service-name=&lt;service-name&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre> <pre><code>pmm-admin add external-serverless --external-name=&lt;external-service-name&gt; --host=&lt;hostname&gt; --listen-port=&lt;listen-port&gt; --metrics-path=&lt;metrics-path&gt; --scheme=&lt;scheme&gt;\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#tls-certificate-verification","title":"TLS certificate verification","text":"<p>When connecting to external services over HTTPS, PMM performs TLS certificate validation by default to ensure secure connections. However, in some scenarios you may need to skip this validation. Use the <code>--tls-skip-verify</code> flag when monitoring services with:</p> <ul> <li>self-signed certificates</li> <li>development environments where proper certificates aren\u2019t configured</li> <li>IP-based endpoints that lack proper certificate Subject Alternative Names (SANs)</li> <li>PostgreSQL Operator deployments with HAProxy that use self-signed certificates</li> <li>encounter errors like <code>Connection check failed: Get \"https://127.0.0.1:8008/metrics\": tls: failed to verify certificate: x509: cannot validate certificate for 127.0.0.1 because it doesn't contain any IP SANs</code>, you can resolve this by adding the <code>--tls-skip-verify</code> flag to your command.</li> </ul> <p>Security warning</p> <p>Using <code>--skip-tls-verify</code> disables TLS certificate validation and should only be used in development environments or when connecting to trusted services with certificate issues. This makes connections vulnerable to man-in-the-middle attacks.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#examples-with-tls-skip-verification","title":"Examples with TLS skip verification","text":"<pre><code># \ud83c\udd95 External service with TLS verification skipped\npmm-admin add external --listen-port=8008 --scheme=https --tls-skip-verify\n\n# \ud83c\udd95 External serverless with TLS verification skipped  \npmm-admin add external-serverless --host=example.com --listen-port=9093 --scheme=https --tls-skip-verify\n\n# \ud83c\udd95 HAProxy with TLS verification skipped (useful for PostgreSQL Operator deployments)\npmm-admin add haproxy --listen-port=8404 --scheme=https --tls-skip-verify\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#get-data-from-external-exporters","title":"Get data from external exporters","text":"<p>There two ways to get metrics from other exporters:</p> <ul> <li> <p><code>external</code> will collect metrics from the exporter that is run on the same host as PMM Client\u2019s connection to it by a port. (See more details with <code>pmm-admin add external --help</code>.)</p> </li> <li> <p><code>external-serverless</code> is useful for collecting metrics from cloud services. You need a host and port number to add it to PMM Server. (See more details with <code>pmm-admin add external-serverless --help</code>.)</p> </li> </ul> <p>Here are the differences between <code>external</code> and <code>external-serverless</code> types.</p> <p>Connection schema of external exporter:</p> <p></p> <p>Connection schema of external serverless exporter:</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-a-service-not-supported-by-pmm","title":"Add a service not supported by PMM","text":"<p>PMM can collect any metrics in Open metrics or Prometheus exposition format. You must specify the host and port of these metrics using the <code>pmm-admin add external</code> or <code>pmm-admin add external-serverless</code> commands.</p> <p>From this point, PMM will collect and store available metrics.</p> <p>To browse and visualize collected metrics as a first step, we can look at the Advanced Data Exploration dashboard and select informative services and metrics.</p> <p></p> <p>Another way is to create a new Grafana Dashboard to PMM as needed.</p> <p>One more way is to search for an already created dashboard at https://grafana.com/grafana/dashboards for the added exporter and import it into PMM.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#third-party-exporters","title":"Third-party exporters","text":"<p>You can find more exporters on the official Prometheus page.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#custom-exporter","title":"Custom exporter","text":"<p>You can create a custom external exporter or extend your application to expose metrics in Prometheus exposition format. This gives you complete control over what metrics are collected and how they\u2019re exposed. To learn how to build your own exporter, see Writing Exporter in the Prometheus Docs.</p> Example: Add an HTTP exporter <pre><code>root@mysql1:~# pmm-admin add external --group=processes  --listen-port=9256\nExternal Service added.\nService ID  : 6485f4fd-745b-4dfb-8b72-328e300f8b50\nService name: mysql1-processes\nGroup       : processes\n</code></pre> <p>This command:  - adds an exporter running on local port 9256 to the group called <code>processes</code>. - automatically generates the service name using the host and group names. - uses the default scheme (http) and metrics path (/metrics).</p> Example: Add an HTTPS exporter (Skip TLS verification) <pre><code>root@mysql1:~# pmm-admin add external --group=processes --listen-port=8008 --scheme=https --tls-skip-verify\nExternal Service added.\nService ID  : 7b96c5fe-856c-4efc-9c83-439f411g9c61\nService name: mysql1-processes\nGroup       : processes\n</code></pre> <p>This command:</p> <ul> <li>adds an HTTPS exporter on local port <code>8008</code>.</li> <li>uses the <code>--tls-skip-verify</code> flag to bypass TLS certificate validation (for development or testing only!)</li> <li>automatically generates the service name using the host and group names.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/external.html#add-an-external-service-via-ui","title":"Add an external service via UI","text":"<p>To add an external service via PMM UI:</p> <ol> <li> <p>In the PMM web interface, go to PMM Configuration &gt; PMM Inventory &gt; Add Service &gt; External Service.</p> <p></p> </li> <li> <p>Fill in the form and set the external service endpoint: </p> <ul> <li> <p>manually OR:</p> <p></p> </li> <li> <p>by parsing required data from a URL string. In this case you only need to pass a valid URL:</p> <p></p> </li> </ul> </li> <li> <p>For HTTPS connections: If your external service uses HTTPS with self-signed certificates or certificates that don\u2019t properly validate, check the Skip TLS certificate and hostname validation option under PMM Configuration &gt; PMM Inventory &gt; Services section.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html","title":"Connect Google Cloud Platform instances to PMM","text":"<p>PMM can monitor MySQL or PostgreSQL instances hosted on the Google Cloud Platform.</p> <p>The connection can be direct, or indirect using Cloud SQL Proxy.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#mysql","title":"MySQL","text":"<p>To add a MySQL instance on Google Cloud:</p> <ol> <li> <p>Set up a MySQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure Performance Schema on the MySQL server. Using the GCP console\u2019s Cloud Shell or your own <code>gcloud</code> installation, run:</p> <pre><code>gcloud sql instances patch &lt;instance_name&gt; --database-flags performance_schema=on\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; PMM Inventory &gt;  Service &gt; Add Service &gt; MySQL.</p> </li> <li> <p>Fill in the details for the remote MySQL instance and make sure to enable the Use performance schema option.</p> </li> <li> <p>Click Add service.</p> </li> <li> <p>Go to Dashboards and check for values in the MySQL Instance Summary dashboard and in Query Analytics.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#postgresql","title":"PostgreSQL","text":"<p>To add a PostgreSQL instance on Google Cloud:</p> <ol> <li> <p>Set up a PostgreSQL instance on Google Cloud.</p> </li> <li> <p>The database server must be accessible by PMM Client. If PMM Client is not also hosted on GCP, you will need to add a network interface with a public interface.</p> </li> <li> <p>Configure <code>pg_stat_statements</code>. Open an interactive SQL session with your GCP PostgreSQL server and run:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; PMM Inventory &gt; Services &gt; Add Service &gt; PostgreSQL.</p> </li> <li> <p>Fill in the details for the remote PostgreSQL instance and make sure to PG Stat Statements option under Stat tracking options.</p> </li> <li> <p>Click Add service.</p> </li> <li> <p>Go to Dashboards and check for values in the PostgreSQL Instances Overview  and Query Analytics.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#cloud-sql-proxy","title":"Cloud SQL Proxy","text":""},{"location":"install-pmm/install-pmm-client/connect-database/google.html#mysql_1","title":"MySQL","text":"<p>To add a MySQL instance:</p> <ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Enable Performance Schema.</p> </li> <li> <p>Run Cloud SQL Proxy (runs on PMM Client node).</p> As a Docker containerOn Linux <pre><code>docker run -d \\\n-v ~/path/to/admin-api-file.json:/config \\\n-p 127.0.0.1:3306:3306 \\\ngcr.io/cloudsql-docker/gce-proxy:1.19.1 \\\n/cloud_sql_proxy \\\n-instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:0.0.0.0:3306 \\\n-credential_file=/config\n</code></pre> <pre><code>wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\nchmod +x cloud_sql_proxy\n./cloud_sql_proxy -instances=example-project-NNNN:us-central1:mysql-for-pmm=tcp:3306 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> <li> <p>Add instance:</p> <pre><code>pmm-admin add mysql --host=127.0.0.1 --port=3306 \\\n--username=root --password=secret \\\n--service-name=MySQLGCP --query-source=perfschema\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/google.html#postgresql_1","title":"PostgreSQL","text":"<p>To add a PostgreSQL instance:</p> <ol> <li> <p>Create instance on GCP.</p> </li> <li> <p>Note connection as <code>&lt;project_id&gt;:&lt;zone&gt;:&lt;db_instance_name&gt;</code>.</p> </li> <li> <p>Enable Admin API and download the JSON credential file.</p> </li> <li> <p>Run Cloud SQL Proxy:</p> <pre><code>./cloud_sql_proxy -instances=example-project-NNNN:us-central1:pg-for-pmm=tcp:5432 \\\n-credential_file=/path/to/credential-file.json\n</code></pre> </li> <li> <p>Log into PostgreSQL.</p> </li> <li> <p>Load extension:</p> <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre> </li> <li> <p>Add service:</p> <pre><code>pmm-admin add postgresql --host=127.0.0.1 --port=5432 \\\n--username=\"postgres\" --password=secret --service-name=PGGCP\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html","title":"Connect HAProxy databases to PMM","text":"<p>Monitor your HAProxy load balancer performance with Percona Monitoring and Management (PMM). PMM collects metrics from HAProxy\u2019s built-in Prometheus endpoint to provide insights into proxy performance, backend health, and traffic patterns.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#prerequisites","title":"Prerequisites","text":"<p>Before adding HAProxy to PMM, ensure:</p> <ol> <li> <p>HAProxy configured with metrics endpoint. </p> <ul> <li>HAProxy must expose Prometheus metrics. See How to configure HAProxy.</li> <li>Default metrics endpoint: <code>http://localhost:8404/metrics</code></li> <li>Verify metrics are accessible: <code>curl http://localhost:8404/metrics</code></li> </ul> </li> <li> <p>PMM Client installed and configured</p> </li> <li>PMM Client (pmm-agent) running on the same host as HAProxy</li> <li>Node registered with PMM Server using pmm-admin config</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#add-haproxy-service","title":"Add HAProxy service","text":"<p>Add HAProxy monitoring with the required port specification:</p> <pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> <p>where <code>listen-port</code> is the port number where HAProxy is running. This is the only required flag.</p> Successful output <pre><code>HAProxy Service added.\nService ID  : c481183f-70a2-443f-91e5-cae5cecd06a2\nService name: Ubuntu-haproxy\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#advanced-configuration-options","title":"Advanced configuration options","text":"<p>Customize the HAProxy service with additional parameters:</p> <pre><code># With authentication\npmm-admin add haproxy --listen-port=8404 --username=pmm --password=pmm MyHAProxy\n\n# With custom metrics path and HTTPS\npmm-admin add haproxy --listen-port=8404 --metrics-path=/prom-metrics --scheme=https\n\n# With custom service name\npmm-admin add haproxy --listen-port=8404 Production-HAProxy\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#available-options","title":"Available options","text":"<ul> <li><code>--listen-port</code>: HAProxy metrics port (required)</li> <li><code>--username</code>: Basic authentication username</li> <li><code>--password</code>: Basic authentication password</li> <li><code>--metrics-path</code>: Metrics endpoint path (default: /metrics)</li> <li><code>--scheme</code>: Connection protocol (http or https)</li> <li><code>--skip-connection-check</code>: Skip connectivity validation</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#via-web-ui","title":"Via web UI","text":"<p>To add HAProxy through the PMM web interface:</p> <ol> <li>Go to PMM Configuration &gt; PMM Inventory &gt; Add Service.</li> <li>Select HAProxy from the service types.</li> <li>Configure the connection parameters then click Add Service.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/haproxy.html#verify-the-connection","title":"Verify the connection","text":"<p>Check that HAProxy monitoring is active:</p> <pre><code>pmm-admin status\n</code></pre> <p>HAProxy data is visible in the Advanced Data Exploration dashboard:</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html","title":"Connect Linux databases to PMM","text":""},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#supported-linux-distributions","title":"Supported Linux distributions","text":"<p>PMM Client supports collecting system metrics from various Linux distributions:</p> <ul> <li>Red Hat/CentOS/Oracle Linux 8 and 9</li> <li>Amazon Linux 2023 (native support added in PMM 3.2.0)</li> <li>Debian 11 (Bullseye) and 12 (Bookworm)</li> <li>Ubuntu 22.04 (Jammy) and 24.04 (Noble)</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#add-linux-monitoring","title":"Add Linux monitoring","text":"<p>When you register a node using the PMM Client, system metrics collection is enabled by default:</p> <pre><code>pmm-admin config --server-url=https://admin:admin@pmm-server-ip:443\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#viewing-linux-metrics","title":"Viewing Linux metrics","text":"<p>To view collected Linux metrics:</p> <ol> <li>Go to the Operating System (OS) &gt; Overview dashboard.</li> <li>Select your node from the Node Names dropdown menu.</li> <li>Explore additional OS-specific dashboards for more detailed metrics:<ul> <li>OS &gt; Node Summary</li> <li>OS &gt; CPU Utilization Details</li> <li>OS &gt; Disk Details</li> <li>OS &gt; Memory Details</li> <li>OS &gt; Network Details</li> <li>OS &gt; Node Temperature Details</li> <li>OS &gt; NUMA Details</li> <li>OS &gt; Processes Details</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/linux.html#related-topics","title":"Related topics","text":"<ul> <li>Install PMM Client</li> <li>Operating System dashboard reference</li> <li>Troubleshooting PMM</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html","title":"Connect MongoDB databases to PMM","text":"<p>Connect a MongoDB instance to PMM to monitor a MongoDB or Percona Server for MongoDB database server.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#prerequisites","title":"Prerequisites","text":"<p>Before you start, ensure you have:</p> <ul> <li>PMM Server installed and running with a known IP address or hostname accessible from the Client node.</li> <li>PMM Client installed and the nodes are registered with PMM Server.</li> <li>admin privileges to install and configure PMM Client on the host.</li> <li>preconfigured MongoDB user with appropriate monitoring privileges, or sufficient privileges to create the required roles and users.</li> <li>MongoDB server version 6.0 or higher. PMM may work with MongoDB versions as old as 4.4, but we recommend using MongoDB 6.0+ for complete feature support.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#step-1-set-up-mongodb-monitoring-permissions","title":"Step 1: Set up MongoDB monitoring permissions","text":"<p>Set up MongoDB with a dedicated user for PMM and the required permissions. First, create custom roles with the necessary privileges, then assign them to a PMM-specific user.</p> <p>Role privileges depend on:</p> <ul> <li>MongoDB version: 8.0+ requires the additional <code>directShardOperations</code> role for shard metrics</li> <li>Required features: basic monitoring only, or monitoring plus backup management.</li> <li>Query collection method: profiler or diagnostic log.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#create-monitoring-role","title":"Create monitoring role","text":"<p>After connecting to your MongoDB instance, create custom role with the privileges required for metric collection, working with Query Analytics (QAN) and optionally creating/restoring backups:</p> <p>Important</p> <p>Values for username (<code>user</code>) and password (<code>pwd</code>) are examples. Replace them before using these code snippets.</p> Minimum privilegesFull backup management privileges <p>This role grants the essential minimum privileges needed for monitoring and QAN: <pre><code>db.getSiblingDB(\"admin\").createRole({\n\"role\": \"pmmMonitor\",\n\"privileges\": [\n    {\n    \"resource\": { \"db\": \"\", \"collection\": \"\" },\n    \"actions\": [ \"dbHash\", \"find\", \"listIndexes\", \"listCollections\", \"collStats\", \"dbStats\", \"indexStats\" ]\n    },\n    {\n    \"resource\": { \"db\": \"\", \"collection\": \"system.version\" },\n    \"actions\": [ \"find\" ]\n    },\n    {\n    \"resource\": { \"db\": \"\", \"collection\": \"system.profile\" },\n    \"actions\": [ \"dbStats\", \"collStats\", \"indexStats\" ]\n    }         \n],\n\"roles\": [ ]\n})\n</code></pre></p> <p>If you plan to use PMM\u2019s backup features, create a role with full backup management privileges:</p> <pre><code>db.getSiblingDB(\"admin\").createRole({\n    \"role\": \"pbmAnyAction\",\n    \"privileges\": [\n    {\n        \"resource\": { \"anyResource\": true  },\n        \"actions\": [ \"anyAction\" ]\n    }\n    ],\n    \"roles\": []\n});\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#create-user-and-assign-created-role","title":"Create user and assign created role","text":"<p>After creating the role, create the PMM user and assign role based on your MongoDB version and requirements:</p> MongoDB 8.0+ (Standard)MongoDB 8.0+ (With backups)MongoDB &lt;8.0 (Standard)MongoDB &lt;8.0 (With backups) <p>MongoDB 8.0 introduced stricter security for direct shard access. For MongoDB 8.0 and later, the PMM user also requires the <code>directShardOperations</code> role to collect complete metrics from all cluster components:</p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n    \"roles\": [\n        { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n        { \"db\": \"local\", \"role\": \"read\" },\n        { \"db\": \"admin\", \"role\": \"clusterMonitor\" },\n        { \"db\": \"admin\", \"role\": \"directShardOperations\" }\n    ]\n})\n</code></pre> <p>If you intend to use PMM\u2019s backup management features, create a user with grant these permissions: </p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n    \"roles\": [\n        { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n        { \"db\": \"local\", \"role\": \"read\" },\n        { \"db\": \"admin\", \"role\": \"readWrite\", \"collection\": \"\" },\n        { \"db\": \"admin\", \"role\": \"backup\" },\n        { \"db\": \"admin\", \"role\": \"clusterMonitor\" },\n        { \"db\": \"admin\", \"role\": \"restore\" },\n        { \"db\": \"admin\", \"role\": \"pbmAnyAction\" },\n        { \"db\": \"admin\", \"role\": \"directShardOperations\" }\n    ]\n})      \n</code></pre> <p>Create the PMM user with standard monitoring roles:</p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n    \"roles\": [\n        { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n        { \"db\": \"local\", \"role\": \"read\" },\n        { \"db\": \"admin\", \"role\": \"clusterMonitor\" }\n    ]\n})\n</code></pre> <p>If you intend to use PMM\u2019s backup management features, create a user with these additional permissions: </p> <pre><code>db.getSiblingDB(\"admin\").createUser({\n    \"user\": \"pmm\",\n    \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n    \"roles\": [\n        { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n        { \"db\": \"local\", \"role\": \"read\" },\n        { \"db\": \"admin\", \"role\": \"readWrite\", \"collection\": \"\" },\n        { \"db\": \"admin\", \"role\": \"backup\" },\n        { \"db\": \"admin\", \"role\": \"clusterMonitor\" },\n        { \"db\": \"admin\", \"role\": \"restore\" },\n        { \"db\": \"admin\", \"role\": \"pbmAnyAction\" }\n    ]\n})      \n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#step-2-configure-query-source-for-mongodb-query-analytics","title":"Step 2: Configure query source for MongoDB query analytics","text":"<p>PMM offers two methods for collecting MongoDB queries. Choose based on your environment\u2019s requirements and constraints.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#compare-query-source-methods","title":"Compare query source methods","text":"Feature MongoDB Profiler Diagnostic log Database connections Uses pool continuously One connection at startup to get log path Connection pool impact High Minimal Requires <code>system.profile</code> Yes No Support remote instances Yes No Supports <code>mongos</code> No Yes Database overhead Moderate-High Minimal File-based logging No Yes Query history durability Volatile Disk-persisted Scales with DB count Linear degradation Constant MongoDB Profiler (Default)Diagnostic Log (Recommended for scale) <p>Choose this standard method for simple setups with fewer than 100 databases, remote MongoDB instances, or when you need real-time query collection. </p> <p>The MongoDB Profiler stores query performance data in <code>system.profile</code> collections for each database. PMM continuously reads from these collections to provide query analytics.</p> <p>Key advantages:</p> <ul> <li>Real-time query collection and analysis</li> <li>No additional file system access required</li> <li>Works with managed MongoDB services</li> <li>Immediate data availability after profiling is enabled </li> </ul> <p>To enable the MongoDB Profiler, choose one of the following methods:</p> In MongoDB configuration file (Recommended)On CLIIn MongoDB shell (temporary) <p>This method ensures your settings persist across server restarts and system reboots. It\u2019s the recommended approach for production environments:</p> <ol> <li>Edit the configuration file (usually <code>/etc/mongod.conf</code>).</li> <li> <p>Add or modify the <code>operationProfiling</code> section in the configuration file. Pay close attention to indentation as YAML is whitespace-sensitive:</p> <p><pre><code>operationProfiling:\n    mode: all             \n    slowOpThresholdMs: 200\n    rateLimit: 100        \n</code></pre> These settings control the following:</p> <ul> <li><code>mode: all</code> - Collects data for all operations.</li> <li><code>slowOpThresholdMs: 200</code> - Marks operations exceeding 200ms as \u201cslow.\u201d</li> <li><code>rateLimit: 100</code> -  Limits profiling sampling rate (Percona Server for MongoDB only).</li> </ul> <p>For more information about profiling configuration options, see the MongoDB documentation and the Percona Server for MongoDB documentation.</p> </li> <li> <p>Restart the <code>mongod</code> service using the appropriate command for your system. For example, for <code>systemd</code>:</p> <pre><code>systemctl restart mongod\n</code></pre> </li> </ol> <p>Use this method when starting the MongoDB server manually. Keep in mind that smaller values improve accuracy but can adversely affect the performance of your server:</p> <pre><code>mongod --dbpath=DATABASEDIR --profile 2 --slowms 200 --rateLimit 100\n</code></pre> <ul> <li><code>--dbpath</code>: The path to database files (usually <code>/var/lib/mongo</code>).</li> <li><code>--profile</code>: The MongoDB profiling level. A value of <code>2</code> tells the server to collect profiling data for all operations. To lower the load on the server, use a value of <code>1</code> to only record slow operations.</li> <li><code>--slowms</code>: An operation is classified as slow if it runs for longer than this number of milliseconds.</li> <li><code>--rateLimit</code>: (Only available with Percona Server for MongoDB.) The sample rate of profiled queries. A value of <code>100</code> means sample every 100<sup>th</sup> fast query. (Read more)</li> </ul> <p>This method enables profiling until the next server restart. Profiling must be enabled for each database you want to monitor. For example, to enable the profiler in the <code>testdb</code>, run this:</p> <pre><code>use testdb\ndb.setProfilingLevel(2, {slowms: 0})\n</code></pre> <p>If you have already added a service, you should remove it and re-add it after changing the profiling level.   </p> <p>Choose this method for production environments with 100+ databases, when experiencing connection pool issues, or when monitoring mongos routers.</p> <p>Available from PMM 3.3.0+, this method reads query data directly from MongoDB\u2019s log files instead of querying the database. This eliminates connection pool usage and reduces performance impact.</p> <p>Key advantages:</p> <ul> <li>Zero database connections required for metrics collection</li> <li>Eliminates connection pool errors completely</li> <li>Scales linearly regardless of database count</li> <li>Identical query analytics data as traditional profiler</li> </ul> <p>Prerequisites for Diagnostic Log: </p> <ul> <li>MongoDB 5.0+ (tested with 5.0.20-17)</li> <li>Write access to the configured log directory for MongoDB process</li> <li>Read access to log file for PMM Agent user</li> </ul> <p>To configure mongolog for MongoDB: </p> <ol> <li> <p>Choose one of the following methods to configure MongoDB to log slow operations to the diagnostic log file:</p> Config file (recommended)Command-line flags <p>Edit your MongoDB configuration file (<code>mongod.conf</code>):</p> <pre><code>systemLog:\ndestination: file\npath: /var/log/mongodb/mongod.log\nlogAppend: true\nlogRotate: reopen\n\noperationProfiling:\nmode: off\nslowOpThresholdMs: 100\n</code></pre> <p>Configuration explained:</p> <ul> <li><code>destination: file</code> - ensures MongoDB logs to a file (required for mongolog)</li> <li><code>path</code> - specifies the log file location that mongolog will read</li> <li><code>logAppend: true</code> - appends to existing log file instead of overwriting</li> <li><code>mode: off</code> - logs operations to file only (does NOT populate system.profile)</li> <li><code>slowOpThresholdMs: 100</code> - set based on your requirements</li> </ul> <p>Restart MongoDB after making changes:</p> <pre><code>systemctl restart mongod\n</code></pre> <p>Start <code>mongod</code> with these flags:</p> <pre><code>mongod \\\n--dbpath /var/lib/mongo \\\n--logpath /var/log/mongodb/mongod.log \\\n--logappend \\\n--profile 0 \\\n--slowms 100\n</code></pre> <p>Flag reference:</p> Flag Purpose <code>--logpath</code> Enables logging to a file (required by mongolog) <code>--logappend</code> Appends to the log file instead of overwriting <code>--profile 0</code> Enables logging of slow operations (not full profiling) <code>--slowms 100</code> Sets slow operation threshold (in milliseconds) </li> <li> <p>Create a logrotate configuration file (e.g., <code>/etc/logrotate.d/mongodb</code>) to configure log rotation:</p> <pre><code>/var/log/mongodb/mongod.log {\ndaily\nrotate 7\ncompress\ndelaycompress\ncopytruncate\nmissingok\nnotifempty\ncreate 640 mongod mongod\npostrotate\n    /bin/kill -SIGUSR1 `cat /var/run/mongod.pid 2&gt;/dev/null` &gt;/dev/null 2&gt;&amp;1\nendscript\n}\n</code></pre> <p>Critical requirements:</p> <ul> <li>Use <code>copytruncate</code> to preserve file handle for mongolog</li> <li>Avoid moving/renaming log files as this breaks mongolog\u2019s file tail</li> <li>Do not delete active log files during rotation</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#step-3-add-mongodb-service-to-pmm","title":"Step 3: Add MongoDB service to PMM","text":"<p>After configuring your database server, add a MongoDB service using either the user interface or the command line.</p> <p>Important</p> <p>To monitor MongoDB sharded clusters, PMM requires access to all cluster components. Make sure to add all config servers, all shards, and at least one or two mongos routers. Otherwise, PMM will not be able to correctly collect metrics and populate dashboards.</p> Via CLIVia web UI <p>Use <code>pmm-admin</code> to add the database server as a service using one of these example commands:</p> Standalone MongoDB instanceReplica Set or Sharded cluster componentIgnoring insecure server certificateWith mongolog query sourceSSL/TLS secured MongoDB <pre><code>pmm-admin add mongodb \\\n--username=pmm \\\n--password=your_secure_password \\\n--host=127.0.0.1 \\\n--port=27017 \\\n--enable-all-collectors\n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm \\\n--password=your_secure_password \\\n--host=127.0.0.1 \\\n--port=27017 \\        \n--cluster=my_cluster_name \\\n--enable-all-collectors        \n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm \\\n--password=your_secure_password \\\n--host=127.0.0.1 \\\n--port=27017 \\        \n--cluster=my_cluster_name \\\n--enable-all-collectors \\      \n--tls-skip-verify        \n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm \\\n--password=your_secure_password \\\n--host=127.0.0.1 \\\n--port=27017 \\        \n--cluster=my_cluster_name \\\n--enable-all-collectors \\      \n--query-source=mongolog         \n</code></pre> <pre><code>pmm-admin add mongodb \\\n--username=pmm \\\n--password=your_secure_password \\\n--host=fqdn_of_your_mongo_host \\\n--port=27017 \\          \n--tls \\\n--tls-certificate-key-file=/path/to/client.pem \\\n--tls-certificate-key-file-password=cert_password \\  # If needed\n--tls-ca-file=/path/to/ca.pem \\\n--authentication-mechanism=MONGODB-X509 \\\n--authentication-database=$external \\\n--cluster=my_cluster_name \\\n--enable-all-collectors        \n</code></pre> <p>When successful, PMM Client will print <code>MongoDB Service added</code> with the service\u2019s ID and name. Use the <code>--environment</code> and <code>--custom-labels</code> options to set tags for the service to help identify them.</p> <p>Tips</p> <ul> <li>When adding nodes to a sharded cluster, ensure to add each node using the same <code>--cluster mycluster</code> option. This allows the MongoDB Cluster Summary dashboard to populate correctly. </li> <li>PMM does not gather collection and index metrics if it detects you have more than 200 collections, in order to limit the resource consumption. Check the advanced options section if you want to modify this behaviour. </li> <li>When running mongos routers in containers, specify the <code>diagnosticDataCollectionDirectoryPath</code> to ensure that pmm-agent can properly capture mongos metrics. For example: <code>mongos --setParameter diagnosticDataCollectionDirectoryPath=/var/log/mongo/mongos.diagnostic.data/</code></li> </ul> <p>To add a service with the UI:</p> <ol> <li> <p>Select PMM Configuration &gt; Add Service &gt; MongoDB.</p> </li> <li> <p>Fill in the required fields.</p> </li> <li> <p>Click Add service.</p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#step-4-verify-mongodb-service-configuration","title":"Step 4: Verify MongoDB service configuration","text":"<p>After adding MongoDB service to PMM, verify that it\u2019s properly configured and collecting data. This ensures your monitoring setup is working correctly.</p> <ol> <li> <p>Check service registration:</p> Via command lineVia web UI <p>Look for your service in the output of this command:</p> <pre><code>pmm-admin list\n</code></pre> <p>For mongolog specifically, verify with: <pre><code>pmm-admin status\n</code></pre> Look for <code>mongodb_mongolog_agent</code> - it should show the agent is running with mongolog as the query source.</p> <p>To check the service from the UI:</p> <ol> <li>Select PMM Configuration &gt; Inventory &gt; Services. </li> <li>Find your MongoDB service in the list and verify it shows Active status.</li> <li>Verify the Service name, Addresses, and other connection details are correct.</li> <li>In the Options column, expand the Details section to check that agents are properly connected.</li> </ol> </li> <li> <p>Verify data collection:</p> <ul> <li>On the MongoDB Instances Overview dashboard</li> <li>Set the Service Name to the newly-added service</li> <li>Confirm that metrics are being displayed in the dashboard</li> </ul> </li> <li> <p>Verify Query Analytics for the service:</p> <ul> <li>Open the PMM Query Analytics dashboard and use the filters to select your MongoDB service. </li> <li>Check that query data is visible (it may take a few minutes for data to appear after initial setup).</li> <li>Performance impact is virtually zero since metrics are sourced from existing log files (for mongolog) or real-time profiler data.</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#remove-mongodb-service","title":"Remove MongoDB service","text":"<p>If you need to remove MongoDB service from PMM, follow these steps:</p> Via command lineVia web UI <p>Replace <code>SERVICE_NAME</code> with the name you used when adding the service. You can list all services with <code>pmm-admin</code>:</p> <pre><code>pmm-admin remove mongodb SERVICE_NAME\n</code></pre> <p>To remove the services through the PMM interface:</p> <ol> <li>Go to PMM Configuration &gt; Inventory &gt; Services.</li> <li>In the Status column, check the box for the service you want to remove and click Delete.</li> <li>On the confirmation pop-up, click Delete service and select Force mode if you want to also delete associated Clients.</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mongodb.html#related-topics","title":"Related topics","text":"<ul> <li><code>pmm-admin add mongodb</code></li> <li>Troubleshooting connection difficulties</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html","title":"Connect PostgreSQL databases to PMM","text":"<p>Connect your PostgreSQL databases\u2014whether self-hosted or running in the cloud\u2014to Percona Monitoring and Management (PMM) for comprehensive performance monitoring and analysis.</p> <p>PMM Client supports collecting metrics from PostgreSQL-based database systems:</p> <ul> <li>PostgreSQL</li> <li>Percona Distribution for PostgreSQL</li> </ul> <p>For monitoring Amazon RDS PostgreSQL instances, see Connect Amazon RDS instance.</p> Setup process at a glance <p>These are the high-level steps for configuring PostgreSQL monitoring in PMM:</p> <ol> <li>Prerequisites: Ensure PMM Server is running and PMM Client is installed</li> <li>Create PMM user: <code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD 'StrongPassword'</code></li> <li>Configure extension: Set up <code>pg_stat_statements</code> or <code>pg_stat_monitor</code></li> <li>Add service: Use PMM UI or command line to add the PostgreSQL instance</li> <li>Verify connection: Check PMM Inventory and dashboards for data. </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#before-you-start","title":"Before you start","text":"<p>Check that:</p> <ul> <li>PMM Server is installed and running with a known IP address accessible from the client node.</li> <li>PMM Client is installed and the nodes are registered with PMM Server.</li> <li>You have superuser (root) access on the client host.</li> <li>You have superuser access to any database servers that you want to monitor.</li> </ul> <p>PMM follows PostgreSQL\u2019s end-of-life policy. For specific details on supported platforms and versions, see Percona\u2019s Software Platform Lifecycle page.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>PMM requires a dedicated database account with appropriate permissions to collect metrics effectively. We recommend creating a PMM database account that can connect to the postgres database with the SUPERUSER role.</p> Standard PostgreSQLAmazon RDS/Aurora PostgreSQL <p>To create a user with the SUPERUSER role:</p> <ol> <li> <p>Create a user with SUPERUSER role:</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD 'strong_password';\n</code></pre> </li> <li> <p>Edit the <code>pg_hba.conf</code> file to enable local login:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> </li> </ol> <p>For RDS instances where SUPERUSER cannot be assigned directly:</p> <ol> <li> <p>Create the user:</p> <pre><code>CREATE USER pmm WITH ENCRYPTED PASSWORD 'strong_password';\n</code></pre> </li> <li> <p>Grant the <code>rds_superuser</code> role:</p> <pre><code>GRANT rds_superuser TO pmm;\n</code></pre> </li> <li> <p>Optionally, set a connection limit (only if the user is not a SUPERUSER):</p> <pre><code>ALTER USER pmm CONNECTION LIMIT 10;\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#configure-authentication","title":"Configure authentication","text":"<p>After creating the database user, complete the configuration:</p> <ol> <li> <p>Reload the PostgreSQL configuration:</p> <pre><code>su - postgres\npsql -c \"select pg_reload_conf()\"\n</code></pre> </li> <li> <p>Verify the PMM user can connect locally:</p> <pre><code>psql postgres pmm -c \"\\conninfo\"\n</code></pre> </li> <li> <p>Enter the password for the pmm user when prompted:</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#choose-a-monitoring-extension","title":"Choose a monitoring extension","text":"<p>Decide which  PostgreSQL monitoring extensions to use, and configure your database server for it. </p> <p>Choose:</p> <ul> <li><code>pg_stat_monitor</code> when you need comprehensive monitoring capabilities with more detailed insights into query performance:</li> <li><code>pg_stat_statements</code> when you need a lightweight, built-in solution with minimal overhead</li> </ul> Aspect pg_stat_statements pg_stat_monitor Origin &amp; packaging \u2022 Official PostgreSQL extension\u2022 Part of <code>postgresql-contrib</code> package on Linux \u2022 Developed by Percona\u2022 Requires separate installation Key features \u2714 Basic query statistics\u2714 Simple aggregation\u2714 Minimal overhead\u2714 Query timing and execution counts \u2714 Enhanced metrics collection\u2714 Bucket-based aggregation\u2714 Query examples\u2714 Histogram data\u2714 Includes all pg_stat_statements features Best for \u2714 Development environments\u2714 Simple monitoring needs\u2714 Resource-constrained servers \u2714 Production environments\u2714 Detailed query analysis\u2714 Performance tuning Installation complexity \u26a0 Low \u26a0 Medium Benefits \u2022 Part of official PostgreSQL\u2022 Minimal overhead\u2022 Simple to set up and use \u2022 Builds on pg_stat_statements features\u2022 Bucket-based time-series analysis\u2022 Query examples for troubleshooting\u2022 More accurate performance data Drawbacks \u2022 No aggregated statistics or histograms\u2022 No Query Examples\u2022 Limited metrics collection \u2022 Slightly higher resource overhead\u2022 Requires separate installation\u2022 More complex configuration Known Issues None \u26a0\ufe0f PMM v2.x/v3.x: Query plan metrics cause incorrect time measurements (off by 1000x+) <p>For a more detailed comparison of extensions, see the pg_stat_monitor documentation.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#configure-monitoring-extension","title":"Configure monitoring extension","text":"pg_stat_monitorpg_stat_statements <p><code>pg_stat_monitor</code> is Percona\u2019s advanced PostgreSQL monitoring extension that enhances observability with detailed query metrics and improved aggregation. It is compatible with PostgreSQL and Percona Distribution for PostgreSQL versions 11 through 17.</p> <p>Query plan metrics known issue</p> <p>Before configuring <code>pg_stat_monitor</code>, make sure that <code>pg_stat_monitor.pgsm_enable_query_plan</code> stays disabled. This is because query plans causes <code>pg_stat_monitor</code> to create multiple records for each query, leading to incorrect timing calculations.</p> <p>To keep query plan disabled during configuration:     <pre><code>ALTER SYSTEM SET pg_stat_monitor.pgsm_enable_query_plan = off;\nSELECT pg_reload_conf();\n</code></pre> To check current setting: <pre><code>SHOW pg_stat_monitor.pgsm_enable_query_plan;\n</code></pre></p> <p>To configure <code>pg_stat_monitor</code>: </p> <ol> <li> <p>Install the extension:</p> <ul> <li>For Percona Distribution for PostgreSQL: Install via your Linux package manager after setting up the Percona repository, making sure to use the command with your actual PostgreSQL version: <code>apt install -y pg-stat-monitor-15</code> </li> <li>For Standard PostgreSQL: Download and compile from source code.</li> </ul> </li> <li> <p>Configure PostgreSQL settings in <code>postgresql.conf</code>:</p> <pre><code># Add to shared libraries\nshared_preload_libraries = 'pg_stat_monitor'\n\n# Required for PMM\npg_stat_monitor.pgsm_query_max_len = 2048\n\n# Recommended settings\npg_stat_monitor.pgsm_normalized_query = 1\n</code></pre> <p>Using both extensions?</p> <p>If using with pg_stat_statements, list it first: <pre><code>shared_preload_libraries = 'pg_stat_statements, pg_stat_monitor'\n</code></pre></p> </li> <li> <p>Restart your PostgreSQL instance:</p> <pre><code>systemctl restart postgresql\n</code></pre> </li> <li> <p>Create the extension:</p> <pre><code>psql -d postgres -c \"CREATE EXTENSION pg_stat_monitor;\"\n</code></pre> </li> <li> <p>Verify the installation:</p> <pre><code>SELECT pg_stat_monitor_version();\n</code></pre> </li> </ol> <p>pg_stat_statements is the built-in PostgreSQL extension for tracking query performance, available as part of the postgresql-contrib package.</p> <ol> <li> <p>Install the required package:</p> <ul> <li>Debian/Ubuntu: <code>apt install -y postgresql-contrib</code></li> <li>Red Hat/CentOS: <code>yum install -y postgresql-contrib</code></li> </ul> </li> <li> <p>Add these lines to your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_statements'\ntrack_activity_query_size = 2048 # Increase tracked query string size\npg_stat_statements.track = all   # Track all statements including nested\ntrack_io_timing = on             # Capture read/write stats\n</code></pre> </li> <li> <p>Restart the PostgreSQL server:</p> <pre><code>systemctl restart postgresql\n</code></pre> </li> <li> <p>Create the extension:</p> <pre><code>psql postgres postgres -c \"CREATE EXTENSION pg_stat_statements SCHEMA public\"\n</code></pre> <p>Best practice</p> <p>Create the extension in the <code>postgres</code> database to access statistics from all databases without configuring each one individually.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#about-bucket-based-aggregation","title":"About bucket-based aggregation","text":"<p><code>pg_stat_monitor</code> uses buckets to collect and aggregate statistics:</p> <ul> <li>Each bucket collects data for a configurable time period</li> <li>When a bucket expires, data moves to the next bucket in the chain</li> <li>When all buckets are full, the oldest bucket is reused</li> <li>If a bucket fills before expiring, excess data is discarded</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#add-service-to-pmm","title":"Add service to PMM","text":"<p>After configuring your database server with the appropriate extension, you need to add it as a service to PMM. You can do this either through the PMM user interface or via the command line.</p> Via web UIVia command line <p>To add the service from the user interface:</p> <ol> <li> <p>Go to  PMM Configuration &gt; Add Service &gt; PostgreSQL.</p> </li> <li> <p>Enter or select values for the fields.</p> </li> <li> <p>Click Add service. </p> </li> <li> <p>If using TLS, check Use TLS for database connections and fill in your TLS certificates and key.       For TLS connection, make sure SSL is configured in your PostgreSQL instance. </p> </li> </ol> <p>Make sure SSL is enabled in the server configuration file <code>postgresql.conf</code>, and that hosts are allowed to connect in the client authentication configuration file <code>pg_hba.conf</code>.  See PostgreSQL documentation on Secure TCP/IP Connections with SSL.</p> Basic setupCustom service nameUNIX socket connectionTLS connection <p>Add an instance with default node name:</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls\n</code></pre> <p>The service name will be automatically generated based on the node name.</p> <p>Add an instance with a specified service name:</p> <pre><code>pmm-admin add postgresql \\\n--username=pmm \\\n--password=password \\\n--server-url=https://admin:admin@X.X.X.X:443 \\\n--server-insecure-tls \\\n--service-name=SERVICE-NAME\n</code></pre> <p>Add an instance using a UNIX socket:</p> <pre><code>pmm-admin add postgresql --socket=/var/run/postgresql\n</code></pre> <p>Where:</p> <ul> <li><code>/var/run/postgresql</code>: Directory containing the socket</li> </ul> <p>Add an instance with TLS security:</p> <pre><code>pmm-admin add postgresql --tls \\\n--tls-cert-file=PATHTOCERT \\\n--tls-ca-file=PATHTOCACERT \\\n--tls-key-file=PATHTOKEY \\\n--host=HOST \\\n--port=PORT \\\n--username=USER \\\n--service-name=SERVICE-NAME\n</code></pre> <p>where:</p> <ul> <li><code>PATHTOCERT</code>: Path to client certificate file</li> <li><code>PATHTOCACERT</code>: Path to certificate authority file</li> <li><code>PATHTOKEY</code>: Path to client key file</li> <li><code>HOST</code>: Instance hostname or IP</li> <li><code>PORT</code>: PostgreSQL service port number</li> <li><code>USER</code>: Database user allowed to connect via TLS (should match the CN in the client certificate)</li> <li><code>SERVICE-NAME</code>: Name to give to the service within PMM</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#configure-auto-discovery","title":"Configure auto-discovery","text":"<p>Auto-discovery dynamically identifies all databases in your PostgreSQL instance. This feature helps balance comprehensive monitoring with resource efficiency.</p> <p>Performance impact</p> <p>Limiting auto-discovery may result in fewer metrics being captured from the non-primary databases. Ensure that you set the limit appropriately:</p> <ul> <li>High limits may impact performance by creating too many connections</li> <li>Low limits may result in missing metrics from non-primary databases</li> </ul> Via command lineVia web UI <p>The <code>pmm-admin</code> flag controls Auto-discovery behavior:</p> <pre><code>--auto-discovery-limit=XXX\n</code></pre> <p>How the limit works:</p> <ul> <li>If number of databases &gt; Auto-discovery limit: Auto-discovery is OFF</li> <li>If number of databases &lt;= Auto-discovery limit: Auto-discovery is ON</li> <li>If Auto-discovery limit is not defined: Default value is 0 (server-defined with limit 10)</li> <li>If Auto-discovery limit &lt; 0: Auto-discovery is OFF</li> </ul> <p>Example:</p> <pre><code>pmm-admin add postgresql \\\n--username=\"pmm\" \\\n--password=\"password\" \\\n--auto-discovery-limit=10\n</code></pre> <p>If your PostgreSQL instance has 11 databases, automatic discovery will be disabled.</p> <p>By default, Auto-discovery is enabled with a server-defined limit of 10 databases.</p> <p></p> <p>When you select Disabled, the Auto-discovery limit will be set to <code>-1</code>.</p> <p></p> <p>For a custom value, select Custom and enter your preferred limit.</p> <p></p>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#check-the-service","title":"Check the service","text":"<p>After adding a PostgreSQL service, verify that it\u2019s properly connected and sending data to PMM.</p> Via command lineVia web UICheck the dashboard data <p>Run this command to view all services:</p> <pre><code>pmm-admin inventory list services\n</code></pre> <p>Docker environments</p> <p>If using Docker, use:  <pre><code>docker exec pmm-client pmm-admin inventory list services\n</code></pre></p> <p>Look for your PostgreSQL service in the output and verify that its status is \u201cRUNNING\u201d.</p> <p>Use the UI to confirm that your service was added and is actively monitored:</p> <ol> <li> <p>Select Configuration &gt; Inventory.</p> </li> <li> <p>In the Services tab, verify that Service name matches what you configured, Address points to your PostgreSQL instance and Status shows as \u201cActive\u201d.</p> </li> <li> <p>In the Options column, expand the Details section to check that agents are properly registered and that the expected data source is being used.</p> </li> </ol> <p>Ensure PostgreSQL metrics are flowing and visualized correctly:</p> <ol> <li> <p>Open the PostgreSQL Instance Summary dashboard.</p> </li> <li> <p>Select your service name from the dropdown.</p> </li> <li> <p>Verify that metrics are being displayed.</p> </li> <li> <p>Check that the graphs are updating with current data.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#running-custom-queries","title":"Running custom queries","text":"<p>The PostgreSQL exporter can execute custom queries to collect additional metrics beyond what PMM provides by default.</p> Configuration basicsQuery definition formatMetric types <p>Custom queries must be defined in this directory on the host where the exporter is running: <pre><code>/usr/local/percona/pmm/collectors/custom-queries/postgresql\n</code></pre></p> <p>Three resolution directories are available:</p> Directory Execution Frequency <code>high-resolution/</code> Every 5 seconds <code>medium-resolution/</code> Every 10 seconds <code>low-resolution/</code> Every 60 seconds <p>Choose the appropriate directory based on how frequently you need the data.</p> <p>Create YAML files in the appropriate resolution directory with this structure:</p> <pre><code>query_name:\n  query: \"SELECT statement goes here\"\n  master: true|false  # Whether to run only on the master\n  metrics:\n    - metric_name:\n        usage: \"GAUGE|COUNTER|LABEL|MAPPEDMETRIC|DURATION\"\n        description: \"Human-readable description of the metric\"\n</code></pre> <p>Example:</p> <pre><code>pg_postmaster_uptime:\n  query: \"select extract(epoch from current_timestamp - pg_postmaster_start_time()) as seconds\"\n  master: true\n  metrics:\n    - seconds:\n        usage: \"GAUGE\"\n        description: \"PostgreSQL service uptime in seconds\"\n</code></pre> Metric Type Description Use Case <code>GAUGE</code> A value that can go up or down Memory usage, connection count <code>COUNTER</code> A cumulative value that only increases Total queries, bytes transferred <code>LABEL</code> A string value used for labeling Database name, table name <code>MAPPEDMETRIC</code> Maps a query result to a numeric value State conversion (e.g., \u201con\u201d=1, \u201coff\u201d=0) <code>DURATION</code> A time duration Query execution time, lock wait time"},{"location":"install-pmm/install-pmm-client/connect-database/postgresql.html#related-topics","title":"Related topics","text":"<ul> <li><code>pmm-admin</code> man page for <code>pmm-admin add postgresql</code></li> <li>Configuring Percona repositories with percona-release</li> <li>Running custom MySQL queries in PMM</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html","title":"Connect ProxySQL databases to PMM","text":"<p>Monitor your ProxySQL instances with Percona Monitoring and Management (PMM) to track performance metrics and gain insights into query routing behavior.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#prerequisites","title":"Prerequisites","text":"<p>Before adding a ProxySQL instance to PMM:</p> <ul> <li>ensure PMM Server is running and accessible</li> <li>verify PMM Client is installed on the host running ProxySQL</li> <li>configure a dedicated read-only user in ProxySQL for monitoring purposes</li> </ul> <p>Use the <code>proxysql</code> alias to enable ProxySQL performance metrics monitoring.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#add-proxysql-service","title":"Add ProxySQL service","text":"<p>Add your ProxySQL instance to PMM using the proxysql service type:</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#basic-usage","title":"Basic usage","text":"<pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <p>where <code>username</code> and <code>password</code> are credentials for the administration interface of the monitored ProxySQL instance.  You should configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL</p> <p>Additionally, two positional arguments can be appended to the command line flags: a service name to be used by PMM, and a service address. If not specified, they are substituted automatically as <code>&lt;node&gt;-proxysql</code> and <code>127.0.0.1:6032</code>.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#example-output","title":"Example output","text":"<p>The output of this command may look as follows:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=pmm\n</code></pre> <pre><code>ProxySQL Service added.\nService ID  : f69df379-6584-4db5-a896-f35ae8c97573\nService name: ubuntu-proxysql\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#configuration-options","title":"Configuration options","text":"<p>You can customize the ProxySQL service configuration using command-line flags. These flags provide more control than positional arguments and take higher priority when both are specified.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#service-identification-flags","title":"Service identification flags","text":"<ul> <li><code>--service-name</code>: Custom name for the ProxySQL service in PMM</li> <li><code>--host</code>: Hostname or IP address of the ProxySQL instance  </li> <li><code>--port</code>: Port number for ProxySQL admin interface</li> <li><code>--socket</code>: UNIX socket path (alternative to host/port)</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/proxysql.html#connection-examples","title":"Connection examples","text":"<p>TCP connection with custom service name: ```sh pmm-admin add proxysql \\   \u2013username=pmm \\   \u2013password=pmm \\   \u2013service-name=my-new-proxysql \\   \u2013host=127.0.0.1 \\   \u2013port=6032</p>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html","title":"Connect remote instance to PMM","text":""},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#recommended-resolution-settings","title":"Recommended resolution settings","text":"<p>When monitoring remote instances (including RDS and Google Cloud databases), network latency can affect data collection and cause timeout errors. For this reason, it is recommended to lower the metrics resolution.</p> <p>PMM dynamically sets scrape timeouts based on the data collection resolution:</p> <ul> <li>FHigh frequency collection (\u2264 2 seconds resolution): 1 second timeout</li> <li>Medium frequency collection (\u2264 10 seconds resolution): (resolution - 1) second timeout. Example: For 10 second resolution, timeout is 9 seconds</li> <li>Low frequency collection (&gt; 10 seconds resolution): 90% of the resolution. Example: For 60 second resolution, timeout is 54 seconds</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#troubleshooting-scrape-timeouts","title":"Troubleshooting scrape timeouts","text":"<p>If dashboards show no data despite proper setup, check for scrape target failures:</p> <ol> <li>Browse to <code>http://&lt;your-pmm-server-address&gt;/prometheus/targets</code>.</li> <li>Click the Unhealthy button to filter problematic agents. </li> </ol> <p></p> <ol> <li>Review error messages and scrape durations:</li> </ol> <p></p> <p>In the example:</p> <ul> <li>error shows context deadline exceeded </li> <li>scrape duration column says the scrape took 10 seconds. This means that the exporter didn\u2019t respond in the 10 seconds the scrape process was allowed to run due to the configured metric resolutions and their timeouts.</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/remote.html#resolving-timeout-issues","title":"Resolving timeout issues","text":"<p>If you see timeout errors, increase the metric resolution values in PMM:</p> <p></p> <p>Higher resolution values (lower collection frequency) provide more time for remote agents to respond, reducing timeout errors while maintaining effective monitoring.RetryClaude can make mistakes. Please double-check responses.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html","title":"Optimize MySQL monitoring performance in PMM","text":"<p>When monitoring MySQL instances with a large number of tables, PMM\u2019s data collection can impact both client and database performance. </p> <p>Here are a few optimization options to ensure efficient monitoring without overloading your systems.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#options-for-table-statistics-optimization","title":"Options for table statistics optimization","text":"<p>PMM provides two command-line options when adding MySQL instances to control table statistics collection:</p> <ul> <li><code>--disable-tablestats</code>- Completely disables table statistics collection when there are more than 1000 tables (the default limit).</li> <li><code>--disable-tablestats-limit</code>- Customizes the threshold (number of tables) at which table statistics collection is disabled</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#when-to-use-these-options","title":"When to use these options","text":"<p>Consider using these options in the following when:</p> <ul> <li>monitoring MySQL instances with thousands of tables</li> <li>you notice high resource usage on either PMM Client or your MySQL server</li> <li>you observe monitoring delays or timeouts during data collection</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#disable-table-statistics","title":"Disable table statistics","text":"<p>For MySQL instances with many tables, you can completely disable per-table statistics collection: <pre><code>pmm-admin add mysql --disable-tablestats\n</code></pre></p> <p>This command configures PMM to: </p> <ul> <li>add your MySQL instance to PMM without collecting table-level statistics</li> <li>still collect all instance-level and database-level metrics</li> <li>significantly reduce the monitoring load when you have more than 1000 tables</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#set-a-custom-table-limit","title":"Set a custom table limit","text":"<p>For more precise control, you can specify a custom limit for when table statistics should be disabled.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#change-the-number-of-tables","title":"Change the number of tables","text":"<p>When adding an instance with <code>pmm-admin add</code>, the <code>--disable-tablestats-limit</code> option changes the number of tables (from the default of 1000) beyond which per-table statistics collection is disabled:</p> <pre><code>pmm-admin add mysql --disable-tablestats-limit=&lt;LIMIT&gt;\n</code></pre> <p>This command configures PMM to: </p> <ul> <li>collect table statistics normally until the instance reaches 2000 tables</li> <li>automatically disable table statistics when the number of tables exceeds 2000</li> <li>continue collecting all other MySQL metrics normally</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#best-practices-for-performance-optimization","title":"Best practices for performance optimization","text":"<p>To find the right balance between visibility and performance:</p> <ul> <li>If you have more than 1000 tables, begin with <code>--disable-tablestats</code> to start conservative</li> <li>Check CPU, memory, and network usage on the client to monitor PMM Client resource usage</li> <li>Watch for increased load during monitoring intervals to monitor MySQL load</li> <li>If resources permit, you can try enabling table statistics with a higher limit and adjust incrementally</li> </ul> <p>Additional performance considerations: </p> <ul> <li>For high-traffic MySQL servers, consider using query sampling with the slow log. For details, see MySQL data source configuration</li> <li>Adjust metrics collection frequency for remote instances. For details, see Remote instances monitoring</li> <li>Ensure PMM Client has adequate CPU and memory resources on busy database servers</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#change-settings-after-initial-setup","title":"Change settings after initial setup","text":"<p>These settings only apply when adding an instance with <code>pmm-admin add</code>. Only one of the table statistics options can be used when adding an instance.</p> <p>To change them after initial setup:</p> <ol> <li>Remove the existing MySQL service: <pre><code>pmm-admin remove mysql SERVICE_NAME\n</code></pre></li> <li>Add the service again with the desired table statistics settings: <pre><code>pmm-admin add mysql --disable-tablestats-limit=3000 [OTHER_OPTIONS] SERVICE_NAME\n</code></pre></li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#performance-impact-comparison","title":"Performance impact comparison","text":"Scenario Table stats enabled Table stats disabled Small MySQL (&lt; 100 tables) Minimal impact Not necessary Medium MySQL (100\u20131000 tables) Moderate impact Minimal performance gain Large MySQL (1000\u20135000 tables) High impact Significant performance improvement Very large MySQL (&gt; 5000 tables) Severe impact Strongly recommended"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/improve_perf.html#related-topics","title":"Related topics","text":"<ul> <li>MySQL connection options</li> <li>Performance Schema vs. Slow Query Log</li> <li>Configure metrics resolution</li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html","title":"Connect MySQL databases to PMM","text":"<p>Easily connect your MySQL databases\u2014whether self-hosted or running on AWS EC2\u2014to Percona Monitoring and Management (PMM) for in-depth performance insights.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#quick-setup","title":"Quick setup","text":"<p>Get your MySQL instance connected to PMM in just a few steps:</p> <ol> <li> <p>Create a dedicated MySQL user with the required permissions:</p> <pre><code>-- Create PMM user with required permissions\nCREATE USER 'pmm'@'localhost' IDENTIFIED BY 'StrongPassword123!' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD ON *.* TO 'pmm'@'localhost';\nFLUSH PRIVILEGES;\n</code></pre> </li> </ol> <p>Note:    If you are using an Administrative Connection, you will also need to grant the <code>SERVICE_CONNECTION_ADMIN</code> privilege to the <code>pmm</code> user.</p> <ol> <li> <p>Register your MySQL instance with PMM:</p> <pre><code># Add MySQL service to PMM\npmm-admin add mysql \\\n  --username=pmm \\\n  --password=StrongPassword123! \\\n  --host=localhost \\\n  --port=3306 \\\n  --query-source=slowlog \\\n  --environment=production \\\n  MySQL-Primary\n</code></pre> </li> <li> <p>Verify the connection is working:</p> <pre><code>pmm-admin status\n</code></pre> </li> </ol> <p>That\u2019s it! Your MySQL instance should now appear in PMM dashboards. For advanced configuration options, continue reading below.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#advanced-configuration","title":"Advanced configuration","text":"<p>PMM Client supports collecting metrics from various MySQL-based database systems:</p> <ul> <li>MySQL</li> <li>Percona Server for MySQL</li> <li>Percona XtraDB Cluster</li> <li>MariaDB</li> </ul> <p>For monitoring Amazon RDS MySQL instances, see Connect Amazon RDS instance.</p> Setup process at a glance <p>These are the high-level steps for configuring MySQL monitoring in PMM:</p> <ol> <li>Prerequisites: Ensure PMM Server is running and PMM Client is installed</li> <li>Create PMM user: <code>CREATE USER 'pmm'@'localhost' IDENTIFIED BY '&lt;StrongPassword&gt;'</code> </li> <li>Grant permissions: <code>GRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD ON *.* TO 'pmm'@'localhost'</code></li> <li>Configure data source: Enable Slow Query Log or Performance Schema </li> <li>Add service: Use PMM UI or command line to add the MySQL instance</li> <li>Verify connection: Check PMM Inventory and dashboards for data</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#prerequisites","title":"Prerequisites","text":"<p>Before connecting MySQL to PMM, review the prerequisites for your monitoring setup:</p> Local MySQL monitoringRemote MySQL monitoring <ul> <li>PMM Server is installed and running.</li> <li>PMM Client is installed and the nodes are registered with PMM Server.</li> <li><code>Root</code>/<code>sudo</code> access is required if PMM Client was installed from packages (RPM/DEB) or if you need to access MySQL slow query logs. Non-root access may be sufficient if PMM Client was installed via tarball or if you\u2019re only monitoring performance schema metrics</li> </ul> <ul> <li>PMM Server is installed and running</li> <li>PMM Server has direct network access to the MySQL instance</li> <li>You have a MySQL user with appropriate permissions on the remote MySQL instance.</li> </ul> <p>When is <code>root</code> access required?</p> <p>Root or <code>sudo</code> access on the client host is needed when: - PMM Client was installed from RPM or DEB packages - you want to monitor MySQL slow query logs (requires file system access) - you need to configure system-level monitoring (CPU, memory, disk I/O)</p> <p>For remote monitoring or when using only Performance Schema metrics, <code>root</code> access on the database server itself is not required.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#security-setup","title":"Security setup","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#create-a-database-account-for-pmm","title":"Create a database account for PMM","text":"<p>For security best practices, connect PMM Client to your database using a dedicated monitoring user with limited permissions. </p> Password security <ul> <li>Use a strong, unique password for the PMM database user</li> <li>At least 12 characters long</li> <li>Mix of uppercase and lowercase letters</li> <li>Include numbers and special characters</li> <li>Avoid common words or patterns</li> <li>Never use default, test, or example passwords in production</li> </ul> <p>This example creates a pmm user account that has just enough access to collect monitoring data without full administrative privileges:</p> On MySQL 5.7/MariaDB 10.xOn MySQL 8.0 <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY '&lt;your_strong_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD ON *.* TO 'pmm'@'localhost';\n</code></pre> <pre><code>CREATE USER 'pmm'@'localhost' IDENTIFIED BY '&lt;your_strong_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'localhost';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#choose-and-configure-a-source","title":"Choose and configure a source","text":"<p>PMM can collect metrics from two primary sources: Slow query log and Performance Schema.</p> <p>While you can use both at the same time we recommend using only one\u2013there is some overlap in the data reported, and each incurs a small performance penalty.</p> <p>The choice depends on the version and variant of your MySQL instance, and how much detail you want to see.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#data-source-comparison","title":"Data source comparison","text":"<p>Here are the benefits and drawbacks of Slow query log and Performance Schema metrics sources:</p> Source Best for Advantages Disadvantages Slow Query Log - Percona Server- When detailed query analysis is critical \u2714 More detailed query information\u2714 Lower resource impact with query sampling \u26a0 Requires log file access\u26a0 Log files need management\u26a0 Higher disk I/O Performance Schema - MySQL 5.6+- MariaDB 10.0+- Production environments with resource constraints \u2714 Lower overhead\u2714 Faster parsing\u2714 No file management needed \u26a0 Less detailed query information\u26a0 Higher memory usage"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#version-specific-recommendations","title":"Version-specific recommendations","text":"Database server Versions Recommended source MySQL 5.1-5.5 Slow query log MySQL 5.6+ Performance Schema MariaDB 10.0+ Performance Schema Percona Server for MySQL 5.7, 8.0 Slow query log Percona XtraDB Cluster 5.6, 5.7, 8.0 Slow query log"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#configure-data-source","title":"Configure data source","text":"Slow query logPerformance Schema <p>The slow query log records the details of queries that take more than a certain amount of time to complete. </p> <p>With the database server configured to write this information to a file rather than a table, PMM Client parses the file and sends aggregated data to PMM Server via the Query Analytics part of <code>pmm-agent</code>.</p> <p>To configure a MySQL-based database server to use Performance Schema as a source of metrics:</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#settings","title":"Settings","text":"Variable Value Description <code>slow_query_log</code> ON Enables the slow query log. <code>log_output</code> <code>'FILE'</code> Ensures the log is sent to a file. This is the default on MariaDB. <code>long_query_time</code> 0 The slow query threshold in seconds. In heavily-loaded applications, many quick queries can affect performance more than a few slow ones. Setting this value to <code>0</code> ensures all queries are captured. <code>log_slow_admin_statements</code> ON Includes the logging of slow administrative statements. <code>log_slow_slave_statements</code> ON Enables logging for queries that have taken more than <code>long_query_time</code> seconds to execute on the replica. Basic configurationExtended configuration (Percona Server/XtraDB) <p>Add these settings to your MySQL configuration file (my.cnf/my.ini):</p> <pre><code># Enable slow query logging\nslow_query_log = ON\nlog_output = FILE\n\n# Log all queries (0 seconds threshold)\nlong_query_time = 0\n\n# Include administrative and replica statements\nlog_slow_admin_statements = ON\nlog_slow_slave_statements = ON\n</code></pre> <p>Alternatively, set these variables at runtime:</p> <pre><code>SET GLOBAL slow_query_log = 1;\nSET GLOBAL log_output = 'FILE';\nSET GLOBAL long_query_time = 0;\nSET GLOBAL log_slow_admin_statements = 1;\nSET GLOBAL log_slow_slave_statements = 1;\n</code></pre> <p>For Percona Server for MySQL (5.7+, 8.0+) and Percona XtraDB Cluster, add these additional settings:</p> Variable Value Description <code>log_slow_rate_limit</code> 100 Defines the rate of queries captured by the slow query log. A good rule of thumb is 100 queries logged per second. For example, if your Percona Server instance processes 10,000 queries per second, you should set <code>log_slow_rate_limit</code> to <code>100</code> and capture every 100<sup>th</sup> query for the slow query log. <code>log_slow_rate_type</code> <code>'query'</code> Set so that it applies to queries, rather than sessions. <code>slow_query_log_always_write_time</code> 1 Specifies which queries should ignore sampling. With query sampling this ensures that queries with longer execution time will always be captured by the slow query log. <code>log_slow_verbosity</code> <code>'full'</code> Ensures that all information about each captured query is stored in the slow query log. <code>slow_query_log_use_global_control</code> <code>'all'</code> Configure the slow query log during runtime and apply these settings to existing connections. Configuration file example <pre><code># Sample 1% of queries (1 out of 100)\nlog_slow_rate_limit = 100\nlog_slow_rate_type = 'query'\n\n# Always log queries slower than 1 second regardless of sampling\nslow_query_log_always_write_time = 1\n\n# Store comprehensive query information\nlog_slow_verbosity = 'full'\n\n# Apply settings to existing connections\nslow_query_log_use_global_control = 'all'\n</code></pre> Session example <pre><code>SET GLOBAL log_slow_rate_limit = 100;\nSET GLOBAL log_slow_rate_type = 'query';\nSET GLOBAL slow_query_log_always_write_time = 1;\nSET GLOBAL log_slow_verbosity = 'full';\nSET GLOBAL slow_query_log_use_global_control = 'all';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#slow-query-log-rotation","title":"Slow query log rotation","text":"<p>The slow query log can grow quickly in size, potentially affecting your system performance. To manage this, PMM Client can automatically rotate the log files to prevent them from becoming too large, or you can choose to manage log rotation yourself:</p> Automatic log rotationManual log rotation <p>To configure automatic rotation when adding a service, use the <code>--size-slow-logs</code> option with the <code>pmm-admin</code> command. This option sets the size threshold at which the slow query log file will be rotated. </p> <p>The size is specified as a number followed by a suffix (e.g., <code>10M</code> for 10 megabytes). For detailed syntax, refer to pmm-admin add mysql.</p> <p>When the log reaches the specified size, PMM Client will:</p> <ul> <li>Remove the previous <code>.old</code> slow query log file.</li> <li>Rename the current log file by appending the <code>.old</code> suffix.</li> <li>Execute the MySQL <code>FLUSH LOGS</code> command to finalize the rotation.</li> <li>Only one <code>.old</code> file is retained at a time, and older versions are automatically deleted.</li> </ul> <p>If you prefer to handle log rotation manually, such as with logrotate, you can disable PMM Client\u2019s automatic log rotation. To do this, set a negative value for the <code>--size-slow-logs</code> option when adding a service with the <code>pmm-admin add</code> command.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#applicable-versions","title":"Applicable versions","text":"<ul> <li>Percona Server for MySQL: 5.6, 5.7, 8.0</li> <li>Percona XtraDB Cluster: 5.6, 5.7, 8.0</li> <li>MariaDB: 10.3+</li> </ul> <p>PMM\u2019s MySQL Performance Schema Details dashboard charts the various <code>performance_schema</code> metrics.</p> <p>To use Performance Schema, set these variables:</p> Variable Value Description <code>performance_schema</code> <code>ON</code> Enables Performance Schema metrics. This is the default in MySQL 5.6.6 and higher. <code>performance-schema-instrument</code> <code>'statement/%=ON'</code> Configures Performance Schema instruments. <code>performance-schema-consumer-statements-digest</code> <code>ON</code> Configures the <code>statements-digest</code> consumer. <code>innodb_monitor_enable</code> all Enables InnoDB metrics counters. MySQL Performance Schema configuration examples <ul> <li> <p>Configuration file:</p> <pre><code>performance_schema=ON\nperformance-schema-instrument='statement/%=ON'\nperformance-schema-consumer-statements-digest=ON\ninnodb_monitor_enable=all\n</code></pre> </li> <li> <p>Session:</p> <p>(<code>performance_schema</code> cannot be set in a session and must be set at server start-up.)</p> <pre><code>UPDATE performance_schema.setup_consumers\nSET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\nSET GLOBAL innodb_monitor_enable = all;\n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#mariadb-1057-or-lower","title":"MariaDB 10.5.7 or lower","text":"<p>There is no Explain or Example data shown by default in Query Analytics when monitoring MariaDB instances version 10.5.7 or lower. A workaround is to set this variable.</p> Variable Value Description <code>performance_schema.setup_instruments</code> <code>'statement/%'</code> List of instrumented object classes."},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#session","title":"Session","text":"<pre><code>UPDATE performance_schema.setup_instruments SET ENABLED = 'YES', TIMED = 'YES' WHERE NAME LIKE 'statement/%';\nUPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME LIKE '%statements%';\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#transactions","title":"Transactions","text":"<p>MariaDB doesn\u2019t implement queries history for transactions. All queries executed within a transaction won\u2019t have query examples since PMM relies on the <code>performance_schema.events_statements_history</code> to grab the query example but that table won\u2019t have any query executed as part of a transaction.  </p> <p>This behavior is because MariaDB doesn\u2019t implement these consumers:</p> <pre><code>events_transactions_current\nevents_transactions_history\nevents_transactions_history_long\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#query-response-time","title":"Query response time","text":"<p>Query time distribution is a chart in the Details tab of Query Analytics showing the proportion of query time spent on various activities. It is enabled with the <code>query_response_time_stats</code> variable and associated plugins.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#supported-versions","title":"Supported versions","text":"<ul> <li>Percona Server for MySQL: 5.7 (available through Post-EOL support program)</li> <li>NOT available in Percona Server for MySQL 8.0 (removed features)</li> <li>MariaDB: 10.0.4</li> </ul> <p>Limited version support</p> <p>This feature is not available in current Percona Server 8.0. Use this information only if you are using Percona Server 5.7 through our Post-EOL support program, where it remains actively supported.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#required-variable","title":"Required variable","text":"<p>To enable query time distribution charts, set the <code>[query_response_time_stats][ps_query_response_time_stats] = ON</code> and install the plugin.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#plugin-installation","title":"Plugin installation","text":"<p>Before installing the plugins, ensure you have the necessary plugin files and run these commands in your MySQL session:</p> <ol> <li>Check that <code>/usr/lib/mysql/plugin/query_response_time.so</code> exists.</li> <li> <p>Install the plugins and activate:</p> For MariaDB 10.3For Percona Server for MySQL 5.7 <p>For MariaDB 10.3, run: <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre></p> <p>For Percona Server for MySQL 5.7, run:      <pre><code>INSTALL PLUGIN QUERY_RESPONSE_TIME_AUDIT SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_READ SONAME 'query_response_time.so';\nINSTALL PLUGIN QUERY_RESPONSE_TIME_WRITE SONAME 'query_response_time.so';\nSET GLOBAL query_response_time_stats = ON;\n</code></pre></p> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#tablestats","title":"Tablestats","text":"<p>Some table metrics are automatically disabled when the number of tables exceeds a default limit of 1000 tables. This prevents PMM Client from affecting the performance of your database server.</p> <p>You can change the limit when configuring MySQL performance improvements with the following options:</p> <code>pmm-admin</code> option Description <code>--disable-tablestats</code> Disables tablestats collection when the default limit is reached. <code>--disable-tablestats-limit=N</code> Sets the number of tables (<code>N</code>) for which tablestats collection is disabled. 0 means no limit. A negative number means tablestats is completely disabled (for any number of tables)."},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#user-statistics","title":"User statistics","text":""},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#applicable-versions_1","title":"Applicable versions","text":"<p>User activity, individual table and index access details are shown on the MySQL User Details dashboard when the <code>userstat</code> variable is set:</p> <ul> <li>Percona Server for MySQL: 5.6, 5.7, 8.0</li> <li>Percona XtraDB Cluster: 5.6, 5.7, 8.0</li> <li>MariaDB: 5.2.0+</li> </ul> MySQL user statistics configuration examples <ul> <li> <p>Configuration file: <code>userstat=ON</code>.</p> </li> <li> <p>Session: <code>SET GLOBAL userstat = ON;</code></p> </li> </ul>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#add-service-to-pmm","title":"Add service to PMM","text":"<p>After creating your PMM database user, you can quickly add your MySQL service to PMM. You can do this either through the PMM user interface or via the command line.</p> Using the PMM user interfaceUsing the command line <p>To add the service from the user interface:</p> <ol> <li> <p>Go to PMM Configuration &gt; PMM Inventory &gt; Add Service.</p> </li> <li> <p>Select MySQL service type.</p> </li> <li> <p>Enter or select values for the fields:</p> <ul> <li>Service Name: A descriptive name for your MySQL instance</li> <li>Host/Socket: Use <code>localhost</code> for local monitoring or hostname/IP for remote monitoring</li> <li>Port: MySQL port (default: 3306)</li> <li>Username: The PMM user created earlier</li> <li>Password: Your PMM user password</li> <li>Query Source: Choose between Slow Log or Performance Schema</li> <li>PMM Agent: Select which PMM agent should monitor this instance</li> </ul> </li> <li> <p>Click Add Service.</p> </li> <li> <p>If using TLS, check Use TLS for database connections and fill in your TLS certificates and key information.  </p> </li> </ol> Basic setupRemote monitoringWith custom labelsTLS connection <p>Add a local MySQL instance with default settings:</p> <pre><code>pmm-admin add mysql \\\n  --username=pmm \\\n  --password=StrongPassword \\\n  --host=localhost \\\n  --port=3306 \\\n  --query-source=slowlog \\\n  MySQL-Primary\n</code></pre> <p>Add a remote MySQL instance:</p> <pre><code>pmm-admin add mysql \\\n  --username=pmm \\\n  --password=StrongPassword \\\n  --host=remote-mysql.example.com \\\n  --port=3306 \\\n  --query-source=perfschema \\\n  --environment=production \\\n  Remote-MySQL\n</code></pre> <p>Add an instance with environment and custom labels:</p> <pre><code>pmm-admin add mysql \\\n  --username=pmm \\\n  --password=StrongPassword \\\n  --host=localhost \\\n  --port=3306 \\\n  --query-source=slowlog \\\n  --environment=production \\\n  --custom-labels=\"role=primary,datacenter=east\" \\\n  MySQL-Primary\n</code></pre> <p>Add an instance with TLS security:</p> <pre><code>pmm-admin add mysql \\\n  --username=pmm \\\n  --password=StrongPassword \\\n  --host=mysql-server.example.com \\\n  --port=3306 \\\n  --tls \\\n  --tls-ca=/path/to/ca.pem \\\n  --tls-cert=/path/to/client-cert.pem \\\n  --tls-key=/path/to/client-key.pem \\\n  --query-source=slowlog \\\n  MySQL-TLS\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#after-adding-the-service","title":"After adding the service","text":"<p>Upon successful addition, PMM Client will display a confirmation message:</p> <pre><code>MySQL Service added\nService ID  : /service_id/abcd1234-5678-efgh-ijkl-mnopqrstuvwx\nService name: MySQL-Primary\n</code></pre>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#verify-your-mysql-service","title":"Verify your MySQL service","text":"<p>After adding your MySQL service to PMM, it\u2019s important to verify that it\u2019s properly connected and collecting data.</p>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#check-service-status","title":"Check service status","text":"Via command lineVia web UI <p>Use these commands to manage and monitor your MySQL services:</p> <ol> <li> <p>List all MySQL services and their status:    <pre><code>pmm-admin inventory list services --service-type=mysql\n</code></pre></p> </li> <li> <p>Find more detailed information about a specific service:    <pre><code>pmm-admin describe service --service-name=\"MySQL-Service-Name\"\n</code></pre></p> </li> <li> <p>Check the overall PMM Client status:    <pre><code>pmm-admin status\n</code></pre></p> </li> </ol> <p>To verify your service in the web interface:</p> <ol> <li>Navigate to PMM Configuration &gt; PMM Inventory.</li> <li>In the Services tab, find your newly added MySQL service.</li> <li>Verify the Service Name and Address match your configuration.</li> <li>Check the Status column shows as Active.</li> <li>In the Options column, expand the Details section to confirm:<ul> <li>the correct agents are running</li> <li>your selected query source (Slow Log or Performance Schema) is active</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#verify-data-collection","title":"Verify data collection","text":"<p>Once the service is confirmed as active, verify that metrics are being properly collected:</p> General MySQL metricsDatabase-specific metrics <p>To verify basic MySQL metrics are being collected:</p> <ol> <li>Open the MySQL Instance Summary dashboard</li> <li>Select your MySQL service from the Service Name dropdown</li> <li>Confirm that metrics are appearing on the dashboard</li> <li>Check that the graphs show recent data (within the last few minutes)</li> </ol> <p>For Percona Server for MySQL or MariaDB:</p> <p>If you installed the Query Response Time plugin, verify it:</p> <ol> <li>Open the MySQL Query Response Time Details dashboard</li> <li>Select your service from the dropdown</li> <li>Alternatively, go to Query Analytics, select a query, and check for the Query time distribution bar</li> </ol> <p>For Percona XtraDB Cluster: To verify XtraDB Cluster monitoring:</p> <ol> <li>Open the PXC/Galera Cluster Summary dashboard</li> <li>Select your cluster service from the dropdown</li> <li>Verify that cluster-specific metrics are being displayed</li> </ol>"},{"location":"install-pmm/install-pmm-client/connect-database/mysql/mysql.html#related-topics","title":"Related topics","text":"<ul> <li>Percona Server for MySQL \u2013 slow query log extended</li> <li>Percona Server for MySQL \u2013 user statistics</li> <li>MariaDB \u2013 Slow query log overview</li> <li>MariaDB \u2013 Slow query log extended statistics</li> <li>MariaDB \u2013 User statistics</li> <li>PERFORMANCE_SCHEMA vs Slow Query Log: performance impact</li> <li>Understanding MySQL\u2019s INNODB_METRICS table</li> <li>Rotating MySQL slow logs safely</li> <li>Impact of logging on MySQL\u2019s performance</li> <li>Running custom MySQL queries in PMM</li> </ul>"},{"location":"install-pmm/install-pmm-server/index.html","title":"PMM Server installation overview","text":"<p>PMM Server is the central component of Percona Monitoring and Management (PMM) that collects, analyzes, and visualizes monitoring data from your database environment.</p> Common installation process at a glance <p>While specific steps vary by deployment method, the general installation process includes:</p> <ol> <li>Deploy PMM Server using your preferred method.</li> <li>Access the PMM web interface (default: <code>https://your-server-address</code>)</li> <li>Log in with default credentials (username: <code>admin</code>, password: <code>admin</code>).</li> <li>Change the default password.</li> <li>Configure PMM Server settings. </li> </ol>"},{"location":"install-pmm/install-pmm-server/index.html#before-you-begin","title":"Before you begin","text":"<p>Before installing PMM Server, make sure to first read the Hardware and system requirements and the Network and firewall requirements.</p>"},{"location":"install-pmm/install-pmm-server/index.html#deployment-options","title":"Deployment options","text":"<p>Install and run at least one PMM Server using one of the following deployment methods:</p> Environment/Requirement Recommended Method Documentation Link Kubernetes environments Helm chart Helm installation guide \u2192 Virtual machines Virtual appliance VM installation \u2192 Quick setup needs Docker container Docker guide \u2192 Security-focused setups Podman (rootless containers) Podman instructions \u2192 AWS cloud deployments AWS Marketplace AWS instructions \u2192"},{"location":"install-pmm/install-pmm-server/index.html#next-steps","title":"Next steps","text":"<p>After installing PMM Server:</p> <ul> <li>Install PMM Client on hosts you want to monitor</li> <li>Connect databases for monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html","title":"Prerequisites for PMM Server","text":"<p>Before installing PMM Server, ensure your environment meets these requirements.</p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#quick-requirements-checklist","title":"Quick requirements checklist","text":"<p>\u2713 Hardware: CPU with SSE4.2 support, 4+ cores, 8+ GB RAM, 100+ GB storage \u2713 OS: Modern 64-bit Linux or container platform (Docker/Podman/Kubernetes) \u2713 Network: Ports 80/443 accessible to PMM Clients and users \u2713 Container runtime: Docker 17.03+ or Podman (for containerized deployments) \u2713 Storage: Persistent storage solution for data retention  </p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#system-requirements","title":"System requirements","text":"<p>PMM Server requirements scale with the number of monitored nodes:</p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#hardware-specifications-by-deployment-size","title":"Hardware specifications by deployment size","text":"Small (1-30 nodes)Medium (31-200 nodes)Large (200+ nodes) <ul> <li>CPU: 4 cores with SSE4.2 support</li> <li>Memory: 8 GB RAM</li> <li>Storage: 100 GB</li> <li>Use cases: Development, small businesses, initial deployments</li> </ul> <ul> <li>CPU: 8-16 cores with SSE4.2 support</li> <li>Memory: 16-32 GB RAM</li> <li>Storage: 200+ GB</li> <li>Use cases: Production environments, mid-sized companies</li> </ul> <ul> <li>CPU: 16+ cores with SSE4.2 support</li> <li>Memory: 32+ GB RAM</li> <li>Storage: 500+ GB</li> <li>Use cases: Large enterprises, mission-critical database fleets</li> </ul> <p>For detailed sizing calculations, see Hardware and system requirements.</p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#architecture-requirements","title":"Architecture requirements","text":"<ul> <li>CPU: Must support SSE4.2 instruction set (required for Query Analytics)</li> <li>x86_64: Native support for optimal performance</li> <li>ARM64: Supported via Docker emulation using <code>--platform linux/amd64</code></li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#storage-planning","title":"Storage planning","text":"<p>PMM Server stores metrics data, requiring persistent storage:</p> <ul> <li>Storage type: Use persistent volumes (Docker volumes, cloud storage or host directories)</li> <li>Capacity planning: <code>nodes \u00d7 retention_period_in_weeks \u00d7 1 GB</code></li> <li>Quick estimate: <code>number_of_nodes \u00d7 4 GB</code> for default 30-day retention</li> <li>Performance: SSD recommended for better I/O performance</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#network-connectivity","title":"Network connectivity","text":"<p>PMM Server requires these network connections:</p> Connection Port Purpose Required Users &gt; PMM Server 443 (HTTPS) Web interface access Essential Users &gt; PMM Server 80 (HTTP) Web interface (insecure) Optional PMM Clients &gt; PMM Server 443/80 Metrics reporting Essential PMM Server &gt; Internet 443 Updates, telemetry Optional <p>For complete port specifications, see Network and firewall requirements.</p>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#deployment-specific-prerequisites","title":"Deployment-specific prerequisites","text":"<p>Choose your deployment method and ensure it meets these specific requirements:</p>  Docker Podman Kubernetes Virtual Appliance (OVA) <p>Version requirements:</p> <ul> <li>Docker version 17.03 or higher</li> <li>CPU with <code>x86-64-v2</code> support</li> </ul> <p>System resources:</p> <ul> <li>Recommended: 2+ CPU cores, 4+ GB RAM, 100+ GB disk space</li> </ul> <p>Optional but recommended:</p> <ul> <li>Watchtower for UI-based updates</li> <li>Docker Compose for multi-container setups</li> </ul> <p>Security considerations for Watchtower:</p> <ul> <li>Limit Watchtower\u2019s access to Docker network or localhost</li> <li>Configure network to ensure only PMM Server is exposed externally</li> <li>Secure Docker socket access for Watchtower</li> <li>Place both Watchtower and PMM Server on the same Docker network</li> </ul> <p>Version requirements:</p> <ul> <li>Recent Podman version with systemd support</li> <li>Rootless Podman configuration</li> </ul> <p>System configuration:</p> <ul> <li>Allow non-root users to bind to privileged ports (port 443)</li> <li>Podman socket enabled for Watchtower integration</li> <li>systemd user services enabled</li> </ul> <p>Required setup commands:</p> <pre><code># Configure privileged port access\necho \"net.ipv4.ip_unprivileged_port_start=443\" | sudo tee /etc/sysctl.d/99-pmm.conf\nsudo sysctl -p /etc/sysctl.d/99-pmm.conf\n\n# Enable Podman socket\nsystemctl --user enable --now podman.socket\n</code></pre> <p>Security advantages:</p> <ul> <li>Enhanced security isolation with rootless containers</li> <li>Better systemd integration for service management</li> <li>Fine-grained permission control</li> </ul> <p>Cluster requirements:</p> <ul> <li>Kubernetes 1.19+ with supported version</li> <li>kubectl configured to communicate with your cluster</li> </ul> <p>Helm requirements:</p> <ul> <li>Helm v3 installed and configured</li> <li>Access to Percona Helm charts repository</li> </ul> <p>Storage requirements:</p> <ul> <li>Storage driver with snapshot support (for backups)</li> <li>Dynamic provisioning capability</li> <li>Persistent Volume support</li> </ul> <p>Production considerations:</p> <ul> <li>Separate PMM Server from monitored systems</li> <li>High availability configuration for continuous monitoring</li> <li>Workload separation through node configurations and affinity rules</li> </ul> <p>Hypervisor compatibility:</p> <ul> <li>VMware ESXi 6.0+, Workstation 12.0+, Fusion 10.0+</li> <li>VirtualBox 6.0+</li> </ul> <p>VM specifications (default):</p> <ul> <li>OS: Oracle Linux 9.3</li> <li>CPU: 1 (adjustable after deployment)</li> <li>Memory: 4096 MB (adjustable after deployment)</li> <li>Disk 1: 40 GB (system)</li> <li>Disk 2: 400 GB (data)</li> </ul> <p>Network access:</p> <ul> <li>Outbound internet access for updates (optional)</li> <li>Access to monitored database instances</li> <li>Access from client browsers to PMM web interface</li> </ul> <p>Security note:</p> <ul> <li>Default users: <code>admin/admin</code> and <code>root/percona</code></li> <li>Must change default passwords immediately after installation</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#security-considerations","title":"Security considerations","text":""},{"location":"install-pmm/install-pmm-server/prerequisites.html#ssltls-certificates","title":"SSL/TLS certificates","text":"<ul> <li>Self-signed: PMM Server generates these automatically</li> <li>Custom certificates: Prepare SSL certificates for production deployments</li> <li>Certificate authority: Consider using trusted CA certificates for public access</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#access-control","title":"Access control","text":"<ul> <li>Admin credentials: Plan initial admin username/password strategy</li> <li>Default passwords: Change immediately (especially for OVA deployment)</li> <li>User management: Consider integration with existing authentication systems</li> <li>Network security: Plan firewall rules and network segmentation</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#data-protection","title":"Data protection","text":"<ul> <li>Backup strategy: Plan for PMM Server data backup and recovery</li> <li>Encryption: Consider encryption for data at rest and in transit</li> <li>Compliance: Ensure deployment meets organizational security requirements</li> </ul>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#before-you-install","title":"Before you install","text":"<p>Complete these preparation steps:</p> <ol> <li>Choose deployment method based on your environment and requirements</li> <li>Prepare infrastructure (servers, storage, networking)</li> <li>Plan capacity using sizing guidelines above</li> <li>Configure security (certificates, firewall rules, access controls)</li> <li>Prepare persistent storage for data retention</li> <li>Install required tools (Docker/Podman/Helm/kubectl as needed)</li> <li>Document configuration for maintenance and disaster recovery</li> </ol>"},{"location":"install-pmm/install-pmm-server/prerequisites.html#next-steps","title":"Next steps","text":"<p>After confirming your environment meets these prerequisites:</p> <ol> <li>Choose your deployment method based on your infrastructure</li> <li> <p>Install PMM Server  using your selected method:</p> </li> <li> <p>Docker installation</p> </li> <li>Podman installation</li> <li>Kubernetes/Helm installation</li> <li>Virtual Appliance deployment</li> <li>Configure security settings for production use</li> <li>Install PMM Clients on systems you want to monitor</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html","title":"Configure PMM Server on AWS","text":"<p>Complete the essential security configuration, user management, and ongoing maintenance for your PMM Server deployment on AWS.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#prerequisites","title":"Prerequisites","text":"<p>Before configuring your PMM Server, ensure you have:</p> <ul> <li>completed planning your PMM Server deployment including instance sizing, storage, and network requirements</li> <li>successfully deployed PMM Server from AWS Marketplace </li> <li>completed the initial login and changed default credentials</li> <li>your PMM Server instance running and accessible via HTTPS</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#secure-your-deployment","title":"Secure your deployment","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#configure-ssltls","title":"Configure SSL/TLS","text":"<p>Replace the self-signed certificate with a proper SSL certificate for production.</p> Let\u2019s Encrypt certificateCommercial certificate <p>If you want to use a free Let\u2019s Encrypt certificate:</p> <ol> <li>Make sure that the domain name is pointing to your PMM Server\u2019s IP address.</li> <li>Install and configure: <pre><code># Install certbot\nsudo apt update\nsudo apt install certbot\n\n# Obtain certificate (replace yourdomain.com)\nsudo certbot certonly --standalone -d pmm.yourdomain.com\n\n# Stop PMM temporarily\nsystemctl --user stop pmm-server\n\n# Configure PMM to use the certificate\nsudo cp /etc/letsencrypt/live/pmm.yourdomain.com/fullchain.pem /home/admin/volume/pmm-certs/certificate.crt\nsudo cp /etc/letsencrypt/live/pmm.yourdomain.com/privkey.pem /home/admin/volume/pmm-certs/certificate.key\nsudo chown pmm:pmm /home/admin/volume/pmm-certs/certificate.*\nsudo chmod 600 /home/admin/volume/pmm-certs/certificate.*\n\n# Restart PMM Server\nsystemctl --user start pmm-server\n</code></pre></li> </ol> <p>If you have a commercial SSL certificate:</p> <ol> <li> <p>Upload certificate files:    <pre><code>scp -i /path/to/your-key.pem certificate.crt admin@&lt;instance-ip&gt;:/tmp/\nscp -i /path/to/your-key.pem private.key admin@&lt;instance-ip&gt;:/tmp/\n</code></pre></p> </li> <li> <p>Install certificates:    <pre><code>sudo mv /tmp/certificate.crt /home/admin/volume/pmm-certs/\nsudo mv /tmp/private.key /home/admin/volume/pmm-certs/certificate.key\nsudo chown pmm:pmm /home/admin/volume/pmm-certs/certificate.*\nsudo chmod 600 /home/admin/volume/pmm-certs/certificate.*\nsystemctl --user restart pmm-server\n</code></pre></p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#harden-network-access","title":"Harden network access","text":"<p>Configure the operating system-level firewall on your PMM Server instance to further restrict access to required ports. This adds an additional layer of security beyond AWS Security Groups.</p> <pre><code># SSH to PMM Server\nssh -i /path/to/your-key.pem admin@&lt;your-instance-ip&gt;\n\n# Configure firewall rules\nsudo ufw allow 22/tcp    # SSH access\nsudo ufw allow 443/tcp   # HTTPS PMM interface\nsudo ufw --force enable\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#manage-users-and-access","title":"Manage users and access","text":"<p>After the initial setup, create additional user accounts in PMM for your team members. Follow the principle of least privilege when assigning user roles.</p> <ol> <li>Go to Administration &gt; Users and access &gt; Users.</li> <li> <p>Click New user and configure the user with an appropriate role:</p> <ul> <li>Admin: Full system access</li> <li>Editor: Dashboard editing, no system config</li> <li>Viewer: Read-only access</li> </ul> </li> <li> <p>Limit access based on job responsibilities and use viewer accounts for stakeholders who only need to see metrics.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#configure-network-and-ip","title":"Configure network and IP","text":"<p>By default, your EC2 instance will have a private IP for internal VPC network access. You can configure your PMM Server to use only a private IP or a static Elastic IP.</p> Use private IP onlyUse Elastic IP <p>During EC2 instance creation:</p> <ol> <li>In the Network Settings section, uncheck Auto-assign public IP.</li> <li>Do not assign an Elastic IP to the instance.</li> <li>To access PMM Server using only a private IP, ensure you\u2019re connected to your VPC and use the private IP address for access.</li> </ol> <p>For an existing instance:</p> <ol> <li>If a public IP is assigned, remove it by disassociating it in the EC2 console.</li> <li>If an Elastic IP is assigned, disassociate it from the instance.</li> <li>To access PMM Server using only a private IP, ensure you\u2019re connected to your VPC and use the private IP address for access.</li> </ol> <p>For a static, public-facing IP address:</p> <ol> <li> <p>Allocate an Elastic IP address in the EC2 console:</p> <p></p> </li> <li> <p>Associate the Elastic IP address with your EC2 instance\u2019s network interface ID:     </p> </li> </ol> <p>Note</p> <p>Associating a new Elastic IP to an instance with an existing Elastic IP will disassociate the old one, but it will remain allocated to your account.</p> <p>For detailed information on EC2 instance IP addressing, see the AWS documentation on using instance addressing.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#expand-storage-capacity","title":"Expand storage capacity","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#resize-pmm-data-volume","title":"Resize PMM data volume","text":"<p>When monitoring more hosts or extending data retention, you may need additional storage space:</p> <ol> <li> <p>Increase the EBS volume size in the AWS Console following the AWS documentation. </p> </li> <li> <p>Expand the file system to use the additional space:</p> <pre><code># SSH to your PMM instance\nssh -i /path/to/your-key.pem admin@&lt;pmm-server-ip&gt;\n\n# Verify the volume size increase was detected\nsudo dmesg | grep \"capacity change\"\n\n# Resize the physical volume to use new space\nsudo pvresize /dev/xvdb\n\n# Extend the thin pool to use all available space\nsudo lvextend /dev/mapper/DataVG-ThinPool -l 100%VG\n\n# Extend the data volume to use remaining space\nsudo lvextend /dev/mapper/DataVG-DataLV -l 100%FREE\n\n# Grow the XFS filesystem\nsudo xfs_growfs /home/admin/volume\n\n# Verify the expansion\ndf -h /home/admin/volume\n</code></pre> </li> <li> <p>PMM automatically detects the storage increase within ~5 minutes and adjusts its configuration.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#resize-root-volume","title":"Resize root volume","text":"<p>If the root filesystem runs low on space:</p> <ol> <li>Increase the root EBS volume in the AWS Console.</li> <li> <p>Expand the disk from AWS Console/CLI to the desired capacity:</p> <ul> <li> <p>Log in to the PMM EC2 instance and verify that the disk capacity has increased. For example, if you have expanded disk from 8G to 10G, <code>dmesg</code>:</p> <pre><code># dmesg | grep \"capacity change\"\n[63175.044762] nvme0n1: detected capacity change from 8589934592 to 10737418240\n</code></pre> </li> <li> <p>Use the <code>lsblk</code> command to see that our disk size has been identified by the kernel correctly, but LVM2 is not yet aware of the new size:</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0     8G  0 part /\n...\n</code></pre> </li> <li> <p>For volumes that have a partition, such as the root volume shown in the previous step, use the <code>growpart</code> command to extend the partition:</p> <pre><code># growpart /dev/nvme0n1 1\nCHANGED: partition=1 start=2048 old: size=16775168 end=16777216 new: size=20969439 end=20971487\n</code></pre> </li> <li> <p>Verify that the partition reflects the increased volume size, use the <code>lsblk</code> command again:</p> <pre><code># lsblk\nNAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nnvme0n1                   259:1    0    10G  0 disk\n\u2514\u2500nvme0n1p1               259:2    0    10G  0 part /\n...\n</code></pre> </li> <li> <p>Extend the XFS file system on the root volume by <code>xfs_growfs</code> command:</p> <pre><code># xfs_growfs -d /\nmeta-data=/dev/nvme0n1p1         isize=512    agcount=4, agsize=524224 blks\n        =                       sectsz=512   attr=2, projid32bit=1\n        =                       crc=1        finobt=0 spinodes=0\ndata     =                       bsize=4096   blocks=2096896, imaxpct=25\n        =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal               bsize=4096   blocks=2560, version=2\n        =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\ndata blocks changed from 2096896 to 2621120\n</code></pre> </li> <li> <p>Verify that file system reflects the increased volume size:</p> <pre><code># df -hT /\nFilesystem     Type  Size  Used Avail Use% Mounted on\n/dev/nvme0n1p1 xfs    10G  5,6G  4,5G  56% /\n</code></pre> </li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#upgrade-ec2-instance-class","title":"Upgrade EC2 instance class","text":"<p>Scale your PMM Server by upgrading to a larger instance when CPU or memory usage becomes a bottleneck. </p> <p>PMM fully supports resizing EC2 instances, as long as you follow the steps outlined in the AWS EC2 resizing guide.</p> <p>Data safety</p> <p>PMM uses a separate EBS volume for monitoring data, so changing instance types doesn\u2019t affect your collected metrics or dashboards.</p> <p>To upgrade the instance type:</p> <ol> <li> <p>Open the Amazon EC2 console.</p> </li> <li> <p>In the navigation pane, choose PMM Server Instances.</p> </li> <li> <p>Select the instance and choose Actions &gt; Instance state &gt; Stop instance.</p> </li> <li> <p>In the Change instance type dialog box, select the instance type that you want.</p> <p></p> </li> <li> <p>Choose Apply to accept the new settings and start the stopped instance.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#configure-pmm-clients","title":"Configure PMM Clients","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#set-server-url","title":"Set server URL","text":"<p>Configure the PMM Server URL for client connections:</p> Public deploymentPrivate deployment <pre><code>PMM_SERVER_URL=\"https://&lt;elastic-ip-or-domain&gt;:443\"\n</code></pre> <pre><code>PMM_SERVER_URL=\"https://&lt;private-ip&gt;:443\"\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#configure-authentication","title":"Configure authentication","text":"<p>PMM Client authentication uses the same credentials you set for the web interface:</p> <pre><code># Example PMM Client configuration command\npmm-admin config --server-insecure-tls --server-url=https://admin:your-password@&lt;pmm-server-ip&gt;:443\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#test-connection","title":"Test connection","text":"<p>Test PMM Client connectivity:</p> <pre><code># Test PMM Server connectivity\ncurl -k https://&lt;pmm-server-ip&gt;:443/ping\n# Expected response: \"OK\"\n\n# Test API authentication\ncurl -k -u admin:your-password https://&lt;pmm-server-ip&gt;:443/v1/readyz\n# Expected response: {\"status\":\"ok\"}\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#back-up-and-restore","title":"Back up and restore","text":"<p>To restore PMM Server from a backup:</p> <ol> <li> <p>Create a new volume using the latest snapshot of the PMM data volume:</p> <p></p> </li> <li> <p>Stop the PMM Server instance.</p> </li> <li> <p>Detach the current PMM data volume:</p> <p></p> </li> <li> <p>Attach the new volume:</p> <p></p> </li> <li> <p>Start the PMM Server instance.  The restore process typically takes 5-15 minutes depending on volume size and AWS region performance.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#remove-pmm-server-from-aws","title":"Remove PMM Server from AWS","text":"<p>Data loss warning</p> <p>Instance termination permanently deletes all data. Ensure you have completed all backup procedures before terminating an instance.</p> <p>To permanently delete your PMM Server instance and clean up resources:</p> From the AWS console (UI)From AWS CLI <p>Use the AWS console for a visual, step-by-step termination process:</p> <ol> <li> <p>Go to the EC2 Console.</p> </li> <li> <p>Find the instance you want to remove.    </p> </li> <li> <p>Open the Instance state menu and select Terminate instance.    </p> </li> <li> <p>Confirm termination.</p> </li> </ol> <p>Use the AWS CLI when you want to automate termination with cleanup:</p> <ol> <li> <p>Create a final backup:    <pre><code>aws ec2 create-snapshot --volume-id $DATA_VOLUME_ID --description \"Final backup before termination\"\n</code></pre></p> </li> <li> <p>Disconnect all PMM clients:    <pre><code># On each monitored server\npmm-admin remove --all\n</code></pre></p> </li> <li> <p>Export configuration:    <pre><code>podman  exec pmm-server pmm-admin summary &gt; pmm-final-config.txt\n</code></pre></p> </li> <li> <p>Stop PMM services:    <pre><code>podman stop pmm-server\n</code></pre></p> </li> <li> <p>Terminate the instance:    <pre><code>aws ec2 terminate-instances --instance-ids i-1234567890abcdef0\n</code></pre></p> </li> <li> <p>Clean up AWS resources (optional):    <pre><code># Release Elastic IP if allocated\naws ec2 release-address --allocation-id eipalloc-12345678\n</code></pre></p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/configure_aws.html#next-steps","title":"Next steps","text":"<p>With your PMM Server fully configured and secured:</p> <ul> <li>Configure PMM clients to start monitoring your infrastructure</li> <li>Register client nodes with your PMM Server</li> <li>Configure SSL certificates for production use</li> <li>Set up monitoring alerts for proactive monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html","title":"Deploy PMM Server on AWS","text":"<p>After planning your instance size, storage, and network requirements, deploy PMM Server from AWS Marketplace to get monitoring running.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#launch-pmm-server-from-aws-marketplace","title":"Launch PMM Server from  AWS Marketplace","text":"<p>To launch  PMM Server via AWS Marketplace:</p> <ol> <li> <p>Go to AWS Marketplace and search for Percona Monitoring and Management Server or access the PMM Server listing directly.</p> </li> <li> <p>Click View purchase options on the PMM Server listing page, review the terms and conditions, then click Continue to Configuration.</p> </li> <li> <p>Select the latest version (recommended), choose the AWS region where you want to deploy PMM, then click Continue to Launch.</p> </li> <li> <p>Choose Launch from Website to configure and launch directly from the AWS Marketplace or Launch through EC2 if you prefer launching via the EC2 Management Console for more customization.</p> </li> <li> <p>In the EC2 Instance Type field, select an appropriate instance type based on your monitoring needs and anticipated load. For information on instance sizing and storage, see Plan PMM Server deployment from AWS.</p> </li> <li> <p>In the VPC Settings field, choose an existing VPC or create a new one to host your PMM Server. Ensure that the selected VPC has an Internet Gateway attached to it to be reachable over the Internet</p> </li> <li> <p>In the Subnet Settings field, select an existing subnet or create a new one within your VPC.</p> </li> <li> <p>In the Security Group Settings field, choose an existing security group or create a new one. Make sure the security group allows inbound traffic on the Required ports.</p> </li> <li> <p>In the Key Pair Settings field, select an existing key pair for SSH access, or create a new one if necessary.</p> </li> <li> <p>Click Launch to deploy the PMM Server instance. Once the instance is launched, it will appear in the EC2 console.</p> </li> <li> <p>Assign a meaningful name to the instance to help distinguish it from others in your environment.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#access-the-ec2-console","title":"Access the EC2 console","text":"<p>Monitor the deployment progress and access your instance through the EC2 console:</p> <ol> <li> <p>Click the EC2 Console link that appears at the top of the confirmation page after launching, or go directly to the EC2 Console </p> </li> <li> <p>Locate your new PMM instance in the EC2 instances table. Initially, its Status shows Pending while launching and the Name will be empty. </p> </li> </ol> <p></p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#monitor-instance-status","title":"Monitor instance status","text":"<p>Monitor your instance deployment progress through its status checks:</p> Status Description Expected duration Pending Instance is being created 1-2 minutes Running Instance is active and accessible Ready for use Status Checks System and instance checks 2-5 minutes"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#initial-pmm-server-access","title":"Initial PMM Server access","text":"<p>Once your instance status shows \u201cRunning\u201d and passes all status checks in the AWS console:</p> <ol> <li> <p>In the EC2 console, select your instance and copy its IPv4 Public IP in the instance details or the Public IP field from the Properties panel:</p> <p></p> </li> <li> <p>Open the IP address in a web browser and log into PMM using the default credentials:</p> <ul> <li>Username: <code>admin</code> </li> <li>Password: Your EC2 instance ID  available in the Instance ID field in the EC2 console.</li> </ul> <p></p> </li> <li> <p>Change the default credentials then use the new ones to log in to the PMM Server home page. You will reuse these credentials when configuring PMM Clients on other hosts.</p> <p></p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#configure-pmm-server-and-ip-settings","title":"Configure PMM Server and IP settings","text":"<p>After initial access, configure your PMM Server\u2019s security groups and IP addressing.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#ssh-access","title":"SSH access","text":"<p>For SSH access instructions, see Connecting to Your Linux Instance Using SSH.</p> <p>Replace the user name <code>ec2-user</code> with <code>admin</code>. You can also add SSH keys later through the PMM Configuration &gt; Settings &gt; SSH Key page.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/deploy_aws.html#next-steps","title":"Next steps","text":"<p>With your PMM Server deployed and accessible:</p> <ul> <li>Configure PMM Server for security and authentication</li> <li>Configure PMM Clients to start monitoring your infrastructure</li> <li>Register client nodes with your PMM Server</li> <li>Improve PMM EC2 instance resilience using CloudWatch Alarm actions</li> <li>Simplify use of ENV eariables in PMM AMI</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html","title":"Plan PMM Server deployment from AWS","text":"<p>Deploy PMM Server with AWS Marketplace when you need a quick setup with pre-configured settings, integrated billing, and enterprise-grade security for your existing AWS infrastructure.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>an active AWS account with appropriate permissions</li> <li>IAM permissions to create and manage EC2 instances, storage, VPC and security groups</li> <li>understanding of AWS networking concepts (VPC, subnets, security group concepts)</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#choose-the-right-instance-size","title":"Choose the right instance size","text":"<p>Select an EC2 instance based on the number of hosts you plan to monitor. </p> <p>Start small and scale as your monitoring needs grow. EC2 instances can be resized with minimal downtime.</p> Monitored hosts Instance type vCPUs Memory Storage 1-10 hosts t3.medium 2 4 GB 20 GB 10-50 hosts t3.large 2 8 GB 50 GB 50-200 hosts t3.xlarge 4 16 GB 100 GB 200+ hosts t3.2xlarge+ 8+ 32+ GB 200+ GB"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#plan-storage","title":"Plan storage","text":"<p>PMM Server stores all monitoring data in the <code>/home/admin/volume</code> partition. Plan storage based on the:</p> <ul> <li>number of monitored hosts</li> <li>retention period for collected data</li> <li>frequency of metric collection</li> </ul> <p>As a reference, the PMM Demo site consumes approximately 230 MB per host per day, which totals around 6.9 GB per host over a 30-day retention period.</p> <p>For 50 hosts with 30-day retention: 50 \u00d7 6.9 GB = 345 GB minimum storage. </p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#storage-recommendations","title":"Storage recommendations","text":"<ul> <li>include 20-30% buffer for unexpected spikes and growth</li> <li>use GP3 volumes for better price/performance than GP2</li> <li>consider higher IOPS for deployments with 100+ hosts</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#network-and-security-planning","title":"Network and security planning","text":"<p>Plan your network configuration before deployment:</p> <p>Required ports:</p> <ul> <li>port <code>22</code> (SSH): Administrative access to the instance</li> <li>port <code>80</code> (HTTP): Initial PMM web interface access</li> <li>port <code>443</code> (HTTPS): Secure PMM web interface access</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#estimate-costs","title":"Estimate costs","text":"<p>PMM Server software is free, but plan for AWS infrastructure costs depending on your instance size and storage needs.</p> <p>Use the AWS pricing calculator to estimate monthly costs based on your planned configuration.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#plan-backups","title":"Plan backups","text":"<p>PMM Server uses a simple backup architecture - all monitoring data is stored in the <code>/home/admin/volume</code> partition, which means you only need to back up one EBS volume to protect all your PMM data. This simplifies your backup strategy and reduces complexity.</p> <p>When planning your deployment, consider that you\u2019ll need to create point-in-time snapshots of the EBS volume containing the <code>/home/admin/volume</code> partition. Plan for snapshot storage costs and determine your backup frequency and retention requirements.</p> <p>Follow the AWS documentation for Create Amazon EBS snapshots to understand the backup process you\u2019ll implement after deployment.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/aws/plan_aws.html#next-steps","title":"Next steps","text":"<p>Once you\u2019ve completed your planning:</p> <ul> <li>Deploy PMM Server </li> <li>Configure security and access </li> <li>Install PMM Client</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html","title":"Install PMM Server with Docker","text":"<p>Deploy PMM Server as a Docker container for a fast, flexible and isolated setup. </p> <p>While PMM Server runs independently, we highly recommend that you streamline upgrades via the PMM user interface by installing Watchtower alongside PMM Server. </p> <p>With Watchtower installed, you can easily update PMM Server directly from the Upgrade page or by clicking the Upgrade Now button on the Home dashboard.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#prerequisites","title":"Prerequisites","text":"<p>Before installation, ensure you have:</p> <ul> <li>Docker version 17.03 or higher</li> <li>CPU with <code>x86-64-v2</code> support</li> <li>Sufficient system resources (recommended: 2+ CPU cores, 4+ GB RAM, 100+ GB disk space)</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#watchtower-security-requirements","title":"Watchtower security requirements","text":"<p>Watchtower requires access to the Docker socket to monitor and update containers. Since the Docker socket provides root-level access to the host system, it\u2019s critical to limit Watchtower\u2019s exposure to prevent potential security vulnerabilities.</p> <p>To ensure a secure setup when using Watchtower:</p> <ul> <li>limit Watchtower\u2019s access to Docker network or localhost to prevent unauthorized external connections. See Container network isolation guide.</li> <li>configure network to ensure only PMM Server is exposed externally. See Docker networking best practices.</li> <li>secure Docker socket access for Watchtower. See Docker socket security.</li> <li>place both Watchtower and PMM Server on the same Docker network. See Watchtower network configuration.</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#installation-options","title":"Installation options","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#container-setup-summary","title":"Container setup summary","text":"Container setup at a glance <ul> <li>Pull the Docker image: <code>docker pull percona/pmm-server:3</code></li> <li>Choose storage: Docker volumes (recommended) or host directory</li> <li>Run the container: Using the appropriate <code>docker run</code> command</li> <li>Access the UI: Navigate to <code>https://SERVER_IP_ADDRESS</code> in your browser</li> <li>Log in: Default credentials <code>admin</code> / <code>admin</code></li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#install-pmm-server-watchtower","title":"Install PMM Server + Watchtower","text":"<p>You can install PMM Server with Watchtower using one of two methods:</p> Easy-install script (Recommended for simplicity)Manual installation (For customization) <p>The Easy-install script simplifies setup by including Watchtower commands, enabling a one-step installation of PMM with Watchtower. Run the following command:</p> <pre><code>curl -fsSL https://www.percona.com/get/pmm | /bin/bash\n</code></pre> <p>For a more customizable setup, follow these steps:</p> <ol> <li> <p>Create a Docker network for PMM and Watchtower:      <pre><code>docker network create pmm-network\n</code></pre></p> </li> <li> <p>(Optional but recommended) Install Watchtower to enable PMM Server upgrades via the UI:</p> <ul> <li> <p>Create a user-defined token to secure Watchtower\u2019s HTTP API. You can use any value or generate a secure token using <code>openssl</code> or another method. Ensure the same token is used in both the Watchtower and PMM Server configurations:</p> <pre><code>openssl rand -hex 16\n# Example output:\ne09541c81e672bf0e48dbc72d4f92790\n</code></pre> </li> <li> <p>Install Watchtower using your token: </p> <pre><code>docker run --detach \\\n--restart always \\\n--network=pmm-network \\\n-e WATCHTOWER_HTTP_API_TOKEN=your_token \\\n-e WATCHTOWER_HTTP_API_UPDATE=1 \\\n--volume /var/run/docker.sock:/var/run/docker.sock \\\n--name watchtower \\\npercona/watchtower:latest\n</code></pre> </li> </ul> </li> <li> <p>Run PMM Server with Docker based on your preferred data storage method:</p> <ul> <li>Run Docker with host directory</li> <li>Run Docker with volume</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#configuration-options","title":"Configuration options","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#storage-configuration","title":"Storage configuration","text":"<p>You can choose either of two storage options offered by PMM Server:</p> Option Suitable for Docker parameter Docker volumes (Recommended) Production environments <code>--volume pmm-data:/srv</code> Host directory Development/testing <code>--volume /path/on/host:/srv</code>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#environment-variables","title":"Environment variables","text":"<p>Configure PMM Server\u2019s behavior using environment variables:</p> <pre><code>docker run -e PMM_DATA_RETENTION=720h -e PMM_DEBUG=true percona/pmm-server:3\n</code></pre> <p>Common variables:</p> Variable Default Description <code>PMM_DATA_RETENTION</code> <code>30d</code> Duration to retain metrics data <code>PMM_METRICS_RESOLUTION</code> <code>1s</code> Base metrics collection interval <code>PMM_ENABLE_UPDATES</code> <code>true</code> Allow version checks and UI updates <code>PMM_ENABLE_TELEMETRY</code> <code>true</code> Send usage statistics <p>For a complete list, see the environment variables.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#access-pmm-server","title":"Access PMM Server","text":"<p>After installation:</p> <ol> <li> <p>Access the PMM interface in your browser: <code>https://SERVER_IP_ADDRESS</code> (replace with your server\u2019s address)</p> </li> <li> <p>Log in with default credentials: <code>admin</code> / <code>admin</code>. </p> </li> <li> <p>Change the default password on first login.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#advanced-configuration","title":"Advanced configuration","text":"<p>After basic installation, you may want to customize your PMM Server setup:</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#security-options","title":"Security options","text":"<ul> <li>Configure a trusted SSL certificate to remove browser warnings.</li> <li> <p>Disable the upgrade panel if needed:</p> <ul> <li>via Docker:  add <code>-e PMM_ENABLE_UPDATES=false</code> to the <code>docker run</code> command (for the life of the container)</li> <li>via UI: go to PMM Configuration &gt; Settings &gt; Advanced Settings and disable Check for Updates (can be turned back on by any admin in the UI)</li> </ul> </li> <li> <p>Enable HTTP (insecure, NOT recommended): add <code>--publish 80:8080</code> to the <code>docker run</code> command.</p> </li> </ul> <p>Warning</p> <p>PMM Client requires a secure (TLS-encrypted) connection and will only communicate with PMM Server over HTTPS.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/index.html#next-steps","title":"Next steps","text":"<ul> <li>Install PMM Client on hosts you want to monitor</li> <li>Connect databases for monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html","title":"Back up PMM Server Docker container","text":"<p>Regular backups of your PMM Server are essential for protecting your monitoring configuration and historical data.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html#backup-overview","title":"Backup overview","text":"Summary <ul> <li>Stop and rename the <code>pmm-server</code> container.</li> <li>Take a local copy of the <code>pmm-server</code> container\u2019s <code>/srv</code> directory.</li> <li>Copy the dat<code>a directory (</code>/srv`) to your host</li> <li>Resume normal operations</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html#backing-up-grafana-plugins","title":"Backing up Grafana plugins","text":"<p>Grafana plugins have been moved to the <code>/srv</code> directory since PMM 2.23.0. So if you are upgrading PMM from a version before 2.23.0 and have installed additional plugins, you\u2019ll need to reinstall them after the upgrade.</p> <p>To check used Grafana plugins:</p> <pre><code>docker exec -t pmm-server ls -l /var/lib/grafana/plugins\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html#back-up-procedure","title":"Back up procedure","text":"<p>To back up your PMM Server container:</p> <ol> <li> <p>Stop the running PMM Server container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Rename the container to preserve it as a backup source:</p> <pre><code>docker rename pmm-server pmm-server-backup\n</code></pre> </li> <li> <p>Create a backup subdirectory (e.g., <code>pmm-data-backup</code>) and navigate to it:</p> <pre><code>mkdir pmm-data-backup &amp;&amp; cd pmm-data-backup\n</code></pre> </li> <li> <p>Back up the data:</p> <pre><code>docker cp pmm-server-backup:/srv .\n</code></pre> </li> <li> <p>Verify the backup was created successfully:     <pre><code>ls -la srv/\n</code></pre></p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html#next-steps-after-backup","title":"Next steps after backup","text":"<p>After creating your backup, you have two options:</p> <ol> <li>Resume normal operations if you were creating a routine backup, restart your original container.</li> <li>Upgrade or restore the container if you were backing up before an upgrade or restoration.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/backup_container.html#backup-storage-recommendations","title":"Backup storage recommendations","text":"<ul> <li>Store backups in a location separate from the PMM Server host</li> <li>Implement automated rotation of backups to manage disk space</li> <li>Consider encrypting backups containing sensitive monitoring data</li> <li>Test restores periodically to verify backup integrity</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html","title":"Run Docker via the Easy-install script","text":"<p>The Easy-install script provides the simplest way to deploy PMM Server with Docker, handling all the necessary setup steps automatically.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html#security-best-practice","title":"Security best practice","text":"<p>Before running the script:</p> <ul> <li> <p>Download the installation script from the official Percona domain.</p> </li> <li> <p>Review the script content to understand its actions.</p> </li> <li> <p>Consider running the script with the <code>--interactive</code> flag to customize:</p> <ul> <li>port mappings (default: 443 for HTTPS)</li> <li>location where PMM Server stores its data</li> <li>PMM Server version (specific version or latest)</li> <li>additional configuration parameters (environment variables, resource limits)</li> </ul> </li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html#installation-instructions","title":"Installation instructions","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html#linux-or-macos","title":"Linux or macOS","text":"<p>Download and install PMM Server using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>curl -fsSL https://www.percona.com/get/pmm | /bin/bash\n</code></pre> <pre><code>wget -O - https://www.percona.com/get/pmm | /bin/bash\n</code></pre> What does the script do? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not already installed on your system.</li> <li>Stops and renames any currently running PMM Server Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old pmm-server container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Server Docker image.</li> <li>Can run in Interactive mode to change the default settings:</li> </ul> <pre><code>   curl -fsSLO https://www.percona.com/get/pmm (or wget https://www.percona.com/get/pmm) \n   chmod +x pmm\n   ./pmm --interactive\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html#docker-installation-issues","title":"Docker installation issues","text":"<p>If you encounter Docker installation issues with the Easy-install script (such as <code>ERROR: Unsupported distribution 'rocky' on Rocky Linux</code>):</p> <ol> <li>Install Docker manually</li> <li>Run the Easy-install script above again</li> </ol> <p>This two-step approach resolves most installation issues, especially on Rocky Linux where automatic installation may fail.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/easy-install.html#next-steps","title":"Next steps","text":"<p>After deploying PMM Server successfully, continue by setting up PMM Client:</p> <p>Install PMM Client </p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html","title":"Configure environment variables for PMM Server","text":"<p>Configure PMM Server behavior by setting environment variables when running the Docker container. This allows you to customize performance, storage, features, and other settings without modifying configuration files.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#using-environment-variables","title":"Using environment variables","text":"<p>Configure PMM Server by setting Docker container environment variables using the <code>-e var=value</code> syntax:</p> <pre><code>docker run -e PMM_DATA_RETENTION=720h -e PMM_DEBUG=true percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#core-configuration-variables","title":"Core configuration variables","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#performance-storage","title":"Performance &amp; storage","text":"<p>Fine-tune data retention and collection intervals to balance monitoring detail with resource usage:</p> Variable Default Description Example <code>PMM_DATA_RETENTION</code> <code>30d</code> Duration to retain metrics data (must be in multiples of 24h) <code>720h</code> (30 days) <code>PMM_METRICS_RESOLUTION</code> <code>1s</code> Base metrics collection interval <code>5s</code> <code>PMM_METRICS_RESOLUTION_HR</code> <code>5s</code> High-resolution metrics interval <code>10s</code> <code>PMM_METRICS_RESOLUTION_MR</code> <code>10s</code> Medium-resolution metrics interval <code>30s</code> <code>PMM_METRICS_RESOLUTION_LR</code> <code>60s</code> Low-resolution metrics interval <code>300s</code> <p>Performance Impact</p> <p>Higher resolution (lower values) provides more detailed metrics but increases storage requirements and system load. For high-traffic production environments, consider increasing these values.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#feature-controls","title":"Feature controls","text":"<p>Enable or disable specific PMM features:</p> Variable Default Effect when enabled <code>PMM_ENABLE_UPDATES</code> <code>true</code> Allows version checks and UI updates <code>PMM_ENABLE_TELEMETRY</code> <code>true</code> Enables usage data collection <code>PMM_ENABLE_ALERTING</code> <code>true</code> Enables Percona Alerting system <code>PMM_ENABLE_BACKUP_MANAGEMENT</code> <code>true</code> Enables backup features <code>PMM_ENABLE_AZURE_DISCOVER</code> <code>false</code> Enables Azure database discovery"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#debugging-and-troubleshooting","title":"Debugging and troubleshooting","text":"<p>Use these variables when diagnosing issues with PMM Server:</p> Variable Default Purpose <code>PMM_DEBUG</code> <code>false</code> Enables verbose logging <code>PMM_TRACE</code> <code>false</code> Enables detailed trace logging <p>Production use</p> <p>Debug and trace logging can significantly impact performance and generate large log volumes. Use only temporarily when troubleshooting issues.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#advanced-configuration","title":"Advanced configuration","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#network-configuration","title":"Network configuration","text":"<p>Control how PMM Server presents itself on the network:</p> Variable Description <code>PMM_PUBLIC_ADDRESS</code> External DNS/IP for PMM server <code>PMM_INTERFACE_TO_BIND</code> Network interface binding"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#database-connections","title":"Database connections","text":"<p>Configure connections to external database services:</p> Variable Purpose <code>PMM_CLICKHOUSE_*</code> ClickHouse connection settings <code>PMM_POSTGRES_*</code> PostgreSQL connection settings"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#supported-external-variables","title":"Supported external variables","text":"<p>PMM Server passes these variables to integrated components:</p> <ul> <li>Grafana: All <code>GF_*</code> variables (e.g., <code>GF_SECURITY_ADMIN_PASSWOR</code>)</li> <li>VictoriaMetrics: All <code>VM_*</code> variables (e.g., VM_retentionPeriod)</li> <li>Kubernetes: All <code>KUBERNETES_*</code> variables</li> <li>System variables: Standard variables like <code>HOME</code>, <code>PATH</code>, etc.</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#experimental-variables","title":"Experimental variables","text":"<p>PMM includes experimental environment variables prefixed with <code>PERCONA_TEST_*</code> that are under development and subject to change. To see the complete list and details of experimental variables, see Preview environment variables.</p> <p>For testing only</p> <p>Experimental variables are not supported for production use. Use these variables for testing purposes only.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#variables-for-migrating-from-pmm-v2-to-pmm-v3","title":"Variables for migrating from PMM v2 to PMM v3","text":"<p>PMM v3 introduces several important changes to improve consistency and clarity. When migrating from PMM v2 to PMM v3, you\u2019ll need to update your environment variables to match the new naming convention: </p> <p>For example:</p> <ul> <li><code>METRICS_RESOLUTION</code> \u2192 <code>PMM_METRICS_RESOLUTION</code></li> <li><code>METRICS_RESOLUTION_HR</code> \u2192 <code>PMM_METRICS_RESOLUTION_HR</code></li> </ul> <p>To see the full lists of variable name changes between PMM v2 and PMM v3, see the Migration guide.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#common-configuration-examples","title":"Common configuration examples","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#high-traffic-production-server","title":"High-traffic production server","text":"<p>For environments with many monitored systems, increase collection intervals and retention:</p> <pre><code>docker run \\\n -e PMM_DATA_RETENTION=45d \\\n -e PMM_METRICS_RESOLUTION=5s \\\n -e PMM_METRICS_RESOLUTION_HR=30s \\\n -e PMM_METRICS_RESOLUTION_MR=60s \\\n -e PMM_METRICS_RESOLUTION_LR=300s \\\n percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#development-environment","title":"Development environment","text":"<p>For testing and development, you might want debugging enabled:</p> <pre><code>docker run \\\n -e PMM_DATA_RETENTION=7d \\\n -e PMM_DEBUG=true \\\n -e PMM_ENABLE_TELEMETRY=false \\\n percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#restricted-features","title":"Restricted features","text":"<p>To disable certain features for security or policy reasons:</p> <pre><code>docker run \\\n -e PMM_ENABLE_UPDATES=false \\\n -e PMM_ENABLE_TELEMETRY=false \\\n -e PMM_ENABLE_BACKUP_MANAGEMENT=false \\\n percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/env_var.html#related-topic","title":"Related topic","text":"<p>Preview environment variables</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/isolated_hosts.html","title":"Install PMM Server in isolated environments","text":"<p>To deploy PMM Server in air-gapped or isolated environments with no direct internet connectivity, download the Docker image on a separate (internet-connected) host and securely copy it:</p> <ol> <li> <p>On an internet-connected host, download the Docker image and its checksum file:</p> <pre><code>wget https://downloads.percona.com/downloads/pmm/3.3.1/docker/pmm-server-3.3.1.docker\nwget https://downloads.percona.com/downloads/pmm/3.3.1/docker/pmm-server-3.3.1.sha256sum\n</code></pre> </li> <li> <p>Transfer both files to the target host where you\u2019ll run PMM Server using a secure method (such as <code>scp</code>, physical media, or your organization\u2019s approved file transfer mechanism).</p> </li> <li> <p>On the target host, open a terminal and navigate to where you placed the downloaded files.</p> </li> <li> <p>Verify the Docker image file integrity (recommended):</p> <pre><code>shasum -ca 256 pmm-server-3.3.1.sha256sum\n</code></pre> </li> <li> <p>Load the Docker image:</p> <pre><code>docker load -i pmm-server-3.3.1.docker\n</code></pre> </li> <li> <p>Run the PMM Server container as if your image is already pulled using your desired method for a storage volume. Skip any <code>docker pull</code> commands as the image has been pre-staged and available locally.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/isolated_hosts.html#related-resources","title":"Related resources","text":"<ul> <li>Docker installation guide</li> <li>Docker Compose installation</li> <li>PMM Server Docker tags</li> <li>PMM Client Docker setup</li> <li>Setting up trusted certificates</li> <li>Easy installation script</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/preview_env_var.html","title":"Preview environment variables","text":"<p>Warning</p> <p>The <code>PERCONA_TEST_*</code> environment variables are experimental and subject to change. These variables are intended for testing purposes only and should not be used in production environments.</p> <p>For stable, production-ready configuration options, see the main Environment variables for PMM Server documentation.</p> Variable Description <code>PMM_TEST_HA_ENABLE</code> Enable PMM to run in High Availability (HA) mode. <code>PMM_TEST_HA_BOOTSTRAP</code> Bootstrap HA cluster. <code>PMM_TEST_HA_NODE_ID</code> HA Node ID. <code>PMM_TEST_HA_ADVERTISE_ADDRESS</code> HA Advertise address. <code>PMM_TEST_HA_GOSSIP_PORT</code> HA gossip port. <code>PMM_TEST_HA_RAFT_PORT</code> HA raft port. <code>PMM_TEST_HA_GRAFANA_GOSSIP_PORT</code> HA Grafana gossip port. <code>PMM_TEST_HA_PEERS</code> HA Peers."},{"location":"install-pmm/install-pmm-server/deployment-options/docker/preview_env_var.html#available-preview-variables","title":"Available preview variables","text":"Variable Description <code>PERCONA_TEST_SAAS_HOST</code> SaaS server hostname. <code>PMM_CLICKHOUSE_ADDR</code> Name of the host and port of the external ClickHouse database instance <code>PMM_CLICKHOUSE_DATABASE</code> Database name of the external ClickHouse instance <code>\u200b\u200bPMM_CLICKHOUSE_USER</code> Database user <code>PMM_CLICKHOUSE_PASSWORD</code> Database user password"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/preview_env_var.html#using-preview-variables","title":"Using preview variables","text":"<p>Add preview variables to your <code>docker run</code> command for testing purposes:</p> <pre><code>docker run -d \\\n  --name pmm-server \\\n  -e PERCONA_TEST_PMM_CLICKHOUSE_ADDR=clickhouse-test:9000 \\\n  -e PERCONA_TEST_PMM_CLICKHOUSE_DATABASE=pmm_test \\\n  percona/pmm-server:3\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/preview_env_var.html#testing-external-clickhouse-connections","title":"Testing external ClickHouse connections","text":"<p>The ClickHouse-related preview variables are useful for testing PMM Server with an external ClickHouse instance:</p> <ol> <li>Set up a test ClickHouse instance.</li> <li>Configure the connection using the variables above.</li> <li>Launch PMM Server and verify it connects and stores metrics correctly.</li> <li>Monitor logs to validate how metrics display.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/remove_container.html","title":"Remove PMM Server Docker container","text":"<p>Completely remove PMM Server from your Docker environment when you want to uninstall PMM Server, free up resources, or prepare for a clean installation.</p> <p>Warning: Data loss</p> <p>These steps will permanently delete your PMM Server container, Docker image, all stored metrics data, and configuration. This action cannot be undone unless you have a backup.</p> <p>Consider creating a backup first if you might need the data in the future.</p> <p>To completely remove the container from your system:</p> <ol> <li> <p>Stop the running PMM Server container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove the container (preserving data volume):</p> <pre><code>docker rm pmm-server\n</code></pre> </li> <li> <p>Remove the data volume containing all metrics and configuration:</p> <pre><code>docker volume rm pmm-data\n</code></pre> </li> <li> <p>Remove the PMM Server Docker image:</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-server\" | awk '{print $3}')\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/remove_container.html#verification","title":"Verification","text":"<p>Verify that all PMM Server components have been removed. If you successfully removed everything, these commands should return no results:</p> <pre><code># Check if the container is gone\ndocker ps -a | grep pmm-server\n\n# Verify the volume is removed\ndocker volume ls | grep pmm-data\n\n# Confirm the image is removed\ndocker images | grep percona/pmm-server\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/remove_container.html#selective-removal-options","title":"Selective removal options","text":"<p>If you need to remove only specific components:</p> Remove container but keep dataRemove container and image but keep data <p>This allows for future reinstallation without losing historical data:</p> <pre><code>docker stop pmm-server\ndocker rm pmm-server\n# Do NOT remove the volume\n</code></pre> <pre><code>docker stop pmm-server\ndocker rm pmm-server\ndocker rmi $(docker images | grep \"percona/pmm-server\" | awk '{print $3}')\n# Do NOT remove the volume\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/remove_container.html#related-topics","title":"Related topics","text":"<ul> <li>Backup PMM Server to create a backup before removal</li> <li>Restore PMM Server to restore from a backup if needed later</li> <li>Install PMM Server to reinstall PMM Server if needed</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/restore_container.html","title":"Restore PMM Server Docker container","text":"<p>You can restore PMM Server either from a manual backup or from an automated backup volume that was created during migration to PMM v3.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/restore_container.html#before-you-begin","title":"Before you begin","text":"<p>Before proceeding with restoration, ensure you have one of the following:</p> <ul> <li>a manual backup you previously created </li> <li>an automated backup volume created during migration from PMM V3</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/restore_container.html#restore-methods","title":"Restore methods","text":"Restore from manual backupRestore from automated migration backup <p>To restore the container from a manual backup:</p> <ol> <li> <p>Stop the current PMM Server container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Remove the container (preserving volumes):</p> <pre><code>docker rm pmm-server\n</code></pre> </li> <li> <p>Revert to the saved image:</p> <pre><code>docker rename pmm-server-backup pmm-server\n</code></pre> </li> <li> <p>Navigate to the backup directory (e.g. <code>pmm-data-backup</code>):</p> <pre><code>cd pmm-data-backup\n</code></pre> </li> <li> <p>Copy the backup data to the PMM data volume:</p> <pre><code>docker run --rm -v $(pwd)/srv:/backup -v pmm-data:/srv -t percona/pmm-server:3 cp -r /backup/* /srv\n</code></pre> </li> <li> <p>Fix ownership of the restored files to ensure the PMM Server can access and manage the files correctly:</p> <pre><code>docker run --rm -v pmm-data:/srv -t percona/pmm-server:3 chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>Start the restored PMM Server container:</p> <pre><code>docker start pmm-server\n</code></pre> </li> </ol> <p>To restore from an automated backup volume created during migration to PMM v3:</p> <ol> <li>Stop the current PMM v3 container:     <pre><code>docker stop pmm-server\n</code></pre></li> <li>Remove the container (optional):     <pre><code>docker rm pmm-server\n</code></pre></li> <li> <p>Start a PMM v2 container using your backup volume, replacing <code>&lt;backup-volume-name&gt;</code> with your PMM v2 backup volume name (e.g., <code>pmm-data-2025-01-16-165135</code>):</p> <pre><code>docker run -d \\\n-p 443:443 \\\n--volume &lt;backup-volume-name&gt;:/srv \\\n--name pmm-server \\\n--restart always \\\npercona/pmm-server:2.44.0\n</code></pre> </li> <li> <p>Verify that your PMM v2 instance is running correctly and all your data is accessible.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/restore_container.html#find-your-backup-volume-name","title":"Find your backup volume name","text":"<p>If you\u2019re restoring from an automated migration backup and don\u2019t know the volume name:</p> <ul> <li>Your backup volume name was displayed during the automated upgrade process.</li> <li> <p>To list all available Docker volumes, use the following command and look for volumes with names like <code>pmm-data-YYYY-MM-DD-HHMMSS</code>:</p> <pre><code>docker volume ls       \n</code></pre> </li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/restore_container.html#next-steps","title":"Next steps","text":"<ul> <li>Create a backup of your PMM Server</li> <li>Upgrade your PMM Server to a newer version</li> <li>Migrate from PMM v2 to v3 if restoring to upgrade</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html","title":"Run Docker with the host directory","text":"<p>Not recommended for production environments</p> <p>Using a host directory for PMM data persistence is not recommended for production environments. This approach may lead to permission issues, inconsistent backup behavior, and potential data corruption during upgrades. </p> <p>For production deployments, we strongly recommend using Docker volumes instead, which provide better isolation, portability, and compatibility with Docker\u2019s ecosystem.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html#when-to-use-host-directories","title":"When to use host directories","text":"<p>Host directory mounting can be useful in specific scenarios:</p> <ul> <li>development and testing environments</li> <li>when you need direct filesystem access to PMM data</li> <li>integration with existing host-based backup solutions</li> <li>migration from other deployment methods</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html#installation-steps","title":"Installation steps","text":"<p>To deploy PMM Server using a host directory: </p> <ol> <li> <p>Pull the latest PMM Server image:    <pre><code>docker pull percona/pmm-server:3\n</code></pre></p> </li> <li> <p>Create and identify a directory on the host where to store PMM data. For example, <code>/home/user/srv</code>.</p> </li> <li> <p>Run the PMM Server with the host image mounted, making sure to replace <code>your_watchtower_token</code> with the token created during Watchtower setup: </p> <pre><code>docker run --detach --restart always \\\n--publish 443:8443 \\\n--env PMM_WATCHTOWER_HOST=http://your_watchtower_host:8080 \\\n--env PMM_WATCHTOWER_TOKEN=your_watchtower_token \\\n--volume /home/user/srv:/srv \\\n--network=pmm-network \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre> </li> <li> <p>Set a secure password for the default <code>admin</code> user, replacing <code>your_secure_password</code> with a strong, unique password:</p> <pre><code>docker exec -t pmm-server change-admin-password your_secure_password\n</code></pre> </li> <li> <p>Access the PMM web interface at <code>https://localhost:443</code> in a web browser. If you\u2019re connecting from a different machine, replace <code>localhost</code> with your server\u2019s IP address or hostname.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html#migrate-from-data-container-to-host-directory","title":"Migrate from data container to host directory","text":"<p>To migrate data from a Docker volume to a host directory:</p> <pre><code>docker cp &lt;container-id&gt;:/srv /target/host/directory\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html#migrate-from-host-directory-to-docker-volume","title":"Migrate from host directory to Docker volume","text":"<p>To migrate from a host directory to a Docker volume (recommended for production):</p> <ol> <li>Create a new Docker volume: <pre><code>docker volume create pmm-data\n</code></pre></li> <li> <p>Copy data from host directory to the volume: <pre><code>  docker run --rm -v /path/on/host:/source -v pmm-data:/target alpine cp -a /source/. /target/\n</code></pre></p> </li> <li> <p>Update your container to use the volume instead of the host directory. </p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_host_dir.html#next-steps","title":"Next steps","text":"<ul> <li>Install PMM Client to start monitoring your database instances</li> <li>Consider migrating to Docker volumes for production environments</li> <li>Learn how to back up your PMM Server</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_vol.html","title":"Run PMM Server with Docker volumes (Recommended)","text":"<p>Docker volumes provide the recommended storage configuration for PMM Server in production environments. </p> <p>Volumes offer better isolation, portability, and compatibility with Docker\u2019s ecosystem compared to host directory storage.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_vol.html#installation-steps","title":"Installation steps","text":"<p>To deploy PMM Server using Docker volumes:</p> <ol> <li> <p>Pull the latest PMM Server image:</p> <pre><code>docker pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Create a dedicated Docker volume:</p> <pre><code>docker volume create pmm-data\n</code></pre> </li> <li> <p>Run PMM Server with the volume configured, making sure to replace <code>your_watchtower_token</code> with the token created during Watchtower setup: </p> <pre><code>docker run --detach --restart always \\\n--publish 443:8443 \\\n--env PMM_WATCHTOWER_HOST=http://your_watchtower_host:8080 \\\n--env PMM_WATCHTOWER_TOKEN=your_watchtower_token \\\n--volume pmm-data:/srv \\\n--network=pmm-network \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre> </li> <li> <p>Set a secure password for the default <code>admin</code> user, replacing <code>your_secure_password</code> with a strong, unique password:</p> <pre><code>docker exec -t pmm-server change-admin-password your_secure_password\n</code></pre> </li> <li> <p>Access the PMM web interface at <code>https://localhost</code> in a web browser.  If you are accessing the Docker host remotely, replace <code>localhost</code> with your server\u2019s IP address or hostname.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_vol.html#additional-configuration-options","title":"Additional configuration options","text":"<p>You can further customize your PMM Server deployment with:</p> <ul> <li> <p>Environment variables to configure metrics retention, resolution, and features: </p> <pre><code>docker run --detach --restart always \\\n    --publish 443:8443 \\\n    --env PMM_DATA_RETENTION=14d \\\n    --env PMM_METRICS_RESOLUTION=5s \\\n    --volume pmm-data:/srv \\\n    --name pmm-server \\\n    percona/pmm-server:3\n</code></pre> </li> <li> <p>Port mapping to expose PMM Server on a different port:</p> <pre><code>docker run ... --publish 8443:8443 ... percona/pmm-server:3\n</code></pre> </li> </ul> <p>For a complete list of configuration options, see the full list of environment variables.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/run_with_vol.html#next-steps","title":"Next steps","text":"<ul> <li>Install PMM Client to start monitoring your database instances</li> <li>Set up backups to protect your monitoring data</li> <li>Configure SSL certificates for secure communications</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html","title":"Upgrade PMM Server Docker container","text":"<p>Upgrade your PMM Server Docker container to the latest version, ensuring you benefit from new features, improvements, and bug fixes while preserving your monitoring data and configuration.</p> <p>Important</p> <p>Downgrades are not possible. To go back to using a previous version you must have created a backup of it before upgrading.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html#prerequisite-check-current-version","title":"Prerequisite: check current version","text":"<p>Before you start upgrading, check current PMM Server version:</p> Via command lineVia web UI <pre><code>docker exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> <p>For remote access, replace <code>localhost</code> with your PMM Server\u2019s address.</p> <p>Use the PMM Upgrade panel on the Home Dashboard to check for available updates.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html#upgrade-procedure","title":"Upgrade procedure","text":"<p>To upgrade the container:</p> <ol> <li> <p>Stop the current PMM Server container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Create a backup of your current installation:</p> </li> <li> <p>Pull the latest PMM Server image:</p> <pre><code>docker pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Rename the original container to keep it as a fallback: </p> <pre><code>docker rename pmm-server pmm-server-old\n</code></pre> </li> <li> <p>Run a new container with the latest image, connecting to your existing data. Make sure to adjust the volume parameter based on your setup (using <code>--volumes-from</code> for container data, <code>--volume pmm-data:/srv</code> for Docker volumes, or <code>--volume /path/on/host:/srv</code> for host directories):</p> <pre><code>docker run \\\n--detach \\\n--restart always \\\n--publish 443:8443 \\\n--volumes-from pmm-data \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre> </li> <li> <p>Verify the upgrade was successful:     <pre><code>docker exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre></p> </li> <li> <p>Access the PMM web interface and confirm your dashboards and monitoring are working correctly.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues after upgrading:</p> <ol> <li>Check the PMM Server logs:     <pre><code>docker logs pmm-server\n</code></pre></li> <li>If the upgrade fails, revert to your previous version:    <pre><code># Stop and remove the problematic container\ndocker stop pmm-server\ndocker rm pmm-server\n\n# Restore the backup\ndocker rename pmm-server-backup pmm-server\ndocker start pmm-server\n</code></pre></li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html#automated-upgrades-with-watchtower","title":"Automated upgrades with Watchtower","text":"<p>If you installed PMM Server with Watchtower, you can upgrade directly from the PMM UI. This method handles the entire upgrade process automatically, including pulling the new image and restarting the container.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/docker/upgrade_container.html#related-topics","title":"Related topics","text":"<ul> <li>Create a backup before upgrading</li> <li>Restore from backup if needed</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html","title":"Install PMM Server with Helm on Kubernetes clusters","text":"<p>Deploy PMM Server on Kubernetes using Helm for scalable, orchestrated monitoring in containerized environments.</p> <p>Helm is the package manager for Kubernetes. You can find Percona Helm charts in our GitHub repository. </p>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Helm v3</li> <li>Kubernetes cluster running a supported version and Supported Helm versions</li> <li>Storage driver with snapshot support (for backups)</li> <li><code>kubectl</code> configured to communicate with your cluster</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#storage-requirements","title":"Storage requirements","text":"<p>Different Kubernetes platforms offer varying capabilities: </p> <ul> <li>for production use, ensure your platform provides storage drivers supporting snapshots for backups</li> <li>for cloud environments, verify your provider\u2019s Kubernetes storage options and costs</li> <li>for on-premises deployments, confirm your storage solution is compatible with dynamic provisioning</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#deployment-best-practices","title":"Deployment best practices","text":"<p>For optimal monitoring in production environments:</p> <ol> <li> <p>Separate PMM Server from monitored systems by either:</p> <ul> <li>using separate Kubernetes clusters for monitoring and databases</li> <li>configuring workload separation through node configurations, affinity rules, and label selectors</li> </ul> </li> <li> <p>Enable high availability to ensure continuous monitoring during node failures</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#install-pmm-server-on-your-kubernetes-cluster","title":"Install PMM Server on your Kubernetes cluster","text":"<p>Create the required Kubernetes secret and deploy PMM Server using Helm:</p> <ol> <li> <p>Create Kubernetes secret to set up <code>pmm-admin</code> password:     <pre><code>cat &lt;&lt;EOF | kubectl create -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: pmm-secret\n  labels:\n    app.kubernetes.io/name: pmm\ntype: Opaque\ndata:\n# base64 encoded password\n# encode some password: `echo -n \"admin\" | base64`\n  PMM_ADMIN_PASSWORD: YWRtaW4=\nEOF\n</code></pre></p> </li> <li> <p>Verify the secret was created and retrieve the password if needed:</p> <pre><code>kubectl get secret pmm-secret -o jsonpath='{.data.PMM_ADMIN_PASSWORD}' | base64 --decode\n</code></pre> </li> <li> <p>Add the Percona repository and check available PMM versions:</p> <pre><code>helm repo add percona [https://percona.github.io/percona-helm-charts/](https://percona.github.io/percona-helm-charts/)\nhelm repo update\n</code></pre> </li> <li> <p>Choose your PMM version by checking available chart versions:</p> <pre><code>helm search repo percona/pmm --versions\n</code></pre> Example output <pre><code>NAME        CHART VERSION   APP VERSION DESCRIPTION\npercona/pmm 1.4.3           3.1.0       A Helm chart for Percona Monitoring and Managem...\npercona/pmm 1.4.2           3.1.0       A Helm chart for Percona Monitoring and Managem...\npercona/pmm 1.4.1           3.0.0       A Helm chart for Percona Monitoring and Managem...\npercona/pmm 1.4.0           3.0.0       A Helm chart for Percona Monitoring and Managem...\npercona/pmm 1.3.21          2.44.0      A Helm chart for Percona Monitoring and Managem...\n</code></pre> </li> <li> <p>Deploy PMM Server with your chosen version and secret:</p> <pre><code># Choose a specific chart version from the list in previous step\nhelm install pmm \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\n--version 1.4.3 \\\npercona/pmm\n</code></pre> </li> <li> <p>Verify the deployment:     <pre><code>helm list\nkubectl get pods -l app.kubernetes.io/name=pmm\n</code></pre></p> </li> <li> <p>Access PMM Server:</p> <pre><code># If using ClusterIP (default)\nkubectl port-forward svc/pmm-service 443:443\n\n# If using NodePort\nkubectl get svc pmm-service -o jsonpath='{.spec.ports[0].nodePort}'\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#configure-pmm-server","title":"Configure PMM Server","text":""},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#view-available-parameters","title":"View available parameters","text":"<p>Check the list of available parameters in the PMM Helm chart documentation. You can also list the default parameters by either: </p> <ul> <li>check values.yaml file in our repository</li> <li>run the chart definition: <code>helm show values percona/pmm</code></li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#set-configuration-values","title":"Set configuration values","text":"<p>Configure PMM Server using either command-line arguments or a YAML file:</p> <ul> <li>using command-line arguments:      <pre><code>helm install pmm \\\n--set secret.create=false --set secret.name=pmm-secret \\\n--set service.type=\"NodePort\" \\\n    percona/pmm\n</code></pre></li> <li>using a .yaml configuration file:    <pre><code>helm show values percona/pmm &gt; values.yaml\n</code></pre></li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#change-credentials","title":"Change credentials","text":"<p>Helm cannot modify application credentials after deployment.  To change credentials after deployment, either:</p> <ul> <li>redeploy PMM Server with new persistent volumes</li> <li>use PMM\u2019s built-in administrative tools</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#pmm-environment-variables","title":"PMM environment variables","text":"<p>Add environment variables for advanced operations (like custom init scripts) using the <code>pmmEnv</code> property:</p> <pre><code>pmmEnv:\nPMM_ENABLE_UPDATES: \"1\"\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#ssl-certificates","title":"SSL certificates","text":"<p>PMM comes with self-signed SSL certificates, ensuring a secure connection between the Client and Server. However, since these certificates are not issued by a trusted authority, you may encounter a security warning when connecting to PMM.</p> <p>To enhance security, you have two options: </p> <ol> <li> <p>Configure custom certificates:</p> <pre><code>certs:\n  name: pmm-certs\n  files:\n    certificate.crt: &lt;content&gt;\n    certificate.key: &lt;content&gt;\n    ca-certs.pem: &lt;content&gt;\n    dhparam.pem: &lt;content&gt;\n</code></pre> </li> <li> <p>Use Ingress controller with TLS. See PMM network configuration for details.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/index.html#next-steps","title":"Next steps","text":"<ul> <li>Back up PMM Server Helm deployment</li> <li>Configure advanced Kubernetes settings</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html","title":"Back up PMM Server Helm deployment","text":"<p>Create backups of your PMM Server Kubernetes deployment to protect your monitoring data and configuration.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Running PMM Server deployed with Helm</li> <li>Storage class with snapshot support</li> <li>Appropriate permissions to create volume snapshots</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#understanding-kubernetes-storage-for-pmm-server","title":"Understanding Kubernetes storage for PMM Server","text":"<p>PMM Server Helm chart uses PersistentVolume and PersistentVolumeClaim to allocate storage in the Kubernetes cluster.</p> <p>Volumes could be pre-provisioned and dynamic. PMM chart supports both and exposes it through PMM storage configuration.</p> <p>Backups for the PMM Server currently support only storage layer backups and thus require:</p> <ul> <li>a StorageClass that supports volume snapshots</li> <li>a VolumeSnapshotClass configured for your environment</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#verify-snapshot-support","title":"Verify snapshot support","text":"<p>Before attempting a backup, verify that your cluster supports volume snapshots:</p> <pre><code># Check available storage classes\nkubectl get sc\n\n# Check available volume snapshot classes\nkubectl get volumesnapshotclass\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#storage-considerations","title":"Storage considerations","text":"<p>Volume snapshot support varies by platform:</p> <ul> <li>Cloud providers: May incur additional costs for snapshot storage</li> <li>On-premises: Requires storage drivers with snapshot capabilities</li> <li>Storage capacity: Ensure sufficient space for snapshots</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#create-a-pmm-server-backup","title":"Create a PMM Server backup","text":"<p>To create a backup of your PMM Server:</p> <ol> <li> <p>Identify the current PMM version (for restoration purposes):</p> <pre><code>kubectl get deployment pmm -o jsonpath='{.spec.template.spec.containers[0].image}' | cut -d: -f2\n</code></pre> </li> <li> <p>Scale down PMM Server to ensure data consistency:</p> <pre><code>kubectl scale statefulset pmm --replicas=0\nkubectl wait --for=jsonpath='{.status.replicas}'=0 statefulset pmm\n</code></pre> Expected output <pre><code>statefulset.apps/pmm scaled\nstatefulset.apps/pmm condition met\n</code></pre> </li> <li> <p>Create a volume snapshot:</p> <pre><code>cat &lt;&lt;EOF | kubectl create -f -\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: before-v2.34.0-upgrade\n  labels:\n    app.kubernetes.io/name: pmm\nspec:\n  volumeSnapshotClassName: csi-hostpath-snapclass\n  source:\n    persistentVolumeClaimName: pmm-storage-pmm-0\nEOF\n</code></pre> Expected output <pre><code>volumesnapshot.snapshot.storage.k8s.io/pmm-backup-20230615 created\n</code></pre> </li> <li> <p>Wait for the snapshot to complete:</p> <pre><code>kubectl wait --for=jsonpath='{.status.readyToUse}'=true VolumeSnapshot/before-v2.34.0-upgrade\nkubectl scale statefulset pmm --replicas=1\n</code></pre> Expected output <pre><code>volumesnapshot.snapshot.storage.k8s.io/pmm-backup-20230615 condition met\n</code></pre> </li> <li> <p>Restart PMM Server:</p> <pre><code>kubectl scale statefulset pmm --replicas=1\n</code></pre> </li> <li> <p>Verify that PMM Server is running again:</p> <pre><code>kubectl get pods -l app.kubernetes.io/name=pmm\n</code></pre> <p>PMM scale</p> <p>Only one replica set is currently supported for PMM Server on Kubernetes.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#list-available-backups","title":"List available backups","text":"<p>To view your available PMM Server backups:</p> <pre><code>kubectl get volumesnapshot -l app.kubernetes.io/name=pmm\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#backup-rotation","title":"Backup rotation","text":"<p>For production environments, implement a backup rotation policy:</p> <pre><code># List backups older than 30 days\nOLD_BACKUPS=$(kubectl get volumesnapshot -l app.kubernetes.io/name=pmm -o jsonpath='{range .items[?(@.metadata.creationTimestamp &lt; \"'$(date -d \"30 days ago\" -Iseconds)'\")]}{.metadata.name}{\"\\n\"}{end}')\n\n# Delete old backups\nfor backup in $OLD_BACKUPS; do\n  kubectl delete volumesnapshot $backup\ndone\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/backup_container_helm.html#next-steps","title":"Next steps","text":"<ul> <li>Restore PMM Server from backup</li> <li>Upgrade PMM Server on Kubernetes</li> <li>Configure advanced storage options</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html","title":"Restore Helm chart","text":"<p>Recover your PMM Server installation from a previously created volume snapshot.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html#prerequisites","title":"Prerequisites","text":"<ul> <li>An existing volume snapshot backup of PMM Server</li> <li>Access to the Kubernetes cluster where the backup was created</li> <li>Helm v3 installed and configured</li> <li>Knowledge of the PMM version used in the backup</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html#preparing-for-restoration","title":"Preparing for restoration","text":"<p>Before restoring, gather the necessary information:</p> <ol> <li> <p>List available snapshots to identify the one for restoration:    <pre><code>kubectl get volumesnapshot -l app.kubernetes.io/name=pmm\n</code></pre></p> </li> <li> <p>Note the snapshot name and creation date:   <pre><code>  NAME                   READYTOUSE   SOURCEPVC           SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS            SNAPSHOTCONTENT                                    CREATIONTIME   AGE\n  pmm-backup-20230615    true         pmm-storage-pmm-0                           10Gi          csi-hostpath-snapclass   snapcontent-c9a3d320-be77-49c9-85ff-8257e761f05d   3h36m          3h36m\n</code></pre></p> </li> <li> <p>Verify that the version of PMM Server you plan to restore is compatible with the snapshot (must be equal to or newer than the backup version)</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html#restore-pmm-server-from-snapshot","title":"Restore PMM Server from snapshot","text":"<p>To restore PMM Server from a snapshot:</p> <ol> <li>Remove the existing PMM Server deployment:     <pre><code>helm uninstall pmm\n</code></pre></li> <li>Wait for resources to be cleaned up:     <pre><code>kubectl wait --for=delete pod/pmm-0 --timeout=120s\n</code></pre></li> <li> <p>Restore PMM Server using the snapshot as a data source, replacing 3.1.0 with a PMM version that is equal to or newer than the version used in the backup:</p> <pre><code>helm install pmm \\\n--set image.tag=\"3.1.0\" \\\n--set storage.name=\"pmm-storage-old\" \\\n--set storage.dataSource.name=\"before-v3.1.0-upgrade\" \\\n--set storage.dataSource.kind=\"VolumeSnapshot\" \\\n--set storage.dataSource.apiGroup=\"snapshot.storage.k8s.io\" \\\n--set secret.create=false \\\n--set secret.name=pmm-secret \\\npercona/pmm\n</code></pre> </li> <li> <p>Verify the restoration:     <pre><code>kubectl get pods -l app.kubernetes.io/name=pmm\n</code></pre></p> </li> <li> <p>Check that PMM Server is running properly:     <pre><code>kubectl port-forward svc/pmm-service 443:443\n</code></pre></p> </li> <li>Access PMM Server at <code>https://localhost:443</code>. </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html#managing-persistent-volumes","title":"Managing persistent volumes","text":"<p>After restoration, you\u2019ll have multiple PVCs in your cluster:</p> <ol> <li> <p>List the persistent volume claims:</p> <pre><code>kubectl get pvc\n</code></pre> Expected output <pre><code>NAME                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\npmm-restored-pmm-0      Bound    pvc-70e5d2eb-570f-4087-9515-edf2f051666d   10Gi       RWO            csi-hostpath-sc   3s\npmm-storage-pmm-0       Bound    pvc-9dbd9160-e4c5-47a7-bd90-bff36fc1463e   10Gi       RWO            csi-hostpath-sc   89m\n</code></pre> </li> <li> <p>List the underlying persistent volumes:</p> <pre><code>kubectl get pv\n</code></pre> </li> <li> <p>Clean up old volumes when they\u2019re no longer needed:</p> <pre><code># Only delete these when you've confirmed the restoration is successful\nkubectl delete pvc pmm-storage-pmm-0\nkubectl delete pv &lt;corresponding-pv-name&gt;\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/helm/restore_container_helm.html#next-steps","title":"Next steps","text":"<ul> <li>Verify monitoring data in the restored PMM Server</li> <li>Configure backup schedule for your restored environment</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/index.html","title":"Install PMM Server with Podman","text":"<p>Run PMM Server with Podman based on our Docker image when you need enhanced security, rootless container execution, or are working in environments where Docker daemon is not preferred. Podman provides improved security isolation while maintaining compatibility with Docker commands and workflows.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/index.html#about-podman","title":"About Podman","text":"<p>Podman is an open-source, daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers and container images on Linux systems. It is widely supported across Linux distributions and hosted on GitHub.</p> <p>One of Podman\u2019s advantages is that it allows non-privileged users to run containers, enhancing security by avoiding elevated permissions. Podman is compatible with Docker; by using an alias (<code>alias docker=podman</code>), you can run Docker commands seamlessly with Podman. All instructions in the Docker section apply to Podman as well.</p> <p>Choose Podman deployment when:</p> <ul> <li>Security is a priority and you need rootless container execution</li> <li>Your organization has security policies restricting the use of Docker daemon</li> <li>You\u2019re running in environments where fine-grained permission control is required</li> <li>You need systemd integration for better service management</li> </ul> <p>Recommended setup for best performance</p> <p>Percona recommends running PMM with Podman as a non-privileged user and as part of the provided systemd service. Systemd helps ensure that the service is actively running and offers logging and management functions, such as start, stop, and restart.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/index.html#before-you-start","title":"Before you start","text":"<p>Before installing PMM Server with Podman, ensure you have:</p> <ol> <li>Install Podman.</li> <li>Configure rootless Podman.</li> <li>Create the Podman volume for PMM:   <pre><code>podman volume create pmm-data\n</code></pre></li> <li>Create the Podman network for PMM:   <pre><code>podman network create pmm_default\n</code></pre></li> <li>Set up required system configurations:     <pre><code># Allow non-root users to bind to privileged ports (required for port 443)        \n# Make the setting persistent\necho \"net.ipv4.ip_unprivileged_port_start=443\" | sudo tee /etc/sysctl.d/99-pmm.conf\nsudo sysctl -p /etc/sysctl.d/99-pmm.conf\n</code></pre></li> <li>Enable the Podman socket (required for Watchtower integration):     <pre><code>systemctl --user enable --now podman.socket\n</code></pre></li> <li> <p>Configure Watchtower (if using UI updates) with these security considerations:</p> <ul> <li>ensure Watchtower is only accessible from within the Podman network or local host to prevent unauthorized access and enhance container security.</li> <li>configure network settings to expose only the PMM Server container to the external network, keeping Watchtower isolated within the Podman network.</li> <li>grant Watchtower access to the Docker socket to monitor and manage containers effectively, ensuring proper security measures are in place to protect the Docker socket.</li> <li>verify that both Watchtower and PMM Server are on the same network, or ensure PMM Server can connect to Watchtower for communication. This network setup is essential for PMM Server to initiate updates through Watchtower.</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/index.html#update-mechanism","title":"Update mechanism","text":"<p>PMM Server updates work differently in Podman compared to Docker due to security policies:</p> <ul> <li>Docker updates: use a simpler flow where PMM Server directly instructs Watchtower to replace the Docker container in one step.</li> <li>Podman updates: require systemd integration and follow a multi-step process with environment file changes for better security isolation.</li> </ul> <p>When you initiate an update in the UI with Podman:</p> <ul> <li>PMM Server updates its image reference in the environment file</li> <li>Watchtower detects the change and pulls the new image</li> <li>Systemd handles container replacement automatically</li> </ul> Installation with UI updatesInstallation with manual updates <p>This method enables updates through the PMM web interface using Watchtower and systemd services. When you initiate an update in the UI, PMM Server updates its image reference, prompting Watchtower to pull the new image. </p> <p>Watchtower then stops the existing container, and systemd automatically restarts it with the updated image.</p> <ol> <li> <p>Create directories for configuration files if they don\u2019t exist:</p> <pre><code>mkdir -p ~/.config/systemd/user/\n</code></pre> </li> <li> <p>Create PMM Server service file at <code>~/.config/systemd/user/pmm-server.service</code>:</p> <pre><code>[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nEnvironmentFile=%h/.config/systemd/user/pmm-server.env\nEnvironment=PMM_VOLUME_NAME=pmm-data\nTimeoutStartSec=480\nRestart=on-failure\nRestartSec=20\nExecStart=/usr/bin/podman run \\\n    --volume %h/.config/systemd/user/:/home/pmm/update/ \\\n    --volume=${PMM_VOLUME_NAME}:/srv \\\n    --rm --replace=true --name %N \\\n    --env-file=%h/.config/systemd/user/pmm-server.env \\\n    --net pmm_default \\\n    --cap-add=net_admin,net_raw \\\n    --userns=keep-id:uid=1000,gid=1000 \\\n    -p 443:8443/tcp --ulimit=host ${PMM_IMAGE}\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Create the environment file at <code>~/.config/systemd/user/pmm-server.env</code>:</p> <pre><code>PMM_WATCHTOWER_HOST=http://watchtower:8080\nPMM_WATCHTOWER_TOKEN=your_token\nPMM_IMAGE=docker.io/percona/pmm-server:3\n</code></pre> </li> <li> <p>Create or update the Watchtower service file at <code>~/.config/systemd/user/watchtower.service</code>:</p> <pre><code>[Unit]\nDescription=watchtower\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nEnvironmentFile=%h/.config/systemd/user/watchtower.env\nRestart=on-failure\nRestartSec=20\nExecStart=/usr/bin/podman run --rm --replace=true --name %N \\\n    -v ${XDG_RUNTIME_DIR}/podman/podman.sock:/var/run/docker.sock \\\n    --env-file=%h/.config/systemd/user/watchtower.env \\\n    --net pmm_default \\\n    --security-opt label=type:container_runtime_t \\\n    --cap-add=net_admin,net_raw \\\n    ${WATCHTOWER_IMAGE}\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Create the environment file for Watchtower at <code>~/.config/systemd/user/watchtower.env</code>:</p> <pre><code>WATCHTOWER_HTTP_API_UPDATE=1\nWATCHTOWER_HTTP_API_TOKEN=your_token\nWATCHTOWER_NO_RESTART=1\nWATCHTOWER_IMAGE=docker.io/percona/watchtower:latest\n</code></pre> </li> <li> <p>Start the PMM Server and Watchtower services:</p> <pre><code>systemctl --user enable --now pmm-server\nsystemctl --user enable --now watchtower\n</code></pre> </li> <li> <p>Go to <code>https://localhost:443</code> to access the PMM user interface in a web browser. If you are accessing the host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p>The installation with manual updates offers a straightforward setup with direct control over updates, without relying on additional services. </p> <p>In this approach, you manually update the <code>PMM_IMAGE</code> in the environment file and restart the PMM Server service. Systemd then automatically manages the container replacement.</p> <ol> <li> <p>Create directories for configuration files if they don\u2019t exist:</p> <pre><code>mkdir -p ~/.config/systemd/user/\n</code></pre> </li> <li> <p>Create PMM Server service file at <code>~/.config/systemd/user/pmm-server.service</code>:</p> <pre><code>[Unit]\nDescription=pmm-server\nWants=network-online.target\nAfter=network-online.target\nAfter=nss-user-lookup.target nss-lookup.target\nAfter=time-sync.target\n[Service]\nEnvironmentFile=%h/.config/systemd/user/pmm-server.env\nEnvironment=PMM_VOLUME_NAME=pmm-data\nTimeoutStartSec=480\nRestart=on-failure\nRestartSec=20\nExecStart=/usr/bin/podman run \\\n    --volume=${PMM_VOLUME_NAME}:/srv \\\n    --rm --replace=true --name %N \\\n    --env-file=%h/.config/systemd/user/pmm-server.env \\\n    --net pmm_default \\\n    --cap-add=net_admin,net_raw \\\n    --userns=keep-id:uid=1000,gid=1000 \\\n    -p 443:8443/tcp --ulimit=host ${PMM_IMAGE}\nExecStop=/usr/bin/podman stop -t 10 %N\n[Install]\nWantedBy=default.target\n</code></pre> </li> <li> <p>Create the environment file at <code>~/.config/systemd/user/pmm-server.env</code>:</p> <pre><code>PMM_IMAGE=docker.io/percona/pmm-server:3\n</code></pre> </li> <li> <p>Enable and start the PMM Server service:</p> <pre><code>systemctl --user enable --now pmm-server\n</code></pre> </li> <li> <p>Go to <code>https://localhost:443</code> to access the PMM user interface in a web browser. If you are accessing the host remotely, replace <code>localhost</code> with the IP or server name of the host.</p> </li> </ol> <p>For information on manually upgrading, see Upgrade PMM Server using Podman.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/index.html#related-topics","title":"Related topics","text":"<ul> <li>Docker installation alternative </li> <li>Available image tags</li> <li>Upgrade PMM Server using Podman </li> <li>Back up PMM Server Podman container </li> <li>Restore PMM Server Podman container</li> <li>Remove PMM Server Podman container </li> <li>Install PMM Client </li> </ul> <pre><code># first pull can take time\nsleep 80\ntimeout 60 podman wait --condition=running pmm-server\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/backup_container_podman.html","title":"Back up PMM Server Podman container","text":"<p>Create a backup of your PMM Server data to protect against data loss, prepare for upgrades, or migrate to another system.</p> Summary <ul> <li>Stop the PMM Server service</li> <li>Export the data volume to a backup file</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/backup_container_podman.html#backing-up-grafana-plugins","title":"Backing up Grafana plugins","text":"<p>Grafana plugins have been moved to the <code>/srv</code> directory since PMM 2.23.0. So if you are upgrading PMM from a version before 2.23.0 and have installed additional plugins, you\u2019ll need to reinstall them after the upgrade.</p> <p>To check used Grafana plugins: <pre><code>podman exec -t pmm-server ls -l /var/lib/grafana/plugins\n</code></pre></p>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/backup_container_podman.html#back-up-procedure","title":"Back up procedure","text":"<p>To back up your PMM Server container:</p> <ol> <li> <p>Stop the PMM Server service:</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Wait for the container to fully stop:</p> <pre><code>podman wait --condition=stopped pmm-server || true\nsleep 30\n</code></pre> </li> <li> <p>Export the data volume to a backup file. If you changed the default name in the <code>PMM_VOLUME_NAME</code> environment variable, use that name after export instead of <code>pmm-server</code> (which is the default volume name):</p> <pre><code>podman volume export pmm-server --output pmm-server-backup.tar\n</code></pre> </li> <li> <p>Verify the backup file was created successfully:     <pre><code>ls -lh pmm-server-backup.tar\n</code></pre></p> </li> <li> <p>Store the backup in a secure location, preferably outside the current server.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/backup_container_podman.html#backup-storage-recommendations","title":"Backup storage recommendations","text":"<ul> <li>Store backups in a location separate from the PMM Server host</li> <li>Implement automated rotation of backups to manage disk space</li> <li>Consider encrypting backups containing sensitive monitoring data</li> <li>Test restores periodically to verify backup integrity</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/backup_container_podman.html#related-topics","title":"Related topics","text":"<ul> <li>Restore PMM Server Podman container </li> <li>Remove PMM Server Podman container </li> <li>Install PMM Server with Podman </li> <li>Upgrade PMM Server using Podman</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/remove_container_podman.html","title":"Remove PMM Server Podman container","text":"<p>Remove the PMM Server Podman container, images, and data when you no longer need this installation or want to perform a complete reinstallation.</p> <p>Data loss warning</p> <p>These steps delete the PMM Server Docker image and the associated PMM metrics data.</p> <p>To completely remove your container and data:</p> <ol> <li> <p>Stop the PMM Server service:</p> <pre><code>systemctl --user stop pmm-server\n\n# Wait for container to stop completely\npodman wait --condition=stopped pmm-server || true\nsleep 10\n</code></pre> </li> <li> <p>If you\u2019re using Watchtower for UI upgrades, stop it too:</p> <pre><code>systemctl --user stop watchtower\n</code></pre> </li> <li> <p>Remove the PMM data volume:</p> <pre><code>podman volume rm --force pmm-server\n</code></pre> </li> <li> <p>Remove the PMM Server images:</p> <pre><code>podman rmi $(podman images | grep \"pmm-server\" | awk {'print $3'})\n</code></pre> </li> <li> <p>Disable the SystemD services:     <pre><code>systemctl --user disable pmm-server\nsystemctl --user disable watchtower\n</code></pre></p> </li> <li> <p>Optionally, remove service files:     <pre><code>rm -f %h/.config/systemd/user/pmm-server.service\nrm -f %h/.config/systemd/user/pmm-server.env\nrm -f %h/.config/systemd/user/watchtower.service\nrm -f %h/.config/systemd/user/watchtower.env\n</code></pre></p> </li> <li> <p>If you no longer need it, remove the PMM network:     <pre><code>podman network rm pmm_default\n</code></pre></p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/remove_container_podman.html#related-topics","title":"Related topics","text":"<ul> <li>Install PMM Server with Podman</li> <li>Back up PMM Server Podman container </li> <li>Restore PMM Server Podman container </li> <li>Install PMM Client </li> <li>Uninstall PMM Client</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/restore_container_podman.html","title":"Restore PMM Server Podman container","text":"<p>Restore your PMM Server from a backup when you need to recover from an upgrade issue or data corruption, or when migrating to a different system.</p> Summary <ul> <li>Stop the PMM Server service</li> <li>Update the PMM Server image reference to the backed-up version</li> <li>Import the backed-up data volume</li> <li>Start the PMM Server service</li> </ul> <p>Important</p> <p>You must have a backup to restore from. Restoration is only necessary if you experience issues with an upgrade or with your monitoring data.</p> <p>To restore your PMM Server container:</p> <ol> <li> <p>Stop PMM Server:</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Run PMM on the previous image, replacing <code>x.yy.z</code> with the specific version you were using when you created the backup. Using the same version ensures compatibility with your backup data.</p> <pre><code>sed -i \"s|PMM_IMAGE=.*|PMM_IMAGE=docker.io/percona/pmm-server:x.yy.z|g\" %h/.config/systemd/user/pmm-server.env\n</code></pre> </li> <li> <p>Restore the volume:</p> <pre><code>podman volume import pmm-server pmm-server-backup.tar\n</code></pre> </li> <li> <p>Start PMM Server:</p> <pre><code>systemctl --user start pmm-server\n</code></pre> </li> </ol>  sleep 30 timeout 60 podman wait --condition=running pmm-server ```"},{"location":"install-pmm/install-pmm-server/deployment-options/podman/restore_container_podman.html#related-topics","title":"Related topics","text":"<ul> <li>Back up PMM Server Podman container </li> <li>Remove PMM Server Podman container </li> <li>Install PMM Server with Podman </li> <li>Upgrade PMM Server using Podman</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html","title":"Deploy PMM Server as a Virtual Appliance (OVA)","text":"<p>Deploy PMM Server as a pre-configured virtual machine when you need a standalone monitoring solution with minimal setup. The virtual appliance is ideal for environments where container solutions aren\u2019t preferred or for evaluation purposes.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#when-to-choose-ova-deployment","title":"When to choose OVA deployment","text":"<ul> <li>You prefer traditional VM-based deployments over containers</li> <li>You need a solution that works with existing virtualization infrastructure</li> <li>You want minimal configuration steps for quick evaluation</li> <li>Your environment has limited or no internet connectivity</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#terminology","title":"Terminology","text":"<p>When working with the PMM Server virtual appliance, it\u2019s helpful to understand these terms:</p> <ul> <li>Host: The desktop or server machine running the hypervisor</li> <li>Hypervisor: Software (e.g., VirtualBox, VMware) that runs the guest OS as a virtual machine</li> <li>Guest VM: Virtual machine running PMM Server (Oracle Linux 9.3)</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#ova-file-details","title":"OVA file details","text":"Item Value Download page https://www.percona.com/downloads/pmm/3.3.1/ova File name <code>pmm-server-3.3.1.ova</code> VM name <code>pmm-Server-2025-07-30-N</code> (<code>N</code>=build number)"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#vm-specifications","title":"VM specifications","text":"<p>The PMM Server virtual appliance comes pre-configured with these specifications:</p> Component Value OS Oracle Linux 9.3 CPU 1 Base memory 4096 MB Disks LVM, 2 physical volumes Disk 1 (<code>sda</code>) VMDK (SCSI, 40 GB) Disk 2 (<code>sdb</code>) VMDK (SCSI, 400 GB) <p>Note</p> <p>You can adjust CPU and memory resources after deployment to match your monitoring needs.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#system-requirements","title":"System requirements","text":"<p>For optimal performance, we recommend:</p> Minimum (1-30 nodes)Recommended (31-100 nodes)Large (100+ nodes) <ul> <li>CPU: 4 cores</li> <li>Memory: 8 GB</li> <li>Disk: 100 GB</li> </ul> <ul> <li>CPU: 8 cores</li> <li>Memory: 16 GB</li> <li>Disk: 200 GB</li> </ul> <ul> <li>CPU: 16+ cores</li> <li>Memory: 32+ GB</li> <li>Disk: 500+ GB</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#hypervisor-compatibility","title":"Hypervisor compatibility","text":"<p>The PMM Server OVA is compatible with:</p> <ul> <li>VMware ESXi 6.0 and later</li> <li>VMware Workstation 12.0 and later</li> <li>VMware Fusion 10.0 and later</li> <li>VirtualBox 6.0 and later</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#network-requirements","title":"Network requirements","text":"<p>Ensure your network environment allows:</p> <ul> <li>Outbound internet access for updates (optional)</li> <li>Access to monitored database instances</li> <li>Access from client browsers to the PMM Server web interface</li> <li>Standard ports: 443 (HTTPS), 80 (HTTP, redirects to HTTPS)</li> </ul> <p>See Network and firewall requirements for full details.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#default-users","title":"Default users","text":"<p>PMM Server comes with two pre-configured user accounts that you must secure immediately after installation:</p> <ul> <li>admin (default password: <code>admin</code>)</li> <li>root (default password: <code>percona</code>)</li> </ul> <p>Change these default passwords to strong, unique passwords during your first login to prevent unauthorized access.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/index.html#next-steps","title":"Next steps","text":"<p>After reviewing the requirements:</p> <ul> <li>Download the PMM Server OVA file</li> <li>Deploy on VMware</li> <li>Deploy on VirtualBox</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/download_ova.html","title":"Download and verify OVA file","text":"<p>Download the Virtual Appliance (OVA) file to deploy PMM Server as a virtual machine.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/download_ova.html#supported-platforms","title":"Supported platforms","text":"<p>The PMM Server OVA works with:</p> <ul> <li>VMware products (ESXi, Workstation, Fusion)</li> <li>Oracle VirtualBox</li> <li>Other OVF-compatible virtualization platforms</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/download_ova.html#download-options","title":"Download options","text":"Download from the UIDownload with CLI <p>To download an OVA file from the UI:</p> <ol> <li>Visit the Percona Downloads page from a web browser.</li> <li>Make sure PMM 3 is selected, then choose a PMM version and select SERVER - VIRTUAL APPLIANCE OVF.</li> <li>Click the DOWNLOAD link for <code>pmm-server-3.3.1.ova</code> and note where your browser saves it.</li> <li>Right-click the link for <code>pmm-server-3.3.1.sha256sum</code> and save it in the same place as the <code>.ova</code> file.</li> </ol> <p>Download the latest PMM Server OVA and checksum files:</p> <pre><code># Download the OVA file (replace X.Y.Z with the desired version)\nwget https://downloads.percona.com/downloads/pmm/X.Y.Z/ova/PMM-Server-X.Y.Z.ova\n\n# Download the checksum file\nwget https://downloads.percona.com/downloads/pmm/X.Y.Z/ova/PMM-Server-X.Y.Z.ova.sha256sum\n</code></pre>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/download_ova.html#verify-ova-integrity","title":"Verify OVA integrity","text":"<p>After downloading, verify the file integrity to ensure it hasn\u2019t been corrupted:</p> <pre><code># Navigate to the download location\ncd /path/to/download\n\n# Verify the checksum\nsha256sum -c PMM-Server-X.Y.Z.ova.sha256sum\n</code></pre> <p>You should see output confirming the file is OK: <code>PMM-Server-X.Y.Z.ova: OK</code></p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/download_ova.html#next-steps","title":"Next steps","text":"<p>After downloading the OVA file, proceed to deployment:</p> <ul> <li>Deploy on VMware</li> <li>Deploy on VirtualBox</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/login_UI.html","title":"Access the PMM Server Virtual Appliance web interface","text":"<p>After deploying your PMM Server as a virtual appliance (OVA), access its web interface to set up administrator credentials, verify connectivity, and prepare your monitoring environment.</p> <p>To log in to the PMM user interface:</p> <ol> <li> <p>Open a web browser and visit the guest IP address. Your browser may display a security warning about an untrusted certificate. This is expected with the default self-signed certificate. You can safely proceed to the website.</p> </li> <li> <p>The PMM login screen appears.</p> </li> <li> <p>On the login screen, enter the default credentials: <code>admin</code>/<code>admin</code>.</p> </li> <li> <p>(Recommended) Follow the prompts to change the default password. You also can change the default password through SSH by using the <code>change-admin-password</code> command.</p> </li> <li> <p>The PMM Home Dashboard appears.</p> </li> </ol> (Optional) Change root password from UI <p>You can change the root password directly from the user interface:</p> <ol> <li> <p>Start the virtual machine in GUI mode.</p> </li> <li> <p>Log in with the default superuser credentials: <code>root</code>/<code>percona</code></p> </li> <li> <p>Follow on-screen prompts to change the password.</p> </li> </ol> (Optional) Set up SSH from UI/CLI <p>To set up SSH from UI/CLI:</p> <ol> <li> <p>Create a key pair for the <code>admin</code> user:</p> <pre><code>ssh-keygen -f admin\n</code></pre> </li> <li> <p>Log into the PMM user interface.</p> </li> <li> <p>Select PMM Configuration &gt; Settings &gt; SSH Key.</p> </li> <li> <p>Copy and paste the contents of the <code>admin.pub</code> file into the SSH Key field.</p> </li> <li> <p>Click Apply SSH Key. This copies the public key to <code>/home/admin/.ssh/authorized_keys</code> in the guest.</p> </li> <li> <p>Log in via SSH (<code>N.N.N.N</code> is the guest IP address).</p> <pre><code>ssh -i admin admin@N.N.N.N\n</code></pre> </li> </ol> (Optional) Set up static IP via CLI <p>When the guest OS starts, it will get an IP address from the hypervisor\u2019s DHCP server. This IP can change each time the guest OS is restarted. Setting a static IP for the guest OS avoids having to check the IP address whenever the guest is restarted.</p> <ol> <li> <p>Start the virtual machine in non-headless (GUI) mode.</p> </li> <li> <p>Log in as <code>root</code>.</p> </li> <li> <p>Edit <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code></p> </li> <li> <p>Change the value of <code>BOOTPROTO</code>:</p> <pre><code>BOOTPROTO=none\n</code></pre> </li> <li> <p>Add these values:</p> <pre><code>IPADDR=192.168.1.123 # replace with the desired static IP address\nNETMASK=255.255.255.0 # replace with the netmask for your IP address\nGATEWAY=192.168.1.1 # replace with the network gateway for your IP address\nPEERDNS=no\nDNS1=192.168.1.53 # replace with your DNS server IP\n</code></pre> </li> <li> <p>Restart the interface:</p> <pre><code>ifdown eth0 &amp;&amp; ifup eth0\n</code></pre> </li> <li> <p>Check the IP:</p> <pre><code>ip addr show eth0\n</code></pre> </li> <li> <p>Preserve the network configuration across reboots:</p> <pre><code>echo \"network: {config: disabled}\" &gt; /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/login_UI.html#next-steps","title":"Next steps","text":"<p>After the initial login:</p> <ul> <li>Set up trusted SSL certificates (recommended for production)</li> <li>Install PMM Clients on database servers</li> <li>Connect databases for monitoring</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/remove_virtual_machine.html","title":"Remove PMM Server Virtual Appliance","text":"<p>When you no longer need your PMM Server virtual appliance or want to perform a clean reinstallation, follow these steps to completely remove the virtual machine.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/remove_virtual_machine.html#remove-virtual-machine-from-vmware","title":"Remove virtual machine from VMware","text":"<p>To remove a PMM Server virtual machine from VMware:</p> <ol> <li>Select the PMM Server VM in your inventory and select Close &gt; Power Off.</li> <li>With the VM selected, choose Remove &gt; Delete all files and confirm the deletion when prompted.</li> </ol> <p>Data loss warning</p> <p>This action permanently deletes all monitoring data, dashboards, and configurations. If you need to preserve your PMM data, create a backup before removing the virtual machine.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/remove_virtual_machine.html#remove-virtual-machine-from-virtualbox","title":"Remove virtual machine from VirtualBox","text":"<p>To remove a PMM Server virtual machine from VirtualBox:</p> <ol> <li>Select the PMM Server VM in the VirtualBox Manager and right-click and select Close &gt; Power Off. </li> <li>Right-click on the powered-off VM and select Remove .</li> <li>Choose Delete all files to remove the VM and its disk images, then click Remove to confirm.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/remove_virtual_machine.html#verify-removal","title":"Verify removal","text":"<p>After removing the virtual machine, verify that all associated files have been deleted:</p> <ol> <li>Check that the VM no longer appears in your virtualization software\u2019s inventory. </li> <li>Verify that disk space has been reclaimed on your host system.</li> <li>If you used custom storage locations, check those locations for any remaining files.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/remove_virtual_machine.html#next-steps","title":"Next steps","text":"<p>After removing the virtual machine, you can:</p> <ul> <li>Download the latest PMM Server OVA to install a newer version</li> <li>Deploy PMM Server using an alternative method, such as Docker or Kubernetes</li> <li>Set up a new PMM Server virtual appliance with a fresh configuration</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html","title":"Deploy PMM Server on VirtualBox","text":"<p>Import the PMM Server OVA file into Oracle VirtualBox to create a virtual machine for your monitoring environment.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Downloaded PMM Server OVA file</li> <li>Oracle VirtualBox 6.0 or later installed</li> <li>At least 8GB of free RAM and 100GB of free disk space</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#import-ova-file","title":"Import OVA file","text":"Using VirtualBox UIUsing VBoxManage CLI <p>To import the OVA file using the VirtualBox user interface:</p> <ol> <li>Open Oracle VirtualBox.</li> <li>Go to File &gt; Import Appliance.</li> <li>Click on the folder icon and browse to select the downloaded PMM Server OVA file, then click Next.</li> <li>Review the appliance settings:<ul> <li>You can customize the name of the VM</li> <li>Adjust CPU and memory settings if needed</li> <li>Review network settings</li> </ul> </li> <li>Click Import.</li> <li>Wait for the import process to complete (this may take several minutes).</li> </ol> <p>To import the OVA file using the command-line interface:</p> <ol> <li>Open a terminal or command prompt.</li> <li> <p>Use the VBoxManage command to import the OVA:</p> <pre><code>VBoxManage import pmm-server-3.3.1.ova --vsys 0 --vmname \"PMM Server\"\n</code></pre> </li> <li> <p>To customize VM settings during import (optional):</p> <pre><code>VBoxManage import pmm-server-3.3.1.ova --vsys 0 --vmname \"PMM Server\" \\\n  --cpus 4 --memory 8192 --unit 9 --disk pmm-data.vmdk\n</code></pre> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#configure-network-settings","title":"Configure network settings","text":"<p>For the VM to be accessible on your network, configure the network settings appropriately.</p> Using VirtualBox UIUsing VBoxManage CLI <p>To configure network settings using the VirtualBox UI:</p> <ol> <li>Select the imported PMM Server VM.</li> <li>Go to Settings &gt; Network.</li> <li>Ensure Adapter 1 is enabled and attached to:<ul> <li>Bridged Adapter for direct network access (recommended)</li> <li>NAT if you prefer to use port forwarding</li> </ul> </li> <li>If using Bridged Adapter, select the physical network interface to bridge to.</li> <li>Click OK.</li> </ol> <p>To configure network settings using the command line:</p> <ol> <li> <p>For bridged networking (recommended for production):</p> <p><pre><code>VBoxManage modifyvm \"PMM Server\" --nic1 bridged --bridgeadapter1 eth0\n</code></pre> Replace <code>eth0</code> with your actual network interface name.</p> </li> <li> <p>For NAT networking (easier for testing):</p> <pre><code>VBoxManage modifyvm \"PMM Server\" --nic1 nat\n</code></pre> </li> <li> <p>To set up port forwarding with NAT (optional):</p> <p><pre><code>VBoxManage modifyvm \"PMM Server\" --nic1 nat\nVBoxManage modifyvm \"PMM Server\" --natpf1 \"https,tcp,,8443,,443\"\nVBoxManage modifyvm \"PMM Server\" --natpf1 \"http,tcp,,8080,,80\"\n</code></pre> This forwards host ports 8443 and 8080 to guest ports 443 and 80.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#start-the-vm-and-obtain-ip-address","title":"Start the VM and obtain IP address","text":"Using VirtualBox UIUsing VBoxManage CLI <p>To start the VM and get its IP address using the UI:</p> <ol> <li>Select the PMM Server VM in the VirtualBox Manager.</li> <li>Click Start.</li> <li>A console window will open showing the boot process.</li> <li>Wait for the boot process to complete (2-5 minutes).</li> <li>The console will display the IP address once booting is complete.</li> </ol> <p>To start the VM and get its IP address using the command line:</p> <ol> <li> <p>Start the VM in headless mode (no UI):</p> <pre><code>VBoxManage startvm \"PMM Server\" --type headless\n</code></pre> </li> <li> <p>Wait for the VM to fully boot (approximately 2-5 minutes).</p> </li> <li> <p>Get the VM\u2019s IP address (for bridged networking):</p> <pre><code>VBoxManage guestproperty get \"PMM Server\" \"/VirtualBox/GuestInfo/Net/0/V4/IP\"\n</code></pre> </li> <li> <p>If the above command doesn\u2019t show the IP address, you can check the VM\u2019s console:</p> <p><pre><code>VBoxManage startvm \"PMM Server\" --type separate\n</code></pre> This opens just the console window.</p> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#troubleshooting-network-issues","title":"Troubleshooting network issues","text":"<p>If you cannot connect to the VM:</p> <ul> <li>For bridged networking, ensure your host\u2019s firewall allows traffic to the VM</li> <li>For NAT with port forwarding, connect to your host\u2019s IP address with the forwarded port (e.g., <code>https://localhost:8443</code>)</li> <li>Verify VirtualBox network settings are correctly configured</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/virtualbox.html#next-steps","title":"Next steps","text":"<p>After successfully importing and starting the PMM Server VM:</p> <ul> <li>Open a web browser and navigate to <code>https://&lt;vm-ip-address&gt;</code></li> <li>Complete initial login and setup</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html","title":"Deploy PMM Server on VMware","text":"<p>Import the PMM Server OVA file into VMware products including ESXi, vSphere, Workstation, and Fusion to create a virtual machine for your monitoring environment.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Downloaded PMM Server OVA file</li> <li>VMware product installed (Workstation, Fusion, ESXi, or vSphere)</li> <li>At least 8GB of free RAM and 100GB of free disk space</li> <li>Network connectivity to monitored database instances</li> </ul>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#import-ova-file","title":"Import OVA file","text":"OVA file downloaded via CLIOVA file downloaded using WMware UI <p>To import downloaded file using the command-line interface:</p> <ol> <li>Install <code>ovftool</code>. (You need to register.)</li> <li> <p>Import and convert the OVA file using one of these methods:</p> <ul> <li> <p>To download and import the OVA file directly:</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=Wi-Fi \\\nhttps://www.percona.com/downloads/pmm/3.3.1/ova/pmm-server-3.3.1.ova \\\npmm-server-3.3.1.vmx\n</code></pre> </li> <li> <p>To import a previously downloaded OVA file, replacing <code>Wi-Fi</code> with your actual network interface name. You can list available network interfaces with <code>ovftool --listNetworks</code>:</p> <pre><code>ovftool --name=\"PMM Server\" --net:NAT=Wi-Fi \\\npmm-server-3.3.1.ova \\\npmm-server.vmx\n</code></pre> </li> </ul> </li> </ol> <p>To import the OVA file using the VMware user interface:</p> <ol> <li>Select File &gt; Import.</li> <li>Click Choose file (wording may vary depending on VMware product).</li> <li>Navigate to the downloaded <code>.ova</code> file and open it.</li> <li> <p>In the Save as dialog:</p> <ul> <li>(Optional) Change the directory or virtual machine name.</li> <li>Click Save.</li> </ul> </li> <li> <p>Choose one of:</p> <ul> <li>Click Finish to complete the import and start the virtual machine.</li> <li>(Recommended) Click Customize Settings to open the VM\u2019s settings page before starting the machine.</li> </ul> </li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#configure-network-settings","title":"Configure network settings","text":"<p>For PMM Server to be accessible, it must have proper network configuration. Bridged networking is recommended for production environments.</p> <p>When using the command line, the interface is remapped during import.</p>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#configure-networking-with-ui","title":"Configure networking with UI","text":"<p>To configure VM network settings using the UI:</p> <ol> <li>If the VM is running, shut it down first.</li> <li>In the VMware main window, select the imported virtual machine.</li> <li>Click Virtual Machine \u2192 Settings.</li> <li>Click Network Adapter in the hardware list.</li> <li>Select the appropriate networking mode:<ul> <li>Bridged Networking: Recommended for production (direct network access)</li> <li>NAT: For testing environments</li> </ul> </li> <li>If using bridged networking, select Autodetect or choose a specific network adapter.</li> <li>Click OK to save changes.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#start-the-vm-and-obtain-ip-address","title":"Start the VM and obtain IP address","text":"Via command lineVia UI <p>To start the VM and get its IP address using the command line:</p> <ol> <li> <p>Start the virtual machine in GUI mode to view the console:</p> <pre><code>vmrun -gu root -gp percona start \\\npmm-server.vmx gui\n</code></pre> </li> <li> <p>Wait for the boot process to complete and note the IP address displayed in the VM console.</p> </li> <li> <p>Optional: After noting the IP address, you can stop and restart the VM in headless mode:</p> <p><pre><code>vmrun stop pmm-server.vmx\n</code></pre> <pre><code>vmrun -gu root -gp percona start \\\npmm-server.vmx nogui\n</code></pre></p> </li> </ol> <p>To start the VM and find its IP address using the VMware UI:</p> <ol> <li>In the VMware main window, select the imported PMM Server virtual machine.</li> <li>Click the play button  or select Virtual Machine \u2192 Start Up.</li> <li>Wait for the VM to boot completely (this may take 2-5 minutes).</li> <li>Look for the IP address displayed in the VM console window.</li> </ol>"},{"location":"install-pmm/install-pmm-server/deployment-options/virtual/vmware.html#next-steps","title":"Next steps","text":"<p>After successfully importing and starting the PMM Server VM:</p> <ul> <li>Open a web browser and navigate to <code>https://&lt;vm-ip-address&gt;</code></li> <li>Complete initial login and setup</li> </ul> <p>Bookmarking</p> <p>Save the PMM Server IP address or add it to your bookmarks for easy access. For production environments, consider configuring a static IP address or DNS name.</p>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html","title":"Choose a PMM deployment strategy","text":"<p>Whether you\u2019re monitoring a single database or managing hundreds across your organization, it\u2019s important to select the appropriate deployment approach for both PMM Server and PMM Client components.</p> <p>Plan your PMM architecture to align with your infrastructure, growth expectations, and operational needs.</p>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#pmm-architecture-overview","title":"PMM architecture overview","text":"<p>PMM can be deployed in flexible ways depending on your infrastructure and monitoring needs. Its architecture consists of two main components:</p> <ul> <li>PMM Server: The central component that stores, analyzes, and visualizes monitoring data</li> <li>PMM Client: The distributed component installed on database hosts to collect metrics</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#planning-considerations","title":"Planning considerations","text":""},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#hardware-and-network-requirements","title":"Hardware and network requirements","text":"<p>For detailed hardware and network specifications, see:</p> <ul> <li>Hardware and system requirements </li> <li>Network and firewall requirements</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#architecture-considerations","title":"Architecture considerations","text":"<ul> <li>Consider network segmentation and access controls</li> <li>Plan user authentication and authorization strategy</li> <li>Evaluate TLS certificate requirements (self-signed vs custom certificates)</li> <li>For high-security environments, consider Podman\u2019s rootless container capabilities</li> <li>Both binary installation and Docker containers can be run without <code>root</code> privileges, enhancing security</li> </ul> <p>For information on PMM\u2019s architecture, see PMM architecture. </p>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#pmm-server-deployment-options","title":"PMM Server deployment options","text":"Method Best for Advantages Considerations  Docker Development, testing &amp; production \u2714  Quick setup\u2714  Simple upgrades\u2714  Works in various environments \u26a0 Requires Docker knowledge\u26a0 May need additional configuration for production  Podman Security-focused setups \u2714 Rootless containers \u2714  Enhanced security \u2714  OCI-compatible \u26a0 Requires Podman installation &amp; knowledge  Helm Cloud-native environments \u2714  Scalable &amp; high availability \u2714  Kubernetes-native \u26a0 Requires existing Kubernetes cluster\u26a0 More complex setup  Virtual Appliance Traditional environments \u2714  Pre-configured with all dependencies\u2714  Dedicated resources \u26a0 Larger resource footprint\u26a0 Requires a hypervisor  Amazon AWS AWS-based environments Seamless AWS integration, easy provisioning Monthly subscription costs, AWS infrastructure costs"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#pmm-client-deployment-options","title":"PMM Client deployment options","text":"Deployment method Best for Advantages Considerations Package Manager Standard Linux environments \u2022 Easy install\u2022 Native to OS \u2022 OS-specific\u2022 Requires repo access Binary Package Custom/isolated environments \u2022 Portable\u2022 Minimal dependencies \u2022 Manual install &amp; updates Docker Containerized hosts \u2022 Consistent environment\u2022 Easy to manage \u2022 Requires Docker\u2022 Needs access to host metrics"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#recommended-deployment-patterns","title":"Recommended deployment patterns","text":"<p>Based on the scale and environment of your monitoring needs, we recommend different deployment patterns:</p> Small-scale (1-30 database instances)Medium (31-200)Large (200+)Cloud-based database monitoring <ul> <li>PMM Server: Docker or Virtual Appliance</li> <li>PMM Client: Package Manager</li> <li>Implementation tips:<ul> <li>for Docker, use the easy install script for quick setup</li> <li>for Virtual Appliance, use the pre-configured OVA file</li> <li>consider backup options early, even for small deployments</li> </ul> </li> <li>Ideal for: Small businesses, development environments, initial deployments</li> </ul> <ul> <li>PMM Server: Docker with volume storage or Kubernetes</li> <li>PMM Client: Package Manager or Docker</li> <li>Implementation tips:<ul> <li>use Docker volumes instead of host directories for better data management</li> <li>consider setting up high availability for production environments</li> <li>implement regular backup procedures for monitoring data</li> </ul> </li> <li>Ideal for: Mid-sized companies, production environments</li> </ul> <ul> <li>PMM Server: Kubernetes with proper resource allocation</li> <li>PMM Client: Automated deployment via package manager</li> <li>Implementation tips:<ul> <li>use infrastructure as code to manage deployments</li> <li>consider distributed monitoring architecture</li> <li>implement proper monitoring of the PMM Server itself</li> </ul> </li> <li>Ideal for: Large enterprises, mission-critical database fleets</li> </ul> <ul> <li>PMM Client: Package Manager or automated cloud deployment</li> <li>PMM Remote: For monitoring cloud database services (RDS, Azure DB, Cloud SQL)</li> <li>Implementation tips:<ul> <li>use cloud-native storage options for better performance</li> <li>leverage auto-scaling groups for handling variable loads</li> <li>consider network costs when planning your architecture</li> </ul> </li> <li>Ideal for: Cloud-native companies, hybrid cloud environments</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#deployment-planning-checklist","title":"Deployment planning checklist","text":"<p>Review this checklist to help you plan and size your monitoring environment and ensure your PMM environment is efficient, secure, and scalable from day one:</p> <p>\u2713 Inventory of systems - Document all database instances that need monitoring </p> <p>\u2713 Estimate monitoring scope - Calculate number of instances and expected metric volume </p> <p>\u2713 Size the PMM Server - Determine hardware requirements based on monitoring load </p> <p>\u2713 Choose Server deployment method - Select the appropriate PMM Server installation option </p> <p>\u2713 Select Client install methods - Identify the best PMM Client setup for each system type </p> <p>\u2713 Verify network access - Ensure proper connectivity and firewall rules are in place </p> <p>\u2713 Plan data retention - Establish backup and disaster recovery processes </p> <p>\u2713 Define maintenance - Create upgrade and patching procedures for PMM components</p>"},{"location":"install-pmm/plan-pmm-installation/choose-deployment.html#next-step","title":"Next step","text":"<p>Hardware and system requirements </p>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html","title":"Hardware and system requirements","text":"<p>To ensure optimal performance for your monitoring environment, check the appropriate hardware specifications before installing PMM.</p> <p>For guidance on selecting the best deployment method based on these requirements, see the choose your PMM deployment strategy topic.</p>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#pmm-server-resource-requirements","title":"PMM Server resource requirements","text":"<p>Resource requirements scale with the number of nodes and services monitored. Here are our recommendations for different deployment scales:</p> Typical deployment (1-30 nodes)Medium (31-200 nodes)Large (200+ nodes) <p>This is the most common deployment scenario, suitable for small to medium-sized environments:</p> <ul> <li>CPU: 4 cores</li> <li>Memory: 8 GB  </li> <li>Storage: 100 GB</li> <li>Example workloads: Development environments, small businesses, initial deployments</li> </ul> <p>Recommended for environments monitoring MySQL, PostgreSQL, or MongoDB at scale:</p> <ul> <li>CPU: 8-16 cores</li> <li>Memory: 16-32 GB</li> <li>Storage: 200 GB</li> <li>CPU usage: Expect 20-70% utilization</li> <li>Example workloads: Production environments, mid-sized companies</li> </ul> <p>Designed for extensive monitoring environments with high-node counts:</p> <ul> <li>CPU: 16+ cores</li> <li>Memory: 32+ GB</li> <li>Storage: 500+ GB</li> <li>Example workloads: Large enterprises, mission-critical database fleets</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#storage-planning","title":"Storage planning","text":"<p>Adjust storage calculations based on your data retention period and the number of metrics collected. To estimate storage requirements:</p> <ul> <li>Base formula: <code>nodes \u00d7 retention_period_in_weeks \u00d7 1 GB</code></li> <li>Quick estimate: for the default 30-day retention period, use the formula <code>number_of_nodes x 4 GB</code></li> <li>High-precision monitoring: increase estimates by 20-50% when using 1-second collection intervals</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#storage-optimization","title":"Storage optimization","text":"<p>To reduce storage usage, consider disable table statistics, which can significantly decrease the size of the VictoriaMetrics database.</p>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#architecture-requirements","title":"Architecture requirements","text":""},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#pmm-server","title":"PMM Server","text":"<ul> <li>CPU: must support the <code>SSE4.2</code>, which is required for Query Analytics (QAN).</li> <li>ARM64: ensure your system uses a supported ARM64 architecture (such as ARMv8 or later). PMM Server is not currently available as a native ARM64 build. For ARM-based systems, use Docker or Podman to run x86_64 images via emulation. To explicitly force Docker to use the x86_64 image on an ARM system, use: <code>docker run --platform linux/amd64 ... &lt;your_pmm_server_image&gt;</code>. </li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#pmm-client","title":"PMM Client","text":"<ul> <li>Installation storage: Requires 100 MB of storage for installation</li> <li>Cache storage: <ul> <li>VM Agent reserves 1 GB of disk space for caching during network outages</li> <li>Query Analytics (QAN) uses RAM instead of disk storage for its cache</li> </ul> </li> <li>Architecture support: Compatible with both x86_64 and ARM64 architectures</li> <li>Operating systems: Compatible with modern 64-bit Linux distributions including Debian, Ubuntu, Oracle Linux, and \u201cRed Hat\u201d derivatives</li> </ul> <p>For specific version support details, see Percona software support life cycle.</p>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#arm-specific-considerations","title":"ARM-specific considerations","text":"<ul> <li>Docker images: If using Docker for PMM Client on ARM systems, ensure you\u2019re using the ARM64-compatible Docker images.</li> <li>Performance testing: Performance may vary across different ARM implementations. Conduct thorough testing to ensure optimal performance in your environment.</li> <li>Software compatibility: Ensure you\u2019re using ARM-compatible versions of any additional software or databases you\u2019re monitoring with PMM.</li> <li>Resource monitoring: Monitor resource usage closely on ARM systems, as it may differ from x86_64 systems. Adjust your configuration as needed for optimal performance.</li> </ul>"},{"location":"install-pmm/plan-pmm-installation/hardware_and_system.html#next-step","title":"Next step","text":"<p>Network and firewall requirements</p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html","title":"Network and firewall requirements","text":"<p>Before installing PMM, ensure your network configuration allows the necessary connections between PMM components. Here are the required ports and connectivity settings.</p> <p>For guidance on selecting the best deployment method based on these requirements, see the choosing your PMM deployment strategy.</p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#system-requirements","title":"System requirements","text":"<p>For detailed system specifications, see Hardware and system requirements Key requirements at a glance:</p> <p>Compatible with both x86_64 and ARM64 architectures Requires 100 MB storage for installation plus caching space Supports modern 64-bit Linux distributions.</p> <p>This is a list of ports used by the various components of PMM. For PMM to work correctly, your system\u2019s firewall should allow TCP traffic on these ports (UDP is not needed).</p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#essential-ports","title":"Essential ports","text":"<p>These ports must be accessible for basic PMM functionality:</p> PMM component TCP port Direction Description PMM Server 80 both HTTP server, used for gRPC over HTTP and web interface (insecure, use with caution). PMM Server 443 both HTTPS server, used for gRPC over HTTPS and web interface (secure, use of SSL certificates is highly encouraged)."},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#internal-component-ports","title":"Internal component ports","text":"<p>These ports are used for communication between PMM components:</p> PMM component TCP port Direction Description PMM Server 7771 both gRPC, used for communication between <code>pmm-agent</code> and <code>pmm-admin</code>. PMM Server 7772 out HTTP1 server, used for older links like <code>logs.zip</code>. PMM Server 7773 out Debugging. <code>pmm-agent</code> 7777 out Default <code>pmm-agent</code> listen port. <code>vm-agent</code> 8428 both VictoriaMetrics port. <code>pmm-agent</code> 42000 - 51999 in Default range for <code>pmm-agent</code> connected agents."},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#port-range-configuration","title":"Port range configuration","text":"<p>The default port range for <code>pmm-agent</code> is intentionally wide to accommodate various deployment sizes. You can adjust this range to fit your environment:</p> <ul> <li>Small deployments: For monitoring fewer than 20 services, you can reduce the range significantly</li> <li>Custom range: Configure with <code>--ports-min</code> and <code>--ports-max</code> flags when starting <code>pmm-agent</code></li> <li>Minimum allocation: Allow at least one port per monitored service/exporter</li> </ul> <p>For example, to set a custom port range for 50 services:     <pre><code>pmm-agent --ports-min=9001 --ports-max=9050\n</code></pre></p> <p>Learn more about available settings for <code>pmm-agent</code> in Percona PMM-Agent documentation.</p>"},{"location":"install-pmm/plan-pmm-installation/network_and_firewall.html#network-configuration-for-locked-down-environments","title":"Network configuration for locked-down environments","text":"<p>For computers in a locked-down corporate environment without direct access to the Internet:</p> <ul> <li>make sure to enable access to Percona Platform services</li> <li>configure appropriate proxy settings if PMM Server needs to access external services through a proxy</li> <li>consider using offline installation methods for environments without internet access</li> </ul>"},{"location":"pmm-upgrade/index.html","title":"About PMM Server upgrade","text":"<p>Upgrade PMM Server before Clients</p> <ul> <li>When upgrading PMM, always upgrade the PMM Server before upgrading any PMM Clients.</li> <li>Make sure that the PMM Server version is higher than or equal to the PMM Client version. Mismatched versions can lead to configuration issues and failures in Client-Server communication, as the PMM Server may not recognize all parameters in the client configuration.</li> <li>For the UI upgrade option, Watchtower must be installed with PMM Server</li> </ul>"},{"location":"pmm-upgrade/index.html#available-upgrade-methods","title":"Available upgrade methods","text":"<p>Choose your preferred upgrade method based on your setup:</p> <ul> <li> <p>Upgrade PMM Server from the UI</p> </li> <li> <p>Upgrade PMM Client</p> </li> <li> <p>Upgrade PMM Server using Docker</p> </li> <li> <p>Migrate from PMM 2</p> </li> </ul>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html","title":"Migrate external PostgreSQL configuration for PMM 3.2.0+ upgrades","text":"<p>If you\u2019re using an external PostgreSQL database with PMM, you will need to update your configuration before upgrading to PMM 3.2.0. This is due to a regression issue in Grafana, where the single <code>GF_DATABASE_URL</code> environment variable is no longer sufficient for configuring the database.</p> <p>To upgrade to PMM 3.2.0 successfully, convert your configuration to use individual environment variables instead of <code>GF_DATABASE_URL</code>: </p>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#before-you-begin","title":"Before you begin","text":"<ul> <li>Verify you\u2019re using an external PostgreSQL database with PMM</li> <li>Ensure you have the connection details for your PostgreSQL database</li> <li>Back up your PMM data before starting the migration</li> </ul>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#migration-procedure","title":"Migration procedure","text":""},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#1-determine-your-current-database-url-format","title":"1. Determine your current database URL format","text":"<p>Your external PostgreSQL is likely configured with a connection string like: <code>GF_DATABASE_URL=postgres://USER:PASSWORD@HOST:PORT/DATABASE_NAME</code>. </p> <p>Extract these components for the new configuration format.</p>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#2-stop-your-pmm-server","title":"2. Stop your PMM Server","text":"<p>Use the appropriate command for your deployment method to stop and remove the PMM Server:</p> DockerPodmanDocker ComposeKubernetes/Helm <pre><code>docker stop pmm-server\ndocker rm pmm-server\n</code></pre> <pre><code>podman stop pmm-server\npodman rm pmm-server\n</code></pre> <pre><code>docker-compose stop pmm-server\ndocker-compose rm pmm-server\n</code></pre> <pre><code># Scale down the PMM deployment\nkubectl scale deployment pmm-server --replicas=0 -n &lt;namespace&gt;\n# Wait for the pod to terminate\nkubectl wait --for=delete pod -l app=pmm-server -n &lt;namespace&gt;\n</code></pre>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#3-replace-the-database-url-with-individual-parameters","title":"3. Replace the database URL with individual parameters","text":"<p>To configure your external PostgreSQL database for PMM 3.2.0 and later, replace the <code>GF_DATABASE_URL</code> with individual environment variables:</p> Old format New format <code>GF_DATABASE_URL=postgres://USER:PASSWORD@HOST:PORT/DATABASE_NAME</code> <code>GF_DATABASE_USER=USER</code><code>GF_DATABASE_PASSWORD=PASSWORD</code><code>GF_DATABASE_HOST=HOST:PORT</code><code>GF_DATABASE_NAME=DATABASE_NAME</code>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#port-and-type-defaults","title":"Port and type defaults","text":"<ul> <li>If your database URL doesn\u2019t specify a port, the default PostgreSQL port <code>5432</code> will be used.</li> <li>PMM automatically uses PostgreSQL for external database connections, so you don\u2019t need to specify <code>GF_DATABASE_TYPE</code>.</li> </ul>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#4-upgrade-to-pmm-320-and-restart-pmm-server-with-the-new-configuration","title":"4. Upgrade to PMM 3.2.0 and restart PMM Server with the new configuration","text":"<p>Modify your startup command or configuration file to use the new parameters:</p> <p>Version Upgrade</p> <p>This step will upgrade your PMM instance to version 3.2.0 and apply the new database configuration. </p> DockerPodmanDocker ComposeKubernetes/Helm <pre><code>docker run -d \\\n  -p 443:8443 \\\n  -v pmm-data:/srv \\\n  -e GF_DATABASE_USER=your_user \\\n  -e GF_DATABASE_PASSWORD=your_password \\\n  -e GF_DATABASE_HOST=your_host:your_port \\\n  -e GF_DATABASE_NAME=your_db_name \\\n  -e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n  --name pmm-server \\\n  percona/pmm-server:3.2.0\n</code></pre> <pre><code>podman run -d \\\n  -p 443:8443 \\\n  -v pmm-data:/srv \\\n  -e GF_DATABASE_USER=your_user \\\n  -e GF_DATABASE_PASSWORD=your_password \\\n  -e GF_DATABASE_HOST=your_host:your_port \\\n  -e GF_DATABASE_NAME=your_db_name \\\n  -e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n  --name pmm-server \\\n  percona/pmm-server:3.2.0\n</code></pre> <p>Update your <code>docker-compose.yml</code> file to include both PMM and Grafana database configuration variables. <code>PMM_POSTGRES_*</code> is required for PMM\u2019s internal components and <code>GF_DATABASE_*</code> for Grafana. For details, see the Configure PMM with external PostgreSQL topic.</p> <pre><code>services:\n  pmm-server:\n    image: percona/pmm-server:3.2.0\n    ports:\n      - \"443:8443\"\n    volumes:\n      - pmm-data:/srv\n    environment:\n      # PMM PostgreSQL connection variables\n      - PMM_POSTGRES_ADDR=your_host:your_port\n      - PMM_POSTGRES_DBNAME=your_pmm_db_name\n      - PMM_POSTGRES_USERNAME=your_pmm_user\n      - PMM_POSTGRES_DBPASSWORD=your_pmm_password\n      # Grafana PostgreSQL connection variables (for PMM 3.2.0+)\n      - GF_DATABASE_USER=your_grafana_user\n      - GF_DATABASE_PASSWORD=your_grafana_password\n      - GF_DATABASE_HOST=your_host:your_port\n      - GF_DATABASE_NAME=your_grafana_db_name\n      # Disable built-in PostgreSQL\n      - PMM_DISABLE_BUILTIN_POSTGRES=1\n    restart: always\n\nvolumes:\n  pmm-data:\n</code></pre> <p>Then restart: <pre><code>docker-compose up -d\n</code></pre></p> <p>Update your values file to include the new parameters:</p> <pre><code>env:\n  - name: GF_DATABASE_USER\n    value: your_user\n  - name: GF_DATABASE_PASSWORD\n    value: your_password\n  - name: GF_DATABASE_HOST\n    value: your_host:your_port\n  - name: GF_DATABASE_NAME\n    value: your_db_name\n  - name: PMM_DISABLE_BUILTIN_POSTGRES\n    value: \"1\"\n</code></pre> <p>Then upgrade or restart: <pre><code>helm upgrade pmm percona/pmm-server -n &lt;namespace&gt; -f values.yaml\n# Or scale back up if you scaled down earlier\nkubectl scale deployment pmm-server --replicas=1 -n &lt;namespace&gt;\n</code></pre></p>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#5-verify-the-upgrade","title":"5. Verify the upgrade","text":"<p>After completing the upgrade, check that PMM Server is functioning correctly and your external PostgreSQL database is properly connected:</p> <ol> <li>Wait for PMM Server to start. </li> <li>Access the PMM web interface. </li> <li>Check that dashboards and metrics are loading correctly. </li> <li>Verify that no database connection errors appear in the PMM Server logs. </li> </ol>"},{"location":"pmm-upgrade/external_postgres_pmm_upgrade.html#troubleshooting","title":"Troubleshooting","text":"<p>If PMM fails to connect to your PostgreSQL database, verify that:</p> <ul> <li>Database credentials are correct</li> <li>Database host is accessible from the PMM Server container</li> <li>PostgreSQL is configured to accept connections from PMM Server\u2019s IP address</li> <li>PostgreSQL server is running and healthy</li> </ul> <p>You can check the Grafana logs for more detailed error messages: <code>docker exec pmm-server grep -i database /srv/logs/grafana.log</code>.</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html","title":"Migrate PMM 2 to PMM 3","text":"<p>PMM 2 is no longer actively developed. For new features, security updates and ongoing support, you\u2019ll need to migrate to PMM 3.</p> <p>PMM 3 delivers significant architectural changes that require a gradual transition from PMM 2. The migration process keeps your existing monitoring data and configurations, ensuring monitoring continuity. You can migrate to PMM 3 automatically using the automated migration script (recommended), or manually, following step-by-step instructions.</p> <p>We recommend beginning your evaluation of PMM 3 in a test environment for a smooth transition. To gradually migrate to PMM 3:</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-1-upgrade-pmm-2-server-to-the-latest-version","title":"Step 1: Upgrade PMM 2 Server to the latest version","text":"<p>Before migrating PMM 2 to PMM 3, ensure your PMM 2 Server is running the latest version:</p> <ol> <li>From the Home page, scroll to the PMM Upgrade panel and click the Refresh button to check for updates manually.</li> <li>If an update is available, click the Update button to install the latest PMM 2 version.</li> <li>Verify that the update was successful by checking the version number after the update completes.</li> </ol>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-2-migrate-pmm-2-server-to-pmm-3","title":"Step 2: Migrate PMM 2 Server to PMM 3","text":"Automated Docker migration (Recommended)Manual migration (Docker/Kubernetes/Podman/AMI/OVF) <p>Use this upgrade script for a simplified migration process.</p> <ol> <li>Download and prepare the automated migration script:  <pre><code>curl -o get-pmm.sh https://www.percona.com/get/pmm\n</code></pre></li> <li>Make the script executable:      <pre><code>chmod +x get-pmm.sh\n</code></pre></li> <li> <p>Run the migration script with the <code>-b</code> flag to create a backup of your PMM2 instance before the migration:</p> <pre><code>./get-pmm.sh -n &lt;container-name&gt; -b\n</code></pre> </li> <li> <p>Note the backup volume name displayed during the migration (e.g., <code>pmm-data-2025-01-16-165135</code>) so that you can restore this backup if needed.</p> </li> <li> <p>Check additional script options:     <pre><code>./get-pmm.sh -h\n</code></pre></p> </li> </ol> <p>Restore PMM 2 backup</p> <p>If you need to revert to the PMM 2 instance, restore the backup created above:</p> <ol> <li>Stop the PMM 3 container:     <pre><code>docker stop pmm-server\n</code></pre></li> <li> <p>Start a PMM 2 container using the backup volume, replacing <code>&lt;backup-volume-name&gt;</code> (e.g., <code>pmm-data-2025-01-16-165135</code>) with your actual backup volume name:</p> <pre><code>docker run -d -p 443:443 --volume &lt;backup-volume-name&gt;:/srv --name pmm-server --restart always percona/pmm-server:2.44.0\n</code></pre> </li> <li> <p>Verify that your PMM 2 instance is running correctly and all your data is accessible.</p> </li> </ol> Docker with volumeDocker with data containerHelmPodmanAMI/OVF instance <p>Follow these manual steps to migrate your PMM 2 Server to PMM 3:</p> <ol> <li> <p>Stop all PMM Server services:</p> <pre><code>docker exec -t &lt;pmm-server&gt; supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:</p> <pre><code>docker exec -t &lt;pmm-server&gt; chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>List and note down your Docker volume:</p> <pre><code>docker inspect -f '{{ range .Mounts }}{{ if eq .Type \"volume\" }}{{ .Name }}{{ \"\\n\" }}{{ end }}{{ end }}' &lt;pmm-server&gt;\n</code></pre> </li> <li> <p>Stop and remove existing container:</p> <pre><code>docker stop pmm-server &amp;&amp; docker rm pmm-server\n</code></pre> </li> <li> <p>Pull PMM 3 Server image:</p> <pre><code>docker pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Run the new version of PMM Server with the existing volume:</p> <pre><code>docker run -d -v pmm-server-data:/srv -p 443:8443 --name pmm-server --restart always percona/pmm-server:3\n</code></pre> </li> </ol> <p>Follow these manual steps to upgrade your PMM 2 Server to PMM 3:</p> <ol> <li> <p>Stop all PMM Server services:</p> <pre><code>docker exec -t &lt;pmm-server&gt; supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:</p> <pre><code>docker exec -t &lt;pmm-server&gt; chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>Identify the data container using either:</p> <pre><code>docker ps -a --filter \"status=created\"\n</code></pre> <p>OR</p> <pre><code>docker inspect -f '{{ range .Mounts }}{{ if eq .Type \"volume\" }}{{ .Name }}{{ \"\\n\" }}{{ end }}{{ end }}' &lt;pmm-server&gt;\n</code></pre> </li> <li> <p>Stop and remove the existing container:</p> <pre><code>docker stop pmm-server &amp;&amp; docker rm pmm-server\n</code></pre> </li> <li> <p>Pull PMM 3 Server image:</p> <pre><code>docker pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Run the new version of PMM Server with the existing data container:</p> <pre><code>docker run -d --volumes-from pmm-server-data -p 443:8443 --name pmm-server --restart always percona/pmm-server:3\n</code></pre> </li> </ol> <p>Follow these steps to migrate your PMM 2 Server deployed with Helm to PMM 3:</p> <ol> <li> <p>Update the Percona Helm repository:</p> <pre><code>helm repo update percona\n</code></pre> </li> <li> <p>Export current values to a file:</p> <pre><code>helm show values percona/pmm &gt; values.yaml\n</code></pre> </li> <li> <p>Update the <code>values.yaml</code> file to match your PMM 2 configuration</p> </li> <li> <p>Stop all PMM Server services:</p> <pre><code>kubectl exec pmm-0 -- supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:</p> <pre><code>kubectl exec pmm-0 -- chown -R pmm:pmm /srv\n</code></pre> </li> <li> <p>Upgrade PMM using Helm:</p> <pre><code>helm upgrade pmm -f values.yaml --set podSecurityContext.runAsGroup=null --set podSecurityContext.fsGroup=null percona/pmm\n</code></pre> </li> <li> <p>If Kubernetes did not trigger the upgrade automatically, delete the pod to force recreation:     <pre><code>kubectl delete pod pmm-0\n</code></pre></p> </li> </ol> <p>Follow these steps to migrate to PMM 3 a PMM 2 Server deployed with Podman:</p> <ol> <li> <p>Pull the PMM 3 Server image:</p> <pre><code>podman pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Stop all PMM Server services:</p> <pre><code>podman exec pmm-server supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer <code>/srv</code> directory ownership:     <pre><code>podman exec pmm-server chown -R pmm:pmm /srv\n</code></pre></p> </li> <li> <p>Remove the existing systemd service file:</p> <pre><code>rm ~/.config/systemd/user/pmm-server.service\n</code></pre> </li> <li> <p>Follow the installation steps from the PMM 3 Podman installation guide to complete the upgrade.</p> </li> </ol> <p>Follow these steps to migrate a PMM 2 Server deployed as an AMI/OVF instance to PMM 3:</p> <ol> <li> <p>Back up your current instance and keep your PMM 2 instance running until confirm a successful migration.</p> </li> <li> <p>Deploy a new PMM 3 AMI/OVF instance.</p> </li> <li> <p>On the new instance, stop the Podman service:</p> <pre><code>systemctl --user stop pmm-server\n</code></pre> </li> <li> <p>Clear the service volume directory:</p> <pre><code>rm -rf /home/admin/volume/srv/*\n</code></pre> </li> <li> <p>On the old instance, stop all services:</p> <pre><code>sudo supervisorctl stop all\n</code></pre> </li> <li> <p>Transfer data from old to new instance:</p> <pre><code>sudo scp -r /srv/* admin@newhost:/home/admin/volume/srv\n</code></pre> </li> <li> <p>Set proper permissions on the new instance:</p> <pre><code>chown -R admin:admin /home/admin/volume/srv/\n</code></pre> </li> <li> <p>Start the PMM service on the new instance:</p> <pre><code>systemctl --user start pmm-server\n</code></pre> </li> <li> <p>Verify that PMM 3 is working correctly with the migrated data.</p> </li> <li> <p>Update PMM Client configurations by editing the <code>/usr/local/percona/pmm2/config/pmm-agent.yml</code> with the new server address, then restart the PMM Client.</p> </li> </ol> <p>Revert AMI/OVF instance to PMM 2</p> <p>If you need to restore to the PMM 2 instance after the migration:</p> <ol> <li>Access old instance via SSH.</li> <li>Start services: <code>supervisorctl start all</code>.</li> <li>Update client configurations to point to old instance.</li> </ol>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-3-migrate-pmm-2-clients-to-pmm-3","title":"Step 3: Migrate PMM 2 Clients to PMM 3","text":"<p>Important</p> <p>PMM 3 Server provides limited support for PMM 2 Clients (metrics and Query Analytics only). This support will be removed in PMM 3.3.</p> <p>Depending on your initial installation method, update PMM Clients using your operating system\u2019s package manager or using a tarball. For detailed instructions, see the Upgrade PMM Client topic.</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#step-4-migrate-your-api-keys-to-service-accounts","title":"Step 4: Migrate your API keys to service accounts","text":"<p>PMM 3 replaces API keys with service accounts to enhance security and simplify access management. You can trigger this API key conversion from the UI or from the CLI.</p> From CLIFrom the UI <p>You can also initiate the conversion using the following command. </p> <p>Be sure to replace <code>admin:admin</code> with your credentials and update the server address to match your PMM Server address (the same URL you use to access the PMM web interface):</p> <pre><code>curl -X POST -k https://YOUR PMM SERVER ADDRESS/graph/api/serviceaccounts/migrate \\\n-u admin:admin \\\n-H \"Content-Type: application/json\"\n</code></pre> <p>The response will display the migration details:</p> <p>Expected output</p> <pre><code>{\"total\":3,\"migrated\":3,\"failed\":0,\"failedApikeyIDs\":[],\"failedDetails\":[]}\n</code></pre> <p>PMM automatically migrates existing API keys to service accounts when you first log in as an Admin user. The migration results are displayed in a popup dialog box. If no popup appears, it likely means there are no API keys to migrate\u2014this is typical for PMM Servers without connected services.</p>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#verify-the-conversion","title":"Verify the conversion","text":"<p>To verify that API keys were successfully migrated, go to Administration &gt; Users and Access &gt; Service Accounts, where you can check the list of service accounts available and confirm that the API Keys menu is no longer displayed.</p> <p>If any API keys fail to migrate, you can either: </p> <ul> <li>delete the problematic API keys and create new service accounts</li> <li>keep using the existing API keys until you\u2019re ready to replace them</li> </ul>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#post-migration-steps","title":"Post-migration steps","text":"<p>After you finish migrating PMM:</p> <ol> <li>Verify that all PMM Clients are up to date by checking PMM Configuration &gt; Updates.</li> <li>Confirm all previously monitored services are reporting correctly to the new PMM 3 Server by reviewing Configuration &gt; PMM Inventory &gt; Services.</li> <li>Check the dashboards to make sure you\u2019re receiving the metrics and QAN data.</li> </ol>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#variables-for-migrating-from-pmm-v2-to-pmm-v3","title":"Variables for migrating from PMM v2 to PMM v3","text":"<p>When migrating from PMM v2 to PMM v3, you\u2019ll need to update your environment variables to match the new naming convention. This is because PMM v3 introduces several important changes to improve consistency and clarity:</p> <ul> <li>environment variables now use <code>PMM_</code> prefix</li> <li>some boolean flags reversed (e.g., <code>DISABLE_</code> \u2192 <code>ENABLE_</code>)</li> <li>removed deprecated variables</li> </ul>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#examples","title":"Examples","text":"<pre><code># PMM v2\n-e DISABLE_UPDATES=true -e DATA_RETENTION=720h\n\n# PMM v3 equivalent\n-e PMM_ENABLE_UPDATES=false -e PMM_DATA_RETENTION=720h\n</code></pre>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#migration-reference-table","title":"Migration reference table","text":"<p>The following table lists all the environment variable changes between PMM v2 and PMM v3. Review this table when updating your deployment configurations.</p> Click to expand migration reference table"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#configuration-variables","title":"Configuration variables","text":"PMM 2 PMM 3 Comments <code>DATA_RETENTION</code> <code>PMM_DATA_RETENTION</code> <code>DISABLE_ALERTING</code> <code>PMM_ENABLE_ALERTING</code> <code>DISABLE_UPDATES</code> <code>PMM_ENABLE_UPDATES</code> <code>DISABLE_TELEMETRY</code> <code>PMM_ENABLE_TELEMETRY</code> <code>DISABLE_BACKUP_MANAGEMENT</code> <code>PMM_ENABLE_BACKUP_MANAGEMENT</code> Note the reverted boolean <code>ENABLE_AZUREDISCOVER</code> <code>PMM_ENABLE_AZURE_DISCOVER</code> <code>ENABLE_RBAC</code> <code>PMM_ENABLE_ACCESS_CONTROL</code> <code>LESS_LOG_NOISE</code> Removed in PMM v3"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#metrics-configuration","title":"Metrics configuration","text":"PMM 2 PMM 3 <code>METRICS_RESOLUTION</code> <code>PMM_METRICS_RESOLUTION</code> <code>METRICS_RESOLUTION_HR</code> <code>PMM_METRICS_RESOLUTION_HR</code> <code>METRICS_RESOLUTION_LR</code> <code>PMM_METRICS_RESOLUTION_LR</code> <code>METRICS_RESOLUTION_MR</code> <code>PMM_METRICS_RESOLUTION_MR</code>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#clickhouse-configuration","title":"ClickHouse configuration","text":"PMM 2 PMM 3 Comments <code>PERCONA_TEST_PMM_CLICKHOUSE_ADDR</code> <code>PMM_CLICKHOUSE_ADDR</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATABASE</code> <code>PMM_CLICKHOUSE_DATABASE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_DATASOURCE</code> <code>PMM_CLICKHOUSE_DATASOURCE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_HOST</code> <code>PMM_CLICKHOUSE_HOST</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_PORT</code> <code>PMM_CLICKHOUSE_PORT</code> <code>PERCONA_TEST_PMM_DISABLE_BUILTIN_CLICKHOUSE</code> <code>PMM_DISABLE_BUILTIN_CLICKHOUSE</code> <code>PERCONA_TEST_PMM_CLICKHOUSE_BLOCK_SIZE</code> Removed in PMM v3, new version <code>PERCONA_TEST_PMM_CLICKHOUSE_POOL_SIZE</code> Removed in PMM v3, new version"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#postgresql-configuration","title":"PostgreSQL configuration","text":"PMM 2 PMM 3 <code>PERCONA_TEST_POSTGRES_ADDR</code> <code>PMM_POSTGRES_ADDR</code> <code>PERCONA_TEST_POSTGRES_DBNAME</code> <code>PMM_POSTGRES_DBNAME</code> <code>PERCONA_TEST_POSTGRES_USERNAME</code> <code>PMM_POSTGRES_USERNAME</code> <code>PERCONA_TEST_POSTGRES_DBPASSWORD</code> <code>PMM_POSTGRES_DBPASSWORD</code> <code>PERCONA_TEST_POSTGRES_SSL_CA_PATH</code> <code>PMM_POSTGRES_SSL_CA_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_CERT_PATH</code> <code>PMM_POSTGRES_SSL_CERT_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_KEY_PATH</code> <code>PMM_POSTGRES_SSL_KEY_PATH</code> <code>PERCONA_TEST_POSTGRES_SSL_MODE</code> <code>PMM_POSTGRES_SSL_MODE</code> <code>PERCONA_TEST_PMM_DISABLE_BUILTIN_POSTGRES</code> <code>PMM_DISABLE_BUILTIN_POSTGRES</code>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#telemetry-development","title":"Telemetry &amp; development","text":"PMM 2 PMM 3 <code>PMM_TEST_TELEMETRY_DISABLE_SEND</code> <code>PMM_DEV_TELEMETRY_DISABLE_SEND</code> <code>PERCONA_TEST_TELEMETRY_DISABLE_START_DELAY</code> <code>PMM_DEV_TELEMETRY_DISABLE_START_DELAY</code> <code>PMM_TEST_TELEMETRY_FILE</code> <code>PMM_DEV_TELEMETRY_FILE</code> <code>PERCONA_TEST_TELEMETRY_HOST</code> <code>PMM_DEV_TELEMETRY_HOST</code> <code>PERCONA_TEST_TELEMETRY_INTERVAL</code> <code>PMM_DEV_TELEMETRY_INTERVAL</code> <code>PERCONA_TEST_TELEMETRY_RETRY_BACKOFF</code> <code>PMM_DEV_TELEMETRY_RETRY_BACKOFF</code> <code>PERCONA_TEST_VERSION_SERVICE_URL</code> <code>PMM_DEV_VERSION_SERVICE_URL</code> <code>PERCONA_TEST_STARLARK_ALLOW_RECURSION</code> <code>PMM_DEV_ADVISOR_STARLARK_ALLOW_RECURSION</code>"},{"location":"pmm-upgrade/migrating_from_pmm_2.html#removed-variables","title":"Removed variables","text":"PMM 2 PMM 3 Comments <code>PERCONA_TEST_AUTH_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code> <code>PERCONA_TEST_CHECKS_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code> <code>PERCONA_TEST_CHECKS_INTERVAL</code> Removed, not used <code>PERCONA_TEST_CHECKS_PUBLIC_KEY</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_PUBLIC_KEY</code> <code>PERCONA_TEST_NICER_API</code> Removed in PMM v3 <code>PERCONA_TEST_SAAS_HOST</code> Removed, use <code>PMM_DEV_PERCONA_PLATFORM_ADDRESS</code>"},{"location":"pmm-upgrade/ui_upgrade.html","title":"Upgrade PMM v3 Server from the UI","text":"<p>PMM Server and Client components are installed and updated separately.</p> <p>PMM v3 Server can run natively, as a Docker image, a virtual appliance or an AWS cloud instance. While each environment has its own specific installation and update steps, the UI-based upgrade method is universal and recommended for most users.</p>"},{"location":"pmm-upgrade/ui_upgrade.html#prerequisites","title":"Prerequisites","text":"<p>To use the UI upgrade feature, you must have Watchtower installed and properly configured with your PMM Server. </p> <p>If Watchtower is not installed, the UI upgrade options will not be available. See Running PMM Server with Watchtower for setup instructions.</p>"},{"location":"pmm-upgrade/ui_upgrade.html#upgrade-process","title":"Upgrade process","text":"<p>The preferred and simplest way to update PMM v3 Server is via the Updates page:</p> <ol> <li> <p>Go to PMM Configuration &gt; Updates in your PMM web interface. Here you can check the current PMM Server version, the timestamp of the last update check and whether your instance is up-to-date.  </p> </li> <li> <p>If an update is available, click the Update now button to install the latest version.</p> </li> </ol> <p></p>"},{"location":"pmm-upgrade/ui_upgrade.html#quick-upgrade-check","title":"Quick upgrade check","text":"<p>For a quick overview of your PMM v3 Server\u2019s update status, you can also check to the Upgrade panel on the Home page.</p> <p></p>"},{"location":"pmm-upgrade/upgrade_aws.html","title":"Upgrade PMM Server on AWS","text":"<p>Keep your PMM Server up to date with the latest features, security patches, and performance improvements.</p>"},{"location":"pmm-upgrade/upgrade_aws.html#prerequisites","title":"Prerequisites","text":"<p>Before upgrading your PMM Server, ensure you have:</p> <ul> <li>a current backup of your PMM data volume</li> <li>scheduled maintenance window for potential downtime</li> </ul>"},{"location":"pmm-upgrade/upgrade_aws.html#upgrade-process","title":"Upgrade process","text":"<p>To upgrade PMM Server on AWS: </p> <ol> <li> <p>Create a backup snapshot of your PMM data volume:</p> <pre><code>aws ec2 create-snapshot --volume-id vol-xxxxxxxxx --description \"Pre-upgrade backup $(date)\"\n</code></pre> </li> <li> <p>Go to PMM Configuration &gt; Updates  and click Update now if a newer version is available.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#post-upgrade-tasks","title":"Post-upgrade tasks","text":"<p>After upgrading PMM Server:</p> <ol> <li> <p>Go to Dashboards &gt; Experimental &gt; PMM Health and check that all services are running. </p> </li> <li> <p>Go to PMM Configuration &gt; Inventory &gt; Services and verify that all monitored nodes and services are listed, their status is Up.</p> </li> <li> <p>Test monitoring functionality to ensure data collection continues normally.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#rollback-procedure","title":"Rollback procedure","text":"<p>If issues occur after upgrade:</p> <ol> <li> <p>Stop the new PMM container:    <pre><code>systemctl --user stop pmm-server\n</code></pre></p> </li> <li> <p>Restore using your pre-upgrade snapshot. Create a volume from the snapshot, attach it to the instance, and start the previous PMM version.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_aws.html#troubleshooting-upgrades","title":"Troubleshooting upgrades","text":"<p>If the container won\u2019t start after the upgrade:</p> <pre><code># Check container logs\npodman logs pmm-server\n\n# Check systemd service logs\njournalctl -u pmm-server.service\n\n# Verify volume mounts\npodman inspect pmm-server\n</code></pre>"},{"location":"pmm-upgrade/upgrade_client.html","title":"Upgrade PMM Client","text":"<p>There are two primary methods to update PMM Clients, depending on your initial installation method:</p> <ol> <li>Using your operating system\u2019s package manager</li> <li>Updating from a tarball</li> </ol>"},{"location":"pmm-upgrade/upgrade_client.html#1-package-manager-method","title":"1. Package Manager method","text":"<p>The package manager method is generally more convenient and efficient. Percona provides the percona-release package, which helps you install Percona software, including PMM Client. PMM Client is available from the <code>pmm-client</code> repository.</p> <p>To deploy a new version of the Client via package manager, simply replace the currently installed package with the latest version of the PMM Client or with a specific version.</p>"},{"location":"pmm-upgrade/upgrade_client.html#install-the-latest-pmm-client-version","title":"Install the latest PMM Client version","text":"<p>Run the commands below to install the latest PMM Client version via package manager and keep your existing Client configuration during the update process.</p> <p>For example, to install the latest version of the PMM Client on Red Hat or its derivatives:</p> Debian-basedRed Hat-based <pre><code>percona-release enable pmm3-client\napt update\napt install pmm-client\n</code></pre> <pre><code>percona-release enable pmm3-client\nyum update pmm-client\n</code></pre>"},{"location":"pmm-upgrade/upgrade_client.html#deploy-a-specific-version","title":"Deploy a specific version","text":"<p>To deploy a specific version of the PMM Client via package manager, check the available versions and then provide the full name of the package. For example:</p> Red Hat-basedDebian-based <pre><code>yum --showduplicates search pmm-client\npmm-client-3.0.0-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\npmm-client-3.0.1-6.el9.x86_64 : Percona Monitoring and Management Client (pmm-agent)\nyum update pmm-client-3.0.1-6.el9.x86_64\n</code></pre> <pre><code>apt-cache madison pmm-client\npmm-client | 3.1.0-6.jammy | http://repo.percona.com/pmm-client/apt jammy/main amd64 Packages\npmm-client | 3.0.0-6.jammy | http://repo.percona.com/pmm-client/apt jammy/main amd64 Packages\napt install pmm-client=3.0.1-6.jammy\n</code></pre>"},{"location":"pmm-upgrade/upgrade_client.html#2-tarball-method","title":"2. Tarball method","text":"<p>If you initially installed the PMM Client from a tarball, you can update it by replacing the currently installed package with the latest version:</p> <ol> <li>Download <code>tar.gz</code> with <code>pmm-client</code>.</li> <li>Extract the tarball.</li> <li>Run <code>./install_tarball</code> script with the <code>-u</code> flag.</li> </ol> <p>Important</p> <p>The configuration file will be overwritten if you do not provide the <code>-u</code> flag while the <code>pmm-agent</code> is updated.</p>"},{"location":"pmm-upgrade/upgrade_docker.html","title":"Manual upgrade: Upgrade PMM Server using Docker","text":""},{"location":"pmm-upgrade/upgrade_docker.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires an backup made prior to the upgrade.</p> </li> <li> <p>Verify your current PMM version: Check your current PMM version by navigating to PMM Configuration &gt; Updates or by running the following command: </p> <pre><code>docker exec -it pmm-server curl -ku admin:admin https://localhost:8443/v1/version\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_docker.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings. In case of any issues, you can restore your system using the backup created in the preparation steps.</p> <ol> <li> <p>Stop the current container:</p> <pre><code>docker stop pmm-server\n</code></pre> </li> <li> <p>Pull the latest image:</p> <pre><code>docker pull percona/pmm-server:3\n</code></pre> </li> <li> <p>Rename the original container:</p> <pre><code>docker rename pmm-server pmm-server-old\n</code></pre> </li> <li> <p>Run the new container:</p> <pre><code>docker run \\\n--detach \\\n--restart always \\\n--publish 443:8443 \\\n--volumes-from pmm-data \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre> </li> <li> <p>After upgrading, verify that PMM Server is running correctly and all your data is accessible. You can always rerestore your PMM Server using the backup you created above.</p> </li> </ol>"},{"location":"pmm-upgrade/upgrade_helm.html","title":"Upgrade PMM Server using Helm","text":"<p>Percona releases new chart versions to update containers when:</p> <ul> <li>A new version of the main container is available</li> <li>Significant changes are made</li> <li>Critical vulnerabilities are addressed</li> </ul> <p>UI Update feature disabled by default</p> <p>The UI update feature is disabled by default and should remain so. Do not modify or add the following parameter in your custom <code>values.yaml</code> file: <pre><code>pmmEnv:\nPMM_ENABLE_UPDATES: 'false'\n</code></pre></p>"},{"location":"pmm-upgrade/upgrade_helm.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires a backup made prior to the upgrade.</p> </li> <li> <p>To reduce downtime, pre-pull the new image on the node where PMM is running:</p> <pre><code># Replace &lt;version&gt; with the latest PMM version\ndocker pull percona/pmm-server:3\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_helm.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings\u2014you can restore from your backup if needed.</p> <ol> <li> <p>Update Helm repository:</p> <pre><code>helm repo update percona\n</code></pre> </li> <li> <p>Upgrade PMM:</p> <pre><code>helm upgrade pmm -f values.yaml --set podSecurityContext.runAsGroup=null --set podSecurityContext.fsGroup=null percona/pmm\n</code></pre> </li> <li> <p>After the upgrade, verify that PMM Server is running correctly and all your data is accessible:</p> <p><pre><code>kubectl get pods | grep pmm-server\n</code></pre> 4. Check the logs for any errors:</p> <pre><code>kubectl logs deployment/pmm-server\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_podman.html","title":"Manual upgrade: Upgrade PMM Server using Podman","text":""},{"location":"pmm-upgrade/upgrade_podman.html#before-you-begin","title":"Before you begin","text":"<p>Before starting the upgrade, complete these preparation steps to ensure you can recover your system if needed and confirm compatibility with the new version:</p> <ol> <li> <p>Create a backup before upgrading, as downgrades are not possible. Therefore, reverting to a previous version requires an backup made prior to the upgrade.</p> </li> <li> <p>Verify your current PMM version: Check your current PMM version by navigating to PMM Configuration &gt; Updates or by running the following command: </p> <pre><code>podman exec -it pmm-server \\\ncurl -ku admin:admin https://localhost/v1/version\n</code></pre> </li> </ol>"},{"location":"pmm-upgrade/upgrade_podman.html#upgrade-steps","title":"Upgrade steps","text":"<p>Follow these steps to upgrade your PMM Server while preserving your monitoring data and settings. In case of any issues, you can restore your system using the backup created in the preparation steps.</p> <ol> <li> <p>Update PMM version by editing the PMM Server environment file. Replace 3.0.0 with your target version number:</p> <pre><code>sed -i \"s/PMM_IMAGE=.*/PMM_IMAGE=docker.io/percona/pmm-server:3.0.0/g\" ~/.config/systemd/user/pmm-server.env\n</code></pre> </li> <li> <p>Pre-pull the new image to ensure a faster restart:</p> <pre><code>source ~/.config/systemd/user/pmm-server.env\npodman pull ${PMM_IMAGE}\n</code></pre> </li> <li> <p>Restart PMM Server:</p> <pre><code>systemctl --user restart pmm-server\n</code></pre> </li> <li> <p>After the upgrade, verify that PMM Server is running correctly:</p> <pre><code>podman ps | grep pmm-server\n</code></pre> </li> <li> <p>Check the logs for any errors:</p> <pre><code>podman logs pmm-server\n</code></pre> </li> </ol>"},{"location":"quickstart/quickstart.html","title":"Get started with PMM","text":"<p>To get up and running with Percona Monitoring and Management (PMM) in no time, install PMM on Bare Metal/Virtual using the Easy-install script for Docker.</p> <p>This is the simplest and most efficient way to install PMM with Docker.</p> Alternative installation options <p>For alternative setups or if you\u2019re not using Docker, explore the additional installation options detailed in the Setting up chapter:</p> <ul> <li>Deploy on Podman</li> <li>Deploy based on a Docker image</li> <li>Deploy on Virtual Appliance</li> <li>Deploy on Kubernetes via Helm</li> <li>Run a PMM instance hosted at AWS Marketplace</li> </ul>"},{"location":"quickstart/quickstart.html#prerequisites","title":"Prerequisites","text":"<p>Before you start installing PMM, verify that your system meets the compatibility requirements:</p> Verify system compatibility <ul> <li>System: Linux-compatible system with <code>sudo</code> privileges or <code>root</code> access</li> <li>Network: Internet connectivity to download PMM components</li> <li>Ports: Your system\u2019s firewall should allow TCP traffic on port <code>443</code></li> </ul>"},{"location":"quickstart/quickstart.html#install-pmm","title":"Install PMM","text":"<p>The Easy-install script only runs on Linux-compatible systems. To use it, run the command with <code>sudo</code> privileges or as <code>root</code>:</p> <ol> <li> <p>Download and install PMM using <code>cURL</code> or <code>wget</code>:</p> cURLwget <pre><code>curl -fsSL https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash\n</code></pre> <pre><code>wget -qO - https://raw.githubusercontent.com/percona/pmm/refs/heads/v3/get-pmm.sh | /bin/bash    \n</code></pre> </li> <li> <p>After the installation is complete, log into PMM with the default <code>admin:admin</code> credentials.</p> </li> </ol> What\u2019s happening under the hood? <p>This script does the following:</p> <ul> <li>Installs Docker if it is not installed on your system.</li> <li>Stops and renames any currently running PMM Docker container from <code>pmm-server</code> to <code>pmm-server-{timestamp}</code>. This old <code>pmm-server</code> container is not a recoverable backup.</li> <li>Pulls and runs the latest PMM Docker image.</li> </ul>"},{"location":"quickstart/quickstart.html#connect-database","title":"Connect database","text":"<p>Once PMM is set up, choose the database or the application that you want it to monitor:</p>  MySQL PostgreSQL MongoDB ProxySQL HAProxy <p>To connect a self-hosted MySQL database:</p> <ol> <li> <p>Create database account for PMM using the following command example. This creates a database user with name <code>pmm</code>, password <code>&lt;your_password&gt;</code>, and the necessary permissions:</p> <pre><code>CREATE USER 'pmm'@'127.0.0.1' IDENTIFIED BY '&lt;your_password&gt;' WITH MAX_USER_CONNECTIONS 10;\nGRANT SELECT, PROCESS, REPLICATION CLIENT, RELOAD, BACKUP_ADMIN ON *.* TO 'pmm'@'127.0.0.1';\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:    </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install the Percona Release Tool.  If this is already, make sure to update it to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission:</p> <ol> <li> <p>Install percona-release tool. If this is already installed, update percona-release to the latest version.</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MySQL database using Performance Schema:  </p> <pre><code>pmm-admin add mysql --query-source=perfschema --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> Alternative database connection workflows <p>While the default instructions above focus on connecting a self-hosted MySQL database, PMM offers the flexibility to connect to various MySQL databases, including Azure MySQL or Google Cloud MySQL. </p> <p>The PMM Client installation also comes with options: in addition to the installation via Package Manager described above, you can also install it as a Docker container or as a binary package. Explore alternative PMM Client installation options for more information.</p> <p>Additionally, if direct access to the database node isn\u2019t available, opt to Add remote instance via User Interface instead. </p> <p>To connect a PostgreSQL database: </p> <ol> <li> <p>Create a PMM-specific user for monitoring:</p> <pre><code>CREATE USER pmm WITH SUPERUSER ENCRYPTED PASSWORD '&lt;your_password&gt;';\n</code></pre> </li> <li> <p>Ensure that PMM can log in locally as this user to the PostgreSQL instance. To enable this, edit the <code>pg_hba.conf</code> file. If  not already enabled by an existing rule, add:</p> <pre><code>local   all             pmm                                md5\n# TYPE  DATABASE        USER        ADDRESS                METHOD\n</code></pre> </li> <li> <p>Set up the <code>pg_stat_monitor</code> database extension and configure your database server accordingly. </p> <p>If you need to use the <code>pg_stat_statements</code> extension instead, see Adding a PostgreSQL database and the <code>pg_stat_monitor</code> online documentation for details about available parameters.</p> </li> <li> <p>Set or change the value for <code>shared_preload_library</code> in your <code>postgresql.conf</code> file:</p> <pre><code>shared_preload_libraries = 'pg_stat_monitor'\n</code></pre> </li> <li> <p>Set up configuration values in your <code>postgresql.conf</code> file:</p> <pre><code>pg_stat_monitor.pgsm_query_max_len = 2048\n</code></pre> </li> <li> <p>In a <code>psql</code> session, run the following command to create the view where you can access the collected statistics. We recommend that you create the extension for the <code>postgres</code> database so that you can receive access to statistics from each database.</p> <pre><code>CREATE EXTENSION pg_stat_monitor;\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:  </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the PostgreSQL database:</p> <pre><code>pmm-admin add postgresql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions and advanced installation options, see Adding a PostgreSQL database.</p> <p>To connect a MongoDB database:</p> <ol> <li> <p>Run the following command in <code>mongo</code> shell to create a role with the monitoring permissions: </p> <pre><code>db.createRole({\n    \"role\": \"pmmMonitor\",\n    \"privileges\":\n    [\n       { \n         \"resource\": { \"db\": \"\", \"collection\": \"\" },\n         \"actions\": [ \"collStats\", \"dbHash\", \"dbStats\", \"indexStats\", \"find\", \"listIndexes\", \"listCollections\" ]\n       },\n       {\n         \"resource\": { \"db\": \"\", \"collection\": \"system.version\" },\n         \"actions\": [ \"find\" ]\n       },\n       {\n         \"resource\": { \"db\": \"\", \"collection\": \"system.profile\" },\n         \"actions\": [ \"dbStats\", \"collStats\", \"indexStats\" ]\n       }                  \n    ],\n    \"roles\": []\n})\n</code></pre> </li> <li> <p>Create a user and grant it the role created above:</p> MongoDB 8.0+MongoDB &lt;8.0 <p>MongoDB 8.0 introduced stricter security for direct shard access. For MongoDB 8.0 and later, the PMM user also requires the <code>directShardOperations</code> role to collect complete metrics from all cluster components.</p> <pre><code>  db.getSiblingDB(\"admin\").createUser({\n      \"user\": \"pmm\",\n      \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n      \"roles\": [\n          { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n          { \"db\": \"local\", \"role\": \"read\" },\n          { \"db\": \"admin\", \"role\": \"clusterMonitor\" },\n          { \"db\": \"admin\", \"role\": \"directShardOperations\" }\n      ]\n  })\n</code></pre> <pre><code>db.getSiblingDB(\"admin\").createUser({\n      \"user\": \"pmm\",\n      \"pwd\": \"&lt;SECURE_PASSWORD&gt;\",  // Replace with a secure password\n      \"roles\": [\n          { \"db\": \"admin\", \"role\": \"pmmMonitor\" },\n          { \"db\": \"local\", \"role\": \"read\" },\n          { \"db\": \"admin\", \"role\": \"clusterMonitor\" }\n      ]\n  })\n</code></pre> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the MongoDB database:</p> <pre><code>pmm-admin add mongodb --username=pmm --password=&lt;your_password&gt; --cluster &lt;your_cluster_or_replica_set_name&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Adding a MongoDB database for monitoring.</p> <p>To connect a ProxySQL service:</p> <ol> <li> <p>Configure a read-only account for monitoring using the <code>admin-stats_credentials</code> variable in ProxySQL.</p> </li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node:</p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Add the ProxySQL service:</p> <pre><code>pmm-admin add proxysql --username=pmm --password=&lt;your_password&gt;\n</code></pre> </li> </ol> <p>For detailed instructions, see Enable ProxySQL performance metrics monitoring.</p> <p>To connect an HAProxy service:</p> <ol> <li>Set up an HAproxy instance. </li> <li>Add the instance to PMM (default address is http://localhost:8404/metrics), and use the <code>haproxy</code> alias to enable HAProxy metrics monitoring.</li> <li> <p>To optimize server-side resources, install PMM Client via Package Manager on the database node: </p>  Debian-based Red Hat-based <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>wget https://repo.percona.com/apt/percona-release_latest.generic_all.deb\ndpkg -i percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>apt update\napt install -y pmm-client\n</code></pre> </li> </ol> <p>Install the following with <code>root</code> permission: </p> <ol> <li> <p>Install percona-release tool.  If this is already installed, update percona-release to the latest version:</p> <pre><code>yum install -y https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the PMM client repository:</p> <pre><code>percona-release enable pmm3-client release\n</code></pre> </li> <li> <p>Install the PMM Client package:</p> <pre><code>yum install -y pmm-client\n</code></pre> </li> </ol> </li> <li> <p>Register PMM Client:</p> <pre><code>pmm-admin config --server-insecure-tls --server-url=https://admin:admin@X.X.X.X:443\n</code></pre> </li> <li> <p>Run the command below, specifying the `listen-port`` as the port number where HAProxy is running. (This flag is mandatory.)</p> <pre><code>pmm-admin add haproxy --listen-port=8404\n</code></pre> </li> </ol> <p>For detailed instructions and more information on the command arguments, see the HAProxy topic.</p>"},{"location":"quickstart/quickstart.html#check-database-monitoring-results","title":"Check database monitoring results","text":"<p>After installing PMM and connecting the database, go to the database\u2019s Instance Summary dashboard. This shows essential information about your database performance and an overview of your environment.</p> <p>For more information, see PMM Dashboards.</p>"},{"location":"quickstart/quickstart.html#next-steps","title":"Next steps","text":"<ul> <li>Configure PMM via the interface</li> <li>Manage users in PMM</li> <li>Set up roles and permissions</li> <li>Back up and restore data in PMM</li> </ul>"},{"location":"reference/index.html","title":"PMM Architecture","text":"<p>PMM is a client/server application built by Percona comprising its own and third-party components and tools.</p> <p></p>"},{"location":"reference/index.html#pmm-server","title":"PMM Server","text":"<p>PMM Server is the heart of PMM. It receives data from clients, collects it, and stores it. Metrics are drawn as tables, charts and graphs within dashboards, each a part of the web-based user interface.</p>"},{"location":"reference/index.html#pmm-client","title":"PMM Client","text":"<p>PMM Client is a collection of agents and exporters that run on the host being monitored.</p> <p>PMM Client runs on every database host or node you want to monitor. The client collects server metrics, general system metrics, query analytics and sends it to the server. Except when monitoring AWS RDS instances, a PMM Client must be running on the host to be monitored.</p>"},{"location":"reference/index.html#percona-platform","title":"Percona Platform","text":"<p>Percona Platform provides value-added services for PMM.</p>"},{"location":"reference/index.html#pmm-context","title":"PMM context","text":"<p>The PMM Client package provides:</p> <ul> <li>Exporters for each database and service type. When an exporter runs, it connects to the database or service instance, runs the metrics collection routines, and sends the results to PMM Server.</li> <li><code>pmm-agent</code>: Run as a daemon process, it starts and stops exporters when instructed.</li> <li><code>vmagent</code>: A VictoriaMetrics daemon process that sends metrics data (pushes) to PMM Server.</li> </ul> <p>The PMM Server package provides:</p> <ul> <li><code>pmm-managed</code></li> <li>Query Analytics</li> <li>Grafana</li> <li>VictoriaMetrics</li> </ul>"},{"location":"reference/index.html#pmm-server_1","title":"PMM Server","text":"<p>PMM Server includes the following tools:</p> <ul> <li> <p>Query Analytics (QAN) enables you to analyze database query performance over periods of time. In addition to the client-side QAN agent, it includes the following:</p> <ul> <li>QAN API is the back-end for storing and accessing query data collected by the QAN agent running on a PMM Client.</li> <li>QAN App is a web application for visualizing collected Query Analytics data, which is part of the PMM Server\u2019s UI.</li> </ul> </li> <li> <p>Metrics Monitor provides a historical view of metrics that are critical to a MySQL or MongoDB server instance. It includes the following:</p> </li> <li> <p>VictoriaMetrics, a scalable time-series database. </p> </li> <li>ClickHouse is a third-party column-oriented database that facilitates the Query Analytics functionality.</li> <li>Grafana is a third-party dashboard and graph builder for visualizing data aggregated (by VictoriaMetrics or Prometheus) in an intuitive web interface.</li> <li>Percona Dashboards is a set of dashboards for Grafana developed by Percona.</li> </ul>"},{"location":"reference/index.html#pmm-client_1","title":"PMM Client","text":"<p>The PMM Client package consists of the following:</p> <ul> <li> <p><code>pmm-admin</code> is a command-line tool for managing PMM Client, for example, adding and removing database instances that you want to monitor. (Read more).</p> </li> <li> <p><code>pmm-agent</code> is a client-side component of a minimal command-line interface, which is a central entry point in charge of bringing the client functionality: it carries on client\u2019s authentication, gets the client configuration stored on the PMM Server, manages exporters and other agents.</p> </li> <li> <p><code>node_exporter</code> is an exporter that collects general system metrics.</p> </li> <li> <p><code>mysqld_exporter</code> is an exporter that collects MySQL server metrics.</p> </li> <li> <p><code>mongodb_exporter</code> is an exporter that collects MongoDB server metrics.</p> </li> <li> <p><code>postgres_exporter</code> is an exporter that collects PostgreSQL performance metrics.</p> </li> <li> <p><code>proxysql_exporter</code> is an exporter that collects ProxySQL performance metrics.</p> </li> <li> <p><code>rds_exporter</code> is an exporter that collects Amazon RDS performance metrics.</p> </li> <li> <p><code>azure_database_exporter</code> is an exporter that collects Azure database performance metrics.</p> </li> </ul> <p>To make data transfer from PMM Client to PMM Server secure, all exporters are able to use SSL/TLS encrypted connections, and their communication with PMM Server is protected by the HTTP basic authentication.</p> <p></p>"},{"location":"reference/copyright.html","title":"Copyright and licensing information","text":""},{"location":"reference/copyright.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Monitoring and Management documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"reference/faq.html","title":"FAQ","text":""},{"location":"reference/faq.html#how-can-i-contact-the-developers","title":"How can I contact the developers?","text":"<ul> <li>Community forum.</li> <li>PMM project in JIRA.</li> </ul>"},{"location":"reference/faq.html#what-are-the-minimum-system-requirements","title":"What are the minimum system requirements?","text":"<p>See our detailed guides:</p> <ul> <li>PMM hardware and system requirements for complete specifications</li> <li>Setting up PMM Server for server installation  </li> <li>Setting up PMM Client for client setup</li> </ul> <p>Quick reference for typical deployment (up to 30 nodes): - Server:     - CPU: 4 cores (must support SSE4.2)     - Memory: 8 GB     - Storage: 100 GB (approximately 1 GB per node per week) - Client:     - Storage: 100 MB     - Supports x86_64 and ARM64 architectures</p> <p>Note</p> <p>For larger deployments (200+ nodes) or longer retention periods, see our Hardware and system requirements for detailed sizing recommendations.</p>"},{"location":"reference/faq.html#how-can-i-upgrade-from-version-2","title":"How can I upgrade from version 2?","text":"<p>PMM 3 introduces significant architectural changes that require gradual transition from PMM 2. For detailed instructions, see Upgrade from PMM2.</p>"},{"location":"reference/faq.html#why-does-the-pmm-installation-script-fail-during-docker-installation","title":"Why does the PMM installation script fail during Docker installation?","text":"<p>If you encounter errors such as <code>ERROR: Unsupported distribution</code> when running the, follow these steps:</p> <ol> <li>Install Docker manually.</li> <li>Run the PMM Easy-install script again.</li> </ol>"},{"location":"reference/faq.html#retention","title":"Retention","text":"<p>To control data retention, go to PMM Configuration &gt; Settings &gt; Advanced Settings &gt; Data retention to adjust the value in days.</p> <p>See also</p> <p>Configure data retention</p>"},{"location":"reference/faq.html#how-are-pmm-server-logs-rotated","title":"How are PMM Server logs rotated?","text":"<p>PMM Server embeds multiple components, like Victoria Metrics, Query Analytics, Grafana, <code>managed</code>, PostgreSQL, ClickHouse, etc. (components). All PMM Server component logs are rotated by <code>supervisord</code>. The components\u2019 log rotation settings are stored in <code>*.ini</code> files within the <code>/etc/supervisord.d</code> directory. Those settings define both the maximum size of a log file and the number of log files to keep. The log rotation takes place once the log file reaches its maximum size.</p>"},{"location":"reference/faq.html#what-privileges-are-required-to-monitor-a-mysql-instance","title":"What privileges are required to monitor a MySQL instance?","text":"<pre><code>SELECT, PROCESS, SUPER, REPLICATION CLIENT, RELOAD\n</code></pre> <p>See also</p> <p>Setting Up/Client/MySQL.</p>"},{"location":"reference/faq.html#can-i-monitor-multiple-service-instances","title":"Can I monitor multiple service instances?","text":"<p>Yes.</p> <p>You can add multiple instances of MySQL or any other service to be monitored from the same PMM Client.</p> <p>To do this, you provide a unique port and IP address, or a socket for each instance, and specify a unique name for each. (If a name is not provided, PMM uses the name of the PMM Client host.)</p> <p>For example, to add MySQL monitoring for two local MySQL servers:</p> <pre><code>pmm-admin add mysql --username root --password root instance-01 127.0.0.1:3001\npmm-admin add mysql --username root --password root instance-02 127.0.0.1:3002\n</code></pre> <p>See also</p> <p><code>pmm-admin add mysql</code></p>"},{"location":"reference/faq.html#can-i-rename-instances","title":"Can I rename instances?","text":"<p>Yes, by removing and re-adding with a different name.</p> <p>When you remove a monitoring service, previously collected data remains available in Grafana.  However, the metrics are tied to the instance name.  So if you add the same instance back with a different name, it will be considered a new instance with a new set of metrics.  So if you are re-adding an instance and want to keep its previous data, add it with the same name.</p>"},{"location":"reference/faq.html#can-i-add-an-aws-rds-mysql-or-aurora-mysql-instance-from-a-non-default-aws-partition","title":"Can I add an AWS RDS MySQL or Aurora MySQL instance from a non-default AWS partition?","text":"<p>By default, the RDS discovery works with the default <code>aws</code> partition. But you can switch to special regions, like the GovCloud one, with the alternative AWS partitions (e.g. <code>aws-us-gov</code>) adding them to the Settings via the PMM Server API.</p> <p></p> <p>To specify other than the default value, or to use several, use the JSON Array syntax: <code>[\"aws\", \"aws-cn\"]</code>.</p>"},{"location":"reference/faq.html#what-resolution-is-used-for-metrics","title":"What resolution is used for metrics?","text":"<p>The default values (in seconds):</p> Preset Low Medium High Rare 300 180 60 Standard 60 10 5 Frequent 30 5 1 Custom (defaults) 60 10 5 <p>See also</p> <p>Metrics resolution</p>"},{"location":"reference/faq.html#how-do-i-set-up-alerting","title":"How do I set up Alerting?","text":"<p>When a monitored service metric reaches a defined threshold, PMM Server can trigger alerts for it using embedded Grafana Alerting functionality.</p> <p>For this, you must configure alerting rules that define conditions under which an alert should be triggered, and the contact points used to send the alert (e.g. email).</p> <p>Percona templated alerts enable you to create alerts based on built-in or custom templates to simplify the alert setup process. Grafana managed alerts allows attaching rules to your dashboard panel and enables you to create more sophisticated alerting rules. In addition, it can be easier to manage installations with a large number of hosts. This additional flexibility comes at the expense of simplicity.</p> <p>See also</p> <p>Grafana Alerting</p>"},{"location":"reference/faq.html#how-do-i-use-a-custom-prometheus-configuration-file","title":"How do I use a custom Prometheus configuration file?","text":"<p>Normally, PMM Server fully manages the Prometheus configuration file.</p> <p>However, some users may want to change the generated configuration to add additional scrape jobs, configure remote storage, etc.</p> <p>From version 2.4.0, when <code>pmm-managed</code> starts the Prometheus file generation process, it tries to load the <code>/srv/prometheus/prometheus.base.yml</code> file first, to use it as a base for the <code>prometheus.yml</code> file.</p> <p>The <code>prometheus.yml</code> file can be regenerated by restarting the PMM Server container, or by using the <code>SetSettings</code> API call with an empty body.</p> <p>See also</p> <ul> <li>API</li> <li>Percona blog: Extending PMM\u2019s Prometheus Configuration</li> </ul>"},{"location":"reference/faq.html#how-to-troubleshoot-an-upgrade","title":"How to troubleshoot an upgrade?","text":"<p>See Troubleshoot update.</p>"},{"location":"reference/faq.html#what-are-my-login-credentials-when-i-try-to-connect-to-a-prometheus-exporter","title":"What are my login credentials when I try to connect to a Prometheus Exporter?","text":"<ul> <li>User name: <code>pmm</code></li> <li>Password: Agent ID</li> </ul> <p>PMM protects an exporter\u2019s output from unauthorized access by adding an authorization layer. To access an exporter, you can use <code>pmm</code> as a user name and the Agent ID as a password. You can find the Agent ID corresponding to a given exporter by running <code>pmm-admin list</code>.</p> <p>See also</p> <p><code>pmm-admin list</code></p>"},{"location":"reference/faq.html#how-to-provision-pmm-server-with-non-default-admin-password","title":"How to provision PMM Server with non-default admin password?","text":"<p>Currently, there is no API available to change the <code>admin</code> password at deployment time. However, you can use the <code>GF_SECURITY_ADMIN_PASSWORD</code> environment variable to set the password for the default <code>admin</code> user.</p> <pre><code>docker run -d --name pmm-server \\\n  -e GF_SECURITY_ADMIN_PASSWORD=\"your_secure_password\" \\\n  -p 443:8443 \\\n  percona/pmm-server:latest\n</code></pre>"},{"location":"reference/faq.html#how-to-change-the-pmm-password-for-the-default-admin-user","title":"How to change the PMM password for the default admin user?","text":"<p>Once PMM has started, you can use either of the following to change the password  (assuming your container is named <code>pmm-server</code>):</p> <ul> <li>a helper script <code>change-admin-password</code>:</li> </ul> <pre><code>docker exec -t pmm-server change-admin-password your_secure_password\n</code></pre> <ul> <li>or a code snippet:</li> </ul> <pre><code>PMM_PASSWORD=\"mypassword\"\necho \"Waiting for PMM to initialize to set password...\"\nuntil [ $(docker inspect -f '{{.State.Health.Status}}' pmm-server) = \"healthy\" ]; do sleep 1; done\ndocker exec -t pmm-server bash -c \u00a0\"grafana cli --homepath /usr/share/grafana --config=/etc/grafana/grafana.ini admin reset-admin-password $PMM_PASSWORD\"\n</code></pre>"},{"location":"reference/faq.html#how-to-use-a-non-default-listen-port-for-pmm-admin","title":"How to use a non-default listen-port for pmm-admin?","text":"<p>If you configure the PMM agent to use a non-default listen-port, for pmm-admin to communicate with the agent, use the global flag <code>--pmm-agent-listen-port=LISTEN_PORT</code>.</p> <pre><code>--pmm-agent-listen-port=LISTEN_PORT\n</code></pre> <p>Example: To use the listen-port 8000</p> <pre><code>pmm-admin --pmm-agent-listen-port=8000 add postgresql --username=pmm-agent --password=pmm-agent-password --query-source=pgstatmonitor nameofpostgres\n</code></pre> <p>If you are using OVF/AMI, you can change the default password through SSH by using the following command:</p> <pre><code>change-admin-password &lt;new_password&gt;\n</code></pre>"},{"location":"reference/faq.html#how-does-pmm-handle-personal-and-confidential-data","title":"How does PMM handle personal and confidential data?","text":"<p>Read our Privacy Policy to learn how PMM manages personal and confidential data. More technical details can be found in Data handling in PMM.</p>"},{"location":"reference/faq.html#why-am-i-getting-a-user-already-exists-error-when-logging-back-into-pmm","title":"Why am I getting a \u201cUser already exists\u201d error when logging back into PMM?","text":"<p>Following CVE fix 2023-3128 in the 2.38 release, PMM increases security by only allowing authentications based on the unique user ID provided by the identity provider.</p> <p>If you are trying to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, PMM will show this error on second and subsequent authentications.</p> <p>Solution: we recommend logging into PMM using a Percona Account, as this is a highly secure authentication method. Workaround: if you need to log into PMM via a third-party authentication provider which doesn\u2019t support a unique ID field, you can use the following workaround to log into PMM:</p> <ul> <li>pass the <code>GF_AUTH_OAUTH_ALLOW_INSECURE_EMAIL_LOOKUP=1</code> environment variable to the PMM container OR</li> <li>set the <code>oauth_allow_insecure_email_lookup</code> config key in the auth section of the <code>grafana.ini</code> file. Keep in mind that any changes you make to this file are lost when upgrading PMM, so make sure to manually update this file after each upgrade.</li> </ul> <p>Important</p> <p>We do not recommend using the above workaround for an extended period. Instead, ensure user uniqueness across multiple identity providers, while also encouraging your identity provider to support a unique ID field, or choose a provider who does.</p>"},{"location":"reference/glossary.html","title":"Glossary","text":""},{"location":"reference/glossary.html#glossary","title":"Glossary","text":""},{"location":"reference/glossary.html#annotation","title":"Annotation","text":"<p>A way of showing a mark on dashboards signifying an important point in time.</p>"},{"location":"reference/glossary.html#dimension","title":"Dimension","text":"<p>In the Query Analytics dashboard, to help focus on the possible source of performance issues, you can group queries by dimension, one of: Query, Service Name, Database, Schema, User Name, Client Host</p>"},{"location":"reference/glossary.html#ebs","title":"EBS","text":"<p>Amazon\u2019s Elastic Block Store.</p>"},{"location":"reference/glossary.html#fingerprint","title":"Fingerprint","text":"<p>A normalized statement digest\u2014a query string with values removed that acts as a template or typical example for a query.</p>"},{"location":"reference/glossary.html#iam","title":"IAM","text":"<p>Identity and Access Management (for Amazon AWS).</p>"},{"location":"reference/glossary.html#mm","title":"MM","text":"<p>Metrics Monitor.</p>"},{"location":"reference/glossary.html#numa","title":"NUMA","text":"<p>Non-Uniform Memory Access.</p>"},{"location":"reference/glossary.html#pem","title":"PEM","text":"<p>Privacy Enhanced Mail.</p>"},{"location":"reference/glossary.html#qps","title":"QPS","text":"<p>Queries Per Second. A measure of the rate of queries being monitored.</p>"},{"location":"reference/glossary.html#query-analytics","title":"Query Analytics","text":"<p>Component of PMM Server that enables you to analyze MySQL query performance over periods of time.</p>"},{"location":"reference/glossary.html#advisors","title":"Advisors","text":"<p>Automated checks that you can run against connected databases to identify any potential security threats, configuration problems, performance concerns, policy non-compliance issues etc. </p>"},{"location":"reference/glossary.html#technical-preview","title":"Technical Preview","text":"<p>Releases intended for public preview and feedback, but with no support or service level agreement (SLA). Should not be used on production or business-critical systems. May contain breaking changes to UI, API, CLI. (Read more.)</p>"},{"location":"reference/glossary.html#vg","title":"VG","text":"<p>Volume Group.</p>"},{"location":"reference/nomad.html","title":"Configure Nomad","text":"<p>Percona Monitoring and Management (PMM) includes HashiCorp Nomad to enable future extensibility and enhanced service capabilities.</p> <p>Nomad is a workload orchestrator designed to deploy and manage containers and non-containerized applications. In PMM, Nomad provides the underlying infrastructure to:</p> <ul> <li>improve resource allocation across monitoring components</li> <li>enable future PMM extensibility </li> <li>manage distributed monitoring agents more efficiently</li> </ul> <p>Nomad is disabled by default in PMM and has no impact on system performance when not enabled. </p>"},{"location":"reference/nomad.html#prerequisites","title":"Prerequisites","text":"<p>Before enabling Nomad, check that PMM Server has a public address configured under PMM Configuration &gt; Advanced Settings. This is required for Nomad to function properly and enable communication between Nomad components.</p>"},{"location":"reference/nomad.html#enable-nomad","title":"Enable Nomad","text":"<p>If you\u2019re an advanced user who needs Nomad for specific use cases, follow these steps to enable Nomad in PMM:</p> <ol> <li> <p>Start PMM Server with the <code>PMM_ENABLE_NOMAD</code> environment variable:    <pre><code>-e PMM_ENABLE_NOMAD=1\n</code></pre></p> </li> <li> <p>Expose the Nomad port:    <pre><code>-p 4647:4647\n</code></pre></p> </li> <li> <p>Go to PMM\u2019s Advanced Settings and set the public address.</p> </li> </ol> Docker run command <pre><code>docker run -d \\\n-e PMM_ENABLE_NOMAD=1 \\\n-p 4647:4647 \\\n-p 443:8443 \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre>"},{"location":"reference/nomad.html#disable-nomad","title":"Disable Nomad","text":"<p>To disable Nomad:</p> <pre><code>-e PMM_ENABLE_NOMAD=0\n</code></pre> <p>When Nomad is disabled on the PMM Server, the Nomad agent on PMM Clients will automatically stop.</p>"},{"location":"reference/nomad.html#system-requirements","title":"System requirements","text":"<p>When Nomad is enabled, PMM Client nodes have the following additional requirements:</p> <ul> <li><code>iproute</code> package must be installed</li> <li>access to cgroup must be available</li> </ul>"},{"location":"reference/nomad.html#verification","title":"Verification","text":"<p>To verify that Nomad is running correctly:</p> <ol> <li> <p>Check that the Nomad API is available at:    <pre><code>https://&lt;PMM_SERVER_URL&gt;/nomad/v1/nodes\n</code></pre></p> </li> <li> <p>Confirm that Nomad agents appear in the node list.</p> </li> </ol>"},{"location":"reference/nomad.html#internal-architecture","title":"Internal architecture","text":"<p>When enabled, PMM runs the following Nomad components:</p> <ul> <li>Nomad server on PMM Server - manages the cluster and schedules workloads</li> <li>Nomad client on PMM Server - executes jobs (workloads) on remote instances</li> <li>Nomad client on PMM Clients - executes distributed workloads</li> </ul> <p>Communication between these components is secured and managed automatically when configured with the proper public address.</p>"},{"location":"reference/nomad.html#api-access","title":"API access","text":"<p>The Nomad API is available through the PMM Server\u2019s HTTPS port via the <code>/nomad</code> prefix. This allows you to access Nomad endpoints without requiring a separate port for the Nomad API.</p> <ul> <li>Nomad endpoints are only available to users with admin privileges</li> <li>All Nomad API endpoints are accessible under the <code>/nomad</code> path</li> <li>The standard Nomad API documentation applies, but all requests must use the <code>/nomad</code>prefix</li> </ul> Example API request <p><code>https://&lt;PMM_SERVER_URL&gt;/nomad/v1/jobs</code></p>"},{"location":"reference/nomad.html#future-compatibility","title":"Future compatibility","text":"<p>Nomad is included in PMM to support future extensibility features. Nomad will remain within PMM to provide infrastructure for upcoming enhancements and to deliver improved services for existing Percona customers.</p>"},{"location":"reference/nomad.html#related-links","title":"Related links","text":"<ul> <li>Nomad documentation</li> </ul>"},{"location":"reference/personal_data_handling.html","title":"Data handling in PMM","text":"<p>The following questions are being answered related to personal and confidential data handling in PMM:</p> <ol> <li> <p>Which type of data is transmitted?</p> Data collection source Data collected DB host to PMM Database performance metrics  SQL query examples for query analytics (optional). PMM to DB Host DSN and credentials for database access. A separate DB user is used (limited access) to retrieve metrics from the database. DB Host to S3 compatible storage location Database backup - optional if PMM Administrator configures it with Public Cloud (AWS, GCP, etc) as a possible storage location. PMM Server to Percona Cloud Telemetry data is collected.  PMM Server collects varying amounts of data from version to version, and no personal or confidential information is collected. See Telemetry for details on the data being transmitted. </li> <li> <p>Where is the data obtained from the DB host transmitted?</p> <p>All data gathered from the DB Host is transmitted to the PMM Server. It is possible to transmit DB backups to Cloud S3 storage (optional). </p> <p>Telemetry data is sent to Percona Cloud. This does not contain any sensitive or personally identifiable information.</p> </li> <li> <p>What is the purpose and nature of data processing?</p> <p>As per our Privacy Policy, the data collection purposes are to provide the services and product enhancements.</p> <p>Although, PMM does not collect nor transfer personal data explicitly, in case query analytics is enabled and query examples collection is not disabled, we gather SQL query examples with real data and personal data may appear there if it is stored in DB.  All QAN data always remains within the PMM Server, and is never transmitted anywhere else.</p> </li> <li> <p>What is the frequency and volume of processed data?</p> <p>By default, metrics data is gathered every 5, 10 or 60 minutes. In case Query Analytics is enabled and SQL query examples are gathered every minute, we don\u2019t use any special processing for personal or confidential data. PMM Server has no clue about the meaning of the data inside the SQL query.</p> <p>So it is processed as usual, which is to store inside the PMM Server and present on the PMM UI by request.</p> <p>Other than email addresses for Grafana users, PMM does not directly ask or collect any other personal data. For more information about the telemetry data that is collected, please refer to the Percona Privacy Policy. </p> </li> <li> <p>What applications or third parties can access the data created and processed by the cloud service?</p> <p>Third parties or other applications are not able to access the data gathered by the PMM Server.</p> </li> <li> <p>Is Personal Data processed for other applications or parties, and should the data that is processed in the cloud service be available to other applications or 3<sup>rd</sup> parties?</p> <p>PMM Server doesn\u2019t pass any gathered, personal or confidential data to any third party or other applications nor to Percona Cloud.</p> </li> <li> <p>How safe is the encryption? </p> <p>It\u2019s a must to encrypt all connections to and from the cloud including the data in the cloud storage and PMM does so by default. </p> <p>We use TLS (v1.2 at least) for connections between:</p> <ul> <li> <p>Database host to PMM Server (optionally, depending on user configuration)</p> </li> <li> <p>PMM Server to Percona Cloud</p> </li> <li>PMM Server to remote database (optionally, depending on user configuration)</li> <li>End-user to PMM Server web interface/api (self-signed by default)</li> </ul> <p>For more information about Percona security posture, please refer to our Trust Center here.</p> </li> </ol>"},{"location":"reference/pmm_components_and_versions.html","title":"PMM components and versions","text":"<p>The following table lists all the PMM client/server components and their versions:</p> PMM client/server component Version Documentation Location on GitHub Grafana 11.6.1* Grafana documentation Github Grafana VictoriaMetrics 1.114.0 VictoriaMetrics documentation Github VictoriaMetrics Nginx 1.20.1 Nginx documentation Github Nginx Percona Distribution for PostgreSQL 14.5 Percona Distribution for PostgreSQL 14 documentation Clickhouse 23.8.2.7 ClickHouse documentation Github ClickHouse PerconaToolkit 3.5.2 Percona Toolkit documentation Github Percona Toolkit MongoDB exporter 0.45.0 Github MongoDB Exporter MySQL exporter v0.17.2* MySQL Server Exporter Documentation Github MySQL Server Exporter PostgreSQL exporter v0.14.0* Github PostgreSQL Server Exporter RDS exporter 0.7.2 Github RDS Exporter Node exporter v1.8.2* Node Exporter Documentation Github Node Exporter Azure exporter 2.30.0* Github Azure Metrics Exporter * - Original upstream version along with some changes authored by Percona"},{"location":"reference/trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html","title":"Advanced Data Exploration","text":"<p>The Advanced Data Exploration dashboard provides detailed information about the progress of a single Prometheus metric across one or more hosts.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#view-actual-metric-values-gauge","title":"View actual metric values (Gauge)","text":"<p>A gauge is a metric that represents a single numerical value that can arbitrarily go up and down.</p> <p>Gauges are typically used for measured values like temperatures or current memory usage, but also \u201ccounts\u201d that can go up and down, like the number of running goroutines.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#view-metric-rate-of-change-counter","title":"View Metric Rate of Change (Counter)","text":"<p>A counter is a cumulative metric that represents a single numerical value that only ever goes up. A counter is typically used to count requests served, tasks completed, errors occurred, etc. Counters should not be used to expose current counts of items whose number can also go down, e.g. the number of currently running goroutines. Use gauges for this use case.</p>"},{"location":"reference/dashboards/dashboard-advanced-data-exploration.html#metric-rates","title":"Metric Rates","text":"<p>Shows the number of samples Per second stored for a given interval in the time series.</p> <p>This dashboard supports metrics related to NUMA. The names of all these metrics start with <code>node_memory_numa</code>.</p> <p></p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html","title":"CPU Utilization Details","text":""},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-utilization","title":"Overall CPU Utilization","text":"<p>The Overall CPU Utilization metric shows how much of the overall CPU time is used by the server. It has these components:</p> Max Core Utilization No description System This component the proportion of time the CPUs spent inside the Linux kernel for operations like context switching, memory allocation and queue handling. User This component is the time spent in the user space.  Normally, most of the MySQL CPU time is in user space. A high value of user time indicates a CPU bound workload. Softirq This component is the portion of time the CPU spent servicing software interrupts generated by the device drivers.  A high value of softirq may indicates a poorly configured device.  The network devices are generally the main source of high softirq values. Steal When multiple virtual machines share the same physical host, some virtual machines may be allowed to use more of their share of CPU and that CPU time is accounted as Steal by the virtual machine from which the time is taken. Iowait This component is the time the CPU spent waiting for disk IO requests to complete.  A high value of iowait indicates a disk bound load. Nice No description <p>In addition, sampling of the Max utilization of a single core is shown.</p> <p>This metric presents global values: while there may be a lot of unused CPU, a single core may be saturated.  Look at the Max Core Utilization to see if any core is reaching close to 100%.</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#current-cpu-threads-utilization","title":"Current CPU Threads Utilization","text":"<p>This shows the total utilization of each CPU core along with the average utilization of all CPU cores.  Watch for any core close to 100% utilization and investigate the root cause.</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#cpu-threads-frequency","title":"CPU Threads Frequency","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#current-cpu-cores-temperature","title":"Current CPU Cores Temperature","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-cpu-utilization-details.html#overall-cpu-threads-utilization-details","title":"Overall CPU Threads Utilization Details","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-disk-details.html","title":"Disk Details","text":""},{"location":"reference/dashboards/dashboard-disk-details.html#mount-point-usage","title":"mount point Usage","text":"<p>Shows the percentage of disk space utilization for every mount point defined on the system. Having some of the mount points close to 100% space utilization is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where the mount point is close to 100% consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#mount-point","title":"mount point","text":"<p>Shows information about the disk space usage of the specified mount point.</p> <p>Used is the amount of space used.</p> <p>Free is the amount of space not in use.</p> <p>Used+Free is the total disk space allocated to the mount point.</p> <p>Having Free close to 0 B is not good because of the risk of a \u201cdisk full\u201d error that can block one of the services or even cause a crash of the entire system.</p> <p>In cases where Free is close to 0 B consider removing unused files or expanding the space allocated to the mount point.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-latency","title":"Disk Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-operations","title":"Disk Operations","text":"<p>Shows amount of physical IOs (reads and writes) different devices are serving. Spikes in number of IOs served often corresponds to performance problems due to IO subsystem overload.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-bandwidth","title":"Disk Bandwidth","text":"<p>Shows volume of reads and writes the storage is handling. This can be better measure of IO capacity usage for network attached and SSD storage as it is often bandwidth limited.  Amount of data being written to the disk can be used to estimate Flash storage life time.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-load","title":"Disk Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows disk Utilization as percent of the time when there was at least one IO request in flight. It is designed to match utilization available in iostat tool. It is not very good measure of true IO Capacity Utilization. Consider looking at IO latency and Disk Load Graphs instead.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#avg-disks-operations-merge-ratio","title":"Avg Disks Operations Merge Ratio","text":"<p>Shows how effectively Operating System is able to merge logical IO requests into physical requests.  This is a good measure of the IO locality which can be used for workload characterization.</p>"},{"location":"reference/dashboards/dashboard-disk-details.html#disk-io-size","title":"Disk IO Size","text":"<p>Shows average size of a single disk operation.</p>"},{"location":"reference/dashboards/dashboard-env-overview.html","title":"Environment Overview","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Dashboard provides the user with a high-level view of all the environments in PMM.</p>"},{"location":"reference/dashboards/dashboard-environment-summary.html","title":"Environment Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>The Environment Summary Dashboard provides an at-a-glance view specific to the selected environment in PMM, including an overview of the services and nodes running in that environment.</p>"},{"location":"reference/dashboards/dashboard-haproxy-instance-summary.html","title":"HAProxy Instance Summary","text":""},{"location":"reference/dashboards/dashboard-home.html","title":"Home Dashboard","text":"<p>The Home Dashboard provides a high-level overview of your environment, such as the services, infrastructure, and critical issues (if any). It is the starting page of PMM from which you can open the tools of PMM and browse online resources.</p> <p>This Home Dashboard displays data that is organized in panels as given below.</p> <p></p>"},{"location":"reference/dashboards/dashboard-home.html#overview","title":"Overview","text":"<p>This panel lists all added hosts along with essential information about their performance. For each host, you can find the current values of the following metrics:</p> <ul> <li>Monitored DB Services</li> <li>Monitored DB Instances</li> <li>Monitored Nodes</li> <li>Memory Available</li> <li>Disk Reads</li> <li>Disk Writes</li> <li>Network IO</li> <li>DB Connections</li> <li>DB QPS</li> <li>Virtual CPUs</li> <li>RAM</li> <li>Host Uptime</li> <li>DB Uptime</li> <li>Advisors check</li> </ul> <p>This panel also displays the current version number. Use Upgrade to X.X.X version to upgrade to the most recent version of PMM.</p>"},{"location":"reference/dashboards/dashboard-home.html#anomaly-detection","title":"Anomaly Detection","text":"<p>The Anomaly Detection panel lists all the anomalies in your environment. Color-coded states on the panels provide a quick visual representation of the problem areas.</p> <p>The following anomalies are displayed on this panel:</p> <ul> <li>CPU anomalies (high as well as low)</li> <li>High CPU servers</li> <li>Low CPU servers</li> <li>Disk Queue anomalies</li> <li>High disk queue</li> <li>High Memory Used</li> </ul>"},{"location":"reference/dashboards/dashboard-home.html#command-center","title":"Command Center","text":"<p>You can find critical information such as CPU utlization, memory utilization, anomalies, read and write latency, etc., about your environment on the Command Center panel. </p> <p>The information is represented graphically on the Command Center panel. In this panel, the graphs for the last hour and the previous week are displayed adjacently, making it easy to identify the trends.</p> <p>The following information is displayed on the Command Center for the Top 20 nodes:</p> <ul> <li>CPU usage</li> <li>Disk queue</li> <li>Disk Write latency</li> <li>Disk Read latency</li> <li>Memory usage</li> </ul> <p>Command Center lists the </p>"},{"location":"reference/dashboards/dashboard-home.html#service-summary","title":"Service Summary","text":"<p>The Service Summary panel provides the following information for the services being monitored:</p> <ul> <li>DB connections</li> <li>DB QPS (Query per sec)</li> <li>DB uptime</li> </ul>"},{"location":"reference/dashboards/dashboard-memory-details.html","title":"Memory Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html","title":"MongoDB PBM Details dashboard","text":"<p>The MongoDB PBM Details dashboard offers an integrated view of your Percona Backup for MongoDB (PBM) environment directly within Percona Monitoring and Management (PMM).</p> <p>The dashboard consolidates key information\u2014such as backup configuration, status, performance metrics, and agent health\u2014into a single, easy-to-use interface.</p> <p>By accessing PBM insights directly from PMM, you can efficiently monitor and manage your MongoDB backups without switching between tools.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#backup-configured","title":"Backup Configured","text":"<p>Shows whether backups are properly configured for your MongoDB environment. A green \u201cYes\u201d indicates that PBM is properly set up and functioning, while a No in red signals that backups are not configured. </p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#pitr-enabled","title":"PITR Enabled","text":"<p>Displays whether Point-in-Time Recovery (PITR) is enabled for your MongoDB environment. A green Yes confirms PITR is active, while a No in red indicates this feature is not currently enabled.</p> <p>PITR allows for more granular recovery options, enabling restoration to any point in time rather than just to specific backup points. </p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#agent-status","title":"Agent Status","text":"<p>This panel monitors the operational status of each PBM agent connected to your MongoDB cluster nodes using a color-coded timeline visualization.</p> <p>Each replica set node (e.g., <code>rs101:27017</code>, <code>rs102:27017</code>, <code>rs103:27017</code>) is shown with an OK status in green when the PBM agent is functioning correctly. This allows you to quickly identify any agents that may be experiencing issues and potentially affecting backup operations.</p> <p>Arbiter nodes, whether in replica sets or sharded clusters, will appear with a Fail status. This is because arbiters are designed only to participate in elections and do not store data, so they do not and cannot run PBM agents. In future updates, this status will be clarified with a message such as \u201cArbiter node is not supported\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#size-bytes","title":"Size Bytes","text":"<p>Displays the size of your MongoDB backups in a bar chart format. </p> <p>The panel shows the exact size of each backup (e.g., 10.7 MB), helping you track storage requirements and identify any unusual changes in backup size that might indicate problems with your data or backup process.</p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#duration","title":"Duration","text":"<p>Shows how long each backup operation takes to complete, displayed in seconds.</p> <p>By monitoring backup times, you can quickly pinpoint any backups that are taking an unusually long time to complete, which may signal underlying performance problems within your MongoDB setup.</p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#backup-history","title":"Backup History","text":"<p>Provides a tabular view of recent backup operations with columns for Name (timestamp of the backup) and Status (Done, Error, etc.). </p> <p>This historical record helps you verify that scheduled backups are running successfully and lets you quickly identify any failed backup operations that may require attention.</p> <p>The current status reporting in this panel may not yet capture the full range of error states available in PBM\u2019s native tools (including \u201cstuck\u201d or \u201cincompatible\u201d backups). This will be improved with an upcoming release to provide a more complete picture of your backup status.</p>"},{"location":"reference/dashboards/dashboard-mongodb-PBM-details.html#last-successful-backup","title":"Last Successful Backup","text":"<p>Shows details of the most recent successful backup operation, including its timestamp. This gives you confidence in your recovery capabilities by confirming when your last good backup was taken, ensuring you know your current recovery point objective (RPO) status.</p> <p>This dashboard works with both replica sets and sharded clusters, providing unified visibility into your MongoDB backup infrastructure. </p> <p>To use it effectively, select the appropriate environments, clusters, and replica sets using the filters at the top of the dashboard.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html","title":"MongoDB Sharded Cluster Summary","text":"<p>This dashboard provides a comprehensive view of your MongoDB sharded cluster\u2019s performance, health, and resource utilization. It displays essential data for individual nodes organized by component type (shards, config servers, and mongos routers), offering insights into:</p> <ul> <li>shard distribution and balance</li> <li>query operations and performance</li> <li>resource utilization (CPU, memory, disk, network)</li> <li>replication status across the cluster</li> <li>component-specific health indicators</li> </ul> <p>For MongoS (Router) specific monitoring, see the MongoDB Router Summary dashboard.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#overview","title":"Overview","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#feature-compatibility-version","title":"Feature Compatibility Version","text":"<p>Displays the Feature Compatibility Version (FCV) currently active in your MongoDB deployment. The FCV controls which database features are available and affects data file format compatibility between MongoDB versions.</p> <p>This panel helps you confirm that your cluster is running the expected FCV\u2014especially useful after upgrades, when the FCV may lag behind the MongoDB binary version.</p> <p>Monitoring FCV is important when planning upgrades or downgrades, as setting a newer FCV can enable advanced features but may prevent rolling back to older MongoDB versions.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#qps-of-services-in-shard","title":"QPS of Services in Shard","text":"<p>Displays the Queries Per Second (QPS) for each shard and the config server replica set in your MongoDB cluster. It shows the rate of operations (excluding commands) for each component, helping you quickly assess the query load distribution across your sharded environment.</p> <p>The chart uses the most recent non-null value and updates based on your selected time interval. This visualization allows you to easily identify which shards are handling the most queries and spot any potential load imbalances. </p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#shards","title":"Shards","text":"<p>Reports the number of shards in your MongoDB cluster. The number of shards indicates how your data is distributed across the cluster, which is crucial for understanding your database\u2019s scalability and performance.</p> <p>A shard contains a subset of sharded data for a sharded cluster. Together, the cluster\u2019s shards hold the entire data set for the cluster.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#mongos","title":"Mongos","text":"<p>Number of mongos routers registered as part of the cluster.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#draining-shards","title":"Draining Shards","text":"<p>Displays a single number representing the current count of shards that are in the process of being drained from your MongoDB cluster.</p> <p>When you run <code>removeShard</code>, MongoDB drains the shard by using the balancer to move the shard\u2019s chunks to other shards in the cluster. Once the shard is drained, MongoDB removes the shard from the cluster. The number shown here indicates how many shards are currently undergoing this draining process.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#dbs","title":"DBs","text":"<p>Shows the number of user-created databases in your MongoDB sharded cluster. It provides a quick view of how many databases your cluster is managing, updating every 5 minutes.</p> <p>This simple count helps you track database growth and understand the scale of your MongoDB deployment at a glance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#sharded-collections","title":"Sharded Collections","text":"<p>Provides a quick view of how many collections in your MongoDB cluster are sharded. This is an important metric for understanding the scale and distribution of your data across the sharded cluster. </p> <p>A higher number indicates more collections are distributed across multiple shards, which can improve performance for large datasets. However, it also implies more complex data management.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#balancer-enabled","title":"Balancer Enabled","text":"<p>Background process that monitors the number of chunks on each shard and whether the MongoDB Balancer is currently enabled in your sharded cluster.</p> <p>The balancer is crucial for maintaining an even distribution of chunks across shards, so knowing its status is important for cluster health and performance.</p> <p>A YES indicates that the balancer is active and working to keep your data evenly distributed, while a NO might indicate a manual override or a potential issue that needs investigation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#total-amount-of-chunks","title":"Total amount of Chunks","text":"<p>Provides a quick view of the total number of chunks in your sharded MongoDB cluster to give you an idea of how your data is distributed across the cluster.</p> <p>A high number of chunks could indicate a well-distributed dataset, while a sudden increase might suggest increased data volume or changes in your sharding strategy.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#last-election","title":"Last Election","text":"<p>Provides a quick view of how long it has been since the last election in your MongoDB replica set.</p> <p>Elections occur when a new primary node needs to be chosen, which can happen during normal operations (like planned maintenance) or due to issues (like a primary node failure).</p> <p>A very recent election might indicate a recent change or issue in your cluster that warrants investigation, while a long time since the last election suggests stability in the primary node assignment.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#chunks-distribution","title":"Chunks distribution","text":"<p>Displays the distribution of chunks across different shards in a MongoDB cluster as a series of horizontal bars. It updates every minute, showing the percentage of total chunks each shard holds.</p> <p>Use this to quickly identify any imbalances in data distribution among shards, which is crucial for maintaining optimal performance in a sharded MongoDB setup.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#command-operations","title":"Command Operations","text":"<p>Provides a comprehensive overview of MongoDB operation rates across your deployment. It displays the frequency of primary operations (query, insert, update, delete, and getmore), replicated operations on secondary nodes, and document deletions by Time-To-Live (TTL) indexes. </p> <p>By aggregating data from selected environments, clusters, and replica sets over customizable time intervals, the graph enables you to quickly identify workload patterns, potential replication lags, and the impact of automated data cleanup processes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#top-hottest-collections-by-read","title":"Top Hottest Collections by Read","text":"<p>Displays the five MongoDB collections with the highest read rates. It shows the number of read operations per second for each collection, aggregated across your selected environment and cluster. </p> <p>The bar gauge visualization helps quickly identify which collections are experiencing the most read activity, useful for performance monitoring and resource planning. Data is updated regularly to reflect recent changes in read patterns.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#query-execution-times","title":"Query execution times","text":"<p>Shows the average time taken for MongoDB to execute read, write, and other operations. It displays latency in microseconds over time, helping you spot performance trends or issues across different operation types. </p> <p>Use this to quickly identify any unusual delays in database operations.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#top-hottest-collections-by-write","title":"Top Hottest Collections by Write","text":"<p>Displays the five MongoDB collections with the highest write activity. It shows the number of write operations (inserts, updates, and deletes) per second for each collection, aggregated across your selected environment and cluster. </p> <p>The bar gauge visualization helps quickly identify which collections are experiencing the most write activity, useful for performance monitoring and resource planning. Data is updated regularly to reflect recent changes in write patterns.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#operations-per-shard","title":"Operations Per Shard","text":"<p>Shows the total number of operations per second for each shard in your MongoDB cluster. </p> <p>It combines all types of operations (queries, inserts, updates, deletes, and getmore) into a single metric for each shard. The stacked area chart allows you to see both individual shard activity and total cluster activity over time. </p> <p>This visualization helps you monitor the distribution of workload across shards and identify any imbalances or unusual patterns in operation rates.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#mongodb-versions","title":"MongoDB Versions","text":"<p>Displays the current MongoDB version for each service in your cluster.</p> <p>This information helps you quickly identify which version of MongoDB is running on each service, ensuring all parts of your cluster are using consistent and up-to-date software.</p> <p>Use this to track version differences across your MongoDB deployment and plan upgrades as needed.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#current-topology","title":"Current Topology","text":"<p>Displays a visual representation of your MongoDB sharded cluster\u2019s architecture, organizing nodes into their respective functional groups. Each node is represented by a hexagonal icon with color-coding to indicate its role:</p> <ul> <li>Green: Primary nodes or \u201cUP\u201d status for mongos routers</li> <li>Yellow: Secondary nodes</li> <li>Orange: Arbiter nodes (when present)</li> <li>Red: Nodes in \u201cDOWN\u201d state</li> </ul> <p>This visualization provides a clear overview of your cluster\u2019s structure, making it easy to verify configuration, monitor health status, and ensure replication sets maintain the expected primary-secondary relationships.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#config-servers","title":"Config Servers","text":"<p>Displays config server nodes that store metadata and configuration settings for the entire cluster. These servers maintain the mapping of chunks to shards.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#mongos-routers","title":"Mongos Routers","text":"<p>Shows router instances that direct queries to appropriate shards. These routers process queries from the application layer and determine the location of data within the sharded cluster.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#shards_1","title":"Shards","text":"<p>Groups data-bearing nodes by shard name (e.g., <code>Shard - rs1</code>, <code>Shard - rs2</code>). Each shard contains a subset of the sharded data.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#configuration-for-visualizing-mongodb-cluster-topology-correctly","title":"Configuration for visualizing MongoDB cluster topology correctly","text":"<p>To ensure your MongoDB sharded cluster components appear in the correct sections of the dashboard, follow these configuration guidelines when adding MongoDB instances using the <code>pmm-admin add mongodb</code> command or via the PMM UI:</p> <ul> <li>use the same <code>--cluster</code> name for all components of your sharded cluster</li> <li>add each component (config servers, shard nodes, and mongos routers) as a separate service. </li> </ul> <p>For detailed instructions on adding MongoDB nodes, see Add MongoDB services via CLI.</p> Example command for adding a MongoDB shard node <pre><code> pmm-admin add mongodb --username=pmm --password=password \\\n --service-name=rs-0-1 --replication-set=shard0 \\\n --host=127.0.0.1 --port=27018 --cluster=myMongoCluster\n</code></pre>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#node-states","title":"Node States","text":"<p>Displays a timeline of each node\u2019s status in your MongoDB replica set over the selected time period. Node states (PRIMARY, SECONDARY, ARBITER, etc.) are color-coded for easy monitoring, with green indicating healthy states and red showing potential issues.</p> <p>Use this visualization to track role changes, identify replica set instability, and monitor the overall health of your MongoDB cluster at a glance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#collection-details","title":"Collection Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#size-of-collections-in-shards","title":"Size of Collections in Shards","text":"<p>Displays the storage size of MongoDB collections across different shards in your cluster, excluding system databases, excluding system databases. The data is organized by database and collection, with separate columns for each shard.</p> <p>This visualization helps you understand how your data is distributed and identify which collections are using the most storage space. Use this information to optimize data distribution and storage usage in your MongoDB cluster.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#number-of-collections-in-shards","title":"Number of Collections in Shards","text":"<p>Shows how many collections each database has across different shards in your MongoDB cluster, excluding system databases. It lists database names in rows and shard names in columns, with the number of collections at each intersection.</p> <p>This overview helps you quickly see how your data is spread out, identify databases with many collections, and check if collections are evenly distributed across shards. </p> <p>Use this information to optimize your database structure and sharding strategy for better performance and resource usage.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#connections","title":"Connections","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#current-connections-per-shard","title":"Current Connections Per Shard","text":"<p>Shows the number of current TCP connections for each shard in your MongoDB cluster over time. It uses a stacked area chart to display incoming connections across different shards, allowing you to see both individual shard activity and total cluster connections at a glance. </p> <p>This visualization helps you monitor connection load distribution, identify any shards experiencing unusual connection patterns, and track overall cluster usage. Use this information to balance workloads, plan for capacity, and ensure your MongoDB cluster is handling connections efficiently.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#available-connections","title":"Available Connections","text":"<p>Displays the number of available connections for each service in your MongoDB cluster over time. It uses a stacked area chart to show how many connections are still open for new client requests across different services.</p> <p>This visualization helps you monitor connection capacity, identify services that might be reaching their connection limits, and track overall cluster availability. Use this information to ensure your MongoDB cluster has sufficient capacity to handle incoming connections, plan for scaling, and prevent potential connection-related issues before they impact performance or availability.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#chunks-in-shards","title":"Chunks in Shards","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#amount-of-chunks-in-shards","title":"Amount of Chunks in Shards","text":"<p>Shows how data chunks are distributed across shards in your MongoDB cluster. It displays the shard names and the number of chunks each shard contains. Chunks are subsets of your sharded data, and their distribution indicates how evenly your data is spread across the cluster.</p> <p>This overview helps you quickly identify any imbalances in data distribution, which could affect query performance and storage utilization. Use this information to assess your sharding strategy and determine if rebalancing is needed to optimize your MongoDB cluster\u2019s performance and resource usage.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#dynamic-of-chunks","title":"Dynamic of Chunks","text":"<p>Shows how the number of data chunks changes over time for each shard in your MongoDB cluster. It displays the rate of change in chunks per second, helping you visualize the balancer\u2019s activity in redistributing data across shards.</p> <p>This dynamic view allows you to monitor how your cluster adapts to data growth and changing query patterns. Use this information to assess the effectiveness of your sharding strategy, identify periods of high balancing activity, and ensure that your data remains evenly distributed for optimal performance and scalability.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#chunks-move-events","title":"Chunks Move Events","text":"<p>Displays the frequency of chunk movement events in your MongoDB sharded cluster over time. It shows how often chunks are being migrated between shards to maintain an even data distribution. The graph helps you visualize the balancer\u2019s activity, with higher bars indicating periods of more frequent chunk migrations. </p> <p>This information is crucial for understanding your cluster\u2019s balancing behavior, identifying times of high data redistribution activity, and ensuring that your sharded data remains optimally distributed for efficient query performance and storage utilization across all shards.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#chunk-split-activity","title":"Chunk Split Activity","text":"<p>Shows how frequently chunks are being split in your MongoDB sharded cluster over time. It visualizes the rate at which chunks grow beyond their configured size limit and need to be divided, typically due to data insertions or updates.</p> <p>Higher bars indicate periods of more frequent chunk splits, which can signal rapid data growth or changes in data distribution.</p> <p>This information helps you understand your cluster\u2019s data growth patterns, assess the effectiveness of your current chunk size configuration, and anticipate when you might need to adjust your sharding strategy or add capacity to maintain optimal performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#replication","title":"Replication","text":""},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#replication-lag-by-shard","title":"Replication Lag by Shard","text":"<p>Displays the maximum replication lag for each shard in your MongoDB cluster over time. Replication lag shows how far behind secondary nodes are in applying operations from the primary node. </p> <p>The chart helps you visualize lag trends across different shards, with higher values indicating longer delays in data replication. This information is crucial for monitoring the health of your replica sets, identifying potential performance issues, and ensuring data consistency across your sharded cluster.</p> <p>Use this graph to quickly spot any shards experiencing significant replication delays, which could impact read operations directed to secondary nodes and overall cluster reliability.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#oplog-range-by-shard","title":"Oplog Range by Shard","text":"<p>Shows the time span covered by the oplog (operation log) for each shard in your MongoDB cluster. It displays the duration between the oldest and newest operations stored in the oplog, measured in seconds. </p> <p>This information is crucial for understanding your cluster\u2019s replication capacity and resilience. A larger time range indicates a longer history of operations is available for replication, which can be beneficial for recovery scenarios or when secondary nodes fall behind.</p> <p>Monitor this graph to ensure your oplogs maintain sufficient history across all shards, helping you manage replication health and plan for potential adjustments to oplog size if needed.</p>"},{"location":"reference/dashboards/dashboard-mongodb-cluster-summary.html#oplog-gbhour","title":"Oplog GB/Hour","text":"<p>Shows the size of the MongoDB oplog generated by the Primary server. Use this to track oplog growth, plan storage needs, and detect high-write periods. Values are displayed in bytes with hourly intervals.</p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_details.html","title":"Experimental MongoDB Collection Details","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime experimental dashboard provides detailed information about the top collections by document count, size, and document read for MongoDB databases.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_collection_overview.html","title":"Experimental MongoDB Collection Overview","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime dashboard contains panels of data about the Hottest Collections in the MongoDB database.</p> <p>The Instance level includes two panels, one for the Hottest Collections by Read (Total) and the Hottest Collections by Write (total). </p> <p>The next panel displays data at the Database Level, where you can view MongoDB metrics such as Commands, Inserts, Updates, Removes, and Getmore.</p> <p>The last panel shows the number of operations in the chosen database.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-experimental_oplog.html","title":"Experimental MongoDB Oplog Details","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>This realtime dashboard contains Oplog details such as Recovery Window, Processing Time, Buffer Capacity, and Oplog Operations.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html","title":"MongoDB InMemory Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-transactions","title":"InMemory Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-capacity","title":"InMemory Capacity","text":"<p>Configured max and current size of the WiredTiger cache.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-sessions","title":"InMemory Sessions","text":"<p>Internal WiredTiger storage engine cursors and sessions currently open.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-pages","title":"InMemory Pages","text":"<p>Pages in the WiredTiger cache</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-concurrency-tickets","title":"InMemory Concurrency Tickets","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cTickets available\u201d = hard coded high value - \u201cTickets Out\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#inmemory-cache-eviction","title":"InMemory Cache Eviction","text":"<p>This panel shows the number of pages that have been evicted from the WiredTiger cache for the given time period. The InMemory storage engine only evicts modified pages which signals a compaction of the data and removal of the dirty pages.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-inmemory-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html","title":"MongoDB Instance Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#command-operations","title":"Command Operations","text":"<p>Ops or Replicated Ops/sec classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>). And (from the internal TTL threads) the docs deletes/sec by TTL indexes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#latency-detail","title":"Latency Detail","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#connections","title":"Connections","text":"<p>TCP connections (Incoming)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#cursors","title":"Cursors","text":"<p>Open cursors. Includes idle cursors.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#document-operations","title":"Document Operations","text":"<p>Docs per second inserted, updated, deleted or returned. (not 1-to-1 with operation counts.)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Ratio of Documents returned or Index entries scanned / full documents scanned</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-time","title":"<code>getLastError</code> Write Time","text":"<p>Legacy driver operation: Number of, and Sum of time spent, per second executing <code>getLastError</code> commands to confirm write concern.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#getlasterror-write-operations","title":"<code>getLastError</code> Write Operations","text":"<p>Legacy driver operation: Number of <code>getLastError</code> commands that timed out trying to confirm write concern.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#assert-events","title":"Assert Events","text":"<p>This panel shows the number of assert events per second on average over the given time period. In most cases assertions are trivial, but you would want to check your log files if this counter spikes or is consistently high.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instance-summary.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html","title":"MongoDB Instances Compare","text":""},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#connections","title":"Connections","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#cursors","title":"Cursors","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#latency","title":"Latency","text":"<p>Average latency of operations (classified by read, write, or (other) command)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#scan-ratios","title":"Scan Ratios","text":"<p>Ratio of index entries scanned or whole docs scanned / number of documents returned</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#index-filtering-effectiveness","title":"Index Filtering Effectiveness","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#requests","title":"Requests","text":"<p>Ops/sec (classified by (legacy) wire protocol request type)</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#document-operations","title":"Document Operations","text":"<p>Documents inserted/updated/deleted or returned per sec</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#queued-operations","title":"Queued Operations","text":"<p>The number of operations that are currently queued and waiting for a lock</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-compare.html#used-memory","title":"Used Memory","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html","title":"MongoDB Instances Overview","text":"<p>This dashboard provides basic information about MongoDB instances.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#command-operations","title":"Command Operations","text":"<p>Shows how many times a command is executed per second on average during the selected interval.</p> <p>Look for peaks and drops and correlate them with other graphs.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#connections","title":"Connections","text":"<p>Keep in mind the hard limit on the maximum number of connections set by your distribution.</p> <p>Anything over 5,000 should be a concern, because the application may not close connections correctly.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#cursors","title":"Cursors","text":"<p>Helps identify why connections are increasing.  Shows active cursors compared to cursors being automatically killed after 10 minutes due to an application not closing the connection.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#document-operations","title":"Document Operations","text":"<p>When used in combination with Command Operations, this graph can help identify write amplification.  For example, when one <code>insert</code> or <code>update</code> command actually inserts or updates hundreds, thousands, or even millions of documents.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#queued-operations","title":"Queued Operations","text":"<p>Any number of queued operations for long periods of time is an indication of possible issues.  Find the cause and fix it before requests get stuck in the queue.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#getlasterror-write-time-getlasterror-write-operations","title":"<code>getLastError</code> Write Time, <code>getLastError</code> Write Operations","text":"<p>This is useful for write-heavy workloads to understand how long it takes to verify writes and how many concurrent writes are occurring.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#asserts","title":"Asserts","text":"<p>Asserts are not important by themselves, but you can correlate spikes with other graphs.</p>"},{"location":"reference/dashboards/dashboard-mongodb-instances-overview.html#memory-faults","title":"Memory Faults","text":"<p>Memory faults indicate that requests are processed from disk either because an index is missing or there is not enough memory for the data set.  Consider increasing memory or sharding out.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html","title":"MongoDB MMAPv1 Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#document-activity","title":"Document Activity","text":"<p>Docs per second inserted, updated, deleted or returned. Also showing replicated write ops and internal TTL index deletes.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-lock-wait-time","title":"MMAPv1 Lock Wait Time","text":"<p>Time spent per second waiting to acquire locks.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-page-faults","title":"MMAPv1 Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-write-activity","title":"MMAPv1 Journal Write Activity","text":"<p>MB processed through the journal in memory.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-journal-commit-activity","title":"MMAPv1 Journal Commit Activity","text":"<p>MB committed to disk for the journal.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#mmapv1-background-flushing-time","title":"MMAPv1 Background Flushing Time","text":"<p>Average time in ms, over full uptime of <code>mongod</code> process, the MMAP background flushes have taken.</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#queued-operations","title":"Queued Operations","text":"<p>Queue size of ops waiting to be submitted to storage engine layer. (see WiredTiger concurrency tickets for number of ops being processed simultaneously in storage engine layer.)</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#client-operations","title":"Client Operations","text":"<p>Ops and Replicated Ops/sec, classified by legacy wire protocol type (<code>query</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>getmore</code>).</p>"},{"location":"reference/dashboards/dashboard-mongodb-mmapv1-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html","title":"MongoDB ReplSet Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#overview","title":"Overview","text":"<p>Displays key metrics for individual nodes, such as their role, CPU usage, memory consumption, disk space, network traffic, uptime, and current MongoDB version.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#feature-compatibility-version","title":"Feature Compatibility Version","text":"<p>Shows the Feature Compatibility Version (FCV) currently active in your MongoDB deployment. The FCV controls which database features are available and affects data file format compatibility between MongoDB versions.</p> <p>This panel helps you confirm that your cluster is running the expected FCV\u2014especially useful after upgrades, when the FCV may lag behind the MongoDB binary version.</p> <p>Monitoring FCV is important when planning upgrades or downgrades, as setting a newer FCV can enable advanced features but may prevent rolling back to older MongoDB versions.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#nodes","title":"Nodes","text":"<p>Displays the total number of nodes in the replica set, including all members regardless of state. </p> <p>Monitoring this value ensures the replica set maintains the expected number of nodes for proper replication and fault tolerance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#dbs","title":"DBs","text":"<p>Shows the total number of user-created databases, excluding system databases (like admin, local, and config). This metric helps track database growth and understand the scale of your MongoDB deployment.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#last-election","title":"Last Election","text":"<p>Displays the time elapsed since the most recent primary election.</p> <p>Frequent elections can indicate connectivity issues or node failures. A stable replica set should show a relatively high value.</p> <p>If the value is low, it may indicate a problem that needs investigation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#state","title":"State","text":"<p>Shows the current replica set state of this MongoDB node. MongoDB replica set members can be in various states including PRIMARY (handling all write operations), SECONDARY (replicating data from the primary), ARBITER (participating in elections but not storing data), or several transitional states.</p> <p>This status indicator helps you quickly identify the role of each node and spot any nodes experiencing issues. Color coding makes it easy to distinguish primaries (green) from secondaries (yellow) and problem states.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#cpu-usage","title":"CPU Usage","text":"<p>Shows CPU usage as a percentage from 0% to 100%. It updates every minute, turning from green to red when usage exceeds 80%. This helps quickly spot high CPU load, which could affect system performance, and monitor how hard the CPU is working at a glance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#memory-used","title":"Memory Used","text":"<p>Displays the percentage of total system memory currently in use. It updates regularly, showing green up to 80% of usage and red beyond that threshold.</p> <p>Use this for a quick visual indicator of memory consumption to monitor available memory without swapping as it\u2019s an easy way to assess how close the system is to its memory limits.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows how busy the disk is handling read/write requests. The meter turns red above 80%, warning of potential slowdowns. It updates regularly, giving administrators a quick way to check if the disk is keeping up with demand or if it\u2019s becoming a bottleneck in system performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#disk-space-utilization","title":"Disk Space Utilization","text":"<p>Shows how much of the total disk space is currently in use. The meter turns red when usage exceeds 80%, warning of low free space. It updates regularly, giving you a quick way to check if the disk is nearing capacity. This helps prevent \u201cdisk full\u201d errors that could disrupt services or system operation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#disk-iops","title":"Disk IOPS","text":"<p>Shows how many read and write operations the disk performs each second. The blue color helps spot spikes in disk activity. These spikes could mean the disk is struggling to keep up, which might slow down the system. It\u2019s a quick way for you to check if the disk is working too hard.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#network-traffic","title":"Network Traffic","text":"<p>Combines both incoming (received) and outgoing (transmitted) data, excluding local traffic. It gives you a quick view of overall network activity, helping spot unusual spikes or drops in data flow that might affect system performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#uptime","title":"Uptime","text":"<p>Shows how long the system has been running without a restart. As uptime increases, the color changes from red to orange to green, giving a quick visual indicator of system stability. Red indicates very recent restarts (less than 5 minutes), orange shows short uptimes (5 minutes to 1 hour), and green represents longer uptimes (over 1 hour). This helps you easily spot recent system restarts or confirm continuous operation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#version","title":"Version","text":"<p>Displays the current version of MongoDB running on the system. This information is crucial for ensuring the system is running the intended version and for quickly identifying any nodes that might need updates.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#states","title":"States","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#node-states","title":"Node States","text":"<p>Shows the state timeline of MongoDB replica set members during the selected time range. Each node\u2019s state (PRIMARY, SECONDARY, ARBITER, etc.) is color-coded for easy monitoring, with green indicating healthy states and red showing potential issues. Use this to track role changes and identify stability problems across your replica set.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#details","title":"Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#command-operations","title":"Command Operations","text":"<p>Shows the rate of MongoDB operations per second, including both regular and replicated operations (query, insert, update, delete, getmore), as well as document deletions by TTL indexes. Use this metric to monitor database activity patterns and identify potential performance bottlenecks.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#top-hottest-collections-by-read","title":"Top Hottest Collections by Read","text":"<p>Shows the five MongoDB collections with the highest read operations per second. Use this to identify your most frequently accessed collections and optimize their performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#top-hottest-collections-by-write","title":"Top Hottest Collections by Write","text":"<p>Shows the five MongoDB collections with the highest write operations (inserts, updates, and deletes) per second. Use this to identify your most frequently modified collections and optimize their write performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Shows the ratio of documents or index entries scanned versus documents returned. A ratio of 1 indicates optimal query performance where each scanned document matches the query criteria. </p> <p>Higher values suggest less efficient queries that scan many documents to find matches. Use this to identify queries that might need index optimization.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#queued-operations","title":"Queued Operations","text":"<p>Shows the number of operations waiting because the database is busy with other operations. Use this to identify when MongoDB operations are being delayed due to resource conflicts.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#reads-writes","title":"Reads &amp; Writes","text":"<p>Shows both active and queued read/write operations in your MongoDB deployment. Use this to monitor database activity and identify when operations are being delayed due to high load.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#connections","title":"Connections","text":"<p>Shows the number of current and available MongoDB connections. Use this to monitor connection usage and ensure your deployment has sufficient capacity for new client connections.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#query-execution-times","title":"Query Execution Times","text":"<p>Shows the average latency in microseconds (\u00b5s) for read, write, and command operations. Use this metric to monitor query performance and identify slow operations that may need optimization.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#collection-details","title":"Collection Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#size-of-collections","title":"Size of Collections","text":"<p>Shows storage size of MongoDB collections across different databases. Use this to monitor database growth and plan storage capacity needs.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#number-of-collections","title":"Number of Collections","text":"<p>Shows the total number of collections in each MongoDB database. Use this to track database organization and growth patterns.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#replication","title":"Replication","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#replication-lag","title":"Replication Lag","text":"<p>Shows how many seconds Secondary nodes are behind the Primary in replicating data. Higher values indicate potential issues with network latency or system resources. The red threshold line at 10 seconds helps identify when lag requires attention.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#oplog-recovery-window","title":"Oplog Recovery Window","text":"<p>Shows the time range (in seconds) between the newest and oldest operations in the oplog. Use this to ensure sufficient history is maintained for recovery and secondary synchronization.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#oplog-gbhour","title":"Oplog GB/Hour","text":"<p>Shows the size of the MongoDB oplog generated by the Primary server. Use this to track oplog growth, plan storage needs, and detect high-write periods. Values are displayed in bytes with hourly intervals.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#performance","title":"Performance","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#flow-control","title":"Flow Control","text":"<p>Shows the frequency and duration (in microseconds) of MongoDB write throttling. Use this to understand when your deployment is slowing down writes to keep replication lag under control.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#wiredtiger-concurrency-tickets-available","title":"WiredTiger Concurrency Tickets Available","text":"<p>Shows how many more read and write operations your MongoDB deployment can handle simultaneously. Use this to monitor database concurrency limits and potential bottlenecks.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#nodes-summary","title":"Nodes Summary","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#nodes-overview","title":"Nodes Overview","text":"<p>Shows key system metrics for each node: uptime, load average, memory usage, disk space, and more. Use this table to monitor the health and resource utilization of your infrastructure at a glance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#cpu-usage_1","title":"CPU Usage","text":"<p>Shows CPU utilization as a percentage of total capacity, broken down by user and system activity. Use this to monitor CPU load and identify potential performance bottlenecks.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#cpu-saturation","title":"CPU Saturation","text":""},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>Shows how heavily your CPU is loaded with waiting processes and maximum core utilization. Use this to identify when your system needs more CPU capacity or when processes are competing for CPU time.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Shows disk I/O operations (reads/writes) and memory swap activity for each MongoDB node, measuring data flow between storage and RAM. </p> <p>Use this metric to monitor storage performance, detect memory pressure, and identify when MongoDB\u2019s working set may exceed available RAM.</p>"},{"location":"reference/dashboards/dashboard-mongodb-replset-summary.html#network-traffic_1","title":"Network Traffic","text":"<p>Shows inbound and outbound network traffic for each MongoDB node, measuring data flow in bytes per second. </p> <p>Use this metric to monitor bandwidth usage, identify unusual traffic patterns, and detect potential network bottlenecks that could affect replication performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html","title":"MongoDB Router Summary","text":"<p>This dashboard monitors MongoS router nodes in sharded MongoDB clusters.</p> <p></p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#overview","title":"Overview","text":"<p>For each MongoS in the cluster, this section includes main monitoring metrics like CPU, memory and disk usage. Uptime and MongoS version are reported as well.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#cpu-usage","title":"CPU Usage","text":"<p>Shows CPU usage as a percentage from 0% to 100%. It updates every minute, turning from green to red when usage exceeds 80%. This helps quickly spot high CPU load, which could affect system performance, and monitor how hard the CPU is working at a glance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#memory-used","title":"Memory Used","text":"<p>Displays the percentage of total system memory currently in use. It updates regularly, showing green up to 80% of usage and red beyond that threshold.</p> <p>Use this for a quick visual indicator of memory consumption to monitor available memory without swapping as it\u2019s an easy way to assess how close the system is to its memory limits.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#disk-io-utilization","title":"Disk IO Utilization","text":"<p>Shows how busy the disk is handling read/write requests. The meter turns red above 80%, warning of potential slowdowns. It updates regularly, giving administrators a quick way to check if the disk is keeping up with demand or if it\u2019s becoming a bottleneck in system performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#disk-space-utilization","title":"Disk Space Utilization","text":"<p>Shows how much of the total disk space is currently in use. The meter turns red when usage exceeds 80%, warning of low free space. It updates regularly, giving you a quick way to check if the disk is nearing capacity. This helps prevent \u201cdisk full\u201d errors that could disrupt services or system operation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#disk-iops","title":"Disk IOPS","text":"<p>Shows how many read and write operations the disk performs each second. The blue color helps spot spikes in disk activity. These spikes could mean the disk is struggling to keep up, which might slow down the system. It\u2019s a quick way for you to check if the disk is working too hard.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#network-traffic","title":"Network Traffic","text":"<p>Combines both incoming (received) and outgoing (transmitted) data, excluding local traffic. It gives you a quick view of overall network activity, helping spot unusual spikes or drops in data flow that might affect system performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#uptime","title":"Uptime","text":"<p>Shows how long the system has been running without a restart. As uptime increases, the color changes from red to orange to green, giving a quick visual indicator of system stability. Red indicates very recent restarts (less than 5 minutes), orange shows short uptimes (5 minutes to 1 hour), and green represents longer uptimes (over 1 hour). This helps you easily spot recent system restarts or confirm continuous operation.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#version","title":"Version","text":"<p>Displays the current version of MongoDB running on the system. This information is crucial for ensuring the system is running the intended version and for quickly identifying any nodes that might need updates.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#node-states","title":"Node States","text":"<p>Shows the status of all MongoDB Shard (MongoS) nodes in the selected cluster over time. It uses a color-coded timeline: green bars mean a node is \u201cUP\u201d and working, while red bars show it\u2019s \u201cDOWN\u201d or unreachable. This simple view helps you quickly spot which nodes are active, see any recent status changes, and identify patterns in node availability.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#details","title":"Details","text":"<p>This section includes additional information like \u201cCommand Operations\u201d, \u201cConnections\u201d, \u201cQuery execution times\u201d and \u201cQuery efficiency\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#command-operations","title":"Command Operations","text":"<p>Shows MongoDB command operations over time, displaying rates for inserts, updates, deletes, queries, and TTL deletions per second.</p> <p>Use this to monitor overall database workload, compare operation types, spot peak usage and unusual patterns, assess replication activity, and track automatic data cleanup.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#connections","title":"Connections","text":"<p>Displays MongoDB connection metrics over time, showing both current and available connections. Use this to monitor connection usage trends, identify periods of high demand, and ensure the database isn\u2019t reaching its connection limits.</p> <p>By comparing current to available connections, it\u2019s easy to spot potential bottlenecks or capacity issues before they impact performance.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#query-execution-times","title":"Query execution times","text":"<p>Shows the average execution times for MongoDB queries over time, categorized into read, write, and other command operations.</p> <p>Use this to identify slow queries, performance bottlenecks, and unusual spikes in execution times. Comparing latencies across operation types can also guide decisions on indexing strategies and query optimizations.</p>"},{"location":"reference/dashboards/dashboard-mongodb-router-summary.html#query-efficiency","title":"Query Efficiency","text":"<p>Visualizes MongoDB query efficiency over time, displaying the ratio of scanned documents or index entries to returned documents, along with operation latencies.</p> <p>A ratio near 1 indicates highly efficient queries, while higher values (e.g., 100) suggest inefficiency.</p> <p>Compare document scans, index scans, and operation latencies to quickly identify poorly performing queries, and ensure that queries execute as efficiently as possible.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html","title":"MongoDB WiredTiger Details","text":""},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-transactions","title":"WiredTiger Transactions","text":"<p>WiredTiger internal transactions</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-activity","title":"WiredTiger Cache Activity","text":"<p>Data volume transferred per second between the WT cache and data files. Writes out always imply disk; Reads are often from OS file buffer cache already in RAM, but disk if not.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-block-activity","title":"WiredTiger Block Activity","text":"<p>Data volume handled by the WT block manager per second</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-sessions","title":"WiredTiger Sessions","text":"<p>Internal WT storage engine cursors and sessions currently open</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-concurrency-tickets-available","title":"WiredTiger Concurrency Tickets Available","text":"<p>A WT \u2018ticket\u2019 is assigned out for every operation running simultaneously in the WT storage engine. \u201cAvailable\u201d = hard-coded high value - \u201cOut\u201d.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#queued-operations","title":"Queued Operations","text":"<p>Operations queued due to a lock.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-checkpoint-time","title":"WiredTiger Checkpoint Time","text":"<p>The time spent in WT checkpoint phase. Warning: This calculation averages the cyclical event (default: 1 min) execution to a per-second value.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-eviction","title":"WiredTiger Cache Eviction","text":"<p>Least-recently used pages being evicted due to WT cache becoming full.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-capacity","title":"WiredTiger Cache Capacity","text":"<p>Configured max and current size of the WT cache.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-cache-pages","title":"WiredTiger Cache Pages","text":""},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-operations","title":"WiredTiger Log Operations","text":"<p>WT internal write-ahead log operations.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-activity","title":"WiredTiger Log Activity","text":"<p>Data volume moved per second in WT internal write-ahead log.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#wiredtiger-log-records","title":"WiredTiger Log Records","text":"<p>Number of records appended per second in WT internal log.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#document-changes","title":"Document Changes","text":"<p>Mixed metrics: Docs per second inserted, updated, deleted or returned on any type of node (primary or secondary); + replicated write Ops/sec; + TTL deletes per second.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#scanned-and-moved-objects","title":"Scanned and Moved Objects","text":"<p>This panel shows the number of objects (both data (<code>scanned_objects</code>) and index (<code>scanned</code>)) as well as the number of documents that were moved to a new location due to the size of the document growing. Moved documents only apply to the MMAPv1 storage engine.</p>"},{"location":"reference/dashboards/dashboard-mongodb-wiredtiger-details.html#page-faults","title":"Page Faults","text":"<p>Unix or Window memory page faults. Not necessarily from MongoDB.</p>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html","title":"MySQL Amazon Aurora Details","text":""},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-transaction-commits","title":"Amazon Aurora Transaction Commits","text":"<p>This graph shows the number of Commits which Amazon Aurora engine performed as well as average commit latency. Graph Latency does not always correlate with the number of performed commits and can be quite high in certain situations.</p> <ul> <li> <p>Number of Amazon Aurora Commits: The average number of commit operations per second.</p> </li> <li> <p>Amazon Aurora Commit avg Latency: The average amount of latency for commit operations</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-load","title":"Amazon Aurora Load","text":"<p>This graph shows us what statements contribute most load on the system as well as what load corresponds to Amazon Aurora transaction commit.</p> <ul> <li> <p>Write Transaction Commit Load: Load in Average Active Sessions per second for COMMIT operations</p> </li> <li> <p>UPDATE load: Load in Average Active Sessions per second for UPDATE queries</p> </li> <li> <p>SELECT load: Load in Average Active Sessions per second for SELECT queries</p> </li> <li> <p>DELETE load: Load in Average Active Sessions per second for DELETE queries</p> </li> <li> <p>INSERT load: Load in Average Active Sessions per second for INSERT queries</p> </li> </ul> <p>An active session is a connection that has submitted work to the database engine and is waiting for a response from it. For example, if you submit an SQL query to the database engine, the database session is active while the database engine is processing that query.</p>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#aurora-memory-used","title":"Aurora Memory Used","text":"<p>This graph shows how much memory is used by Amazon Aurora lock manager as well as amount of memory used by Amazon Aurora to store Data Dictionary.</p> <ul> <li> <p>Aurora Lock Manager Memory: the amount of memory used by the Lock Manager, the module responsible for handling row lock requests for concurrent transactions.</p> </li> <li> <p>Aurora Dictionary Memory: the amount of memory used by the Dictionary, the space that contains metadata used to keep track of database objects, such as tables and indexes.</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-statement-latency","title":"Amazon Aurora Statement Latency","text":"<p>This graph shows average latency for the most important types of statements. Latency spikes are often indicative of the instance overload.</p> <ul> <li> <p>DDL Latency: Average time to execute DDL queries</p> </li> <li> <p>DELETE Latency: Average time to execute DELETE queries</p> </li> <li> <p>UPDATE Latency: Average time to execute UPDATE queries</p> </li> <li> <p>SELECT Latency: Average time to execute SELECT queries</p> </li> <li> <p>INSERT Latency: Average time to execute INSERT queries</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-special-command-counters","title":"Amazon Aurora Special Command Counters","text":"<p>Amazon Aurora MySQL allows a number of commands which are not available in standard MySQL. This graph shows usage of such commands.  Regular <code>unit_test</code> calls can be seen in default Amazon Aurora install, the rest will depend on your workload.</p> <ul> <li> <p><code>show_volume_status</code>: The number of executions per second of the command SHOW VOLUME STATUS. The SHOW VOLUME STATUS query returns two server status variables, Disks and Nodes. These variables represent the total number of logical blocks of data and storage nodes, respectively, for the DB cluster volume.</p> </li> <li> <p><code>awslambda</code>: The number of AWS Lambda calls per second. AWS Lambda is an event-drive, server-less computing platform provided by AWS. It is a compute service that run codes in response to an event. You can run any kind of code from Aurora invoking Lambda from a stored procedure or a trigger.</p> </li> <li> <p><code>alter_system</code>: The number of executions per second of the special query ALTER SYSTEM, that is a special query to simulate an instance crash, a disk failure, a disk congestion or a replica failure. It\u2019s a useful query for testing the system.</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-amazon-aurora-details.html#amazon-aurora-problems","title":"Amazon Aurora Problems","text":"<p>This graph shows different kinds of Internal Amazon Aurora MySQL Problems which general should be zero in normal operation.</p> <p>Anything non-zero is worth examining in greater depth.</p>"},{"location":"reference/dashboards/dashboard-mysql-command-handler-counters-compare.html","title":"MySQL Command/Handler Counters Compare","text":"<p>This dashboard shows server status variables. On this dashboard, you may select multiple servers and compare their counters simultaneously.</p> <p>Server status variables appear in two sections: Commands and Handlers. Choose one or more variables in the Command and Handler fields in the top menu to select the variables which will appear in the COMMANDS or HANDLERS section for each host. Your comparison may include from one up to three hosts.</p> <p>By default or if no item is selected in the menu, PMM displays each command or handler respectively.</p>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html","title":"MySQL Group Replication Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#overview","title":"Overview","text":"<ul> <li>PRIMARY Service</li> <li>Group Replication Service States</li> <li>Replication Group Members</li> <li>Replication Lag</li> <li>Replication Delay</li> <li>Transport Time</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#transactions","title":"Transactions","text":"<ul> <li>Transaction Details</li> <li>Applied Transactions</li> <li>Sent Transactions</li> <li>Checked Transactions</li> <li>Rolled Back Transactions</li> <li>Transactions Row Validating</li> <li>Transactions in the Queue for Checking</li> <li>Received Transactions Queue</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-group-replication-summary.html#conflicts","title":"Conflicts","text":"<ul> <li>Detected Conflicts</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html","title":"MySQL InnoDB Compression Details","text":"<p>This dashboard helps you analyze the efficiency of InnoDB compression.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#compression-level-and-failure-rate-threshold","title":"Compression level and failure rate threshold","text":"InnoDB Compression Level The level of zlib compression to use for InnoDB compressed tables and indexes. InnoDB Compression Failure Threshold The compression failure rate threshold for a table. Compression Failure Rate Threshold The maximum percentage that can be reserved as free space within each compressed page, allowing room to reorganize the data and modification log within the page when a compressed table or index is updated and the data might be recompressed. Write Pages to the Redo Log Specifies whether images of re-compressed pages are written to the redo log. Re-compression may occur when changes are made to compressed data."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#statistic-of-compression-operations","title":"Statistic of compression operations","text":"Compress Attempts Number of compression operations attempted. Pages are compressed whenever an empty page is created or the space for the uncompressed modification log runs out. Uncompressed Attempts Number of uncompression operations performed. Compressed InnoDB pages are uncompressed whenever compression fails, or the first time a compressed page is accessed in the buffer pool and the uncompressed page does not exist."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#cpu-core-usage","title":"CPU Core Usage","text":"CPU Core Usage for Compression Shows the time in seconds spent by InnoDB Compression operations. CPU Core Usage for Uncompression Shows the time in seconds spent by InnoDB Uncompression operations."},{"location":"reference/dashboards/dashboard-mysql-innodb-compression-details.html#buffer-pool-total","title":"Buffer Pool Total","text":"Total Used Pages Shows the total amount of used compressed pages into the InnoDB Buffer Pool split by page size. Total Free Pages Shows the total amount of free compressed pages into the InnoDB Buffer Pool split by page size."},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html","title":"MySQL InnoDB Details","text":"<p>Tip</p> <p>If metrics are missing, try running: <code>SET GLOBAL innodb_monitor_enable=all;</code> in the MySQL client.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-activity","title":"InnoDB Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#writes-rows","title":"Writes (Rows)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#writes-transactions","title":"Writes (Transactions)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rows-read-per-trx","title":"Rows Read Per Trx","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-space-per-trx","title":"Log Space per Trx","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollbacks","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-reqs-per-row","title":"BP Reqs Per Row","text":"<p>Number of Buffer Pool requests per Row Access. High numbers here indicate going through long undo chains, deep trees and other inefficient data access.  It can be less than zero due to several rows being read from single page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-fsync-per-trx","title":"Log Fsync Per Trx","text":"<p>Log Fsync Per Transaction.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-reads","title":"InnoDB Row Reads","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-writes","title":"InnoDB Row Writes","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-operations_1","title":"InnoDB Row Operations","text":"<p>This graph allows you to see which operations occur and the number of rows affected per operation. A graph like Queries Per Second will give you an idea of queries, but one query could effect millions of rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-only-transactions","title":"InnoDB Read-Only Transactions","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-write-transactions","title":"InnoDB Read-Write Transactions","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-transactions-information-rw","title":"InnoDB Transactions Information (RW)","text":"<p>The InnoDB Transactions Information graph shows details about the recent transactions.  Transaction IDs Assigned represents the total number of transactions initiated by InnoDB.  RW Transaction Commits are the number of transactions not read-only. Insert-Update Transactions Commits are transactions on the Undo entries.  Non Locking RO Transaction Commits are transactions commit from select statement in auto-commit mode or transactions explicitly started with \u201cstart transaction read only\u201d.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#misc-innodb-transactions-information","title":"Misc InnoDB Transactions Information","text":"<p>Additional InnoDB Transaction Information</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-storage-summary","title":"InnoDB Storage Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-tables","title":"InnoDB Tables","text":"<p>Current Number of InnoDB Tables in database</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-buffer-pool-fit","title":"Data Buffer Pool Fit","text":"<p>Buffer Pool Size as Portion of the Data</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-row-size","title":"Avg Row Size","text":"<p>Amount of Data Per Row</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-size-per-row","title":"Index Size Per Row","text":"<p>Index Size Per Row shows how much space we\u2019re using for indexes on per row basics</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-summary","title":"InnoDB Data Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#space-allocated","title":"Space Allocated","text":"<p>Total Amount of Space Allocated. May not exactly match amount of space used on file system but provided great guidance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#space-used","title":"Space Used","text":"<p>Space used in All InnoDB Tables. Reported Allocated Space Less Free Space.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-length","title":"Data Length","text":"<p>Space Used by Data (Including Primary Key).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-length","title":"Index Length","text":"<p>Space Used by Secondary Indexes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#estimated-rows","title":"Estimated Rows","text":"<p>Estimated number of Rows in InnoDB Storage Engine. It is not exact value and it can change abruptly as information is updated.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#indexing-overhead","title":"Indexing Overhead","text":"<p>How Much Indexes Take Compared to Data.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free-space-percent","title":"Free Space Percent","text":"<p>How Much Space is Free. Too high value wastes space on disk.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free","title":"Free","text":"<p>Allocated Space not currently used by Data or Indexes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-file-per-table","title":"InnoDB File Per Table","text":"<p>If Enabled, By Default every Table will have its own Tablespace represented as its own <code>.idb</code> file  rather than all tables stored in single system tablespace.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-disk-io","title":"InnoDB Disk IO","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-size","title":"InnoDB Page Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-data-read-rq-size","title":"Avg Data Read Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-data-write-rq-size","title":"Avg Data Write Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#avg-log-write-rq-size","title":"Avg Log Write Rq Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-written-per-fsync","title":"Data Written Per Fsync","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-written-per-fsync","title":"Log Written Per Fsync","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-read-per-row-read","title":"Data Read Per Row Read","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#data-written-per-row-written","title":"Data Written Per Row Written","text":"<p>Due to difference in timing of Row Write and Data Write the value may be misleading on short intervals.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-io","title":"InnoDB Data I/O","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of fsync() operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-data-bandwidth","title":"InnoDB Data Bandwidth","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-io","title":"InnoDB Log IO","text":"<p>InnoDB I/O</p> <ul> <li>Data Writes - The total number of InnoDB data writes.</li> <li>Data Reads - The total number of InnoDB data reads (OS file reads).</li> <li>Log Writes - The number of physical writes to the InnoDB redo log file.</li> <li>Data Fsyncs - The number of <code>fsync()</code> operations. The frequency of <code>fsync()</code> calls is influenced by the setting of the <code>innodb_flush_method</code> configuration option.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fsyncs","title":"InnoDB FSyncs","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-io","title":"InnoDB Pending IO","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-pending-fsyncs","title":"InnoDB Pending Fsyncs","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-extend-increment","title":"InnoDB Auto Extend Increment","text":"<p>When Growing InnoDB System Tablespace extend it by this size at the time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-double-write","title":"InnoDB Double Write","text":"<p>Whether InnoDB Double Write Buffer is enabled. Doing so doubles amount of writes InnoDB has to do to storage but is required to avoid potential data corruption during the crash on most storage subsystems.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fast-shutdown","title":"InnoDB Fast Shutdown","text":"<p>Fast Shutdown means InnoDB will not perform complete Undo Space and Change Buffer cleanup on shutdown, which is faster but may interfere with certain major upgrade operations.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-open-files","title":"InnoDB Open Files","text":"<p>Maximum Number of Files InnoDB is Allowed to use.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-file-use","title":"InnoDB File Use","text":"<p>Portion of Allowed InnoDB Open Files Use.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-objects","title":"InnoDB IO Objects","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-targets-write-load","title":"InnoDB IO Targets Write Load","text":"<p>Write Load Includes both Write and fsync (referred as misc).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool","title":"InnoDB Buffer Pool","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size","title":"Buffer Pool Size","text":"<p>InnoDB Buffer Pool Size</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-size-of-total-ram","title":"Buffer Pool Size of Total RAM","text":"<p>InnoDB Buffer Pool Size % of Total RAM</p> <p>InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.  Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed data in memory, is one of the most important aspects of MySQL tuning. The goal is to keep the working set in memory. In most cases, this should be between 60%-90% of available memory on a dedicated database host, but depends on many factors.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#numa-interleave","title":"NUMA Interleave","text":"<p>Interleave Buffer Pool between NUMA zones to better support NUMA systems.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-activity","title":"Buffer Pool Activity","text":"<p>Combined value of Buffer Pool Read and Write requests.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-data","title":"BP Data","text":"<p>Percent of Buffer Pool Occupied by Cached Data.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-data-dirty","title":"BP Data Dirty","text":"<p>Percent of Data which is Dirty.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-miss-ratio","title":"BP Miss Ratio","text":"<p>How often buffer pool read requests have to do read from the disk. Keep this percent low for good performance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#bp-write-buffering","title":"BP Write Buffering","text":"<p>Number of Logical Writes to Buffer Pool Per logical Write.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-lru-sub-chain-churn","title":"InnoDB Buffer Pool LRU Sub-Chain Churn","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-chunk-size","title":"Buffer Pool Chunk Size","text":"<p>Size of the \u201cChunk\u201d for buffer pool allocation.  Allocation of buffer pool will be rounded by this number. It also affects the performance impact of online buffer pool resize.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#buffer-pool-instances","title":"Buffer Pool Instances","text":"<p>Number of Buffer Pool Instances. Higher values allow to reduce contention but also increase overhead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#read-ahead-io-percent","title":"Read Ahead IO Percent","text":"<p>Percent of Reads Caused by InnoDB Read Ahead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#read-ahead-wasted","title":"Read Ahead Wasted","text":"<p>Percent of Pages Fetched by Read Ahead Evicted Without Access.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#dump-buffer-pool-on-shutdown","title":"Dump Buffer Pool on Shutdown","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#load-buffer-pool-at-startup","title":"Load Buffer Pool at Startup","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#portion-of-buffer-pool-to-dumpload","title":"Portion of Buffer Pool To Dump/Load","text":"<p>Larger Portion increases dump/load time but get more of original buffer pool content and hence may reduce warmup time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#include-buffer-pool-in-core-dump","title":"Include Buffer Pool in Core Dump","text":"<p>Whenever to Include Buffer Pool in Crash Core Dumps.  Doing so may dramatically increase core dump file slow down restart.  Only makes a difference if core dumping on crash is enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks","title":"InnoDB Old Blocks","text":"<p>Percent of The Buffer Pool To be Reserved for \u201cOld Blocks\u201d - which has been touched repeatedly over period of time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-old-blocks-time","title":"InnoDB Old Blocks Time","text":"<p>The Time which has to pass between multiple touches for the block for it to qualify as old block.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead","title":"InnoDB Random Read Ahead","text":"<p>Is InnoDB Random ReadAhead Enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-random-read-ahead_1","title":"InnoDB Random Read Ahead","text":"<p>The Threshold (in Pages) to trigger Linear Read Ahead.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-read-io-threads","title":"InnoDB Read IO Threads","text":"<p>Number of Threads used to Schedule Reads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-write-io-threads","title":"InnoDB Write IO Threads","text":"<p>Number of Threads used to Schedule Writes.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-native-aio-enabled","title":"InnoDB Native AIO Enabled","text":"<p>Whether Native Asynchronous IO is enabled.  Strongly recommended for optimal performance.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-buffer-pool-replacement-management","title":"InnoDB Buffer Pool - Replacement Management","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-scan-depth","title":"LRU Scan Depth","text":"<p>InnoDB LRU Scan Depth</p> <p>This variable defines InnoDB Free Page Target per buffer pool. When number of free pages falls below this number this number page cleaner will make required amount of pages free, flushing or evicting pages from the tail of LRU as needed.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-clean-page-searches","title":"LRU Clean Page Searches","text":"<p>When Page is being read (or created)  the Page need to be allocated in Buffer Pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#free-list-miss-rate","title":"Free List Miss Rate","text":"<p>The most efficient way to get a clean page is to grab one from free list.  However if no pages are available in Free List the LRU scan needs to be performed.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-loops","title":"LRU Get Free Loops","text":"<p>If Free List was empty LRU Get Free Loop will be performed.  It may perform LRU scan or may use some other heuristics and shortcuts to get free page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-scans","title":"LRU Scans","text":"<p>If Page could not be find any Free list and other shortcuts did not work, free page will be searched by scanning LRU chain which is not efficient.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-in-lru-scans","title":"Pages Scanned in LRU Scans","text":"<p>Pages Scanned Per Second while doing LRU scans.  If this value is large (thousands) it means a lot of resources are wasted.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-lru-scan","title":"Pages scanned per LRU Scan","text":"<p>Number of pages scanned per LRU scan in Average. Large number of scans can consume a lot of resources and also introduce significant addition latency to queries.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-get-free-waits","title":"LRU Get Free Waits","text":"<p>If InnoDB could not find a free page in LRU list and had to sleep. Should be zero.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpointing-and-flushing","title":"InnoDB Checkpointing and Flushing","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-from-flush-list","title":"Pages Flushed from Flush List","text":"<p>Number of Pages Flushed from \u201cFlush List\u201d  This combines Pages Flushed through Adaptive Flush and Background Flush.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-flush-batches-executed","title":"Page Flush Batches Executed","text":"<p>InnoDB Flush Cycle typically Runs on 1 second intervals.  If too far off from this number it can indicate an issue.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-per-batch","title":"Pages Flushed Per Batch","text":"<p>How many pages are flushed per Batch.  Large Batches can \u201cchoke\u201d IO subsystem and starve other IO which needs to happen.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing-enabled","title":"Neighbor Flushing Enabled","text":"<p>Neighbor Flushing is Optimized for Rotational Media  and unless you\u2019re Running spinning disks you should disable it.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-checkpoint-age","title":"InnoDB Checkpoint Age","text":"<p>InnoDB Checkpoint Age</p> <p>The maximum checkpoint age is determined by the total length of all transaction log files (<code>innodb_log_file_size</code>).</p> <p>When the checkpoint age reaches the maximum checkpoint age, blocks are flushed synchronously. The rules of the thumb is to keep one hour of traffic in those logs and let the check-pointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-adaptive","title":"Pages Flushed (Adaptive)","text":"<p>Adaptive Flush  Flushes pages from Flush List based on the need to advance Checkpoint (driven by Redo Generation Rate) and by maintaining number of dirty pages within set limit.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-flush-batches-executed","title":"Adaptive Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-adaptive","title":"Pages Per Batch (Adaptive)","text":"<p>Pages Flushed Per Adaptive Batch.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flushing","title":"Neighbor Flushing","text":"<p>To optimize IO for rotational Media InnoDB may flush neighbor pages. It can cause significant wasted IO for flash storage.    Generally for flash you should run with <code>innodb_flush_neighbors=0</code> but otherwise this shows how much IO you\u2019re wasting.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-lru","title":"Pages Flushed (LRU)","text":"<p>Flushing from the tail of the LRU list is needed to keep readily-available free pages for new data to be read when data does not fit in the buffer pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lru-flush-batches-executed","title":"LRU Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-lru","title":"Pages Per Batch (LRU)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lsn-age-flush-batch-target","title":"LSN Age Flush Batch Target","text":"<p>Target for Pages to Flush due to LSN Age.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-neighbor","title":"Pages Flushed (Neighbor)","text":"<p>Number of Neighbor pages flushed (If neighbor flushing is enabled)  from Flush List and LRU List Combined.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#neighbor-flush-batches-executed","title":"Neighbor Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-neighbor","title":"Pages Per Batch (Neighbor)","text":"<p>Pages Flushed Per Neighbor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#sync-flush-waits","title":"Sync Flush Waits","text":"<p>If InnoDB could not keep up with Checkpoint Flushing and had to trigger Sync flush.  This should never happen.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-flushed-background","title":"Pages Flushed (Background)","text":"<p>Pages Flushed by Background Flush which is activated when server is considered to be idle.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#background-flush-batches-executed","title":"Background Flush Batches Executed","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-per-batch-background","title":"Pages Per Batch (Background)","text":"<p>Pages Flushed Per Background Batch.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo) is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-flushing-by-type","title":"InnoDB Flushing by Type","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-lru","title":"Pages Evicted (LRU)","text":"<p>This correspond to number of clean pages which were evicted (made free) from the tail of LRU buffer.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-eviction-batches","title":"Page Eviction Batches","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-evicted-per-batch","title":"Pages Evicted per Batch","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-log-space-used","title":"Max Log Space Used","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#single-page-flushes","title":"Single Page Flushes","text":"<p>Single Page flushes happen in rare case, then clean page could not be found in LRU list. It should be zero for most workloads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#single-page-flush-pages-scanned","title":"Single Page Flush Pages Scanned","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#pages-scanned-per-single-page-flush","title":"Pages Scanned Per Single Page Flush","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity","title":"InnoDB IO Capacity","text":"<p>Estimated number of IOPS storage system can provide.  Is used to scale background activities. Do not set it to actual storage capacity.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-io-capacity-max","title":"InnoDB IO Capacity Max","text":"<p>InnoDB IO Capacity to use when falling behind and need to catch up with Flushing.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-logging","title":"InnoDB Logging","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#total-log-space","title":"Total Log Space","text":"<p>Number of InnoDB Log Files Multiplied by Their Size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-buffer-size","title":"Log Buffer Size","text":"<p>InnoDB Log Buffer Size</p> <p>The size of buffer InnoDB uses for buffering writes to log files.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#at-transaction-commit","title":"At Transaction Commit","text":"<p>What to do with Log file At Transaction Commit. Do nothing and wait for timeout to  flush the data from Log Buffer,  Flush it to OS Cache but not FSYNC or Flush only.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#flush-transaction-log-every","title":"Flush Transaction Log Every","text":"<p>Every Specified Number of Seconds Flush Transaction Log.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-write-ahead-block-size","title":"InnoDB Write Ahead Block Size","text":"<p>This variable can be seen as minimum IO alignment InnoDB will use for Redo log file.  High Values cause waste, low values can make IO less efficient.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-write-amplification","title":"Log Write Amplification","text":"<p>How much Writes to Log Are Amplified compared to how much Redo is Generated.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-fsync-rate","title":"Log Fsync Rate","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generated-per-trx","title":"Redo Generated per Trx","text":"<p>Amount of Redo Generated Per Write Transaction.  This is a good indicator of transaction size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-usage-hourly","title":"InnoDB Log File Usage Hourly","text":"<p>InnoDB Log File Usage Hourly</p> <p>Along with the buffer pool size, <code>innodb_log_file_size</code> is the most important setting when we are working with InnoDB. This graph shows how much data was written to InnoDB\u2019s redo logs over each hour. When the InnoDB log files are full, InnoDB needs to flush the modified pages from memory to disk.</p> <p>The rules of the thumb is to keep one hour of traffic in those logs and let the checkpointing perform its work as smooth as possible. If you don\u2019t do this, InnoDB will do synchronous flushing at the worst possible time, i.e., when you are busiest.</p> <p>This graph can help guide you in setting the correct <code>innodb_log_file_size</code>.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-padding-written","title":"Log Padding Written","text":"<p>Amount of Log Padding Written.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-file-size","title":"InnoDB Log File Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-log-files","title":"InnoDB Log Files","text":"<p>Number of InnoDB Redo Log Files.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#log-bandwidth","title":"Log Bandwidth","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#redo-generation-rate_1","title":"Redo Generation Rate","text":"<p>Rate at which LSN (Redo)  is Created. It may not match how much data is written to log files due to block size rounding.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-group-commit-batch-size","title":"InnoDB Group Commit Batch Size","text":"<p>The InnoDB Group Commit Batch Size graph shows how many bytes were written to the InnoDB log files per attempt to write. If many threads are committing at the same time, one of them will write the log entries of all the waiting threads and flush the file. Such process reduces the number of disk operations needed and enlarge the batch size.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-locking","title":"InnoDB Locking","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#lock-wait-timeout","title":"Lock Wait Timeout","text":"<p>InnoDB Lock Wait Timeout</p> <p>How long to wait for row lock before timing out.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-deadlock-detection","title":"InnoDB Deadlock Detection","text":"<p>If Disabled InnoDB Will not detect deadlocks but rely on timeouts.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-auto-increment-lock-mode","title":"InnoDB Auto Increment Lock Mode","text":"<p>Will Define How much locking will come from working with Auto Increment Columns.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollback-on-timeout","title":"Rollback on Timeout","text":"<p>Whenever to rollback all transaction on timeout or just last statement.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-lock-blocking","title":"Row Lock Blocking","text":"<p>Percent of Active Sections which are blocked due to waiting on InnoDB Row Locks.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#row-writes-per-trx_1","title":"Row Writes per Trx","text":"<p>Rows Written Per Transactions which modify rows. This is better indicator of transaction write size than looking at all transactions which did not do any writes as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollbacks_1","title":"Rollbacks","text":"<p>Percent of Transaction Rollbacks (as portion of read-write transactions).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-activity","title":"InnoDB Row Lock Wait Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-time","title":"InnoDB Row Lock Wait Time","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-lock-wait-load","title":"InnoDB Row Lock Wait Load","text":"<p>Average Number of Sessions blocked from proceeding due to waiting on row level lock.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-row-locks-activity","title":"InnoDB Row Locks Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-table-lock-activity","title":"InnoDB Table Lock Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-locks","title":"Current Locks","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-and-purging","title":"InnoDB Undo Space and Purging","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#undo-tablespaces","title":"Undo Tablespaces","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-undo-log-size","title":"Max Undo Log Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-log-truncate","title":"InnoDB Undo Log Truncate","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-threads","title":"Purge Threads","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag","title":"Max Purge Lag","text":"<p>Maximum number of  Unpurged Transactions, if this number exceeded delay will be introduced to incoming DDL statements.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-purge-lag-delay","title":"Max Purge Lag Delay","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-purge-delay","title":"Current Purge Delay","text":"<p>The Delay Injected due to Purge Thread(s) unable to keep up with purge progress.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rollback-segments","title":"Rollback Segments","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-activity","title":"InnoDB Purge Activity","text":"<p>The InnoDB Purge Performance graph shows metrics about the page purging process.  The purge process removed the undo entries from the history list and cleanup the pages of the old versions of modified rows and effectively remove deleted rows.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#transactions-and-undo-records","title":"Transactions and Undo Records","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-undo-space-usage","title":"InnoDB Undo Space Usage","text":"<p>The InnoDB Undo Space Usage graph shows the amount of space used by the Undo segment.  If the amount of space grows too much, look for long running transactions holding read views opened in the InnoDB status.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#transaction-history","title":"Transaction History","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-purge-throttling","title":"InnoDB Purge Throttling","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#records-per-undo-log-page","title":"Records Per Undo Log Page","text":"<p>How Many Undo Operations Are Handled Per Each Undo Log Page.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-invoked","title":"Purge Invoked","text":"<p>How Frequently Purge Operation is Invoked.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ops-per-purge","title":"Ops Per Purge","text":"<p>Home Many Purge Actions are done Per invocation.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#undo-slots-used","title":"Undo Slots Used","text":"<p>Number of Undo Slots Used.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#max-transaction-history-length","title":"Max Transaction History Length","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#purge-batch-size","title":"Purge Batch Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rseg-truncate-frequency","title":"Rseg Truncate Frequency","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-operations","title":"InnoDB Page Operations","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-splits-and-merges","title":"InnoDB Page Splits and Merges","text":"<p>The InnoDB Page Splits graph shows the InnoDB page maintenance activity related to splitting and merging pages.  When an InnoDB page, other than the top most leaf page, has too much data to accept a row update or a row insert, it has to be split in two.  Similarly, if an InnoDB page, after a row update or delete operation, ends up being less than half full, an attempt is made to merge the page with a neighbor page. If the resulting page size is larger than the InnoDB page size, the operation fails.  If your workload causes a large number of page splits, try lowering the <code>innodb_fill_factor</code> variable (5.7+).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#page-merge-success-ratio","title":"Page Merge Success Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorg-attempts","title":"InnoDB Page Reorg Attempts","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-page-reorgs-failures","title":"InnoDB Page Reorgs Failures","text":"<p>The InnoDB Page Reorgs graph shows information about the page reorganization operations.  When a page receives an  update or an insert that affect the offset of other rows in the page, a reorganization is needed.  If the reorganization process finds out there is not enough room in the page, the page will be split. Page reorganization can only fail for compressed pages.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-fill-factor","title":"InnoDB Fill Factor","text":"<p>The portion of the page to fill then doing sorted Index Build.   Lowering this value will worsen space utilization but will reduce need to split pages when new data is inserted in the index.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-hash-index","title":"InnoDB Adaptive Hash Index","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-enabled","title":"Adaptive Hash Index Enabled","text":"<p>Adaptive Hash Index helps to optimize index Look-ups but can be severe hotspot for some workloads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#adaptive-hash-index-partitions","title":"Adaptive Hash Index Partitions","text":"<p>How many Partitions Used for Adaptive Hash Index (to reduce contention).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#percent-of-pages-hashed","title":"Percent of Pages Hashed","text":"<p>Number of Pages Added to AHI vs Number of Pages Added to Buffer Pool.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ahi-miss-ratio","title":"AHI Miss Ratio","text":"<p>Percent of Searches which could not be resolved through AHI.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#rows-added-per-page","title":"Rows Added Per Page","text":"<p>Number of Rows \u201cHashed\u201d  Per Each Page which needs to be added to AHI.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ahi-roi","title":"AHI ROI","text":"<p>How Many Successful Searches using AHI are performed per each row maintenance operation.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-usage","title":"InnoDB AHI Usage","text":"<p>The InnoDB AHI Usage graph shows the search operations on the InnoDB adaptive hash index and its efficiency.  The adaptive hash index is a search hash designed to speed access to InnoDB pages in memory.  If the Hit Ratio is small, the working data set is larger than the buffer pool, the AHI should likely be disabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-miss-ratio","title":"InnoDB AHI Miss Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-rows","title":"InnoDB AHI Churn - Rows","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-ahi-churn-pages","title":"InnoDB AHI Churn - Pages","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer","title":"InnoDB Change Buffer","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (as Percent of Buffer Pool Size).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#change-buffer-max-size_1","title":"Change Buffer Max Size","text":"<p>The Maximum Size of Change Buffer (Bytes).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-change-buffer-merge-load","title":"InnoDB Change Buffer Merge Load","text":"<p>Number of Average of Active Merge Buffer Operations in Process.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention","title":"InnoDB Contention","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-concurrency","title":"InnoDB Thread Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-commit-concurrency","title":"InnoDB Commit Concurrency","text":"<p>If Enabled limits number of Threads allowed inside InnoDB Kernel at the same time during Commit Stage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-thread-sleep-delay","title":"InnoDB Thread Sleep Delay","text":"<p>The Time the thread will Sleep before Re-Entering InnoDB Kernel if high contention.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-adaptive-max-sleep-delay","title":"InnoDB Adaptive Max Sleep Delay","text":"<p>If Set to Non-Zero Value InnoDB Thread Sleep Delay will be adjusted automatically depending on the load up to the value specified by this variable.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-concurrency-tickets","title":"InnoDB Concurrency Tickets","text":"<p>Number of low level operations InnoDB can do after it entered InnoDB kernel before it is forced to exit and yield to another thread waiting.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-delay","title":"InnoDB Spin Wait Delay","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-spin-wait-pause-multiplier","title":"InnoDB Spin Wait Pause Multiplier","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-sync-spin-loops","title":"InnoDB Sync Spin Loops","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-os-waits","title":"InnoDB Contention - OS Waits","text":"<p>The InnoDB Contention - OS Waits graph shows the number of time an OS wait operation was required while waiting to get the lock.  This happens once the spin rounds are exhausted.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-contention-spin-rounds","title":"InnoDB Contention - Spin Rounds","text":"<p>The InnoDB Contention - Spin Rounds graph shows the number of spin rounds executed to get a lock.  A spin round is a fast retry to get the lock in a loop.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-misc","title":"InnoDB Misc","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-main-thread-utilization","title":"InnoDB Main Thread Utilization","text":"<p>The InnoDB Main Thread Utilization graph shows the portion of time the InnoDB main thread spent at various task.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-activity_1","title":"InnoDB Activity","text":"<p>The InnoDB Activity graph shows a measure of the activity of the InnoDB threads.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-dedicated-server","title":"InnoDB Dedicated Server","text":"<p>InnoDB automatically optimized for Dedicated Server Environment (auto scaling cache and some other variables).</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-sort-buffer-size","title":"InnoDB Sort Buffer Size","text":"<p>This Buffer is used for Building InnoDB Indexes using Sort algorithm.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-stats-auto-recalc","title":"InnoDB Stats Auto Recalc","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#update-stats-when-metadata-queried","title":"Update Stats when Metadata Queried","text":"<p>Refresh InnoDB Statistics when meta-data queries by <code>SHOW TABLE STATUS</code> or <code>INFORMATION_SCHEMA</code> queries.  If Enabled can cause severe performance issues.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#index-condition-pushdown-icp","title":"Index Condition Pushdown (ICP)","text":"<p>Index Condition Pushdown (ICP) is an optimization for the case where MySQL retrieves rows from a table using an index. Without ICP, the storage engine traverses the index to locate rows in the base table and returns them to the MySQL server which evaluates the\u00a0WHERE condition for the rows. With ICP enabled, and if parts of the\u00a0WHERE\u00a0condition can be evaluated by using only columns from the index, the MySQL server pushes this part of the\u00a0WHERE\u00a0condition down to the storage engine. The storage engine then evaluates the pushed index condition by using the index entry and only if this is satisfied is the row read from the table. ICP can reduce the number of times the storage engine must access the base table and the number of times the MySQL server must access the storage engine.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-statistics","title":"InnoDB Persistent Statistics","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-persistent-sample-pages","title":"InnoDB Persistent Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Enabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-transient-sample-pages","title":"InnoDB Transient Sample Pages","text":"<p>Number of Pages To Sample if Persistent Statistics are Disabled.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-online-operations-mariadb","title":"InnoDB Online Operations (MariaDB)","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-defragmentation","title":"InnoDB Defragmentation","text":"<p>The InnoDB Defragmentation graph shows the status information related to the InnoDB online defragmentation feature of MariaDB for the optimize table command.  To enable this feature, the variable <code>innodb-defragment</code> must be set to 1 in the configuration file.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#innodb-online-ddl","title":"InnoDB Online DDL","text":"<p>The InnoDB Online DDL graph shows the state of the online DDL (alter table) operations in InnoDB.  The progress metric is estimate of the percentage of the rows processed by the online DDL.</p> <p>Currently available only on a MariaDB server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-summary","title":"MySQL Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-uptime","title":"MySQL Uptime","text":"<p>MySQL Uptime</p> <p>The amount of time since the last restart of the MySQL server process.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#current-qps","title":"Current QPS","text":"<p>Current QPS</p> <p>Based on the queries reported by MySQL\u2019s <code>SHOW STATUS</code> command, it is the number of statements executed by the server within the last second. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count <code>COM_PING</code> or <code>COM_STATISTICS</code> commands.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#file-handlers-used","title":"File Handlers Used","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-miss-ratio","title":"Table Open Cache Miss Ratio","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-open-cache-size","title":"Table Open Cache Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#table-definition-cache-size","title":"Table Definition Cache Size","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-connections","title":"MySQL Connections","text":"<p>Max Connections</p> <p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that mysqld requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p>mysqld actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":"<p>MySQL Active Threads</p> <p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-handlers","title":"MySQL Handlers","text":"<p>MySQL Handlers</p> <p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#top-command-counters","title":"Top Command Counters","text":"<p>Top Command Counters</p> <p>The <code>Com_{{ xxx }}</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count <code>DELETE</code> and <code>UPDATE</code> statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to <code>DELETE</code> and <code>UPDATE</code> statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#mysql-network-traffic","title":"MySQL Network Traffic","text":"<p>MySQL Network Traffic</p> <p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#node-summary","title":"Node Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#system-uptime","title":"System Uptime","text":"<p>The parameter shows how long a system has been up and running without a shut down or restart.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#load-average","title":"Load Average","text":"<p>The system load is a measurement of the computational work the system is performing. Each running process either using or waiting for CPU resources adds 1 to the load.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#ram","title":"RAM","text":"<p>RAM (Random Access Memory) is the hardware in a computing device where the operating system, application programs and data in current use are kept so they can be quickly reached by the device\u2019s processor.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#memory-available","title":"Memory Available","text":"<p>Percent of Memory Available</p> <p>On Modern Linux Kernels amount of Memory Available for application is not the same as Free+Cached+Buffers.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#virtual-memory","title":"Virtual Memory","text":"<p>RAM + SWAP</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#disk-space","title":"Disk Space","text":"<p>Sum of disk space on all partitions.</p> <p>It can be significantly over-reported in some installations.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#min-space-available","title":"Min Space Available","text":"<p>Lowest percent of the disk space available.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p> <p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"reference/dashboards/dashboard-mysql-innodb-details.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html","title":"MySQL Instance Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-connections","title":"MySQL Connections","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#max-connections","title":"Max Connections","text":"<p>Max Connections is the maximum permitted number of simultaneous client connections. By default, this is 151. Increasing this value increases the number of file descriptors that <code>mysqld</code> requires. If the required number of descriptors are not available, the server reduces the value of Max Connections.</p> <p><code>mysqld</code> actually permits Max Connections + 1 clients to connect. The extra connection is reserved for use by accounts that have the SUPER privilege, such as root.</p> <p>Max Used Connections is the maximum number of connections that have been in use simultaneously since the server started.</p> <p>Connections is the number of connection attempts (successful or not) to the MySQL server.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-aborted-connections","title":"MySQL Aborted Connections","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#aborted-connections","title":"Aborted Connections","text":"<p>When a given host connects to MySQL and the connection is interrupted in the middle (for example due to bad credentials), MySQL keeps that info in a system table (since 5.6 this table is exposed in <code>performance_schema</code>).</p> <p>If the amount of failed requests without a successful connection reaches the value of <code>max_connect_errors</code>, <code>mysqld</code> assumes that something is wrong and blocks the host from further connection.</p> <p>To allow connections from that host again, you need to issue the <code>FLUSH HOSTS</code> statement.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-client-thread-activity","title":"MySQL Client Thread Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-active-threads","title":"MySQL Active Threads","text":"<p>Threads Connected is the number of open connections, while Threads Running is the number of threads not sleeping.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache","title":"MySQL Thread Cache","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-thread-cache_1","title":"MySQL Thread Cache","text":"<p>The <code>thread_cache_size</code> variable sets how many threads the server should cache to reuse. When a client disconnects, the client\u2019s threads are put in the cache if the cache is not full. It is auto-sized in MySQL 5.6.8 and above (capped to 100). Requests for threads are satisfied by reusing threads taken from the cache if possible, and only when the cache is empty is a new thread created.</p> <ul> <li><code>threads_created</code>: The number of threads created to handle connections.</li> <li><code>threads_cached</code>: The number of threads in the thread cache.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries","title":"MySQL Slow Queries","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-slow-queries_1","title":"MySQL Slow Queries","text":"<p>Slow queries are defined as queries being slower than the <code>long_query_time</code> setting. For example, if you have <code>long_query_time</code> set to 3, all queries that take longer than 3 seconds to complete will show on this graph.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types","title":"MySQL Select Types","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-select-types_1","title":"MySQL Select Types","text":"<p>As with most relational databases, selecting based on indexes is more efficient than scanning an entire table\u2019s data. Here we see the counters for selects not done with indexes.</p> <ul> <li>Select Scan is how many queries caused full table scans, in which all the data in the table had to be read and either discarded or returned.</li> <li>Select Range is how many queries used a range scan, which means MySQL scanned all rows in a given range.</li> <li>Select Full Join is the number of joins that are not joined on an index, this is usually a huge performance hit.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts","title":"MySQL Sorts","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-sorts_1","title":"MySQL Sorts","text":"<p>Due to a query\u2019s structure, order, or other requirements, MySQL sorts the rows before returning them. For example, if a table is ordered 1 to 10 but you want the results reversed, MySQL then has to sort the rows to return 10 to 1.</p> <p>This graph also shows when sorts had to scan a whole table or a given range of a table to return the results and which could not have been sorted via an index.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-locks","title":"MySQL Table Locks","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#table-locks","title":"Table Locks","text":"<p>MySQL takes a number of different locks for varying reasons. In this graph we see how many Table level locks MySQL has requested from the storage engine. In the case of InnoDB, many times the locks could actually be row locks as it only takes table level locks in a few specific cases.</p> <p>It is most useful to compare Locks Immediate and Locks Waited. If Locks waited is rising, it means you have lock contention. Otherwise, Locks Immediate rising and falling is normal activity.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-questions","title":"MySQL Questions","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-questions_1","title":"MySQL Questions","text":"<p>The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries used in the QPS calculation.</p> <p>This variable does not count the following commands:</p> <ul> <li><code>COM_PING</code></li> <li><code>COM_STATISTICS</code></li> <li><code>COM_STMT_PREPARE</code></li> <li><code>COM_STMT_CLOSE</code></li> <li><code>COM_STMT_RESET</code></li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic","title":"MySQL Network Traffic","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-traffic_1","title":"MySQL Network Traffic","text":"<p>Here we can see how much network traffic is generated by MySQL. Outbound is network traffic sent from MySQL and Inbound is network traffic MySQL has received.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly","title":"MySQL Network Usage Hourly","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-network-usage-hourly_1","title":"MySQL Network Usage Hourly","text":"<p>Here we can see how much network traffic is generated by MySQL per hour. You can use the bar graph to compare data sent by MySQL and data received by MySQL.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-internal-memory-overview","title":"MySQL Internal Memory Overview","text":"<p>System Memory: Total Memory for the system.</p> <p>InnoDB Buffer Pool Data: InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.</p> <p>TokuDB Cache Size: Similar in function to the InnoDB Buffer Pool, TokuDB will allocate 50% of the installed RAM for its own cache.</p> <p>Key Buffer Size: Index blocks for MyISAM tables are buffered and are shared by all threads. <code>key_buffer_size</code> is the size of the buffer used for index blocks.</p> <p>Adaptive Hash Index Size: When InnoDB notices that some index values are being accessed very frequently, it builds a hash index for them in memory on top of B-Tree indexes.</p> <p>Query Cache Size: The query cache stores the text of a SELECT statement together with the corresponding result that was sent to the client. The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time.</p> <p>InnoDB Dictionary Size: The data dictionary is InnoDB\u2019s internal catalog of tables. InnoDB stores the data dictionary on disk, and loads entries into memory while the server is running.</p> <p>InnoDB Log Buffer Size: The MySQL InnoDB log buffer allows transactions to run without having to write the log to disk before the transactions commit.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters","title":"Top Command Counters","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters_1","title":"Top Command Counters","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly","title":"Top Command Counters Hourly","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#top-command-counters-hourly_1","title":"Top Command Counters Hourly","text":"<p>The <code>Com_xxx</code> statement counter variables indicate the number of times each <code>xxx</code> statement has been executed. There is one status variable for each type of statement. For example, <code>Com_delete</code> and <code>Com_update</code> count DELETE and UPDATE statements, respectively. <code>Com_delete_multi</code> and <code>Com_update_multi</code> are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers","title":"MySQL Handlers","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-handlers_1","title":"MySQL Handlers","text":"<p>Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes.</p> <p>This is in fact the layer between the Storage Engine and MySQL.</p> <ul> <li><code>read_rnd_next</code> is incremented when the server performs a full table scan and this is a counter you don\u2019t really want to see with a high value.</li> <li><code>read_key</code> is incremented when a read is done with an index.</li> <li><code>read_next</code> is incremented when the storage engine is asked to \u2018read the next index entry\u2019. A high value means a lot of index scans are being done.</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory","title":"MySQL Query Cache Memory","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-memory_1","title":"MySQL Query Cache Memory","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity","title":"MySQL Query Cache Activity","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-query-cache-activity_1","title":"MySQL Query Cache Activity","text":"<p>The query cache has huge scalability problems in that only one thread can do an operation in the query cache at the same time. This serialization is true not only for SELECTs, but also for INSERT/UPDATE/DELETE.</p> <p>This also means that the larger the <code>query_cache_size</code> is set to, the slower those operations become. In concurrent environments, the MySQL Query Cache quickly becomes a contention point, decreasing performance. MariaDB and AWS Aurora have done work to try and eliminate the query cache contention in their flavors of MySQL, while MySQL 8.0 has eliminated the query cache feature.</p> <p>The recommended settings for most environments is to set:</p> <ul> <li><code>query_cache_type=0</code></li> <li><code>query_cache_size=0</code></li> </ul> <p>Tip</p> <p>While you can dynamically change these values, to completely remove the contention point you have to restart the database.</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status","title":"MySQL Table Open Cache Status","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-open-cache-status_1","title":"MySQL Table Open Cache Status","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables","title":"MySQL Open Tables","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-open-tables_1","title":"MySQL Open Tables","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache","title":"MySQL Table Definition Cache","text":""},{"location":"reference/dashboards/dashboard-mysql-instance-summary.html#mysql-table-definition-cache_1","title":"MySQL Table Definition Cache","text":"<p>The recommendation is to set the <code>table_open_cache_instances</code> to a loose correlation to virtual CPUs, keeping in mind that more instances means the cache is split more times. If you have a cache set to 500 but it has 10 instances, each cache will only have 50 cached.</p> <p>The <code>table_definition_cache</code> and <code>table_open_cache</code> can be left as default as they are auto-sized MySQL 5.6 and above (i.e., do not set them to any value).</p>"},{"location":"reference/dashboards/dashboard-mysql-instances-compare.html","title":"MySQL Instances Compare","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-mysql-instances-overview.html","title":"MySQL Instances Overview","text":""},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html","title":"MySQL MyISAM/Aria Details","text":""},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#myisam-key-buffer-performance","title":"MyISAM Key Buffer Performance","text":"<p>The <code>Key Read Ratio</code>  (<code>Key_reads</code> / <code>Key_read_requests</code>) ratio should normally be less than 0.01.</p> <p>The  <code>Key Write Ratio</code> (<code>Key_writes</code> / <code>Key_write_requests</code>) ratio is usually near 1 if you are using mostly updates and deletes, but might be much smaller if you tend to do updates that affect many rows at the same time or if you are using the <code>DELAY_KEY_WRITE</code> table option.</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-readswrites","title":"Aria Pagecache Reads/Writes","text":"<p>This graph is similar to InnoDB buffer pool reads/writes. <code>aria-pagecache-buffer-size</code> is the main cache for the Aria storage engine. If you see high reads/writes (physical IO), i.e. reads are close to read requests and/or writes are close to write requests you may need to increase the <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-transaction-log-syncs","title":"Aria Transaction Log Syncs","text":"<p>This is similar to InnoDB log file syncs. If you see lots of log syncs and want to relax the durability settings you can change <code>aria_checkpoint_interval</code> (in seconds) from 30 (default) to a higher number. It is good to look at the disk IO dashboard as well.</p>"},{"location":"reference/dashboards/dashboard-mysql-myisam-aria-details.html#aria-pagecache-blocks","title":"Aria Pagecache Blocks","text":"<p>This graph shows the utilization for the Aria pagecache. This is similar to InnoDB buffer pool graph. If you see all blocks are used you may consider increasing <code>aria-pagecache-buffer-size</code> (may need to decrease other buffers: <code>key_buffer_size</code>, <code>innodb_buffer_pool_size</code>, etc.)</p>"},{"location":"reference/dashboards/dashboard-mysql-myrocks-details.html","title":"MySQL MyRocks Details","text":"<p>The MyRocks storage engine developed by Facebook based on the RocksDB storage engine is applicable to systems which primarily interact with the database by writing data to it rather than reading from it. RocksDB also features a good level of compression, higher than that of the InnoDB storage engine, which makes it especially valuable when optimizing the usage of hard drives.</p> <p>PMM collects statistics on the MyRocks storage engine for MySQL in the Metrics Monitor information for this dashboard comes from the Information Schema tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-myrocks-details.html#metrics","title":"Metrics","text":"<ul> <li>MyRocks cache</li> <li>MyRocks cache data bytes R/W</li> <li>MyRocks cache index hit rate</li> <li>MyRocks cache index</li> <li>MyRocks cache filter hit rate</li> <li>MyRocks cache filter</li> <li>MyRocks cache data bytes inserted</li> <li>MyRocks bloom filter</li> <li>MyRocks memtable</li> <li>MyRocks memtable size</li> <li>MyRocks number of keys</li> <li>MyRocks cache L0/L1</li> <li>MyRocks number of DB ops</li> <li>MyRocks R/W</li> <li>MyRocks bytes read by iterations</li> <li>MyRocks write ops</li> <li>MyRocks WAL</li> <li>MyRocks number reseeks in iterations</li> <li>RocksDB row operations</li> <li>MyRocks file operations</li> <li>RocksDB stalls</li> <li>RocksDB stops/slowdowns</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-performance-schema-details.html","title":"MySQL Performance Schema Details","text":"<p>The MySQL Performance Schema dashboard helps determine the efficiency of communicating with Performance Schema. This dashboard contains the following metrics:</p> <ul> <li>Performance Schema file IO (events)</li> <li>Performance Schema file IO (load)</li> <li>Performance Schema file IO (Bytes)</li> <li>Performance Schema waits (events)</li> <li>Performance Schema waits (load)</li> <li>Index access operations (load)</li> <li>Table access operations (load)</li> <li>Performance Schema SQL and external locks (events)</li> <li>Performance Schema SQL and external locks (seconds)</li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html","title":"MySQL Query Response Time Details","text":""},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time","title":"Average Query Response Time","text":"<p>The Average Query Response Time graph shows information collected using the Response Time Distribution plugin sourced from table <code>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</code>. It computes this value across all queries by taking the sum of seconds divided by the count of queries.</p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#query-response-time-distribution","title":"Query Response Time Distribution","text":"<p>Query response time counts (operations) are grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#average-query-response-time_1","title":"Average Query Response Time","text":"<p>Available only in Percona Server for MySQL, provides  visibility of the split of READ vs WRITE query response time.</p>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#read-query-response-time-distribution","title":"Read Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates READ query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-query-response-time-details.html#write-query-response-time-distribution","title":"Write Query Response Time Distribution","text":"<p>Available only in Percona Server for MySQL, illustrates WRITE query response time counts (operations) grouped into three buckets:</p> <ul> <li> <p>100 ms - 1 s</p> </li> <li> <p>1 s - 10 s</p> </li> <li> <p>&gt; 10 s</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html","title":"MySQL Replication Summary","text":""},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#io-thread-running","title":"IO Thread Running","text":"<p>This metric shows if the IO Thread is running or not. It only applies to a secondary host.</p> <p>SQL Thread is a process that runs on a secondary host in the replication environment. It reads the events from the local relay log file and applies them to the secondary server.</p> <p>Depending on the format of the binary log it can read query statements in plain text and re-execute them or it can read raw data and apply them to the local host.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values","title":"Possible values","text":"Yes The thread is running and is connected to a replication primary No The thread is not running because it is not launched yet or because an error has occurred connecting to the primary host Connecting The thread is running but is not connected to a replication primary No value The host is not configured to be a replication secondary <p>IO Thread Running is one of the parameters that the command <code>SHOW SLAVE STATUS</code> returns.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#sql-thread-running","title":"SQL Thread Running","text":"<p>This metric shows if the SQL thread is running or not. It only applies to a secondary host.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values_1","title":"Possible values","text":"Yes SQL Thread is running and is applying events from the relay log to the local secondary host No SQL Thread is not running because it is not launched yet or because of an error occurred while applying an event to the local secondary host"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#replication-error-no","title":"Replication Error No","text":"<p>This metric shows the number of the last error in the SQL Thread encountered which caused replication to stop.</p> <p>One of the more common errors is Error: 1022 Duplicate Key Entry. In such a case replication is attempting to update a row that already exists on the secondary. The SQL Thread will stop replication to avoid data corruption.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#read-only","title":"Read only","text":"<p>This metric indicates whether the host is configured to be in Read Only mode or not.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#possible-values_2","title":"Possible values","text":"Yes <p>The secondary host permits no client updates except from users who have the SUPER privilege or the REPLICATION SLAVE privilege.</p> <p>This kind of configuration is typically used for secondary hosts in a replication environment to avoid a user can inadvertently or voluntarily modify data causing inconsistencies and stopping the replication process.</p> No The secondary host is not configured in Read Only mode."},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#mysql-replication-delay","title":"MySQL Replication Delay","text":"<p>This metric shows the number of seconds the secondary host is delayed in replication applying events compared to when the primary host applied them, denoted by the <code>Seconds_Behind_Master</code> value, and only applies to a secondary host.</p> <p>Since the replication process applies the data modifications on the secondary asynchronously, it could happen that the secondary replicates events after some time. The main reasons are:</p> <ul> <li> <p>Network round trip time - high latency links will lead to non-zero replication lag values.</p> </li> <li> <p>Single threaded nature of replication channels - primary servers have the advantage of applying changes in parallel, whereas secondary ones are only able to apply changes in serial, thus limiting their throughput. In some cases Group Commit can help but is not always applicable.</p> </li> <li> <p>High number of changed rows or computationally expensive SQL - depending on the replication format (<code>ROW</code> vs <code>STATEMENT</code>), significant changes to the database through high volume of rows modified, or expensive CPU will all contribute to secondary servers lagging behind the primary.</p> </li> </ul> <p>Generally adding more CPU or Disk resources can alleviate replication lag issues, up to a point.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-size","title":"Binlog Size","text":"<p>This metric shows the overall size of the binary log files, which can exist on both primary and secondary servers.</p> <p>The binary log (also known as the binlog) contains events that describe database changes: <code>CREATE TABLE</code>, <code>ALTER TABLE</code>, updates, inserts, deletes and other statements or database changes.</p> <p>The binlog file is read by secondaries via their IO Thread process to replicate database changes modification on the data and on the table structures. There can be more than one binlog file depending on the binlog rotation policy (for example using the configuration variables <code>max_binlog_size</code> and <code>expire_logs_days</code>) or because of server reboots.</p> <p>When planning the disk space, take care of the overall dimension of binlog files and adopt a good rotation policy or think about having a separate mount point or disk to store the binlog data.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-data-written-hourly","title":"Binlog Data Written Hourly","text":"<p>This metric shows the amount of data written hourly to the binlog files during the last 24 hours. This metric can give you an idea of how big is your application in terms of data writes (creation, modification, deletion).</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlog-count","title":"Binlog Count","text":"<p>This metric shows the overall count of binary log files, on both primary and secondary servers.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#binlogs-created-hourly","title":"Binlogs Created Hourly","text":"<p>This metric shows the number of binlog files created hourly during the last 24 hours.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#relay-log-space","title":"Relay Log Space","text":"<p>This metric shows the overall size of the relay log files. It only applies to a secondary host.</p> <p>The relay log consists of a set of numbered files containing the events to be executed on the secondary host to replicate database changes.</p> <p>The relay log has the same format as the binlog.</p> <p>There can be multiple relay log files depending on the rotation policy adopted (using the configuration variable <code>max_relay_log_size</code>).</p> <p>As soon as the SQL thread completes to execute all events in the relay log file, the file is deleted.</p> <p>If this metric contains a high value, the variable <code>max_relay_log_file</code> is high too. Generally, this not a serious issue. If the value of this metric is constantly increased, the secondary is delaying too much in applying the events.</p> <p>Treat this metric in the same way as the MySQL Replication Delay metric.</p>"},{"location":"reference/dashboards/dashboard-mysql-replication-summary.html#relay-log-written-hourly","title":"Relay Log Written Hourly","text":"<p>This metric shows the amount of data written hourly into relay log files during the last 24 hours.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html","title":"MySQL Table Details","text":""},{"location":"reference/dashboards/dashboard-mysql-table-details.html#largest-tables","title":"Largest Tables","text":"Largest Tables by Row Count The estimated number of rows in the table from <code>information_schema.tables</code>. Largest Tables by Size The size of the table components from <code>information_schema.tables</code>."},{"location":"reference/dashboards/dashboard-mysql-table-details.html#pie","title":"Pie","text":"Total Database Size The total size of the database: as data + index size, so freeable one. Most Fragmented Tables by Freeable Size The list of 5 most fragmented tables ordered by their freeable size"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#table-activity","title":"Table Activity","text":"<p>The next two graphs are available only for Percona Server and MariaDB and require <code>userstat</code> variable turned on.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#rows-read","title":"Rows read","text":"<p>The number of rows read from the table, shown for the top 5 tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#rows-changed","title":"Rows Changed","text":"<p>The number of rows changed in the table, shown for the top 5 tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-table-details.html#auto-increment-usage","title":"Auto Increment Usage","text":"<p>The current value of an <code>auto_increment</code> column from <code>information_schema</code>, shown for the top 10 tables.</p>"},{"location":"reference/dashboards/dashboard-mysql-tokudb-details.html","title":"MySQL TokuDB Details","text":""},{"location":"reference/dashboards/dashboard-mysql-user-details.html","title":"MySQL User Details","text":"<p>This dashboard requires Percona Server for MySQL 5.1+ or MariaDB 10.1/10.2 with XtraDB. Also <code>userstat</code> should be enabled, for example with the <code>SET GLOBAL userstat=1</code> statement. See Setting up MySQL.</p> <p>Data is displayed for the 5 top users.</p> Top Users by Connections Created The number of times user\u2019s connections connected using SSL to the server. Top Users by Traffic The number of bytes sent to the user\u2019s connections. Top Users by Rows Fetched/Read The number of rows fetched by the user\u2019s connections. Top Users by Rows Updated The number of rows updated by the user\u2019s connections. Top Users by Busy Time The cumulative number of seconds there was activity on connections from the user. Top Users by CPU Time The cumulative CPU time elapsed, in seconds, while servicing connections of the user."},{"location":"reference/dashboards/dashboard-mysql-wait-event-analyses-details.html","title":"MySQL Wait Event Analyses Details","text":"<p>This dashboard helps to analyze Performance Schema wait events. It plots the following metrics for the chosen (one or more) wait events:</p> <ul> <li>Count - Performance Schema Waits</li> <li>Load - Performance Schema Waits</li> <li>Avg Wait Time - Performance Schema Waits</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html","title":"Network Details","text":""},{"location":"reference/dashboards/dashboard-network-details.html#last-hour-statistic","title":"Last Hour Statistic","text":"<p>This section reports the inbound speed, outbound speed, traffic errors and drops, and retransmit rate.</p>"},{"location":"reference/dashboards/dashboard-network-details.html#network-traffic","title":"Network Traffic","text":"<p>This section contains the Network traffic and network utilization hourly metrics.</p>"},{"location":"reference/dashboards/dashboard-network-details.html#network-traffic-details","title":"Network Traffic Details","text":"<p>This section offers the following metrics:</p> <ul> <li>Network traffic by packets</li> <li>Network traffic errors</li> <li>Network traffic drop</li> <li>Network traffic multicast</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#network-netstat-tcp","title":"Network Netstat TCP","text":"<p>This section offers the following metrics:</p> <ul> <li>Timeout value used for retransmitting</li> <li>Min TCP retransmission timeout</li> <li>Max TCP retransmission timeout</li> <li>Netstat: TCP</li> <li>TCP segments</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#network-netstat-udp","title":"Network Netstat UDP","text":"<p>In this section, you can find the following metrics:</p> <ul> <li>Netstat: UDP</li> <li>UDP Lite</li> </ul> <p>The graphs in the UDP Lite metric give statistics about:</p> <code>InDatagrams</code> Packets received <code>OutDatagrams</code> Packets sent <code>InCsumErrors</code> Datagrams with checksum errors <code>InErrors</code> Datagrams that could not be delivered to an application <code>RcvbufErrors</code> Datagrams for which not enough socket buffer memory to receive <code>SndbufErrors</code> Datagrams for which not enough socket buffer memory to transmit <code>NoPorts</code> Datagrams received on a port with no listener"},{"location":"reference/dashboards/dashboard-network-details.html#icmp","title":"ICMP","text":"<p>This section has the following metrics:</p> <ul> <li>ICMP Errors</li> <li>Messages/Redirects</li> <li>Echos</li> <li>Timestamps/Mask Requests</li> </ul>"},{"location":"reference/dashboards/dashboard-network-details.html#icmp-errors","title":"ICMP Errors","text":"<code>InErrors</code> Messages which the entity received but determined as having ICMP-specific errors (bad ICMP checksums, bad length, etc.) <code>OutErrors</code> Messages which this entity did not send due to problems discovered within ICMP, such as a lack of buffers <code>InDestUnreachs</code> Destination Unreachable messages received <code>OutDestUnreachs</code> Destination Unreachable messages sent <code>InType3</code> Destination unreachable <code>OutType3</code> Destination unreachable <code>InCsumErrors</code> Messages with ICMP checksum errors <code>InTimeExcds</code> Time Exceeded messages received"},{"location":"reference/dashboards/dashboard-network-details.html#messagesredirects","title":"Messages/Redirects","text":"<code>InMsgs</code> Messages which the entity received. Note that this counter includes all those counted by <code>icmpInErrors</code> <code>InRedirects</code> Redirect messages received <code>OutMsgs</code> Messages which this entity attempted to send. Note that this counter includes all those counted by <code>icmpOutErrors</code> <code>OutRedirects</code> Redirect messages sent. For a host, this object will always be zero, since hosts do not send redirects"},{"location":"reference/dashboards/dashboard-network-details.html#echos","title":"Echos","text":"<code>InEchoReps</code> Echo Reply messages received <code>InEchos</code> Echo (request) messages received <code>OutEchoReps</code> Echo Reply messages sent <code>OutEchos</code> Echo (request) messages sent"},{"location":"reference/dashboards/dashboard-network-details.html#timestampsmask-requests","title":"Timestamps/Mask Requests","text":"<code>InAddrMaskReps</code> Address Mask Reply messages received <code>InAddrMasks</code> Address Mask Request messages received <code>OutAddrMaskReps</code> Address Mask Reply messages sent <code>OutAddrMasks</code> Address Mask Request messages sent <code>InTimestampReps</code> Timestamp Reply messages received <code>InTimestamps</code> Timestamp Request messages received <code>OutTimestampReps</code> Timestamp Reply messages sent <code>OutTimestamps</code> Timestamp Request messages sent"},{"location":"reference/dashboards/dashboard-node-summary.html","title":"Node Summary","text":""},{"location":"reference/dashboards/dashboard-node-summary.html#system-summary","title":"System Summary","text":"<p>The output from <code>pt-summary</code>, one of the Percona Toolkit utilities.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#cpu-usage","title":"CPU Usage","text":"<p>The CPU time is measured in clock ticks or seconds. It is useful to measure CPU time as a percentage of the CPU\u2019s capacity, which is called the CPU usage.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#cpu-saturation-and-max-core-usage","title":"CPU Saturation and Max Core Usage","text":"<p>When a system is running with maximum CPU utilization, the transmitting and receiving threads must all share the available CPU. This will cause data to be queued more frequently to cope with the lack of CPU. CPU Saturation may be measured as the length of a wait queue, or the time spent waiting on the queue.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#interrupts-and-context-switches","title":"Interrupts and Context Switches","text":"<p>Interrupt is an input signal to the processor indicating an event that needs immediate attention. An interrupt signal alerts the processor and serves as a request for the processor to interrupt the currently executing code, so that the event can be processed in a timely manner.</p> <p>Context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point. This allows multiple processes to share a single CPU, and is an essential feature of a multitasking operating system.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#swap-activity","title":"Swap Activity","text":"<p>Swap Activity is memory management that involves swapping sections of memory to and from physical storage.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#io-activity","title":"I/O Activity","text":"<p>Disk I/O includes read or write or input/output operations involving a physical disk. It is the speed with which the data transfer takes place between the hard disk drive and RAM.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#disk-io-latency","title":"Disk IO Latency","text":"<p>Shows average latency for Reads and Writes IO Devices.  Higher than typical latency for highly loaded storage indicates saturation (overload) and is frequent cause of performance problems.  Higher than normal latency also can indicate internal storage problems.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#disk-io-load","title":"Disk IO Load","text":"<p>Shows how much disk was loaded for reads or writes as average number of outstanding requests at different period of time.  High disk load is a good measure of actual storage utilization. Different storage types handle load differently - some will show latency increases on low loads others can handle higher load with no problems.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#local-network-errors","title":"Local Network Errors","text":"<p>Total Number of Local Network Interface Transmit Errors, Receive Errors and Drops.  Should be  Zero</p>"},{"location":"reference/dashboards/dashboard-node-summary.html#tcp-retransmission","title":"TCP Retransmission","text":"<p>Retransmission, essentially identical with Automatic repeat request (ARQ), is the resending of packets which have been either damaged or lost. Retransmission is one of the basic mechanisms used by protocols operating over a packet switched computer network to provide reliable communication (such as that provided by a reliable byte stream, for example TCP).</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html","title":"Node Temperature Details","text":"<p>The Node Temperature Details dashboard exposes hardware monitoring and sensor data obtained through the <code>sysfs</code> virtual file system of the node.</p> <p>Hardware monitoring devices attached to the CPU and/or other chips on the motherboard let you monitor the hardware health of a system. Most modern systems include several of such devices. The actual list can include temperature sensors, voltage sensors, fan speed sensors, and various additional features, such as the ability to control the rotation speed of the fans.</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#cpu-cores-temperatures","title":"CPU Cores Temperatures","text":"<p>Presents data taken from the temperature sensors of the CPU</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#chips-temperatures","title":"Chips Temperatures","text":"<p>Presents data taken from the temperature sensors connected to other system controllers</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#fan-rotation-speeds","title":"Fan Rotation Speeds","text":"<p>Fan rotation speeds reported in RPM (rotations per minute).</p>"},{"location":"reference/dashboards/dashboard-node-temperature-details.html#fan-power-usage","title":"Fan Power Usage","text":"<p>Describes the pulse width modulation of the PWN-equipped fans. PWM operates like a switch that constantly cycles on and off, thereby regulating the amount of power the fan gains: 100% makes it rotate at full speed, while lower percentage slows rotation down proportionally.</p>"},{"location":"reference/dashboards/dashboard-nodes-compare.html","title":"Nodes Compare","text":"<p>This dashboard lets you compare a wide range of parameters. Parameters of the same type are shown side by side for all servers, grouped into the following sections:</p> <ul> <li>System Information</li> <li>CPU</li> <li>Memory</li> <li>Disk Partitions</li> <li>Disk Performance</li> <li>Network</li> </ul> <p>The System Information section shows the System Info summary of each server, as well as System Uptime, CPU Cores, RAM, Saturation Metrics, and Load Average gauges.</p> <p>The CPU section offers the CPU Usage, Interrupts, and Context Switches metrics.</p> <p>In the Memory section, you can find the Memory Usage, Swap Usage, and Swap Activity metrics.</p> <p>The Disk Partitions section encapsulates two metrics, Mountpoint Usage and Free Space.</p> <p>The Disk Performance section contains the I/O Activity, Disk Operations, Disk Bandwidth, Disk IO Utilization, Disk Latency, and Disk Load metrics.</p> <p>Finally, Network section shows Network Traffic, and Network Utilization Hourly metrics.</p>"},{"location":"reference/dashboards/dashboard-nodes-overview.html","title":"Nodes Overview","text":"<p>The Nodes Overview dashboard provides details about the efficiency of work of the following components. Each component is represented as a section in the dashboard.</p> <ul> <li>CPU</li> <li>Memory &amp; Swap</li> <li>Disk</li> <li>Network</li> </ul> <p>The CPU section offers the CPU Usage, CPU Saturation and Max Core Usage, Interrupts and Context Switches, and Processes metrics.</p> <p>In the Memory section, you can find the Memory Utilization, Virtual Memory Utilization, Swap Space, and Swap Activity metrics.</p> <p>The Disk section contains the I/O Activity, Global File Descriptors Usage, Disk IO Latency, and Disk IO Load metrics.</p> <p>In the Network section, you can find the Network Traffic, Network Utilization Hourly, Local Network Errors, and TCP Retransmission metrics.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html","title":"NUMA Details","text":"<p>For each node, this dashboard shows metrics related to Non-uniform memory access (NUMA).</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#memory-usage","title":"Memory Usage","text":"<p>Remotes over time the total, used, and free memory.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#free-memory-percent","title":"Free Memory Percent","text":"<p>Shows the free memory as the ratio to the total available memory.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#numa-memory-usage-types","title":"NUMA Memory Usage Types","text":"<code>Dirty</code> Memory waiting to be written back to disk <code>Bounce</code> Memory used for block device bounce buffers <code>Mapped</code> Files which have been mapped, such as libraries <code>KernelStack</code> The memory the kernel stack uses. This is not reclaimable."},{"location":"reference/dashboards/dashboard-numa-details.html#numa-allocation-hits","title":"NUMA Allocation Hits","text":"<p>Memory successfully allocated on this node as intended.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#numa-allocation-missed","title":"NUMA Allocation Missed","text":"<p>Memory missed is allocated on a node despite the process preferring some different node.</p> <p>Memory foreign is intended for a node, but actually allocated on some different node.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#anonymous-memory","title":"Anonymous Memory","text":"Active Anonymous memory that has been used more recently and usually not swapped out. Inactive Anonymous memory that has not been used recently and can be swapped out."},{"location":"reference/dashboards/dashboard-numa-details.html#numa-file-pagecache","title":"NUMA File (PageCache)","text":"<p>Active(file) Pagecache memory that has been used more recently and usually not reclaimed until needed.</p> <p>Inactive(file) Pagecache memory that can be reclaimed without huge performance impact.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#shared-memory","title":"Shared Memory","text":"<p>Shmem Total used shared memory (shared between several processes, thus including RAM disks, SYS-V-IPC and BSD like SHMEM).</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#hugepages-statistics","title":"HugePages Statistics","text":"Total Number of hugepages being allocated by the kernel (Defined with <code>vm.nr_hugepages</code>). Free The number of hugepages not being allocated by a process <code>Surp</code> The number of hugepages in the pool above the value in <code>vm.nr_hugepages</code>. The maximum number of surplus hugepages is controlled by <code>vm.nr_overcommit_hugepages</code>."},{"location":"reference/dashboards/dashboard-numa-details.html#local-processes","title":"Local Processes","text":"<p>Memory allocated on a node while a process was running on it.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#remote-processes","title":"Remote Processes","text":"<p>Memory allocated on a node while a process was running on some other node.</p>"},{"location":"reference/dashboards/dashboard-numa-details.html#slab-memory","title":"Slab Memory","text":"<code>Slab</code> Allocation is a memory management mechanism intended for the efficient memory allocation of kernel objects. <code>SReclaimable</code> The part of the Slab that might be reclaimed (such as caches). <code>SUnreclaim</code> The part of the Slab that can\u2019t be reclaimed under memory pressure"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html","title":"PostgreSQL Checkpoints, Buffers and WAL Usage","text":"<p>This dashboard monitors PostgreSQL\u2019s checkpoint behavior, buffer management, and Write-Ahead Log (WAL) activity to help you identify I/O bottlenecks and optimize your database performance. </p> <p>Use this to correlate checkpoint activity with disk I/O patterns and understand their impact on your storage subsystem.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#checkpointing-and-wal","title":"Checkpointing and WAL","text":""},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#checkpoint-timeout","title":"Checkpoint Timeout","text":"<p>Shows the maximum time PostgreSQL waits between automatic WAL checkpoints. This controls how often PostgreSQL automatically saves your database changes to ensure data recovery after crashes. </p> <p>Longer intervals mean fewer checkpoint interruptions but potentially longer recovery times.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#checkpoint-completion-target","title":"Checkpoint Completion Target","text":"<p>Shows what percentage of the checkpoint interval PostgreSQL uses to spread out checkpoint writes. For example, 0.9 (90%) means PostgreSQL tries to complete checkpoints within 90% of the timeout period. </p> <p>This helps you avoid I/O spikes by spreading checkpoint work over time instead of rushing to finish.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#checkpoint-flush-after","title":"Checkpoint Flush After","text":"<p>Shows the data threshold that triggers PostgreSQL to force the operating system to write checkpoint data to storage. </p> <p>When PostgreSQL writes more than this amount during a checkpoint, it tells the OS to flush the data immediately rather than buffering it. </p> <p>This helps prevent large write bursts that could overwhelm your storage.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#log-checkpoints","title":"Log Checkpoints","text":"<p>Shows whether PostgreSQL records checkpoint activity in your server logs. When ON, PostgreSQL logs details about each checkpoint including how many buffers it wrote and how long the process took. </p> <p>Use this to monitor checkpoint performance and identify I/O bottlenecks.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#log-checkpoint-warning","title":"Log Checkpoint Warning","text":"<p>Shows the time threshold for checkpoint frequency warnings. When checkpoints happen closer together than this setting (because WAL fills up too quickly), PostgreSQL logs a warning suggesting you increase <code>max_wal_size</code>.</p> <p>If you see these warnings frequently, your WAL size is too small for your workload.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#fsync","title":"fsync","text":"<p>Shows whether PostgreSQL forces writes to physically reach your disk storage. </p> <p>When <code>ON</code> (green), PostgreSQL ensures your data survives system crashes by calling fsync() after writes. </p> <p>When <code>OFF</code> (red), PostgreSQL runs faster but you risk losing data during power failures or crashes\u2014only disable this for testing environments.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#min-wal-size","title":"Min WAL Size","text":"<p>Shows the minimum WAL disk space reserved for recycling. WAL files below this threshold are recycled rather than removed at checkpoints, to ensure enough space for WAL usage spikes during batch operations.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#max-wal-size","title":"Max WAL Size","text":"<p>Displays the soft limit for WAL growth during automatic checkpoints. </p> <p>While WAL can exceed this under heavy load or failing archiving, staying within this limit helps you prevent forced checkpoints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#wal-buffers","title":"WAL Buffers","text":"<p>Shows shared memory allocated for WAL data not yet written to disk. The default (<code>-1</code>) selects 1/32<sup>nd</sup> of shared_buffers, helping you optimize write performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#wal-keep-size","title":"WAL Keep Size","text":"<p>Indicates minimum past log segments retained in <code>pg_wal</code> directory for standby servers. </p> <p>This ensures your replicas can retrieve the WAL segments they need to stay synchronized.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#full-page-writes","title":"Full Page Writes","text":"<p>Shows whether PostgreSQL writes full page content to WAL after checkpoints. When ON (green), it ensures data integrity after system failures.</p> <p>When OFF (red), PostgreSQL runs faster but your data could become corrupted during system failures.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#disk-io-and-swap-activity","title":"Disk I/O and Swap Activity","text":"<p>Correlates disk I/O patterns with checkpoint activity:</p> <ul> <li>Disk Reads/Writes: Page-level I/O operations</li> <li>Swap In/Out: Memory pressure indicators</li> </ul> <p>High swap activity during checkpoints suggests your system has memory constraints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#cpu-usage","title":"CPU Usage","text":"<p>Displays CPU utilization breakdown showing you the impact of checkpoint and I/O operations on your system resources. Spikes during checkpoints indicate CPU-bound I/O operations.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#checkpoints","title":"Checkpoints","text":"<p>Tracks checkpoint frequency:</p> <ul> <li>Scheduled Checkpoints: triggered by <code>checkpoint_timeout</code> or <code>CHECKPOINT</code> command</li> <li>Requested Checkpoints: forced by insufficient <code>max_wal_size</code> or server shutdown</li> </ul> <p>Frequent requested checkpoints indicate that you should <code>increase max_wal_size</code>.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#background-writer-sync-and-write-times","title":"Background Writer Sync and Write Times","text":"<p>Tracks how long PostgreSQL spends:</p> <ul> <li>Syncing files to disk: time to <code>fsync</code> files during checkpoints</li> <li>Writing files to disk: time to write dirty buffers</li> </ul> <p>High values mean your I/O subsystem is struggling during checkpoints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#wal-writes","title":"WAL Writes","text":"<p>Shows Write-Ahead Log generation rate in bytes per second. </p> <p>Use this to plan your WAL storage capacity and identify heavy write periods. </p> <p>This metric requires a custom query collector to populate the data.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#wal-writes-per-checkpoint-timeout","title":"WAL Writes Per Checkpoint Timeout","text":"<p>Displays WAL bytes written grouped by <code>checkpoint_timeout</code> intervals. </p> <p>When bars exceed the red Max WAL size line, consider increasing <code>max_wal_size</code> to reduce forced checkpoints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#buffers-and-background-writer","title":"Buffers and Background Writer","text":""},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#shared-buffers","title":"Shared Buffers","text":"<p>Shows memory allocated for database shared memory buffers.</p> <p>We recommend setting this to 25% of your system\u2019s RAM, but avoid going above 40%.</p> <p>PostgreSQL uses this memory as its primary cache to store frequently accessed data pages.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#bgwriter-lru-max-pages","title":"BgWriter LRU Max Pages","text":"<p>Shows the maximum number of dirty pages the background writer flushes during each cleaning round. </p> <p>Higher values allow more aggressive cleaning but may impact foreground query performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#bgwriter-delay","title":"BgWriter Delay","text":"<p>Shows how long PostgreSQL waits between background writer cleaning rounds. Shorter delays mean more frequent cleaning but higher CPU overhead. </p> <p>Longer delays reduce CPU usage but may leave more dirty buffers for checkpoints to handle, potentially causing I/O spikes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#bgwriter-flush-after","title":"BgWriter Flush After","text":"<p>Shows the data threshold that triggers PostgreSQL to ask the operating system to write buffered data to storage. </p> <p>When the background writer accumulates more than this amount of dirty data, it tells the OS to flush writes immediately rather than waiting. </p> <p>This helps prevent large write bursts during checkpoints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#bgwriter-lru-multiplier","title":"BgWriter LRU Multiplier","text":"<p>Shows the multiplier PostgreSQL uses to estimate how many buffers to clean in the next background writer round. </p> <p>Higher values make the background writer more aggressive at cleaning buffers based on recent usage patterns. </p> <p>Lower values result in more conservative cleaning that may leave work for checkpoints.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#bgwriter-stats-reset","title":"BgWriter Stats Reset","text":"<p>Shows when PostgreSQL last reset the background writer statistics.</p> <p>Use this timestamp to understand how long your current background writer metrics have been accumulating. Reset statistics after configuration changes to get clean baseline measurements for tuning.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#buffers-read","title":"Buffers Read","text":"<p>Monitors buffers loaded into shared memory from either page cache (memory) or disk I/O. </p> <p>High rates indicate your working set exceeds available memory.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#buffers-written","title":"Buffers Written","text":"<p>Shows buffer write activity by source:</p> <ul> <li>During checkpoints: bulk writes during checkpoint operations</li> <li>By the background writer: proactive cleaning of dirty buffers</li> <li>Directly by a backend: emergency writes when no clean buffers available</li> </ul> <p>Backend writes indicate insufficient background writer activity.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#fsync-backend-calls","title":"Fsync Backend Calls","text":"<p>Shows <code>fsync</code> calls made directly by backend processes. High values mean your backends are waiting for writes to finish, suggesting you should tune your checkpoint or background writer settings.</p>"},{"location":"reference/dashboards/dashboard-postgresql-checkpoints-buffers-wal-usage.html#background-writer-stops-due-to-lru-max-reached","title":"Background Writer Stops due to LRU max Reached","text":"<p>Tracks when background writer stops because it reached <code>bgwriter_lru_maxpages</code> limit. </p> <p>Frequent stops suggest you should increase this limit to allow more aggressive buffer cleaning.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html","title":"PostgreSQL Instance Summary","text":"<p>This dashboard shows a detailed overview of a single PostgreSQL instance, monitor its performance metrics, and dive deep into query activity.</p> <p>This is essential for database administrators who need to troubleshoot specific PostgreSQL services, analyze query performance, investigate connection issues, or monitor database activity patterns. </p> <p>Start here when you need to focus on one specific PostgreSQL instance, investigate slow queries, check connection usage, or analyze database-specific performance trends.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#service","title":"Service","text":"<p>Shows essential information about your PostgreSQL instance including service name, version, uptime in days, and the server hostname. The server name is clickable to navigate to detailed node monitoring. This gives you quick access to basic instance identification and health information.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#connections","title":"Connections","text":"<p>Shows current connection counts with total open connections and currently active connections highlighted. Monitor this to ensure you\u2019re not approaching connection limits. High connection counts may indicate connection pooling issues or application problems.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#slow-queries","title":"Slow Queries","text":"<p>Shows the count of queries that exceeded your configured slow query threshold over the selected time range. Focus on reducing this number, considering that high slow query counts indicate performance problems that need query optimization or indexing improvements.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#connections-overview","title":"Connections Overview","text":"<p>Shows connection trends over time broken down by connection state (active, idle, etc.) with a total connections line. Watch for spikes in total connections or unusual patterns. Sudden increases may indicate application issues or connection leaks.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#connections-per-database","title":"Connections per Database","text":"<p>Shows the distribution of connections across different databases in your PostgreSQL instance as a donut chart. </p> <p>Use this to identify which databases consume the most connections. Uneven distribution may indicate workload imbalances or specific database issues.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#qps-queries-per-second","title":"QPS (Queries Per Second)","text":"<p>Shows the top 5 databases by transaction commit rate, indicating query throughput. Monitor this to understand your workload patterns. Consistent QPS indicates steady performance while spikes may require investigation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#number-of-locks","title":"Number of Locks","text":"<p>Shows current lock counts by lock type and database over time. Watch for lock spikes or sustained high lock counts as these can indicate lock contention issues, long-running transactions, or deadlock situations that need attention.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#tuples","title":"Tuples","text":"<p>Shows tuple operation rates (fetched, returned, inserted, updated, deleted) as horizontal bar gauges. Use this to understand your database activity patterns. High fetch-to-return ratios may indicate inefficient queries reading more data than needed.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instance-summary.html#queries","title":"Queries","text":"<p>Shows a detailed table of recent queries with execution times, sorted by performance. Focus optimization efforts on queries with the highest execution times. This table helps you identify specific slow queries that need indexing or rewriting for better performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-compare.html","title":"PostgreSQL Instances Compare","text":"<p>No description</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html","title":"PostgreSQL Instances Overview Extended","text":"<p>This dashboard shows an overview of all your PostgreSQL instances, compare performance across services, and identify which databases need attention. </p> <p>This is essential for database administrators managing multiple PostgreSQL services who need to quickly spot performance issues, resource bottlenecks, or configuration problems across their entire infrastructure. </p> <p>Start here when you need to compare performance across all your databases, identify your busiest services, find instances with connection or memory pressure, or get a high-level health check of your entire PostgreSQL environment.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#overview","title":"Overview","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#services","title":"Services","text":"<p>Shows how many PostgreSQL services you\u2019re currently monitoring with PMM. This gives you a quick count of all active database instances under management across your infrastructure.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-active-connections","title":"Max Active Connections","text":"<p>Shows the highest number of active connections recorded across all your monitored PostgreSQL services. </p> <p>Active connections are currently executing queries or operations. Use this to identify peak connection usage and plan capacity.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-disk-page-buffers-wal-buffers","title":"Total Disk-Page Buffers (WAL Buffers)","text":"<p>Shows the total memory your PostgreSQL instances allocate for caching Write-Ahead Log entries before writing them to disk. </p> <p>The default auto-setting uses 1/32<sup>nd</sup> of your <code>shared_buffers</code> value. If you have heavy write workloads, consider manually tuning this setting higher than the default.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-memory-size-for-each-sort-work-memory","title":"Total Memory Size for each Sort (Work Memory)","text":"<p>Shows the total memory your PostgreSQL instances allocate for internal sort operations and hash tables before spilling to temporary disk files. </p> <p>Each complex query operation can use this amount of memory. Monitor this closely\u2014if set too high with many concurrent users, you could exhaust system memory.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-shared-buffers","title":"Total Shared Buffers","text":"<p>Shows the total memory allocated across all your PostgreSQL instances for shared memory buffers. </p> <p>Set this to 25% of your system\u2019s RAM, but keep it under 40% to leave memory for other processes. This is your primary database cache for frequently accessed data pages.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#services-autovacuum","title":"Services Autovacuum","text":"<p>Shows what percentage of your monitored PostgreSQL services have autovacuum enabled. Keep this at 100% (green) unless you have a specific maintenance strategy. The solution to vacuum problems is usually to vacuum more often, not less.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#connection-details","title":"Connection Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-postgresql-connections","title":"Top 5 PostgreSQL Connections","text":"<p>Shows the five PostgreSQL services with the most total connections (both active and idle). Use this to identify which databases are experiencing the highest connection load and may need connection pooling.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#idle-connections","title":"Idle Connections","text":"<p>Shows each service\u2019s ratio of idle connections to maximum connections. </p> <p>High idle connection ratios may indicate applications not properly closing connections or inefficient connection management.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-active-connections","title":"Top 5 Active Connections","text":"<p>Focuses specifically on active connections (currently executing queries) across your top five busiest services.</p> <p>Compare this with the total connections chart to understand your active vs. idle connection ratio.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#active-connections","title":"Active Connections","text":"<p>Shows each service as a hexagon displaying the ratio of active connections to maximum allowed connections. Active connections are currently executing queries or operations. </p> <p>Colors indicate connection pressure: green (healthy usage under 10%), yellow (moderate usage 50-90%), red (approaching limits over 90%). </p> <p>Click any hexagon to drill down to that service\u2019s detailed dashboard for further investigation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#autovacuum-details","title":"Autovacuum Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#autovacuum-table","title":"Autovacuum table","text":"<p>Lists all your PostgreSQL services and their autovacuum status in tabular format.</p> <p>Use this to quickly audit which services might have autovacuum disabled and need attention.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#autovacuum-visual","title":"Autovacuum visual","text":"<p>Shows each service\u2019s autovacuum status as colored hexagons.</p> <p>This provides a quick visual overview\u2014any non-green hexagons indicate services that need autovacuum configuration review.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#tuples","title":"Tuples","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-tuples","title":"Total Tuples","text":"<p>Shows the combined rate of all tuple operations (fetched, returned, inserted, updated, deleted) across your services.</p> <p>This gives you an overall sense of your database activity level.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-fetched-tuples","title":"Max Fetched Tuples","text":"<p>Shows the highest rate of tuples fetched from disk or cache across all services. </p> <p>High fetch rates may indicate queries scanning large amounts of data or missing indexes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-returned-tuples","title":"Max Returned Tuples","text":"<p>Shows the highest rate of tuples returned to clients.</p> <p>This reflects the volume of data your applications are actually receiving from queries.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-inserted-tuples","title":"Max Inserted Tuples","text":"<p>Shows the peak rate of new tuples being inserted. Monitor this during bulk insert operations or high-volume transaction periods.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-updated-tuples","title":"Max Updated Tuples","text":"<p>Shows the peak rate of existing tuples being modified.</p> <p>High update rates combined with low commit rates may indicate inefficient update patterns.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-deleted-tuples","title":"Max Deleted Tuples","text":"<p>Shows the highest rate of tuples being removed. Consistently high delete rates may require more frequent vacuuming to reclaim space.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#tuple-details","title":"Tuple Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-fetched-tuples-rate-and-fetched-tuples-rate","title":"Top 5 Fetched Tuples Rate and  Fetched Tuples Rate","text":"<p>Time series and hexagon views showing which services are fetching the most data from storage.</p> <p>Use these to identify services with heavy read workloads that might benefit from query optimization.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-returned-tuples-rate-and-returned-tuples-rate","title":"Top 5 Returned Tuples Rate and Returned Tuples Rate","text":"<p>Shows which services are returning the most data to applications. Large differences between fetched and returned tuples may indicate inefficient queries reading more data than needed.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-insertedupdateddeleted-tuples-rate","title":"Top 5 Inserted/Updated/Deleted Tuples Rate","text":"<p>These paired charts show both trending data and current rates for write operations.</p> <p>Monitor these during maintenance windows, bulk operations, or to identify unexpectedly high write activity.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#transactions","title":"Transactions","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-transactions","title":"Total Transactions","text":"<p>Shows the combined rate of all transactions (both commits and rollbacks) across your services.</p> <p>This provides an overall view of your transaction throughput.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-commits-transactions","title":"Max Commits Transactions","text":"<p>Shows the peak rate of successful transactions. This reflects your actual productive database work.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-rollback-transactions","title":"Max Rollback Transactions","text":"<p>Shows the highest rate of failed transactions. High rollback rates may indicate application errors, deadlocks, or constraint violations that need investigation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-transaction-duration","title":"Max Transaction Duration","text":"<p>Shows the longest running transaction currently active across all services.Long-running transactions can block other operations and should be monitored closely.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-number-of-temp-files-and-max-size-of-temp-files","title":"Max Number of Temp Files and  Max Size of Temp Files","text":"<p>Shows when PostgreSQL creates temporary files because operations exceed available memory. </p> <p>High temp file usage indicates you may need to increase <code>work_mem</code> or optimize queries to use less memory.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#transaction-details","title":"Transaction Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-commit-transactions-and-top-5-rollbacks-transactions","title":"Top 5 Commit Transactions and Top 5 Rollbacks Transactions","text":"<p>Time series showing transaction success and failure patterns. </p> <p>Use these to identify services with transaction issues or unusually high failure rates.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-duration-of-active-and-top-5-duration-of-other-transactions","title":"Top 5 Duration of Active and Top 5 Duration of Other Transactions","text":"<p>Shows which services have the longest-running transactions. </p> <p>Long-running transactions can impact performance and should be investigated, especially if they\u2019re blocking other operations.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#temp-files-details","title":"Temp Files Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-number-and-top-5-size-of-temp-files","title":"Top 5 Number and Top 5 Size of Temp Files","text":"<p>Shows which services are creating the most temporary files or using the most temporary storage.</p> <p>High temp file usage indicates memory pressure. Consider increasing <code>work_mem</code> for complex queries or adding more RAM.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#conflicts-locks","title":"Conflicts &amp; Locks","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-locks","title":"Total Locks","text":"<p>Shows the current number of locks held across all databases. </p> <p>Some locking is normal, but excessive locks may indicate lock contention issues or long-running transactions that need attention.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-deadlocks","title":"Total Deadlocks","text":"<p>Shows the rate of deadlocks occurring across your PostgreSQL services. </p> <p>Deadlocks happen when transactions block each other. Any deadlocks indicate application logic issues or transaction design problems that need fixing.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-conflicts","title":"Total Conflicts","text":"<p>Shows the rate of recovery conflicts across your services.</p> <p>Conflicts occur on standby servers when recovery processes interfere with queries. Frequent conflicts may indicate you need to tune recovery settings.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#min-cache-hit-ratio-and-max-cache-hit-ratio","title":"Min Cache Hit Ratio and Max Cache Hit Ratio","text":"<p>Shows the lowest and highest cache hit ratios across your services. </p> <p>Aim for 95%+ cache hit ratios\u2014low ratios indicate insufficient <code>shared_buffers</code> or queries that scan too much data.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-canceled-queries","title":"Total Canceled Queries","text":"<p>Shows the total rate of queries canceled due to various conflicts (buffer pins, deadlocks, locks, snapshots, tablespace issues).</p> <p>High cancellation rates indicate system stress or configuration problems that prevent queries from completing successfully.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#conflicts-locks-details","title":"Conflicts &amp; Locks Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-locks","title":"Top 5 Locks","text":"<p>Shows which services currently hold the most database locks. Use this to identify services experiencing lock contention that might need query optimization or transaction restructuring.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#locks-visual","title":"Locks visual","text":"<p>Displays each service\u2019s current lock count as colored hexagons.</p> <p>This provides a quick visual overview of which services are experiencing the highest lock activity.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-deadlocks","title":"Top 5 Deadlocks","text":"<p>Shows which services are experiencing the most deadlocks over time.</p> <p>Deadlocks always indicate application issues\u2014focus optimization efforts on services appearing in this chart.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#deadlocks-visual","title":"Deadlocks visual","text":"<p>Shows each service\u2019s deadlock rate as colored hexagons with thresholds.</p> <ul> <li>Green: Low deadlocks (normal)</li> <li>Yellow: Moderate deadlocks (review database design and transaction logic)</li> <li>Red: High deadlocks (immediate investigation required for locking conflicts and query optimization)</li> </ul>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-conflicts","title":"Top 5 Conflicts","text":"<p>Shows which services experience the most recovery conflicts.</p> <p>This is primarily relevant for standby servers\u2014high conflicts may indicate replica lag or recovery tuning needs.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#conflicts-visual","title":"Conflicts visual","text":"<p>Displays each service\u2019s conflict rate as colored hexagons. Monitor this especially for read replicas where recovery conflicts can impact query performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#cache-hit-details","title":"Cache Hit Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-lowest-cache-hit-ratio","title":"Top 5 Lowest Cache Hit Ratio","text":"<p>Shows the five services with the worst cache hit ratios.</p> <p>Focus tuning efforts here, considering that low cache hit ratios indicate either insufficient memory allocation or inefficient queries that scan too much data.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#cache-hit-ratio-visual","title":"Cache Hit Ratio Visual","text":"<p>Shows each service\u2019s cache hit ratio as colored hexagons with performance thresholds.</p> <p>Red indicates poor cache performance (below 50%), yellow shows moderate performance (50-80%), green shows good performance (above 80%). Target 95%+ for optimal performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#canceled-queries-details","title":"Canceled Queries Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-canceled-queries","title":"Top 5 Canceled Queries","text":"<p>Shows which services have the highest rate of canceled queries due to various conflicts.This combines all conflict types (buffer pins, deadlocks, locks, snapshots, tablespace issues) to identify services under the most stress.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#canceled-queries","title":"Canceled Queries","text":"<p>Shows query cancellation rates for each service using colored hexagons.</p> <ul> <li>Green: Low cancellations (normal)</li> <li>Yellow: Moderate cancellations (monitor for potential issues)</li> <li>Red: High cancellations (investigate immediately for resource constraints, timeouts, or application issues) </li> </ul>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#block-operations","title":"Block Operations","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-blocks-operations","title":"Total Blocks Operations","text":"<p>Shows the combined rate of all block-level read and write operations across your PostgreSQL services.</p> <p>This gives you an overall sense of your storage I/O activity level.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-blocks-writes","title":"Max Blocks Writes","text":"<p>Shows the peak rate of block write operations across all services.</p> <p>High write rates may indicate heavy INSERT/UPDATE activity or checkpoint pressure.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-blocks-reads","title":"Max Blocks Reads","text":"<p>Shows the peak rate of block read operations across all services. </p> <p>High read rates may indicate queries scanning large amounts of data or cache misses.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#max-allocated-buffers","title":"Max Allocated Buffers","text":"<p>Shows the highest rate of buffer allocation across all services.</p> <p>High allocation rates indicate memory pressure or heavy workloads requiring frequent buffer management.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#total-written-files-to-disk-and-total-files-synchronization-to-disk","title":"Total Written Files to Disk and Total Files Synchronization to Disk","text":"<p>Shows the time PostgreSQL spends writing files to disk and synchronizing them during checkpoints.High values indicate I/O system strain and may require storage optimization or checkpoint tuning.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#block-operations-details","title":"Block Operations Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-read-operations-with-blocks-and-top-5-write-operations-with-blocks","title":"Top 5 Read Operations with Blocks and Top 5 Write Operations with Blocks","text":"<p>Shows which services are performing the most block-level read and write operations.</p> <p>Use these to identify services with heavy I/O workloads that might benefit from query optimization or storage improvements.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#readwrite-operations-with-blocks-visuals","title":"Read/Write Operations with Blocks visuals","text":"<p>Displays each service\u2019s block I/O rates as colored hexagons.</p> <p>Monitor these for services experiencing unusually high I/O activity that could impact performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#buffer-operations-details","title":"Buffer Operations Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-allocated-buffers","title":"Top 5 Allocated Buffers","text":"<p>Shows which services are allocating the most memory buffers.</p> <p>High buffer allocation indicates active workloads. Monitor this to understand memory usage patterns and identify services that might need more <code>shared_buffers</code>.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#allocated-buffers","title":"Allocated Buffers","text":"<p>Displays each service\u2019s buffer allocation rate as hexagons.</p> <p>This helps you quickly identify which services are the most memory-intensive.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-fsync-calls-by-a-backend","title":"Top 5 Fsync Calls by a Backend","text":"<p>Shows which services have backends making the most direct fsync calls.</p> <p>High values mean your backends are waiting for writes to finish. This suggests you need checkpoint or background writer tuning.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#fsync-calls-by-a-backend","title":"Fsync Calls by a Backend","text":"<p>Shows each service\u2019s backend fsync rate as hexagons.</p> <p>Services with high fsync rates may be experiencing I/O bottlenecks or insufficient background writer activity.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-written-directly-by-a-backend","title":"Top 5 Written Directly by a Backend","text":"<p>Shows which services have backends writing buffers directly instead of letting the background writer handle them.</p> <p>High backend writes indicate the background writer can\u2019t keep up\u2014consider tuning <code>bgwriter</code> settings or increasing its aggressiveness.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#written-directly-by-a-backend","title":"Written Directly by a Backend","text":"<p>Displays each service\u2019s direct backend write rate as hexagons.</p> <p>Services showing high values need background writer optimization to reduce the load on query-processing backends.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-written-by-the-background-writer","title":"Top 5 Written by the Background Writer","text":"<p>Shows which services have the most active background writer activity.</p> <p>This is generally good, it means the background writer is proactively cleaning dirty buffers before checkpoints need to handle them.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#written-by-the-background-writer","title":"Written by the background writer","text":"<p>Shows each service\u2019s background writer activity as hexagons. </p> <p>Higher values here (combined with lower backend writes) indicate healthy buffer management.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-written-during-checkpoints","title":"Top 5 Written During Checkpoints","text":"<p>Shows which services write the most buffers during checkpoint operations.</p> <p>High checkpoint writes combined with low background writer activity indicates the background writer isn\u2019t keeping up so consider tuning <code>bgwriter</code> settings.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#written-during-checkpoints","title":"Written During Checkpoints","text":"<p>Displays each service\u2019s checkpoint buffer write activity as hexagons.</p> <p>Services with consistently high checkpoint writes need background writer optimization to spread the I/O load more evenly.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#checkpoint-stats-details","title":"Checkpoint Stats Details","text":""},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-files-synchronization-to-disk","title":"Top 5 Files Synchronization to Disk","text":"<p>Shows which services spend the most time synchronizing files to disk during checkpoints. </p> <p>High sync times indicate storage system strain. Consider faster storage or checkpoint tuning to spread the load over longer periods.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#files-synchronization-to-disk","title":"Files Synchronization to Disk","text":"<p>Displays each service\u2019s file synchronization activity as hexagons. </p> <p>Services showing high sync times may need storage optimization or <code>checkpoint_completion_target</code> tuning.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#top-5-written-files-to-disk","title":"Top 5 Written Files to Disk","text":"<p>Shows which services spend the most time writing files during checkpoint operations. </p> <p>High write times indicate either storage bottlenecks or checkpoints that need to handle too much data at once.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview-extended.html#written-files-to-disk-visual","title":"Written Files to Disk Visual","text":"<p>Shows each service\u2019s checkpoint write time as hexagons. </p> <p>Services with high write times need either storage improvements or checkpoint configuration adjustments to reduce I/O pressure during checkpoint operations.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html","title":"PostgreSQL Instances Overview","text":"<p>This dashboard shows a high-level overview of all your PostgreSQL instances to help you quickly identify performance trends across your entire database infrastructure.</p> <p>Start here when you need to compare performance across all your databases, identify slow queries affecting multiple services, or get a bird\u2019s-eye view of your PostgreSQL infrastructure health.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#databases-monitored","title":"Databases Monitored","text":"<p>Shows a summary of your PostgreSQL monitoring coverage including the number of clusters, total nodes, and nodes without cluster configuration. The Databases monitored link takes you to the full inventory of monitored services for detailed management.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#executed-queries","title":"Executed Queries","text":"<p>Shows query execution trends for your top 5 busiest PostgreSQL services over time. Sudden spikes may indicate performance issues or unexpected workload changes that need investigation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#slow-queries","title":"Slow Queries","text":"<p>Shows the total count of queries that exceeded your configured slow query threshold across all monitored services over the selected time range. </p> <p>Focus on reducing this number across your infrastructure. High slow query counts indicate widespread performance problems that need systematic optimization.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#transactions-per-second","title":"Transactions per Second","text":"<p>Shows the current transaction rate across all your PostgreSQL services combined. Use this as a high-level health indicator. Dramatic changes in TPS may indicate infrastructure issues, application problems, or significant workload shifts.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#execution-time","title":"Execution Time","text":"<p>Shows average query execution time trends for your PostgreSQL services over time. </p> <p>Watch for services with increasing execution times. Rising trends indicate performance degradation that needs investigation and optimization.</p>"},{"location":"reference/dashboards/dashboard-postgresql-instances-overview.html#queries","title":"Queries","text":"<p>Shows a detailed table of recent queries across all your PostgreSQL services with execution times, sorted by performance. Focus optimization efforts on queries with the highest execution times. This cross-service view helps you identify the most impactful slow queries across your entire infrastructure.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html","title":"PostgreSQL Patroni Details","text":"<p>This dashboard provides comprehensive monitoring for PostgreSQL clusters managed by Patroni, focusing on cluster member status, replication health, and WAL (Write-Ahead Log) synchronization. </p> <p>Use this dashboard when you need to monitor high-availability PostgreSQL clusters, troubleshoot replication issues, or verify cluster member roles and status.</p> <p>This is essential for database administrators managing production PostgreSQL clusters with automatic failover capabilities.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni","title":"Patroni","text":""},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-version","title":"Patroni Version","text":"<p>Shows the current version of Patroni running on your selected service. </p> <p>Monitor this panel to ensure all nodes in your cluster run compatible Patroni versions.</p> <p>Version mismatches can cause unexpected behavior during failover operations or cluster management tasks. </p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-dcs-last-seen","title":"Patroni DCS Last Seen","text":"<p>Shows the last time Patroni contacted the distributed configuration store (DCS) for your selected service. </p> <p>This critical metric indicates how recently your Patroni instance communicated with etcd, Consul, or ZooKeeper.</p> <p>The timestamp appears as \u201ctime ago\u201d format (e.g., \u201c2 minutes ago\u201d) to quickly assess connection freshness. </p> <p>If this value shows more than a few minutes ago, investigate your DCS connectivity immediately. This could indicate network issues, DCS outages, or Patroni process problems that may prevent automatic failover from working properly.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-leader","title":"Patroni Leader","text":"<p>Shows whether your selected service node currently serves as the primary cluster leader. </p> <p>This displays Yes or No to confirm leadership status.</p> <p>Only one node in your cluster should show Yes at any time.  If multiple nodes show Yes or no nodes show Yes, you have a split-brain condition or leader election failure that requires immediate attention.</p> <p>A properly functioning cluster always maintains exactly one leader for write operations and cluster coordination.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-replica","title":"Patroni Replica","text":"<p>Shows whether your selected service node operates as a replica (standby) in the cluster. </p> <p>This panel displays Yes for replica nodes and No for the primary leader.</p> <p>This status complements the Leader panel. Most nodes in your cluster should show Yes here.</p> <p>If a node shows No for both Leader and Replica panels, investigate the node\u2019s cluster membership status as it may be isolated or experiencing configuration issues that prevent proper cluster participation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-standby-leader","title":"Patroni Standby Leader","text":"<p>Shows whether your selected service node serves as the standby cluster leader. </p> <p>This applies to clusters configured with standby leader functionality for cascading replication or disaster recovery scenarios.</p> <p>In clusters with standby leaders, exactly one replica should show Yes here. </p> <p>If you expect a standby leader but see No across all replicas, check your Patroni configuration and replication topology to ensure standby leader election works correctly for your high availability setup.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-autofailover","title":"Patroni Autofailover","text":"<p>Shows the current state of automatic failover capability for your cluster. The panel displays Enabled when autofailover is active or Disabled when it\u2019s paused.</p> <p>This setting controls whether Patroni automatically promotes a replica to leader when the current primary fails. </p> <p>When you see Disabled, your cluster will not automatically recover from primary failures - you\u2019ll need manual intervention to restore service. </p> <p>This state typically occurs during maintenance windows or when administrators pause autofailover for troubleshooting.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-cluster-unlocked","title":"Patroni Cluster Unlocked","text":"<p>Shows whether your Patroni cluster currently operates in unlocked mode. The panel displays Yes for unlocked clusters or No for normally locked clusters.</p> <p>Clusters typically remain locked for safety but unlocked mode allows potentially dangerous operations. </p> <p>If you see Yes unexpectedly, verify whether someone intentionally unlocked the cluster for maintenance. Leaving clusters unlocked long-term increases the risk of accidental data loss or cluster corruption during administrative operations.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-failsafe-mode-active","title":"Patroni Failsafe Mode Active","text":"<p>Shows whether Patroni currently operates in failsafe mode for your cluster. This safety mechanism activates when Patroni detects potentially dangerous conditions that could compromise data integrity.</p> <p>Failsafe mode typically engages during network partitions, DCS connectivity issues, or other scenarios where automatic actions might cause data loss. When you see Yes, investigate the underlying issue immediately. Your cluster may have reduced functionality or inability to perform automatic failover until the condition resolves.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#patroni-nodes-state","title":"Patroni Nodes State","text":"<p>Shows the leadership state timeline for all nodes in your cluster over the selected time range. This state timeline visualization uses color coding to track primary role transitions across your cluster nodes.</p> <p>Green sections indicate when a node served as primary leader, while yellow sections show secondary (replica) status. </p> <p>Look for frequent color changes that might indicate unstable leadership or unnecessary failovers. </p> <p>A healthy cluster typically shows stable leadership with minimal transitions, except during planned maintenance or actual failure events. </p> <p>Use this timeline to correlate leadership changes with performance issues or outages in your application.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#postgresql","title":"PostgreSQL","text":""},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#postgresql-version","title":"PostgreSQL Version","text":"<p>Shows the PostgreSQL major and minor version numbers running in your cluster. </p> <p>Use this to verify version consistency across cluster nodes and plan upgrades.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#service-name","title":"Service Name","text":"<p>Displays the service name identifier for the selected Patroni cluster member. This helps you identify which specific node you\u2019re monitoring within the cluster.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#uptime","title":"Uptime","text":"<p>Shows when PostgreSQL was last started on this node, displayed as time elapsed since startup. </p> <p>Long uptimes indicate stable operations, while recent restarts may suggest issues or maintenance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#running","title":"Running","text":"<p>Indicates whether PostgreSQL is currently running on this node. </p> <p>Shows Yes (green) when PostgreSQL is active, No (red) when stopped.</p> <p>Any No status requires immediate investigation.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#timeline","title":"Timeline","text":"<p>Shows the PostgreSQL timeline identifier for this cluster member. </p> <p>All cluster members should normally have the same timeline\u2014different timelines may indicate split-brain scenarios or recovery issues.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#pending-restart","title":"Pending Restart","text":"<p>Indicates whether this PostgreSQL instance needs to be restarted to apply configuration changes. </p> <p>Shows No (green) for normal operation, Yes (orange) when restart is required. </p> <p>Plan maintenance windows for nodes showing Yes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#wal-replay","title":"WAL Replay","text":"<p>Shows whether WAL replay is currently enabled or paused on replica nodes. Enabled (green) is normal for active replicas, Paused (red) indicates replication is stopped. Paused replication will cause replicas to fall behind.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#in-archive-recovery","title":"In Archive Recovery","text":"<p>Indicates whether this node is currently in archive recovery mode (typically a replica). Yes indicates this is a standby server, No indicates this is the primary server.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#streaming","title":"Streaming","text":"<p>Shows whether this replica is receiving WAL data via streaming replication. Yes indicates active streaming replication, No on a replica suggests connectivity issues with the primary.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#sync-standby","title":"Sync Standby","text":"<p>Indicates whether this replica is configured as a synchronous standby. Synchronous standbys provide higher data safety by requiring confirmation before primary commits complete.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#primary-wal-location","title":"Primary WAL Location","text":"<p>Shows the current WAL position on the primary server in bytes.</p> <p>This value continuously increases as the primary generates new WAL data. </p> <p>Use this to monitor write activity and calculate replication lag.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#replicas-received-wal-location","title":"Replicas Received WAL Location","text":"<p>Shows the WAL position that replicas have received from the primary. </p> <p>Compare with Primary WAL Location to identify network replication lag\u2014large differences indicate slow WAL transmission.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#replicas-replayed-wal-location","title":"Replicas Replayed WAL Location","text":"<p>Shows the WAL position that replicas have actually applied to their local database. </p> <p>Compare with Received WAL Location to identify replay lag\u2014differences indicate the replica is behind in processing received WAL.</p>"},{"location":"reference/dashboards/dashboard-postgresql-patroni-details.html#wal-replay-paused","title":"WAL Replay Paused","text":"<p>Displays whether WAL replay is currently paused on replica nodes with both status and cluster identification. </p> <p>False (red) indicates normal operation, True (green) means replay is intentionally paused. </p> <p>This is the inverse of the simpler WAL Replay panel and provides cluster context.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html","title":"PostgreSQL Replication Overview","text":"<p>This dashboard monitors PostgreSQL streaming replication health, tracks lag between primary and replica nodes, and identifies replication issues. </p> <p>This information is essential for database administrators managing high-availability PostgreSQL setups who need to verify replication status, troubleshoot lag problems, or investigate failover readiness. </p> <p>Start here when you need to check if your replicas are keeping up with the primary, diagnose replication conflicts, or verify your disaster recovery setup is working properly.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#primary-host","title":"Primary Host","text":"<p>Shows which server currently acts as the primary (master) node in your replication setup. </p> <p>Monitor this to verify the correct node is serving as primary - unexpected changes indicate failover events or configuration issues.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#number-of-replicas","title":"Number of Replicas","text":"<p>Shows how many replica servers are currently connected and replicating from your primary. </p> <p>Watch for drops in replica count - missing replicas reduce your high availability protection and may indicate network or configuration problems.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#replicas","title":"Replicas","text":"<p>Shows detailed information about each replica including client address, replication state, sync state, and current lag in seconds. </p> <p>Focus on replicas with high lag values or \u201cstreaming\u201d state issues - these indicate replication problems that need immediate attention.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#max-replication-lag","title":"Max Replication Lag","text":"<p>Shows the longest delay (in seconds) between when the primary processes a transaction and when your slowest replica applies it. </p> <p>Set alerts based on your data loss tolerance because if your primary fails, you\u2019ll lose any transactions from the lag period when failing over to a replica.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#max-written-lag","title":"Max Written Lag","text":"<p>Shows the maximum lag in bytes for WAL data written to replicas. </p> <p>Monitor for consistently increasing values because growing written lag indicates network or replica performance issues.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#max-flush-lag","title":"Max Flush Lag","text":"<p>Shows the maximum lag in bytes for WAL data flushed to disk on replicas. </p> <p>Watch for spikes during heavy write periods because high flush lag can indicate storage performance bottlenecks on replica nodes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#replication-members-state","title":"Replication Members State","text":"<p>Shows the timeline of which nodes served as primary (green) versus secondary (yellow) over time. </p> <p>Look for frequent role changes because excessive switching may indicate cluster instability or configuration problems.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#replication-lag-seconds","title":"Replication Lag (Seconds)","text":"<p>Shows replication lag trends over time measured in seconds for each replica. </p> <p>Set alerts for lag spikes above your SLA requirements because sustained high lag indicates replicas cannot keep up with primary workload.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#replication-lag-bytes","title":"Replication Lag (Bytes)","text":"<p>Shows replication lag trends over time measured in bytes for each replica. </p> <p>Monitor for consistently growing lag because increasing byte lag often precedes time-based lag increases.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#top-10-replication-conflicts-by-node","title":"Top 10 Replication Conflicts by Node","text":"<p>Shows nodes experiencing the highest rates of replication conflicts. </p> <p>Investigate nodes with consistent conflicts because frequent conflicts indicate query interference between primary workload and replica recovery.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#wal-activity","title":"WAL Activity","text":"<p>Shows Write-Ahead Log activity including WAL writes and data transfer rates to replicas. </p> <p>Monitor for unusual spikes or drops because changes in WAL patterns can indicate performance issues or configuration changes.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#replication-slots-status","title":"Replication Slots Status","text":"<p>Shows the status of replication slots with <code>1</code> indicating active slots and <code>0</code> indicating inactive slots. </p> <p>Ensure critical replicas maintain active slots because inactive slots can cause WAL retention issues and storage problems on the primary.</p>"},{"location":"reference/dashboards/dashboard-postgresql-replication.html#top-10-replication-conflicts","title":"Top 10 Replication Conflicts","text":"<p>Shows databases experiencing the highest rates of replication conflicts. </p> <p>Focus optimization efforts on databases with frequent conflicts considering that high conflict rates can slow replica recovery and affect read query performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html","title":"PostgreSQL Top Queries","text":"<p>This dashboard analyzes query performance across your PostgreSQL instances, helping you identify and optimize slow queries that impact database performance.</p> <p></p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#transactions-per-second","title":"Transactions per Second","text":"<p>Shows the rate of committed transactions for each PostgreSQL instance. The metric combines both regular and replicated transactions, displayed as operations per second with step interpolation for accurate counting between data points.</p> <p>Use this to monitor database activity levels and identify workload patterns across your instances. The table below the graph shows mean, max, and min values for each service.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-slowest-queries","title":"Top 10 Slowest Queries","text":"<p>Displays queries with the highest average execution time across your PostgreSQL databases. Each row shows:</p> <ul> <li>Service Name: PostgreSQL instance running the query</li> <li>Database: database where the query executed</li> <li>Query: normalized query fingerprint</li> <li>Avg Execution Time: average time per query execution, visualized with a color-coded gauge</li> </ul> <p>System queries and PostgreSQL internal operations (<code>pg_stat_*</code>, <code>pg_replication_slots</code>, etc.) are automatically filtered out to focus on application queries.</p> <p>The gauge visualization uses a gradient from green to red, making it easy to spot the worst-performing queries at a glance.</p> <p>Use this table to prioritize query optimization efforts for maximum performance impact.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-time-spent","title":"Top 10 time spent","text":"<p>Shows queries that consumed the most total execution time across all your PostgreSQL services, ranked by cumulative time spent. </p> <p>Focus optimization efforts on the top queries in this list because reducing their execution time will have the biggest impact on overall system performance.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-queries-executed-the-most","title":"Top 10 Queries Executed the most","text":"<p>Shows queries that ran most frequently across your PostgreSQL infrastructure, regardless of individual execution time. </p> <p>Monitor these for optimization opportunities because even small performance improvements to frequently-executed queries can significantly reduce overall system load.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-queries-writing-the-most","title":"Top 10 Queries writing the most","text":"<p>Shows queries that affected the most rows through write operations (INSERT, UPDATE, DELETE) across your services. </p> <p>Review these queries for efficiency because high row counts may indicate bulk operations that could benefit from batching or optimization to reduce lock contention.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-queries-affected-the-most-rows","title":"Top 10 Queries Affected the most rows","text":"<p>Shows queries that processed the largest number of rows (both read and write operations) across all your PostgreSQL services. </p> <p>Investigate these queries for potential optimization because they represent the highest data processing workload and may benefit from indexing or query restructuring.</p>"},{"location":"reference/dashboards/dashboard-postgresql-topqueries.html#top-10-user-executed-the-most-queries","title":"Top 10 User Executed the most queries","text":"<p>Shows which database users generated the most query activity across your PostgreSQL infrastructure. </p> <p>Use this to identify heavy database users and understand usage patterns that may require capacity planning or access optimization.</p>"},{"location":"reference/dashboards/dashboard-postgresql-vacuum-monitoring-experimental.html","title":"Experimental PostgreSQL Vacuum Monitoring","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>This dashboard provides timely insights into the autovacuum process in PostgreSQL.</p> <p>This dashboard contains the following:</p> <ul> <li> <p>Dead tuples - Identifies the number of dead rows in each table even though the rows are physically removed from the table.</p> </li> <li> <p>Last time vacuum ran - Tracks the last time a vacuum or autovacuum process successfully ran on each of your tables.</p> </li> <li> <p>Number of rows modified since last Analyze - The number of rows changed since the last time ANALYZE ran.</p> </li> <li> <p>Manual vacuum events - Tracks the number of times a manual vacuum was run on each table.</p> </li> <li> <p>Table disk usage - Tracking the disk space used by each table is crucial as it enables you to gauge expected changes in the query performance over time - but it can also help you detect potential vacuuming-related issues.</p> </li> </ul>"},{"location":"reference/dashboards/dashboard-processes-details.html","title":"Processes Details","text":"<p>This dashboard displays Linux process information - PIDs, Threads, and Processes.  The dashboard shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O). When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound. When the number of process blocked waiting for I/O is large, the load is disk bound. The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p> <p>The dashboard consists of two parts: the first section describes metrics for all hosts, and the second part provides charts for each host.</p> <p>Charts for all hosts, available in the first section, are the following ones:</p> <ul> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> <li>Runnable Processes</li> <li>Blocked Processes Waiting for I/O</li> <li>Sleeping Processes</li> <li>Running Processes</li> <li>Disk Sleep Processes</li> <li>Stopped Processes</li> <li>Zombie Processes</li> <li>Dead Processes</li> </ul> <p>The following charts are present in the second part, available for each host:</p> <ul> <li>Processes</li> <li>States of Processes</li> <li>Number of PIDs</li> <li>Percentage of Max PIDs Limit</li> <li>Number of Threads</li> <li>Percentage of Max Threads Limit</li> </ul>"},{"location":"reference/dashboards/dashboard-processes-details.html#runnable-processes","title":"Runnable Processes","text":""},{"location":"reference/dashboards/dashboard-processes-details.html#processes","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p>"},{"location":"reference/dashboards/dashboard-processes-details.html#blocked-processes-waiting-for-io","title":"Blocked Processes Waiting for I/O","text":""},{"location":"reference/dashboards/dashboard-processes-details.html#processes_1","title":"Processes","text":"<p>The Processes graph shows how many processes/threads are either in the kernel run queue (runnable state) or in the blocked queue (waiting for I/O).  When the number of process in the runnable state is constantly higher than the number of CPU cores available, the load is CPU bound.  When the number of process blocked waiting for I/O is large, the load is disk bound.  The running average of the sum of these two quantities is the basis of the <code>loadavg</code> metric.</p>"},{"location":"reference/dashboards/dashboard-prometheus-exporter-status.html","title":"Prometheus Exporter Status","text":"<p>The Prometheus Exporter Status dashboard reports the consumption of resources by the Prometheus exporters used by PMM. For each exporter, this dashboard reveals the following information:</p> <ul> <li>CPU usage</li> <li>Memory usage</li> <li>File descriptors used</li> <li>Exporter uptime</li> </ul>"},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html","title":"Prometheus Exporters Overview","text":""},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-summary","title":"Prometheus Exporters Summary","text":"<p>This section provides a summary of how exporters are used across the selected hosts. It includes the average usage of CPU and memory as well as the number of hosts being monitored and the total number of running exporters.</p> Avg CPU Usage per Host Shows the average CPU usage in percent per host for all exporters. Avg Memory Usage per Host Shows the Exporters average Memory usage per host. Monitored Hosts Shows the number of monitored hosts that are running Exporters. Exporters Running Shows the total number of Exporters running with this PMM Server instance. <p>Note</p> <p>The CPU usage and memory usage do not include the additional CPU and memory usage required to produce metrics by the application or operating system.</p>"},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-node","title":"Prometheus Exporters Resource Usage by Node","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for the selected hosts.</p> CPU Usage Plots the Exporters\u2019 CPU usage across each monitored host (by default, All hosts). Memory Usage Plots the Exporters\u2019 Memory usage across each monitored host (by default, All hosts)."},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#prometheus-exporters-resource-usage-by-type","title":"Prometheus Exporters Resource Usage by Type","text":"<p>This section shows how resources, such as CPU and memory, are being used by the exporters for host types: MySQL, MongoDB, ProxySQL, and the system.</p> CPU Cores Used Shows the Exporters\u2019 CPU Cores used for each type of Exporter. Memory Usage Shows the Exporters\u2019 memory used for each type of Exporter."},{"location":"reference/dashboards/dashboard-prometheus-exporters-overview.html#list-of-hosts","title":"List of Hosts","text":"<p>At the bottom, this dashboard shows details for each running host.</p> CPU Used Show the CPU usage as a percentage for all Exporters. Mem Used Shows total Memory Used by Exporters. Exporters Running Shows the number of Exporters running. RAM Shows the total amount of RAM of the host. Virtual CPUs Shows the total number of virtual CPUs on the host. <p>You can click the value of the CPU Used, Memory Used, or Exporters Running columns to open the Prometheus Exporter Status dashboard for further analysis.</p> <p>See also</p> <p>Percona blog: Understand Your Prometheus Exporters with Percona Monitoring and Management (PMM)</p>"},{"location":"reference/dashboards/dashboard-proxysql-instance-summary.html","title":"ProxySQL Instance Summary","text":""},{"location":"reference/dashboards/dashboard-proxysql-instance-summary.html#network-traffic","title":"Network Traffic","text":"<p>Network traffic refers to the amount of data moving across a network at a given point in time.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary-experimental.html","title":"Experimental PXC/Galera Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p>The experimental PXC/Galera Cluster Summary dashboard provides a high level information about the clusters, resource utilization and its state for MySQL databases.</p> <p></p>"},{"location":"reference/dashboards/dashboard-pxc-galera-cluster-summary.html","title":"PXC/Galera Cluster Summary","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html","title":"PXC/Galera Node Summary","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-latency","title":"Galera Replication Latency","text":"<p>Shows figures for the replication latency on group communication. It measures latency from the time point when a message is sent out to the time point when a message is received. As replication is a group operation, this essentially gives you the slowest ACK and longest RTT in the cluster.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-replication-queues","title":"Galera Replication Queues","text":"<p>Shows the length of receive and send queues.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-cluster-size","title":"Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-flow-control","title":"Galera Flow Control","text":"<p>Shows the number of <code>FC_PAUSE</code> events sent/received. They are sent by a node when its replication queue gets too full. If a node is sending out FC messages it indicates a problem.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-parallelization-efficiency","title":"Galera Parallelization Efficiency","text":"<p>Shows the average distances between highest and lowest seqno that are concurrently applied, committed and can be possibly applied in parallel (potential degree of parallelization).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writing-conflicts","title":"Galera Writing Conflicts","text":"<p>Shows the number of local transactions being committed on this node that failed certification (some other node had a commit that conflicted with ours) \u2013 client received deadlock error on commit and also the number of local transactions in flight on this node that were aborted because they locked something an applier thread needed \u2013 deadlock error anywhere in an open transaction. Spikes in the graph may indicate writing to the same table potentially the same rows from 2 nodes.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#available-downtime-before-sst-required","title":"Available Downtime before SST Required","text":"<p>Shows for how long the node can be taken out of the cluster before SST is required. SST is a full state transfer method.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-count","title":"Galera Writeset Count","text":"<p>Shows the count of transactions received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-size","title":"Galera Writeset Size","text":"<p>Shows the average transaction size received/replicated.</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-writeset-traffic","title":"Galera Writeset Traffic","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-node-summary.html#galera-network-usage-hourly","title":"Galera Network Usage Hourly","text":"<p>Shows the bytes of data received from the cluster (any other node) and replicated to the cluster (from this node).</p>"},{"location":"reference/dashboards/dashboard-pxc-galera-nodes-compare.html","title":"PXC/Galera Nodes Compare","text":""},{"location":"reference/dashboards/dashboard-pxc-galera-nodes-compare.html#cluster-galera-cluster-size","title":"$cluster - Galera Cluster Size","text":"<p>Shows the number of members currently connected to the cluster.</p>"},{"location":"reference/dashboards/dashboard-victoriametrics-agents-overview.html","title":"VictoriaMetrics Agents Overview","text":""},{"location":"reference/dashboards/dashboard-victoriametrics.html","title":"VictoriaMetrics","text":"<p>Description coming soon</p>"},{"location":"reference/dashboards/kubernetes_cluster_summary.html","title":"Kubernetes Cluster Summary","text":"<p>Disclaimer</p> <p>This is an Experimental Dashboard that is not part of the official Percona Monitoring and Management (PMM) deployment and might be updated. We ship this Dashboard to obtain feedback from our users.</p> <p></p> <p>Kubernetes Volumes dashboard provides a comprehensive overview of your Kubernetes cluster, including:</p> <ul> <li>Resources</li> <li>Node Status</li> <li>Pod Status</li> <li>PVC status</li> <li>CPU Overview</li> <li>Kubernetes Resource Count</li> <li>Memory Overview and more</li> </ul> <p>With this dashboard, you can view all workloads running in the cluster and optimize their performance.</p>"},{"location":"reference/dashboards/kubernetes_monitor_db_clusters_managed.html","title":"DB clusters managed with Percona Kubernetes Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>This dashboard displays the primary parameters of database clusters created by Percona Operators for various databases and helps identify the performance issues.</p> <p></p>"},{"location":"reference/dashboards/kubernetes_monitor_operators.html","title":"Kubernetes monitoring for Percona Operators","text":"<p>Important</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Monitoring the state of the database is crucial to timely identify and react to performance issues. Percona Monitoring and Management (PMM) solution enables you to do just that.</p> <p>However, the database state also depends on the state of the Kubernetes cluster itself. Hence it\u2019s important to have metrics that can depict the state of the Kubernetes cluster.</p> <p>For information on setting up monitoring for the Kubernetes cluster health, see documentation. </p> <p>This setup has been tested with the PMM Server as the centralized data storage and the Victoria Metrics Kubernetes monitoring stack as the metrics collector. These steps may also apply if you use another Prometheus-compatible storage.</p>"},{"location":"reference/dashboards/kubernetes_monitor_operators.html#kubernetes-overview","title":"Kubernetes overview","text":"<p>The Kubernetes Cluster overview dashboard gives you an overview of Kubernetes health and its objects, including Percona custom resources.</p> <p></p>"},{"location":"reference/third-party/index.html","title":"About third party solutions used in PMM","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"reference/third-party/clickhouse.html","title":"Use external ClickHouse with PMM","text":"<p>You can use an external ClickHouse database instance outside the PMM Server container running on other hosts.</p>"},{"location":"reference/third-party/clickhouse.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow you to use ClickHouse parameters as environment variables.</p> <p>To use ClickHouse as an external database instance, provide the following environment variables: </p> <code>PMM_CLICKHOUSE_ADDR</code> -&gt; hostname:port Name of the host and port of the external ClickHouse database instance.  <code>PMM_CLICKHOUSE_HOST</code> -&gt; hostname Hostname of the external ClickHouse database. <code>PMM_CLICKHOUSE_PORT</code> -&gt; port Port of the external ClickHouse database. <code>PMM_CLICKHOUSE_USER</code> -&gt; username Username to connect to the external ClickHouse database. <code>PMM_CLICKHOUSE_PASSWORD</code> -&gt; password User password to connect to the external ClickHouse database. <code>PMM_DISABLE_BUILTIN_CLICKHOUSE</code> -&gt; 1 Disables the built-in ClickHouse database instance. <p>Optional environment variables</p> <code>PMM_CLICKHOUSE_DATABASE</code> -&gt; database name Database name of the external ClickHouse database instance. <p>Example</p> <p>To use ClickHouse as an external database instance, run PMM in docker or podman with the specified variables for external ClickHouse:</p> <pre><code>-e PMM_CLICKHOUSE_ADDR=$CH_HOST:$CH_PORT\n-e PMM_CLICKHOUSE_DATABASE=$CH_DATABASE\n-e PMM_CLICKHOUSE_USER=$CH_USER\n-e PMM_CLICKHOUSE_PASSWORD=$CH_PASSWORD\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1\n</code></pre> <p>Alternatively, you can use the <code>PMM_CLICKHOUSE_HOST</code> and <code>PMM_CLICKHOUSE_PORT</code> variables instead of <code>PMM_CLICKHOUSE_ADDR</code>.</p> <pre><code>-e PMM_CLICKHOUSE_HOST=$CH_HOST\n-e PMM_CLICKHOUSE_PORT=$CH_PORT\n-e PMM_CLICKHOUSE_DATABASE=$CH_DATABASE\n-e PMM_CLICKHOUSE_USER=$CH_USER\n-e PMM_CLICKHOUSE_PASSWORD=$CH_PASSWORD\n-e PMM_DISABLE_BUILTIN_CLICKHOUSE=1\n</code></pre>"},{"location":"reference/third-party/clickhouse.html#enhance-clickhouse-security-for-pmm","title":"Enhance ClickHouse security for PMM","text":"<p>When configuring PMM to use an external ClickHouse instance, make sure to enforce robust security practices to protect sensitive data and prevent unauthorized access:</p> <ul> <li>Enable SSL/TLS encryption for all connections</li> <li>Ensure that your ClickHouse instance is properly secured and monitored</li> <li>Disable empty passwords and plain text passwords</li> <li>Define all ClickHouse users explicitly, including permissions, to prevent automatic creation of unsecured users without passwords.</li> <li> <p>Generate strong, random passwords for the dedicated PMM ClickHouse user. Use the following commands to generate a password and its SHA256 hash (useful for advanced ClickHouse configurations):</p> <pre><code>PASSWORD=$(base64 &lt; /dev/urandom | head -c12)\necho \"$PASSWORD\" # note it down\necho -n \"$PASSWORD\" | sha256sum | tr -d '-'\n</code></pre> </li> </ul> <p>For more details, see the ClickHouse user and roles settings.</p>"},{"location":"reference/third-party/clickhouse.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the ClickHouse troubleshooting documentation.</p>"},{"location":"reference/third-party/postgresql.html","title":"Configure PMM with external PostgreSQL","text":"<p>Percona Monitoring and Management (PMM) can be configured to use an external PostgreSQL database instead of its built-in instance. This provides several advantages, including:</p> <ul> <li>enhanced high availability (HA) capabilities</li> <li>improved performance with dedicated database servers</li> <li>integration with existing database infrastructure</li> <li>better control over data retention and backups</li> </ul> <p>To configure PMM Server to connect to an external PostgreSQL database running on the same host or a remote server, set up the required environment variables, configure SSL for secure connections, and ensure proper permissions for both PMM components and Grafana.</p>"},{"location":"reference/third-party/postgresql.html#prerequisites","title":"Prerequisites","text":"<p>Before configuring PMM with an external PostgreSQL database, ensure you have a PostgreSQL 14+ server accessible from your PMM Server.</p>"},{"location":"reference/third-party/postgresql.html#configuration-overview","title":"Configuration overview","text":"<p>To configure PMM Server to connect to an external PostgreSQL database:</p> <ul> <li>set up the external PostgreSQL server with required databases and permissions</li> <li>configure required environment variables for both PMM components and Grafana</li> <li>disable the built-in PostgreSQL server</li> <li>start PMM Server with the appropriate configuration</li> </ul>"},{"location":"reference/third-party/postgresql.html#environment-variables","title":"Environment variables","text":"<p>Important for PMM 3.2.0 and later</p> <p>Due to a regression in Grafana 11.6 (included in PMM 3.2.0+), the <code>GF_DATABASE_URL</code> environment variable is no longer sufficient for configuring Grafana\u2019s connection to an external PostgreSQL database. When using PMM 3.2.0 or later with an external PostgreSQL, you must use the individual <code>GF_DATABASE_*</code> environment variables.</p>"},{"location":"reference/third-party/postgresql.html#pmm-postgresql-variables","title":"PMM PostgreSQL variables","text":"<p>To use PostgreSQL as an external database instance, use the following environment variables:</p> Environment variable Flag Description PMM_POSTGRES_ADDR postgres-addr Hostname and port for external PostgreSQL database. PMM_POSTGRES_DBNAME postgres-name Database name for external or internal PostgreSQL database. PMM_POSTGRES_USERNAME postgres-username PostgreSQL user name to connect as. PMM_POSTGRES_DBPASSWORD postgres-password Password to be used for database authentication. PMM_POSTGRES_SSL_MODE postgres-ssl-mode This option determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the database. Currently supported: <code>disable</code>, <code>require</code>, <code>verify-ca</code>, <code>verify-full</code>. PMM_POSTGRES_SSL_CA_PATH postgres-ssl-ca-path This parameter specifies the name of a file containing SSL certificate authority (CA) certificate(s). PMM_POSTGRES_SSL_KEY_PATH postgres-ssl-key-path This parameter specifies the location for the secret key used for the client certificate. PMM_POSTGRES_SSL_CERT_PATH postgres-ssl-cert-path This parameter specifies the file name of the client SSL certificate. PMM_DISABLE_BUILTIN_POSTGRES Environment variable to disable built-in PMM Server database. Note that Grafana depends on built-in PostgreSQL. And if the value of this variable is \u201ctrue\u201d, then it is necessary to pass all the parameters associated with Grafana to use external PostgreSQL. <p>By default, communication between the PMM Server and the database is not encrypted. To secure a connection, follow PostgreSQL SSL instructions and provide <code>POSTGRES_SSL_*</code> variables.</p>"},{"location":"reference/third-party/postgresql.html#grafana-database-configuration","title":"Grafana database configuration","text":"<p>When using an external PostgreSQL database with PMM, configure both PMM\u2019s components and Grafana to use the external database.</p> <ul> <li>For PMM versions prior to 3.2.0, use a single <code>GF_DATABASE_URL</code> in the format <code>postgres://USER:PASSWORD@HOST:PORT/DATABASE_NAME</code>.</li> <li>For PMM 3.2.0 and later, Grafana requires individual database parameters instead of a single connection URL. Use the following environment variables:</li> </ul> Environment variable Description GF_DATABASE_HOST Hostname and port of the PostgreSQL server (e.g., <code>host:5432</code>) GF_DATABASE_NAME Database name for Grafana GF_DATABASE_USER PostgreSQL user for Grafana GF_DATABASE_PASSWORD Password for the Grafana database user GF_DATABASE_SSL_MODE SSL mode for database connection (disable, require, verify-ca, verify-full) GF_DATABASE_CA_CERT_PATH Path to CA certificate file GF_DATABASE_CLIENT_KEY_PATH Path to client key file GF_DATABASE_CLIENT_CERT_PATH Path to client certificate file"},{"location":"reference/third-party/postgresql.html#configuration-requirements","title":"Configuration requirements","text":"<p>To successfully use an external PostgreSQL database with PMM:</p> <ul> <li>Ensure both PMM Server and Grafana database connections are configured. This means providing the appropriate <code>PMM_POSTGRES_*</code> environment variables for PMM\u2019s internal operations and the <code>GF_DATABASE_*</code> variables (or <code>GF_DATABASE_URL</code> for PMM versions prior to 3.2.0) for Grafana\u2019s data source.</li> <li>Enable the <code>pg_stat_statements</code> extension in the PostgreSQL database that PMM will connect to. This extension enables PMM to collect performance statistics.</li> <li>Do not specify <code>GF_DATABASE_TYPE</code>as PMM uses PostgreSQL for external database connection</li> </ul>"},{"location":"reference/third-party/postgresql.html#set-up-postgresql-for-pmm","title":"Set up PostgreSQL for PMM","text":""},{"location":"reference/third-party/postgresql.html#1-prepare-the-postgresql-server","title":"1. Prepare the PostgreSQL Server","text":"<p>To use PostgreSQL as an external database with PMM:</p> <ol> <li> <p>Pull the PostgreSQL Docker image:     <pre><code>docker pull postgres:14\n</code></pre></p> </li> <li> <p>Create a Docker volume for PostgreSQL data:     <pre><code>docker volume create pg_data\n</code></pre></p> </li> <li> <p>Create a directory where PostgreSQL will find initialization SQL scripts:     <pre><code>mkdir -p /path/to/queries\n</code></pre></p> </li> <li> <p>Create an <code>init.sql.template</code> file in the directory with the following content:</p> <pre><code>CREATE DATABASE \"pmm-managed\";\nCREATE USER &lt;YOUR_PG_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_PG_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE \"pmm-managed\" TO &lt;YOUR_PG_USERNAME&gt;;\n\nCREATE DATABASE grafana;\nCREATE USER &lt;YOUR_GF_USERNAME&gt; WITH ENCRYPTED PASSWORD '&lt;YOUR_GF_PASSWORD&gt;';\nGRANT ALL PRIVILEGES ON DATABASE grafana TO &lt;YOUR_GF_USERNAME&gt;;\n\n\\c \"pmm-managed\"\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n</code></pre> </li> <li> <p>Replace the placeholders with your actual values:</p> <pre><code>sed -e 's/&lt;YOUR_PG_USERNAME&gt;/'\"$PG_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_PG_PASSWORD&gt;/'\"$PG_PASSWORD\"'/g' \\\n    -e 's/&lt;YOUR_GF_USERNAME&gt;/'\"$GF_USERNAME\"'/g' \\\n    -e 's/&lt;YOUR_GF_PASSWORD&gt;/'\"$GF_PASSWORD\"'/g' \\\n    init.sql.template &gt; init.sql\n</code></pre> </li> <li> <p>Run the PostgreSQL container:</p> <pre><code>docker run -d \\\n  --name pg \\\n  -p 5432:5432 \\\n  -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n  -v /path/to/queries:/docker-entrypoint-initdb.d \\\n  -v pg_data:/var/lib/postgresql/data \\\n  postgres:14 \\\n  postgres -c shared_preload_libraries=pg_stat_statements \\\n           -c pg_stat_statements.max=10000 \\\n           -c pg_stat_statements.track=all \\\n           -c pg_stat_statements.save=off\n</code></pre> </li> </ol>"},{"location":"reference/third-party/postgresql.html#2-configure-ssl-optional","title":"2. Configure SSL (optional)","text":"<p>If you need to secure the connection with SSL:</p> <ol> <li>Generate all necessary SSL certificates.</li> <li>Deploy certificates with the appropriate permissions:    <pre><code> # Example directory structure for certificates:\n /pmm-server-certificates# ls -la\n drwxr-xr-x 1 1000    1000    4096 Apr  5 12:43 .\n drwxr-xr-x 1 root    root    4096 Apr  5 12:43 ..\n -rw------- 1 1000    1000    1391 Apr  5 12:38 certificate_authority.crt\n -rw------- 1 1000    1000    1257 Apr  5 12:38 pmm_server.crt\n -r-------- 1 1000    1000    1708 Apr  5 12:38 pmm_server.key\n</code></pre></li> <li>Configure PostgreSQL for SSL by updating your PostgreSQL container run command:    <pre><code> docker run -d \\\n --name pg \\\n -p 5432:5432 \\\n -e POSTGRES_PASSWORD=${PG_PASSWORD} \\\n -v /path/to/queries:/docker-entrypoint-initdb.d \\\n -v pg_data:/var/lib/postgresql/data \\\n -v /path/to/certificates:/etc/postgresql/certs \\\n postgres:14 \\\n postgres -c shared_preload_libraries=pg_stat_statements \\\n          -c pg_stat_statements.max=10000 \\\n          -c pg_stat_statements.track=all \\\n          -c pg_stat_statements.save=off \\\n          -c ssl=on \\\n          -c ssl_ca_file=/etc/postgresql/certs/certificate_authority.crt \\\n          -c ssl_key_file=/etc/postgresql/certs/external_postgres.key \\\n          -c ssl_cert_file=/etc/postgresql/certs/external_postgres.crt \\\n          -c hba_file=/path/to/pg_hba.conf\n</code></pre></li> <li>Create a <code>pg_hba.conf</code> file that enforces SSL:</li> </ol> <pre><code>local     all         all                                    trust\nhostnossl all         example_user all                       reject\nhostssl   all         example_user all                       cert\n</code></pre>"},{"location":"reference/third-party/postgresql.html#3-run-pmm-server-with-external-postgresql","title":"3. Run PMM Server with external PostgreSQL","text":"<p>Now that PostgreSQL is set up, configure PMM Server to use it:</p> PMM 3.1.x and 3.0.0PMM 3.2.0 and later <pre><code>docker run -d \\\n-p 443:443 \\\n-v pmm-data:/srv \\\n-e PMM_POSTGRES_ADDR=postgres-host:5432 \\\n-e PMM_POSTGRES_DBNAME=pmm-managed \\\n-e PMM_POSTGRES_USERNAME=pmm_user \\\n-e PMM_POSTGRES_DBPASSWORD=pmm_password \\\n-e GF_DATABASE_URL=postgres://your_grafana_user:your_grafana_password@postgres-host:5432/grafana \\\n-e GF_DATABASE_SSL_MODE=$GF_SSL_MODE \\\n-e GF_DATABASE_CA_CERT_PATH=$GF_CA_PATH \\\n-e GF_DATABASE_CLIENT_KEY_PATH=$GF_KEY_PATH \\\n-e GF_DATABASE_CLIENT_CERT_PATH=$GF_CERT_PATH \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre> <pre><code>docker run -d \\\n-p 443:443 \\\n-v pmm-data:/srv \\\n-e PMM_POSTGRES_ADDR=postgres-host:5432 \\\n-e PMM_POSTGRES_DBNAME=pmm-managed \\\n-e GF_DATABASE_PASSWORD=your_grafana_password \\\n-e PMM_POSTGRES_DBPASSWORD=pmm_password \\\n-e GF_DATABASE_HOST=postgres-host:5432 \\\n-e GF_DATABASE_NAME=grafana \\\n-e GF_DATABASE_USER=your_grafana_user \\\n-e GF_DATABASE_PASSWORD=your_grafana_password \\\n-e GF_DATABASE_SSL_MODE=$GF_SSL_MODE \\\n-e GF_DATABASE_CA_CERT_PATH=$GF_CA_PATH \\\n-e GF_DATABASE_CLIENT_KEY_PATH=$GF_KEY_PATH \\\n-e GF_DATABASE_CLIENT_CERT_PATH=$GF_CERT_PATH \\\n-e PMM_DISABLE_BUILTIN_POSTGRES=1 \\\n--name pmm-server \\\npercona/pmm-server:3\n</code></pre>"},{"location":"reference/third-party/postgresql.html#docker-compose-example","title":"Docker Compose example","text":"<p>When using Docker Compose to run PMM with an external PostgreSQL database, make sure to configure both PMM and Grafana database parameters. Create a <code>docker-compose.yml</code> file with the following content (adjust values as needed), then restart the PMM Server: </p> <pre><code>services:\n  pmm-server:\n    image: percona/pmm-server:3\n    ports:\n      - \"443:443\"\n    volumes:\n      - pmm-data:/srv\n    environment:\n      # PMM PostgreSQL connection variables\n      - PMM_POSTGRES_ADDR=your_host:your_port\n      - PMM_POSTGRES_DBNAME=pmm-managed\n      - PMM_POSTGRES_USERNAME=your_pmm_user\n      - PMM_POSTGRES_DBPASSWORD=your_pmm_password\n      # Grafana PostgreSQL connection variables (for PMM 3.2.0+)\n      - GF_DATABASE_USER=your_grafana_user\n      - GF_DATABASE_PASSWORD=your_grafana_password\n      - GF_DATABASE_HOST=your_host:your_port\n      - GF_DATABASE_NAME=grafana\n      # Disable built-in PostgreSQL\n      - PMM_DISABLE_BUILTIN_POSTGRES=1\n    restart: always\n\nvolumes:\n  pmm-data:\n</code></pre>"},{"location":"reference/third-party/postgresql.html#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues when configuring PMM with an external PostgreSQL database, check the following:</p> <ul> <li>make sure all required environment variables are set (both PMM and Grafana variables)</li> <li>verify that PostgreSQL is running and accessible from the PMM Server container</li> <li>check that the correct database names and credentials are used</li> <li>for PMM 3.2.0+, make sure you\u2019re using the individual Grafana database parameters instead of <code>GF_DATABASE_URL</code></li> <li>confirm that <code>pg_stat_statements</code> extension is enabled in the PostgreSQL database</li> <li>check the Grafana logs for database connection issues</li> </ul>"},{"location":"reference/third-party/victoria.html","title":"VictoriaMetrics","text":"<p>VictoriaMetrics is a third-party monitoring solution and time-series database.</p>"},{"location":"reference/third-party/victoria.html#pushpull-modes","title":"Push/Pull modes","text":"<p>VictoriaMetrics metrics data can be both \u2018pushed\u2019 to the server and \u2018pulled\u2019 by the server. When setting up services, you can decide which mode to use.</p> <p>The mode (push/pull) is controlled by the <code>--metrics-mode</code> flag for the <code>pmm-admin config</code> and <code>pmm-admin add</code> commands.</p> <p>If you need to change the metrics mode for an existing Service, you must remove it and re-add it with the same name and the required flags. (You cannot update a service.)</p>"},{"location":"reference/third-party/victoria.html#remapped-targets-for-direct-prometheus-paths","title":"Remapped targets for direct Prometheus paths","text":"<p>Direct Prometheus paths return structured information directly from Prometheus, bypassing the PMM application.</p> <p>They are accessed by requesting a URL of the form <code>&lt;PMM SERVER URL&gt;/prometheus/&lt;PATH&gt;</code>.</p> <p>As a result of the move to VictoriaMetrics some direct Prometheus paths are no longer available.</p> Prometheus path VictoriaMetrics equivalent <code>/prometheus/alerts</code> No change. <code>/prometheus/config</code> No equivalent, but there is some information at <code>/prometheus/targets</code>. <code>/prometheus/flags</code> The <code>flag</code> metrics at <code>/prometheus/metrics</code>. <code>/prometheus/graph</code> <code>/graph/explore</code> (Grafana) or <code>graph/d/prometheus-advanced/advanced-data-exploration</code> (PMM dashboard). <code>/prometheus/rules</code> No change. <code>/prometheus/service-discovery</code> No equivalent. <code>/prometheus/status</code> Some information at <code>/prometheus/metrics</code>. High cardinality metrics information at <code>/prometheus/api/v1/status/tsdb</code>. <code>/prometheus/targets</code> <code>/victoriametrics/targets</code>"},{"location":"reference/third-party/victoria.html#environment-variables","title":"Environment variables","text":"<p>PMM predefines certain flags that allow users to set all other VictoriaMetrics parameters as environment variables:</p> <p>The environment variable must be prepended with <code>VM_</code>.</p> <p>Example</p> <p>To set downsampling, use the <code>downsampling.period</code> parameter as follows:</p> <pre><code>-e VM_downsampling_period=20d:10m,120d:2h\n</code></pre> <p>This instructs VictoriaMetrics to deduplicate samples older than 20 days with 10 minute intervals and samples older than 120 days with two hour intervals.</p>"},{"location":"reference/third-party/victoria.html#using-victoriametrics-external-database-instance","title":"Using VictoriaMetrics external database instance","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for evaluation purposes only.</p> <p>You can use an external VictoriaMetrics database for monitoring in PMM.</p> <p>The environment variable <code>PMM_VM_URL</code> has been added, which should point to the external VictoriaMetrics database and should have the following format:</p> <pre><code>http(s)://hostname:port/path.\n</code></pre> <p>If the external VictoriaMetrics database requires basic authentication, the following environment variables should be used:</p> <p><pre><code>VMAGENT_remoteWrite_basicAuth_username={username}\nVMAGENT_remoteWrite_basicAuth_password={password}\n</code></pre> If other authentication methods are used on the VictoriaMetrics side, users can use any of the <code>vmagent</code> environment variables by prepending <code>VMAGENT_ prefix</code>.</p> <p>When external VictoriaMetrics is configured, internal VictoriaMetrics stops. In this case, VM Agent on PMM Server pulls metrics from agents configured in the <code>pull metrics mode</code> and from remote nodes. Data is then pushed to external VictoriaMetrics.</p> <p>Note</p> <p>VM Agents run by PMM Clients push data directly to external VictoriaMetrics. </p> <p>Ensure that they can connect to external VictoriaMetrics.</p>"},{"location":"reference/third-party/victoria.html#troubleshooting","title":"Troubleshooting","text":"<p>To troubleshoot issues, see the VictoriaMetrics troubleshooting documentation.</p> <p>You can also contact the VictoriaMetrics team via:</p> <ul> <li>Google Groups</li> <li>Slack</li> <li>Reddit</li> <li>Telegram</li> </ul>"},{"location":"reference/ui/log_in.html","title":"Log into PMM","text":"<p>To log into PMM:</p> <ol> <li> <p>Start a web browser and enter the server name or IP address of the PMM Server host in the address bar.</p> </li> <li> <p>The page loads showing the PMM log in screen.</p> <p></p> </li> <li> <p>Enter the username and password given to you by your system administrator. The defaults are:</p> <ul> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code></li> </ul> </li> <li> <p>Click Log in.</p> </li> <li> <p>If this is your first time logging in, you\u2019ll be asked to set a new password. We recommend you do.</p> <ul> <li>enter a new password in both fields and click Submit, or,</li> <li>click Skip to use the default password.</li> </ul> </li> <li> <p>The PMM Home dashboard loads:</p> <p></p> </li> </ol>"},{"location":"reference/ui/timezone.html","title":"Set timezones","text":"<p>By default Grafana uses the timezone from your web browser. However, you can change this setting.</p> <p>To set the timezone:</p> <ol> <li>On the left menu, hover your cursor over your avatar and then click Preferences.</li> <li>Click to select an option in the Timezone list.</li> <li>Click Save.</li> </ol>"},{"location":"reference/ui/ui_components.html","title":"UI components","text":"<p>This section explains how to access the interface, navigate the layout, and use the various controls within PMM.</p> <p>Here\u2019s how the UI is laid out, and what the controls do:</p> <p></p> <ol> <li>Main menu (also called Grafana menu or side menu)</li> <li>Top navigation bar</li> <li>View controls</li> <li>View selectors</li> <li>Shortcut menu</li> </ol>"},{"location":"reference/ui/ui_components.html#1-main-menu","title":"1. Main menu","text":"<p>You\u2019ll find these options in the left-side menu:</p> Icon Name What you can do Home Access the main dashboard with overview panels for database connections, queries, anomaly detection, and upgrade status. Bookmarks Create personal navigation shortcuts to any page in PMM. Bookmarks are private to your account and can include dashboards, settings pages, or any other PMM page for quick access. Starred Mark important dashboards as favorites. Starred dashboards can be set as your home page and are visible to all users, helping teams identify important monitoring views. Dashboards Create and organize dashboards, create folders, import dashboards, create playlists, and manage snapshots. Operating System (OS) Monitor server-level metrics including CPU, memory, disk, and network performance. MySQL View specialized dashboards for MySQL database performance monitoring. PostgreSQL Access PostgreSQL-specific monitoring dashboards and metrics. Query Analytics (QAN) Analyze database queries over time, identify slow queries, optimize performance, and troubleshoot issues. Explore Run ad-hoc queries with PromQL to investigate specific metrics without creating dashboards. Drilldown Run detailed analysis with specialized views for database metrics. This enables you to dive deeper into specific metrics by clicking through related data points and exploring underlying patterns. Learn more about drilling down into metrics in the Grafana documentation. Backup Configure and manage your database backups and storage locations. Advisors Run health assessment checks on your databases and view recommendations for improving performance. Alerting Create and manage alerts that notify you when metrics exceed thresholds. PMM Configuration Configure PMM-specific settings and manage your monitored database inventory. Connections Set up and manage data sources to integrate additional metrics into PMM. Administration Access Grafana-specific settings for users, permissions, plugins, and system maintenance."},{"location":"reference/ui/ui_components.html#2-top-navigation-bar","title":"2. Top navigation bar","text":"<p>The top bar helps you navigate and understand your current location:</p> <ul> <li>Dashboard title and breadcrumbs: Shows your current location and navigation path</li> <li>Search: Quickly find any dashboard by name</li> <li>Keyboard shortcuts: Access frequently used commands</li> <li>Help: Find documentation and support resources</li> <li>User profile: Manage your account settings and preferences</li> </ul>"},{"location":"reference/ui/ui_components.html#3-view-controls","title":"3. View controls","text":"<p>Customize how you view your dashboard data:</p> <ul> <li>Time range selector: Focus on specific time periods (last hour, day, week)</li> <li>Refresh button: Manually update dashboard data or set automatic refresh intervals</li> <li>View mode: Toggle between different display modes (fullscreen, TV mode)</li> <li>Dashboard settings: Access configuration options for the current dashboard</li> </ul>"},{"location":"reference/ui/ui_components.html#4-view-selectors","title":"4. View selectors","text":"<p>Filter your monitoring data using these contextual options:</p> <ul> <li>Interval: Control the data granularity (Auto, 1m, 5m, etc.)</li> <li>Environment: Focus on specific deployment environments</li> <li>Node Names: Filter metrics to specific servers</li> <li>Service Names: View data for particular database instances</li> <li>PMM Annotations: Toggle visibility of important events on your timelines</li> </ul> <p>These selectors change based on the dashboard you\u2019re viewing, showing only relevant options.</p>"},{"location":"reference/ui/ui_components.html#5-shortcut-menu","title":"5. Shortcut menu","text":"<p>Quick links to related dashboards and features:</p> <ul> <li>Home: Return to the main dashboard</li> <li>Query Analytics: Jump to query performance analysis</li> <li>Services: Access service-specific dashboards</li> <li>Compare: View side-by-side metrics for different nodes</li> <li>Additional shortcuts: Based on your current context</li> </ul> <p>See also</p> <ul> <li>How to render dashboard images</li> <li>How to annotate special events</li> </ul>"},{"location":"release-notes/index.html","title":"Release notes","text":"<ul> <li>Percona Monitoring and Management 3.3.1</li> <li>Percona Monitoring and Management 3.3.0</li> <li>Percona Monitoring and Management 3.2.0</li> <li>Percona Monitoring and Management 3.1.0</li> <li>Percona Monitoring and Management 3.0.0-1</li> <li>Percona Monitoring and Management 3.0.0</li> </ul>"},{"location":"release-notes/3.0.0.html","title":"Percona Monitoring and Management 3.0.0","text":"Release date January 30<sup>th</sup>, 2025 Installation Installing Percona Monitoring and Management Upgrade Migrate PMM 2 to PMM 3 <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>PMM empowers you to: </p> <ul> <li>monitor the health and performance of your database systems</li> <li>identify patterns and trends in database behavior</li> <li>troubleshoot issues effectively</li> <li>execute database management tasks seamlessly, whether your databases are on-premises or in the cloud</li> </ul>"},{"location":"release-notes/3.0.0.html#general-availability-of-pmm-300","title":"General availability of PMM 3.0.0","text":"<p>We\u2019re excited to announce the General Availability of PMM 3.0.0, a new major version that introduces a complete architectural overhaul of PMM. </p> <p>This milestone delivers major security improvements with rootless deployments, encryption of sensitive data, enhanced stability through containerized architecture, and improved user experience with flexible monitoring configurations. Key changes include official ARM support, MongoDB 8.0 monitoring, and a streamlined upgrade process.</p>"},{"location":"release-notes/3.0.0.html#release-summary","title":"Release summary","text":"<ul> <li>Security enhancements</li> <li>Enhanced stability</li> <li>Improved user experience</li> <li>Monitoring improvements</li> <li>Breaking API changes</li> <li>Component upgrades</li> <li>Improvements</li> <li>Fixed issues</li> </ul>"},{"location":"release-notes/3.0.0.html#security-enhancements","title":"Security enhancements","text":""},{"location":"release-notes/3.0.0.html#support-for-rootless-deployments","title":"Support for rootless deployments","text":"<p>Using the root user in applications poses a significant security risk, particularly when outdated software is installed or resides in the environment.</p> <p>PMM Server now supports rootless deployment through multiple methods, including the latest versions of Podman, Helm, Docker, Virtual Appliance, and Amazon AWS.</p> <p>This rootless setup enhances security by eliminating the need for root privileges to create, run, and manage containers. By running PMM Server as a non-root user, you avoid granting root permissions on the host system, providing an additional layer of protection against potential vulnerabilities and security breaches.</p> <p>For instructions on deploying rootless PMM, check the Setting up PMM Server topic.</p>"},{"location":"release-notes/3.0.0.html#internal-port-changes","title":"Internal port changes","text":"<p>As part of the rootless deployment support, PMM 3 changes the internal ports used by the PMM Server to enabling services to run without elevated (root) privileges:</p> Service Old port New port HTTPS 443 8443 HTTP 80 8080"},{"location":"release-notes/3.0.0.html#impact-and-required-actions","title":"Impact and required actions","text":"<ul> <li> <p>if you have custom scripts that reference the old internal ports (<code>443</code> and <code>80</code>), update them to use the new ports (<code>8443</code> and <code>8080</code>)</p> </li> <li> <p>for Docker or Docker Compose deployments, update your port mappings to point to the new internal ports while keeping your external ports the same if desired:</p> </li> </ul> Docker Compose example <pre><code>services:\n    pmm-server:\n        ports:\n            - \"443:8443\"  # Map external 443 to internal 8443\n            - \"80:8080\"   # Map external 80 to internal 8080\n</code></pre> <p>For examples of configuring PMM 3 with Docker Compose, including port mappings, see Docker deployment documentation and this Percona Forum thread.</p>"},{"location":"release-notes/3.0.0.html#ui-based-upgrades-for-podman-installations","title":"UI-based upgrades for Podman installations","text":"<p>You can now upgrade PMM Server installations running under Podman directly through the PMM Configuration &gt; Updates panel in the UI. </p> <p>This functionality integrates Watchtower for automated container updates and requires configuration of new environment variables (<code>PMM_WATCHTOWER_HOST</code>, <code>PMM_WATCHTOWER_TOKEN</code>) as well as relevant systemd service settings.</p> <p>For detailed configuration instructions, see Installation with UI updates.</p>"},{"location":"release-notes/3.0.0.html#encryption-of-sensitive-data","title":"Encryption of sensitive data","text":"<p>Plaintext passwords and credentials are among the top ten security risks identified by OWASP (Open Web Application Security Project).</p> <p>To address this risk, PMM now encrypts all sensitive information stored in its database. This includes usernames, passwords, AWS keys, Azure credentials, and TLS/SSL certificates, significantly enhancing the security of your monitoring environment. Even though we recommend minimal privileges for monitoring user accounts, you can rest assured that the sensitive data is protected! </p> <p>By default, PMM generates an encryption key and stores it at <code>/srv/pmm-encryption.key</code>. Alternatively, you can define a custom path for the encryption key using the new environment variable <code>PMM_ENCRYPTION_KEY_PATH</code>.</p> <p>When upgrading to PMM 3, any existing unencrypted PMM 2 data will be encrypted automatically.</p> <p>For more information, see PMM data encryption.</p>"},{"location":"release-notes/3.0.0.html#enhanced-api-authentication-with-grafana-service-accounts","title":"Enhanced API authentication with Grafana service accounts","text":"<p>We\u2019ve made a significant enhancement to the way API authentication is handled. PMM no longer relies on API keys as the primary method for controlling access to the PMM Server components and resources. Instead, PMM now leverages Grafana service accounts, which provide a more secure and manageable authentication mechanism compared to API keys.</p> <p>Service accounts provide better security through fine-grained access control while maintaining detailed audit logs of all actions. This includes comprehensive tracking of elevated privilege operations and improved visibility into access patterns - continuing the logging capabilities previously available with API keys.</p>"},{"location":"release-notes/3.0.0.html#migration-from-api-keys","title":"Migration from API keys","text":"<p>With this change, API keys are now deprecated and will be automatically converted to service accounts. Here\u2019s what happens when upgrading from PMM 2 to PMM 3:</p> <ul> <li>your existing API keys remain functional but are moved to service accounts</li> <li>the conversion happens when you first log in as an Admin user or via CLI</li> <li>your integrations will continue working with the same API key credentials (hash values remain unchanged)</li> <li>the keys will appear under Administration &gt; Users and Access &gt; Service Accounts</li> </ul> <p>For more information see Migrate to PMM 2 to PMM 3 and Service account authentication.</p> <p></p>"},{"location":"release-notes/3.0.0.html#cves-eliminated-through-architectural-changes","title":"CVEs eliminated through architectural changes","text":"<p>The removal of legacy components like Integrated Alerting and DBaaS, combined with the security enhancements above, eliminates multiple potential vulnerabilities and CVEs. This makes PMM 3 our most secure release yet.</p>"},{"location":"release-notes/3.0.0.html#enhanced-stability","title":"Enhanced stability","text":""},{"location":"release-notes/3.0.0.html#containerized-pmm-architecture-for-ami-and-ovf-deployments","title":"Containerized PMM architecture for AMI and OVF deployments","text":"<p>Previously, AMI and OVF instances of PMM were created as standalone images rather than being containerized like the primary Docker-based PMM version.</p> <p>This difference in architecture led to challenges in maintenance as fixes and updates for AMI and OVF instances required additional effort and were sometimes delayed due to their lower adoption rates.</p> <p>With this update, PMM now uses a unified containerized architecture across all deployment methods. In AMI and OVF environments, PMM components run as Podman-managed containers in rootless mode, eliminating the need for elevated system privileges.</p> <p>This transition not only aligns AMI and OVF deployments with PMM\u2019s core containerized model but also improves security, enables faster troubleshooting, and streamlines updates and patch management.</p>"},{"location":"release-notes/3.0.0.html#more-stable-and-quicker-upgrades","title":"More stable and quicker upgrades","text":"<p>PMM 3 introduces a significant upgrade system overhaul, replacing the earlier method based on internal package updates. While the previous approach offered the convenience of upgrading directly via the Update button on the Home dashboard, it was prone to connection issues and package corruption, often resulting in complex recovery challenges.</p> <p>The new upgrade method moves away from RPM updates to exclusive container updates, eliminating RPM-related complications. This streamlined approach provides consistent upgrade experiences across all deployment types\u2014Docker, Podman, and OVF/AMI.</p> <p>At the same time, we\u2019re maintaining the UI upgrade option by integrating Watchtower, an external upgrading tool. When you click the Upgrade Now button on the Home Dashboard, Watchtower seamlessly replaces the PMM Server container and links the new one to the existing volume, preserving all data and settings intact.</p> <p>For easy adoption, Watchtower comes pre-configured in our Easy-Install script, enabling one-step PMM setup.</p>"},{"location":"release-notes/3.0.0.html#reduced-pmm-container-image-size","title":"Reduced PMM container image size","text":"<p>We\u2019ve optimized the PMM 3 container image from 3.1GB to 2.6GB, reducing its size by 0.5GB. This reduction improves download speeds and enhances deployment reliability, particularly beneficial for environments with limited storage capacity or bandwidth constraints.</p>"},{"location":"release-notes/3.0.0.html#improved-user-experience","title":"Improved user experience","text":""},{"location":"release-notes/3.0.0.html#new-upgrade-ui","title":"New upgrade UI","text":"<p>We\u2019ve introduced a new Updates page under PMM Configuration to support the new container-based upgrade system. This centralized interface offers clear visibility into the versions and configurations of both your PMM Server and Clients, simplifying the update process.</p> <p>With this update, you\u2019ll receive proactive notifications whenever new versions are released to help you make informed decisions before proceeding with available upgrades.</p> <p></p>"},{"location":"release-notes/3.0.0.html#flexible-monitoring-configurations","title":"Flexible monitoring configurations","text":"<p>PMM extends its database monitoring setup process by adding an intuitive UI-driven approach alongside CLI-based configuration. After installing PMM Client on your database server, all further monitoring configurations can be managed directly through the PMM interface, eliminating the need for complex command-line operations.</p> <p>This simplified workflow combines with PMM\u2019s new ability to run database exporters on any PMM Client node rather than solely on PMM Server. By distributing the monitoring load across multiple PMM Clients, this approach enables more efficient monitoring of a larger number of remote and cloud-hosted databases, such as RDS instances.</p> <p>When adding new services through the PMM UI, you can now specify which PMM Client node will run the monitoring exporter. While PMM Server remains the default option, you can choose any node with PMM Client installed, including selecting specific clients on nodes with multiple installations.</p> <p>This distributed monitoring capability is currently available for new service additions, with support for existing service modification planned for a future release.</p> <p>For more details, see Connect services.</p> <p></p>"},{"location":"release-notes/3.0.0.html#simplified-aws-installation-process","title":"Simplified AWS installation process","text":"<p>We\u2019ve simplified AWS installations to match our standard Docker/Podman workflow. After installation, you\u2019ll immediately see the PMM login screen.</p> <p>Use admin as the username and your EC2 Instance ID as the password (the default PMM password cannot be used for security reasons).</p> <p>You can find your Instance ID in the AWS Console. For detailed instructions, see Install PMM Server on AWS Marketplace.</p>"},{"location":"release-notes/3.0.0.html#official-arm-support-for-pmm-client","title":"Official ARM support for PMM Client","text":"<p>PMM 3 now officially supports ARM architecture, upgrading from its experimental status in PMM 2.43. This means you can reliably monitor databases on ARM platforms, taking advantage of their cost-effective infrastructure and energy efficiency in data centers and cloud environments.</p> <p>Installation follows the standard PMM Client process, with no special requirements for ARM systems.  </p> <p>Try out this feature and share your experience on the PMM forum!</p>"},{"location":"release-notes/3.0.0.html#improved-ux-with-grafanas-latest-release","title":"Improved UX with Grafana\u2019s latest release","text":"<p>PMM now integrates Grafana 11.1.8, which delivers the following important enhancements alongside all the advancements introduced since the previous Grafana 9.2.20 integration in PMM 2.</p> <p>For the full list of Grafana changes included with this update, see Grafana\u2019s 11.1.8 changelog and Grafana release highlights.</p>"},{"location":"release-notes/3.0.0.html#improved-navigation","title":"Improved navigation","text":"<p>PMM now includes a revamped header with search, breadcrumbs, and a reorganized menu that groups related tools together, making it easier to navigate PMM\u2019s features and find what you need:</p> <p></p>"},{"location":"release-notes/3.0.0.html#improved-alerting-workflow","title":"Improved Alerting workflow","text":"<p>Leveraging the new Grafana user interface updates, we\u2019ve taken the opportunity to refine the workflow for creating alerts from the Alert Rules and Alert Rule Templates pages.</p> <p>You\u2019ll notice separate, more visible options for creating different types of alert rules, cutting down on unnecessary steps and making it easier to manage various alert rules, templates, and configurations:</p> <p></p>"},{"location":"release-notes/3.0.0.html#simplified-administration-settings-with-dedicated-menus","title":"Simplified administration settings with dedicated menus","text":"<p>Administration settings are now easier to manage with the new Administration menu. This menu brings together all Grafana-related configurations and account management options that were previously scattered across the general Configuration section. This change helps administrators locate and manage Grafana-specific settings more efficiently.</p> <p>Additionally, all PMM settings and inventory options are now grouped under a new PMM Configuration menu. This centralizes access to all PMM-related configurations, making it simpler for users to handle their PMM setup.</p> <p>These improvements make navigating easier and more organized, so you can quickly find and adjust settings for Grafana and PMM.</p>"},{"location":"release-notes/3.0.0.html#monitoring-improvements","title":"Monitoring improvements","text":""},{"location":"release-notes/3.0.0.html#added-monitoring-support-for-default-postgresql-database","title":"Added monitoring support for default PostgreSQL database","text":"<p>PMM now provides full monitoring support for the default <code>postgres</code> database on PostgreSQL instances, with metrics displayed across Query Analytics (QAN).</p> <p>This enhancement resolves a previous visibility gap where database activity was hidden when applications used the default database. </p> <p>While using the default database for applications is not recommended, PMM 3 ensures comprehensive visibility, empowering teams to identify and address this practice proactively and maintain better database management.</p>"},{"location":"release-notes/3.0.0.html#added-oplog-generation-rate-panel-to-mongodb-dashboards","title":"Added Oplog generation rate panel to MongoDB dashboards","text":"<p>The MongoDB Sharded Cluster Summary and MongoDB ReplSet Summary dashboards now include an Oplog GB/Hour panel showing the oplog generation rate per hour in a column format.</p> <p>The panel is located in the Replication section, helping you monitor oplog generation alongside other replication metrics for better visibility into your database replication patterns:</p> <p></p>"},{"location":"release-notes/3.0.0.html#general-availability-of-mongodb-router-summary-dashboard","title":"General availability of MongoDB Router Summary dashboard","text":"<p>The MongoDB Router Summary, initially introduced as an experimental dashboard in PMM 2, is now generally available in PMM 3. This dashboard provides comprehensive monitoring for MongoS routers in sharded MongoDB clusters, offering insights into MongoS availability, version details and resource utilization. </p> <p>You can access this dashboard at MongoDB &gt; High availability &gt; Router summary.</p> <p></p>"},{"location":"release-notes/3.0.0.html#tech-preview-support-for-psmdb-and-community-mongodb-80","title":"[Tech Preview] Support for PSMDB  and Community MongoDB 8.0","text":"<p>The latest version of MongoDB, along with Percona Server for MongoDB 8.0, brings numerous improvements and significant performance enhancements. In this version of PMM, we are also adding support for MongoDB 8, allowing MongoDB users to monitor their new version and observe its performance impact.</p> <p>This includes updates to <code>mongodb_exporter</code> to accommodate PSMDB 8.0\u2019s revised metrics structure and renamed metrics (e.g., <code>wiredTiger.concurrentTransactions</code> is now <code>queues.execution</code>).</p> <p>This enhances monitoring, particularly for sharded cluster deployments, and requires PMM Agent version 2.43.1 or later.</p> <p>Keep in mind that some dashboard metrics may need further updates to fully support MongoDB 8.0\u2019s new format.</p>"},{"location":"release-notes/3.0.0.html#qan-improvements","title":"QAN improvements","text":""},{"location":"release-notes/3.0.0.html#increased-query-length-limit-for-mongodb-in-qan","title":"Increased query length limit for MongoDB in QAN","text":"<p>For MongoDB queries, the default maximum query length in Query Analytics (QAN) is now 4096 characters (up from 2048). This better supports long queries and aggregation pipelines while reducing truncation errors. Other databases retain the 2048-character limit.</p>"},{"location":"release-notes/3.0.0.html#enhanced-mysql-slowlog-query-identification","title":"Enhanced MySQL SlowLog query identification","text":"<p>Improved MySQL Slow Log query identification by extending the query ID length from 16 to 32 characters. This reduces the likelihood of ID collisions and ensures more accurate and reliable QAN results.</p>"},{"location":"release-notes/3.0.0.html#breaking-changes-and-deprecations","title":"Breaking changes and deprecations","text":""},{"location":"release-notes/3.0.0.html#oracle-enterprise-linux-9-images-only","title":"Oracle Enterprise Linux 9 images only","text":"<p>With Enterprise Linux 7 (EL7) approaching its end-of-life date, we\u2019ve made sure that PMM 3 exclusively uses Oracle Enterprise Linux 9 (EL9) as the base system for all PMM images.</p> <p>We began this transition from CentOS 7 to EL9 with the latest PMM 2 releases, and now with PMM 3, we are no longer building Docker containers, AMIs, or OVFs based on EL7.</p> <p>By moving to EL9, we ensure that PMM is built on most recent library versions and stays compatible with new technologies. Moreover, EL9 grants access to faster upstream responses to issues, particularly those concerning security, so that your PMM setup remains up-to-date and secure.</p> <p>Due to this change, PMM 3 cannot be started on host servers running EL7.</p>"},{"location":"release-notes/3.0.0.html#finalized-dbaas-migration-to-percona-everest","title":"Finalized DBaaS migration to Percona Everest","text":"<p>In previous PMM releases, the Database as a Service (DBaaS) functionality has been gradually transferred to Percona Everest, an open source cloud-native database platform that solves the challenge of public cloud DBaaS vendor lock-in.</p> <p>With Percona Everest, you gain the ability to provision and oversee highly performant database clusters on the infrastructure you manage, whether it\u2019s your preferred cloud environment or on-premises. This empowerment extends to regaining control over critical aspects such as data access, database configuration, and the costs associated with cloud-based database operations.</p> <p>While PMM 2.x versions continue to support existing DBaaS functionality, PMM 3 marks the complete deprecation of this feature, removing all references to DBaaS.</p> <p>If you are an existing PMM user who relies on DBaaS functionality, we encourage you to explore Percona Everest and leverage its advanced features for database deployment. Percona Everest also integrates with PMM to provide monitoring capabilities for your database infrastructure.</p> <p>To learn more about integrating Percona Everest with PMM and adding monitoring endpoints, see Add monitoring endpoints in the Everest documentation.</p>"},{"location":"release-notes/3.0.0.html#finalized-integrated-alerting-deprecation-and-api-removal","title":"Finalized Integrated Alerting deprecation and API removal","text":"<p>This release completes the deprecation of Integrated Alerting started in PMM 2.31.0 by removing its remaining components and APIs:</p> <ul> <li>Removed all Integrated Alerting API endpoints, including <code>/v1/Settings/TestEmailAlertingSettings</code></li> <li>Removed Integrated Alerting-related fields from the PMM Settings API (<code>email_alerting_settings</code> and <code>slack_alerting_settings</code>)</li> </ul> <p>If you still have alert rules that haven\u2019t been migrated to Percona Alerting, use the Integrated Alerting Migration Script to migrate them. Percona Alerting provides enhanced capabilities through Grafana\u2019s alerting infrastructure and pre-configured Alert Rule Templates.</p>"},{"location":"release-notes/3.0.0.html#breaking-api-changes","title":"Breaking API changes","text":"<p>This release introduces major breaking API changes:</p> <ul> <li>Database record identifiers no longer use prefixes (e.g., <code>/agent_id/</code>) and are now represented as plain UUIDs.</li> <li>Feature toggles have been simplified from dual booleans to a single boolean control with an <code>enable_feature</code> property.  </li> <li>API responses now consistently emit all fields including those with default or zero values.</li> <li>Service, node, and agent management has been streamlined through consolidated endpoints where the resource type is specified as a top-level property in the request payload.</li> <li>Low-level Inventory API sections have been removed from documentation in favor of the Management API for inventory-related tasks.</li> </ul> <p>For detailed information about all these API changes and new endpoints, see the PMM API documentation. </p>"},{"location":"release-notes/3.0.0.html#new-upgrade-environment-variables","title":"New upgrade environment variables","text":"<p>When migrating from PMM 2 to PMM 3, you\u2019ll need to update your environment variables to match the new naming convention. This is because PMM 3 introduces several important changes to improve consistency and clarity:</p> <ul> <li>environment variables now use PMM_ prefix</li> <li>some boolean flags reversed (e.g., <code>DISABLE_</code> &gt; <code>ENABLE_</code>)</li> <li>removed deprecated variables</li> </ul> <p>To check the Migration reference table, see Environment variables in PMM.</p>"},{"location":"release-notes/3.0.0.html#grafana-angular-support-discontinuation","title":"Grafana Angular support discontinuation","text":"<p>Grafana will discontinue support for Angular starting with version 12, expected in 2025. This affects numerous panels and plugins, including but not limited to Graph and Table panels.</p> <p>We have already migrated many plugins to newer technologies and are actively working on the remaining components to ensure continued functionality. We recommend that you review all plugins in your dashboards and begin planning transitions to newer panel types where necessary.</p> <p>For the full list of affected plugins and guidance on migration, see Grafana\u2019s official documentation on Angular deprecation and plugin migration.</p> <p>We will provide regular updates on our migration progress in future releases to help you prepare for this change and modernize your dashboards.</p>"},{"location":"release-notes/3.0.0.html#component-upgrades","title":"Component upgrades","text":"<p>We\u2019ve upgraded following PMM components to their latest stable versions to enhance functionality, security, and performance:</p> <ul> <li>Grafana 11.1.8: Includes significant improvements over the previous version 9.2.20 integration in PMM 2.</li> <li>Node Exporter 1.8.2: The latest stable release enhances system metrics collection with improved security, additional metrics for custom dashboards, and critical bug fixes. This version strengthens our ability to monitor crucial system-level metrics through upstream improvements.</li> <li>ClickHouse Datasource plugin: Updated to address security vulnerabilities and maintain system integrity. This update ensures continued reliable operation of ClickHouse-related dashboards.</li> <li>ClickHouse-go driver: Upgraded QAN to use version 2 of the driver, improving database connectivity and performance.</li> </ul>"},{"location":"release-notes/3.0.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-13399 - PMM Client packages (DEB, RPM, and tarball) now include the Nomad binary, laying the foundation for expanded functionality in future PMM releases. While the Nomad binary is now included and properly configured within the PMM Client ecosystem, Nomad agent configuration and execution capabilities will be implemented in future releases, which will unlock more capabilities for PMM.</p> </li> <li> <p>PMM-13315 - To prevent node registration failures, PMM now automatically shortens service account names longer than 200 characters. For this, PMM creates a truncated name in the format <code>{prefix}_{hash}</code>, where:</p> <ul> <li>prefix is a portion of the original name, providing context</li> <li>hash is a unique identifier to avoid naming conflicts</li> </ul> <p>For example, a long node name such as:</p> <ul> <li><code>Copyvery_long_mysql_database_server_in_production_environment_with_specific_location_details_and_multiple_configuration_settings_for_east_coast_datacenter_primary_backup_replica_instance_2024</code></li> </ul> <p>would now be shortened to:</p> <ul> <li><code>Copyvery_long_mysql_database_server_in_prod_4a7b3f9d</code>.</li> </ul> </li> <li> <p>PMM-12940 - We\u2019ve added automated update support for AMI/OVF deployments. The new Updates page also enables AMI and OVF deployments to update PMM Server directly from the UI, following the integration of the Watchtower container.</p> </li> <li> <p>PMM-11216 - Added ability to upgrade PMM Server between different version tags, enabling more flexible version management for Docker-based deployments.</p> </li> </ul>"},{"location":"release-notes/3.0.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-13122 - Fixed navigation between pages to properly maintain selected service names and timeframes when switching between different dashboards and metrics views.</p> </li> <li> <p>PMM-12013 - Fixed reliability and memory usage issues with RDS monitoring in large deployments by running separate RDS exporters per AWS access key. This improves metric collection stability and reduces memory consumption when monitoring multiple RDS instances.</p> </li> <li> <p>PMM-13360 - Fixed an issue in the MongoDB ReplSet Summary dashboard where nodes in <code>down</code> state would sometimes disappear from the States panel and their version information would be removed from the MongoDB Versions panel. Nodes in <code>down</code> state now remain visible with their last known version information preserved.</p> </li> <li> <p>PMM-13584 - Fixed an issue in the MongoDB ReplSet Summary dashboard where the bottom graphs displayed \u201cno data\u201d due to incorrect metric query syntax.</p> </li> </ul> <p>Ready to install or migrate to PMM 3?</p> <p>We provide two installation scripts to help you get started with this new version:</p> <ul> <li>For new installations, the Easy-Install script comes with Watchtower pre-configured, enabling one-step PMM setup with automatic updates.</li> <li>For existing PMM 2 users, we provide a dedicated Upgrade script that safely migrates your installation to PMM 3 and ensures data is backed up before the upgrade.</li> </ul>"},{"location":"release-notes/3.0.0_1.html","title":"Percona Monitoring and Management 3.0.0-1","text":"<p>Release date: February 10<sup>th</sup>, 2025                                                                     </p> <p>Percona Monitoring and Management (PMM) is an open-source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB. </p> <p>It provides tools to observe database health, analyze performance trends, troubleshoot issues, and execute database management tasks\u2014whether your databases are on-premises or in the cloud.</p>"},{"location":"release-notes/3.0.0_1.html#severity-critical-immediate-action-required","title":"SEVERITY: CRITICAL - IMMEDIATE ACTION REQUIRED","text":"<p>A critical vulnerability has been identified in PMM Open Virtual Appliance (OVA) installations that enables unauthorized <code>root</code> access and potential exposure of system credentials. This vulnerability is tracked as CVE-2025-26701.</p>"},{"location":"release-notes/3.0.0_1.html#immediate-actions-required","title":"Immediate actions required","text":"<p>Your system may be exposed to unauthorized root access and credential theft. Take the following steps immediately to secure your infrastructure:</p> <ol> <li>UPGRADE IMMEDIATELY to PMM 3.0.0-1 (strongly recommended).</li> <li>CHANGE ALL CREDENTIALS for connected services and databases.</li> <li>AUDIT ACCESS LOGS for potential unauthorized access.</li> </ol>"},{"location":"release-notes/3.0.0_1.html#vulnerability-details","title":"Vulnerability details","text":"<p>This vulnerability stems from default service account credentials in OVA provisioning that enables:</p> <ul> <li>unauthorized SSH access</li> <li>privilege escalation to <code>root</code> via <code>sudo</code> capabilities</li> <li>potential exposure of service credentials and configurations</li> </ul>"},{"location":"release-notes/3.0.0_1.html#affected-installations","title":"Affected installations","text":"<p>The table below lists currently known affected deployments. We will update it if additional products are identified:</p> Affected deployments Version Notes PMM Open Virtual Appliance (OVA) installations \u2265 2.38 <p>Restrict SSH access</p> <p>PMM OVA installations should never have port 22 exposed to the public Internet unless you have implemented additional security hardening measures. Always use firewalls, VPNs, or other secure remote access methods.</p>"},{"location":"release-notes/3.0.0_1.html#not-affected","title":"Not affected","text":"<p>This vulnerability affects ONLY OVA installations. The following deployment methods are NOT affected:</p> <ul> <li>Docker/Podman containers</li> <li>Amazon Machine Images (AMIs)</li> <li>Kubernetes deployments (via Helm)</li> </ul>"},{"location":"release-notes/3.0.0_1.html#mitigation-options","title":"Mitigation options","text":"PREFERRED: Upgrade to PMM 3.0.0-1TEMPORARY: If you cannot upgrade immediately <p>This release enhances security in OVA deployments by automatically removing unnecessary system accounts during the initial setup.</p> <p>To secure your system, follow these steps to upgrade:</p> <ol> <li> <p>Download and deploy the new OVA file from Percona website.</p> </li> <li> <p>Log in to your system:     <pre><code>ssh admin@your-pmm-server\n</code></pre></p> </li> <li> <p>Switch to <code>root</code> or use <code>sudo</code> for the following commands:     <pre><code>sudo -i\n# or use sudo before each command\n</code></pre></p> </li> <li> <p>Stop services on your current installation:      <pre><code>supervisorctl stop all\n</code></pre></p> </li> <li> <p>Back up and transfer your data:     <pre><code>cd /home/admin/volume/srv\ntar -cvf srv.tar .\n</code></pre></p> </li> <li> <p>Transfer srv.tar to new server via scp.</p> </li> <li> <p>Deploy data on the new installation:     <pre><code># Stop all services\nsupervisorctl stop all\n\n# Clear existing data\ncd /home/admin/volume/srv\nrm -rf *\n\n# Extract backup\ntar -xvf /home/admin/volume/srv.tar\n\n# Start all services\nsupervisorctl start all\n</code></pre></p> </li> <li> <p>Update DNS records or swap IP addresses to ensure uninterrupted Client connectivity.</p> </li> </ol> <p>If an upgrade is not immediately possible, follow these steps to mitigate the vulnerability:</p> <ol> <li> <p>Secure SSH access:</p> <ul> <li>block port 22 access at firewall level</li> <li>if remote access is required, restrict it to specific IP addresses</li> <li>consider using a VPN for remote management</li> </ul> </li> <li> <p>Log in to your system:     <pre><code>ssh admin@your-pmm-server\n</code></pre></p> </li> <li> <p>Switch to <code>root</code> or use <code>sudo</code> for the following commands.     <pre><code>sudo -i\n# or use sudo before each command\n</code></pre></p> </li> <li> <p>Execute ONE of these commands to secure the vulnerable account:</p> <ul> <li> <p>disable login:     <pre><code>usermod -s /sbin/nologin vagrant\n</code></pre></p> </li> <li> <p>lock account:     <pre><code>passwd -l vagrant\n</code></pre></p> </li> <li> <p>remove user completely:     <pre><code>kill -9 $(pgrep -f vagrant)\nuserdel -r vagrant\n</code></pre></p> </li> </ul> </li> <li> <p>Update service credentials:</p> <ul> <li>change monitoring user passwords in your databases (MySQL, PostgreSQL, MongoDB)</li> <li>update any custom service accounts you\u2019ve created</li> <li>rotate authentication tokens for monitored services</li> <li>update corresponding credentials in PMM configuration</li> <li>configure SSH access: add public key via PMM Configuration &gt; Settings &gt; SSH Key</li> </ul> </li> <li> <p>Monitor system logs for unauthorized access.</p> </li> </ol>"},{"location":"release-notes/3.0.0_1.html#verification-steps","title":"Verification steps","text":"<p>After upgrading, verify that your system is functioning correctly:</p> <ol> <li>Check service status to confirm both PMM Client and PMM Server are running:     <pre><code>supervisorctl status\n</code></pre></li> <li> <p>Ensure Client connectivity to validate data flow.</p> </li> <li> <p>Test system functionality by performing basic monitoring tasks.</p> </li> </ol>"},{"location":"release-notes/3.0.0_1.html#support-additional-resources","title":"Support &amp; additional resources","text":"<p>If you require further clarification or assistance, we are available to assist you 24/7:</p> <ul> <li>Technical support portal for customers</li> <li>Technical support for community</li> <li>Security advisory announcement</li> </ul>"},{"location":"release-notes/3.0.0_1.html#upgrading-from-pmm-2x","title":"Upgrading from PMM 2.x?","text":"<p>If you are running PMM 2.38 or later, make sure to upgrade to PMM 2.44.0-1. For upgrade instructions, see the PMM 2.44.0-1 Release Notes for specific upgrade instructions.</p>"},{"location":"release-notes/3.1.0.html","title":"Percona Monitoring and Management 3.1.0","text":"Release date March 31th, 2025 Installation Installing Percona Monitoring and Management Upgrade Migrate PMM 2 to PMM 3 <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB.</p> <p>PMM empowers you to: </p> <ul> <li>monitor the health and performance of your database systems</li> <li>identify patterns and trends in database behavior</li> <li>troubleshoot issues effectively</li> <li>execute database management tasks seamlessly, whether your databases are on-premises or in the cloud</li> </ul>"},{"location":"release-notes/3.1.0.html#release-summary","title":"Release summary","text":"<p>PMM 3.1.0 enhances MongoDB monitoring with improved query analytics, better visualization, and streamlined troubleshooting. This release also refines role-based access for advisors and alerts, along with various usability improvements and bug fixes.</p>"},{"location":"release-notes/3.1.0.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/3.1.0.html#enhanced-mongodb-monitoring","title":"Enhanced MongoDB monitoring","text":"<p>We\u2019ve improved MongoDB monitoring with detailed query metrics, better dashboard visualization, and new capabilities to quickly identify performance bottlenecks.</p>"},{"location":"release-notes/3.1.0.html#extended-metrics-and-labels-for-mongodb-query-analytics-qan","title":"Extended metrics and labels for MongoDB Query Analytics (QAN)","text":"<p>The QAN dashboard includes new metrics and filters that highlight inefficient execution paths and offer detailed lock and storage metrics. With the improved filters, you can quickly pinpoint problematic queries based on application, client, user, or plan summary:</p>"},{"location":"release-notes/3.1.0.html#new-metrics","title":"New metrics","text":"<p>In the Query Details section of the QAN dashboard you\u2019ll now find these additional metrics:</p> Query execution metricsResponse metricLock statistics metricsStorage metrics <p>New metrics for identifying inefficient query patterns:</p> <ul> <li>Docs Examined: the number of documents scanned. High values may indicate missing or inefficient indexes.</li> <li>Keys Examined: the number of index keys scanned. Compare this with Docs Examined to assess index efficiency.</li> <li>Docs Returned: the number of documents returned to the PMM Client. A high Docs Examined to Docs Returned ratio may indicate inefficiencies that need optimization. </li> <li>Full Scan (COLLSCAN): tracks instances where the entire dataset is scanned, meaning every document in the collection is read. This results in high I/O operations, long execution times, and scalability challenges. High COLLSCAN should be addressed to enhance performance.</li> </ul> <p>New metric for evaluating query response efficiency:</p> <p>Response Length: measures the size of the response payload in bytes, helping identify large result sets that may impact performance.</p> <p>New metrics for detecting lock contention issues:</p> <ul> <li>Locks Global Acquire Count Read/Write Shared: tracks how often global locks are used, helping to spot delays caused by multiple processes accessing the same data.</li> <li>Locks Database Acquire Count Read Shared: tracks how often read locks are used in the database.</li> <li>Locks Database Acquire Wait Count Read Shared: counts the times a database read lock request had to wait. High values may signal delays due to contention.</li> <li>Locks Database Time Acquiring Micros Read Shared: captures the time spent waiting for database read locks, critical for performance analysis.</li> <li>Locks Collection Acquire Count Read Shared: tracks how often read locks are used at the collection level.</li> </ul> <p>New metrics for analyzing I/O performance:</p> <ul> <li>Storage Bytes Read: measures the volume of data read from storage during operations, helping identify I/O-intensive queries.</li> <li>Storage Time Reading in Microseconds (\u00b5s): tracks the time spent on storage read operations, which is useful for detecting potential storage bottlenecks.</li> </ul>"},{"location":"release-notes/3.1.0.html#new-filters","title":"New filters","text":"<p>The QAN dashboard now includes several additional MongoDB-specific filter options:</p> <ul> <li>Plan Summary: filters queries by execution plan type (COLLSCAN, IXSCAN, etc.) to easily identify inefficient full collection scans. </li> <li>Application Name: filters queries by the application that executed them. </li> <li>User: isolates queries by specific database users. </li> <li> <p>Database: focuses on particular database instances. </p> <p> </p> </li> </ul>"},{"location":"release-notes/3.1.0.html#improved-query-fingerprint-visualization","title":"Improved query fingerprint visualization","text":"<p>MongoDB query fingerprints in QAN now display the actual query structure, including operators and field names, similar to the format used in a MongoDB shell. </p> <p>The previous display only showed operation type and collection name, which provided limited context for troubleshooting. </p> <p>The new fingerprint format makes query patterns immediately recognizable while still anonymizing sensitive data. </p> <p></p>"},{"location":"release-notes/3.1.0.html#enhanced-query-examples-visualization","title":"Enhanced query examples visualization","text":"<p>We\u2019ve refined the query examples interface in Mongo QAN by removing unnecessary enumeration labels (\u201c1 item\u201d, \u201c2 item\u201d, etc.) and upgrading the JSON viewer component. </p>"},{"location":"release-notes/3.1.0.html#improved-mongodb-cluster-topology-visualization","title":"Improved MongoDB cluster topology visualization","text":"<p>We have enhanced the MongoDB Cluster Summary dashboard with a redesigned Current Topology section. </p> <p>This section now properly categorizes MongoDB cluster components\u2014shards, config servers, and mongos routers\u2014within their appropriate hierarchical sections. This replaces the previous implementation that incorrectly grouped all components under the Config Servers section.</p> <p></p>"},{"location":"release-notes/3.1.0.html#enhanced-mongodb-dashboard-visualizations","title":"Enhanced MongoDB dashboard visualizations","text":"<p>Based on community feedback, we\u2019ve made several improvements to the MongoDB ReplicaSet Summary and MongoDB Sharded Cluster Summary dashboards:</p> <ul> <li>improved detection of node states to better identify down nodes</li> <li>optimized Top Hottest Collections panel showing only the most critical data</li> <li>improved readability with rounded numbers in Overview panels</li> <li>increased precision with decimal values (tenths) in Top Hottest Collections panels</li> <li>resolved visualization issues in Disk I/O and Network traffic panels for more reliable performance monitoring</li> </ul>"},{"location":"release-notes/3.1.0.html#enhanced-filtering-capabilities","title":"Enhanced filtering capabilities","text":"<p>We\u2019ve improved the filtering experience on the MongoDB Instances Compare dashboard with four new selection boxes in addition to the existing Service Name filter. These filters allow you to narrow down instances by:</p> <ul> <li>Replication Set</li> <li>Environment</li> <li>Cluster</li> <li>Node </li> </ul> <p></p> <p>These additional filters make it easier to navigate and compare MongoDB instances in larger environments, enabling you to quickly narrow down the specific instances you want to monitor.</p>"},{"location":"release-notes/3.1.0.html#enhanced-role-based-access-control","title":"Enhanced role-based access control","text":"<p>We\u2019ve refined role-based access for Advisors and Alerts, making it easier for teams to collaborate while maintaining security boundaries:</p>"},{"location":"release-notes/3.1.0.html#advisors-access-for-editors","title":"Advisors access for Editors","text":"<p>Users with the Editor role can now access Advisors insights without requiring Admin privileges. This is especially beneficial in managed service environments where Admin access is typically restricted to database administrators.</p> <p>While Editors can view Advisors insights, only Admins can run, disable, or edit Advisors.</p>"},{"location":"release-notes/3.1.0.html#expanded-access-to-fired-alerts","title":"Expanded access to fired alerts","text":"<p>The Fired Alerts page under Alerting is now accessible to both Viewer and Editor roles, allowing teams to monitor triggered alerts without needing elevated permissions:</p> <ul> <li>Editors can now view and silence alerts directly from the Fired alerts page. Previously, silencing alerts was only possible via the Alert rules page.</li> <li>Editors also gain full access to alert templates including the ability to view, create, edit, and delete templates.</li> <li>Viewers cannot access or modify alert templates, protecting critical alert configurations.</li> </ul> <p>For more details, see PMM roles and permissions.</p>"},{"location":"release-notes/3.1.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-12161 - MongoDB components are now properly organized in the Cluster Summary dashboard, replacing the confusing layout where all appeared under Config Servers.</p> </li> <li> <p>PMM-13545 - Enhanced MongoDB dashboard visualizations with improved node state detection, optimized Top Hottest Collections panels, better number formatting, and fixed visualization issues in the Disk I/O and Network traffic panels.</p> </li> <li> <p>PMM-12468, PMM-9288 - Enhanced MongoDB QAN with additional metrics, new filter categories, and the ability to identify inefficient full collection scans (COLLSCAN).</p> </li> <li> <p>PMM-12242 - Expanded alert visibility allowing Viewers to see fired alerts and Editors to manage alerts from the Fired Alerts page.</p> </li> <li> <p>PMM-12356 - Enabled Editor role users to view Advisors insights while maintaining Admin-only control over running and modifying them.</p> </li> <li> <p>PMM-13575 - The <code>mongodb_pbm_agent_status</code> metric in MongoDB exporter now includes a <code>self</code> label to differentiate between a PMM Client reporting its own status versus reporting status of other Clients in the cluster. </p> <p>The <code>self</code> label is set to <code>1</code> when the agent is reporting about itself, and to <code>0</code> when reporting about other Clients. This helps identify more precisely which specific Client is experiencing problems without false positives on functioning nodes. </p> </li> <li> <p>PMM-13718 - Improved user access control to PMM logs. The PMM logs link in the Help menu is now hidden for users without administrative privileges instead of displaying an Access denied error when accessed.</p> </li> <li> <p>PMM-13676 - Redesigned all PMM email templates with PMM branding, replacing Grafana logos and styling. Alert emails now also include options for professional support services when needed.</p> </li> <li> <p>PMM-13374 - Improved MongoDB query fingerprint presentation in QAN to display a more detailed query structure, similar to OpsManager format. This makes query patterns easier to recognizable and improves troubleshooting for users migrating from other MongoDB monitoring tools.</p> </li> <li> <p>PMM-13372 - Improved MongoDB Query Examples presentation in QAN by removing enumeration labels.</p> </li> </ul>"},{"location":"release-notes/3.1.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>PMM-13770 - Corrected metric calculations to accurately capture service counts after updates to job name formatting in PMM3. The Monitored DB services panel on the Home dashboard now displays the correct number of monitored instances.</li> <li>PMM-13769 - Resolved an issue where non-Admin users encountered an Access denied error when trying to download PMM logs. The PMM logs link is now properly hidden for users without administrative privileges.</li> <li>PMM-13715 - Fixed an issue where non-Admin users would encounter access error messages after a PMM upgrade. PMM now correctly verifies user roles before initiating configuration tasks, preventing unnecessary error messages for regular users.</li> <li>PMM-13706 - Fixed an issue where the Grafana status panel on the PMM Health dashboard incorrectly displayed a Down state even when the service was running normally. </li> <li>PMM-13698 - Fixed an issue where expanded service details under Inventory &gt; Services would collapse automatically due to page reloads. Service details now remain expanded for uninterrupted review.</li> <li>PMM-13750 - Reduced excessive error logging in PostgreSQL monitoring by skipping table extraction from truncated queries, significantly lowering log volume in busy environments.</li> <li>PMM-13546 - Added Grafana fix for incorrect Data source link on the Alerting section.</li> <li>PMM-13333 - Removed unnecessary PMM Server Logs section from the VictoriaMetrics dashboard as it only contained a non-functional diagnostics link.</li> <li>PMM-12881 - PMM would display both an error notification and a misleading success notification when changing PMM settings to an invalid value. This issue has been resolved, and PMM now only shows the appropriate error message when a setting change fails.</li> </ul>"},{"location":"release-notes/3.2.0.html","title":"Percona Monitoring and Management 3.2.0","text":"Release date May 29<sup>th</sup>, 2025 Installation Installing Percona Monitoring and Management Upgrade Migrate PMM 2 to PMM 3 <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB. PMM empowers you to: </p> <ul> <li>monitor the health and performance of your database systems</li> <li>identify patterns and trends in database behavior</li> <li>diagnose and resolve issues faster with actionable insights</li> <li>manage databases across on-premises, cloud, and hybrid environments</li> </ul>"},{"location":"release-notes/3.2.0.html#release-summary","title":"Release summary","text":"<p>PMM 3.2.0 comes with better support for Amazon Linux 2023 and MySQL 8.4 replication, an upgrade to Grafana 11.6, secure ClickHouse connections, a new backup dashboard for MongoDB and faster filtering for QAN. This is in addition to many bug fixes and performance improvements!</p>"},{"location":"release-notes/3.2.0.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/3.2.0.html#native-pmm-client-support-for-amazon-linux-2023","title":"Native PMM Client support for Amazon Linux 2023","text":"<p>PMM 3.2.0 introduces official RPM package support for installing the PMM Client on Amazon Linux 2023. If you\u2019ve been deploying PMM Client on AL2023 and relying on tarball-based installation workarounds, you no longer need to \u2014 you can now install the Client through native RPM packages.</p> <p>The RPM support streamlines setup with AL2023, and gets you monitoring databases faster.</p>"},{"location":"release-notes/3.2.0.html#enhanced-mysql-84-support","title":"Enhanced MySQL 8.4 support","text":"<p>PMM 3.2.0 now offers complete support for MySQL 8.4. While PMM 3.0.0 included partial compatibility with Query Analytics (QAN) and basic dashboards, it couldn\u2019t track replication metrics. This was because MySQL 8.4 changed how it exposes replication metrics, shifting from traditional status variables to <code>performance_schema</code> tables.</p> <p>With this release, we\u2019ve upgraded the MySQL Exporter to version 0.17.2, to enable it to collect replication metrics from both legacy status variables and the new <code>performance_schema</code> tables. We\u2019ve also reconfigured the MySQL Replication Summary dashboard to display these metrics properly regardless of their source.</p> <p>This means that PMM can now provide complete replication monitoring across all supported MySQL versions (5.7, 8.0, and 8.4), including critical metrics like IO Thread status, SQL Thread status, and Replication Lag.</p>"},{"location":"release-notes/3.2.0.html#grafana-116-update-and-upgrade-path-for-external-postgresql-users","title":"Grafana 11.6 update and upgrade path for external PostgreSQL users","text":"<p>PMM now ships with Grafana 11.6, which delivers enhanced visualization capabilities, a more efficient alerting workflow, and a wide range of improvements:</p> <ul> <li>Alert state history for reviewing historical changes in alert statuses over time. Full functionality requires Grafana Loki for log aggregation and specific Grafana configuration to enable centralized tracking and storage.</li> <li>Improved panel features and actions visualization for better dashboard interactivity</li> <li>Simplified alert creation with improved UI workflows</li> <li>Recording rules for creating pre-computed metrics to optimize dashboard performance</li> </ul> <p>Dashboard improvements:</p> <ul> <li>Navigation bookmarks for quick access to frequently used dashboards</li> <li>State timeline supports pagination for better performance with large datasets</li> <li>Centralized alert history page for managing all alert rules</li> <li>Improved Grafana Scenes support for modern dashboard architecture</li> </ul> <p>Upgrading to PMM 3.2.0 with an external PostgreSQL database</p> <p>If you\u2019re using an external PostgreSQL database, make sure to update your PMM Server configuration before upgrading to PMM 3.2.0. This is because Grafana 11.6 has a regression issue where the <code>GF_DATABASE_URL</code> environment variable is no longer sufficient for database configuration.  See Migrate External PostgreSQL Configuration for PMM 3.2.0+ for step-by-step instructions.</p>"},{"location":"release-notes/3.2.0.html#secure-external-clickhouse-connections","title":"Secure external ClickHouse connections","text":"<p>PMM now supports connecting to external ClickHouse servers using authenticated credentials. </p> <p>You can now set the <code>PMM_CLICKHOUSE_USER</code> and <code>PMM_CLICKHOUSE_PASSWORD</code> environment variables when deploying PMM Server to enable access to password-protected ClickHouse instances, such as those managed by Altinity\u2019s operator. </p> <p>This means that previous authentication errors are resolved, you no longer need to embed credentials in connection strings, which makes your setup more secure.</p>"},{"location":"release-notes/3.2.0.html#feature-compatibility-version-fcv-panel-in-mongodb-dashboards","title":"Feature Compatibility Version (FCV) panel in MongoDB dashboards","text":"<p>PMM now shows the current MongoDB Feature Compatibility Version (FCV) in the  MongoDB Replica Set and MongoDB Sharded Cluster Summary dashboards. </p> <p>This panel helps you quickly see if your cluster is running the expected FCV\u2014especially after upgrades, when the FCV might not match the MongoDB version yet.</p> <p></p>"},{"location":"release-notes/3.2.0.html#new-pbm-details-dashboard-for-mongodb-backups","title":"New PBM Details dashboard for MongoDB backups","text":"<p>PMM now includes a new MongoDB PBM Details dashboard that enables you to monitor MongoDB backups directly from PMM. This new dashboard is powered by the PBM collector and offers a unified, real-time view of all your backup activity across replica sets and sharded clusters. </p> <p>It displays key information such as backup status, configuration, size, duration, PITR status, and details of the most recent successful backup\u2014all in one place. If you\u2019re already using Percona Backup for MongoDB (PBM) with PMM, this integration lets you track backup operations without switching between tools.</p> <p>To get started, open the PBM Details dashboard and see how it works with your MongoDB environments.</p> <p></p> <p>Future releases will improve the Backup history panel to better display certain error states and special conditions (like stuck or incompatible backups) that are currently only visible when using <code>PBM's pbm status</code> command directly.</p>"},{"location":"release-notes/3.2.0.html#improved-query-analytics-filter-performance","title":"Improved Query Analytics filter performance","text":"<p>We\u2019ve optimized QAN filter loading performance to reduce the number of processed rows by up to 95% in large environments. This means that the filters on the PMM Query Analytics page now load faster, which makes the interface more responsive. </p> <p></p>"},{"location":"release-notes/3.2.0.html#nomad-integration-for-future-extensibility","title":"Nomad integration for future extensibility","text":"<p>We\u2019ve integrated HashiCorp Nomad into PMM to lay the groundwork for future feature development. This workload orchestrator will initially manage monitoring agents to improve service delivery for Percona customers.</p> <p>If you are an advanced user, you can access the Nomad API (internal port <code>4646</code>) through the standard PMM HTTPS port by appending <code>/nomad</code> to your PMM Server URL. The full API path is <code>https://&lt;pmm-server&gt;/nomad/v1/</code>. You must have Administrator rights to access this endpoint.</p> <p>Nomad is disabled by default. Even though it increases the overall Docker image size, it has no performance impact when not enabled. For more information, see Nomad configuration. </p>"},{"location":"release-notes/3.2.0.html#improvements","title":"Improvements","text":"<ul> <li> <p>PMM-13453 - Improved how PMM checks for updates. Automatic checks now use cached information to reduce system load, while clicking Check for updates on the Updates page performs a thorough check for the latest versions.</p> <p>This ensures you get the most accurate information when explicitly checking for updates, while improving overall system performance.</p> </li> <li> <p>PMM-13644 - Added a default 30-day retention policy for ClickHouse system log tables (<code>trace_log</code>, <code>metric_log</code>, <code>query_log</code>). This default policy keeps recent logs readily available for troubleshooting but prevents potential ClickHouse performance issues that excessive log data could cause.</p> <p>You can customize the retention by updating the Time-To-Live (TTL) expression (<code>event_date + INTERVAL X DAY DELETE</code>) in the ClickHouse configuration.</p> </li> <li> <p>PMM-13869 - PMM now outputs Nginx access logs in LOGFMT format, ensuring consistency across all PMM components. This also improves compatibility with log analysis tools like Loki and VictoriaLogs, which means you can analyze logs directly without reformatting or manual parsing.</p> </li> <li> <p>PMM-13171 - Added support for connecting to external ClickHouse databases with custom user credentials using the <code>PMM_CLICKHOUSE_USER</code> and <code>PMM_CLICKHOUSE_PASSWORD</code> environment variables. </p> </li> <li> <p>PMM-13752 - Introduced a new PBM Details dashboard for MongoDB backups for backup operations monitoring directly within PMM. </p> </li> <li> <p>PMM-13785 - You can now install PMM Client on Amazon Linux 2023 environments using official RPM packages, so you don\u2019t need to use tarball-based workarounds.</p> </li> <li> <p>PMM-13406 - Integrated HashiCorp Nomad into PMM to enable future extensibility. </p> </li> <li> <p>PMM-13939 - Improved the performance of a frequently used query in QAN by optimizing the number of rows fetched from the database. This change reduces the time it takes to display QAN filters, resulting in a smoother user experience.</p> </li> <li> <p>PMM-13824 - Updated MongoDB Replicaset summary dashboard and MongoDB Sharded cluster summary dashboard with a new panel to show the current Feature Compatibility Version. We\u2019ve also added panels to show Nodes, Databases count and Last election time.</p> </li> <li> <p>PMM-13832 - We\u2019ve revised the PMM installation documentation to enhance technical accuracy, clarity, and usability. As we continue to refine the topics in this chapter, we welcome your feedback to help us make the documentation even better.</p> </li> </ul>"},{"location":"release-notes/3.2.0.html#components-upgrade","title":"Components upgrade","text":"<ul> <li> <p>PMM-13463 - PMM now ships with Grafana 11.6, bringing a suite of enhancements to visualization, alerting, and dashboard interactivity. </p> </li> <li> <p>PMM-13210 - Upgraded VictoriaMetrics to version 1.114.0. This version includes key upstream improvements and fixes, ensuring more reliable metric collection, storage, and faster data access in PMM.</p> </li> <li> <p>PMM-12153 -  We\u2019ve upgraded <code>mysqld_exporter</code> to the latest stable version (v0.17.2), bringing you the newest features and critical fixes for enhanced MySQL metric collection and also ensuring compatibility with the latest upstream advancements.</p> </li> </ul>"},{"location":"release-notes/3.2.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li> <p>PMM-13139 - Fixed an issue in the ProxySQL Instance Summary dashboard where panels were not correctly filtered by the selected ProxySQL instance. Panels like Executed queries, Queries execution time, and Queries Latency now accurately display data specific to the chosen ProxySQL instance. We\u2019ve also added a Hostgroup filter for a more granular analysis.</p> </li> <li> <p>PMM-13766 - Fixed a security issue where TLS certificates and private keys were not being deleted from PMM Client\u2019s temporary directories after removing the service. PMM now properly cleans up security-sensitive file when you remove services.</p> </li> <li> <p>PMM-13958 - Fixed an issue where PMM Server would ignore the <code>PMM_POSTGRES_*</code> environment variables and start the internal PostgreSQL instance even when <code>PMM_DISABLE_BUILTIN_POSTGRES=1</code> was set. PMM now correctly detects external PostgreSQL settings, and no longer waits for the internal database to start when external settings are available.</p> </li> <li> <p>PMM-13780 - Fixed an issue in the SQL query that prevented group replication metrics from being collected. The MySQL Group Replication Summary dashboard now properly displays transaction and conflict metrics for MySQL 8.0 and 8.4 environments.</p> </li> <li> <p>PMM-13635 - Fixed calculation issues in the MongoDB Collections Overview dashboard that previously resulted in empty or incorrect data displays. The dashboard now properly handles filter selections and displays accurate metrics. </p> <p>These fixes also improve the Top 5 Databases by Size panel, which now accurately reflects database sizes when filtering by specific MongoDB nodes or replica sets. </p> </li> <li> <p>PMM-13694 - Fixed an issue where PostgreSQL QPS calculations were incorrect in QAN when using non-default <code>pg_stat_statements.max</code> values greater than <code>5000</code>.</p> </li> <li> <p>PMM-13956 - The ProxySQL exporter would incorrectly transition to a <code>Done</code> status instead of <code>Running</code> after being added for monitoring. This prevented the exporter from collecting metrics from ProxySQL instances, which meant that PMM could not track ProxySQL performance accurately. This issue is now fixed.</p> </li> <li> <p>PMM-13909 - Fixed an issue where the Services list under PMM Inventory would automatically reset to page 1 while browsing other pages. You can now navigate through multiple pages of services without unexpected page resets.</p> </li> <li> <p>PMM-13897 - Fixed an issue in QAN where selecting MongoDB Plan Summary filters containing bracketed expressions (such as <code>EXPRESS_IXSCAN { id: 1 }</code>) would trigger internal server errors. PMM can now handle  special characters in filter values, regardless of their syntax complexity.</p> </li> <li> <p>PMM-13807 - <code>pmm-agent</code> would crash when processing MySQL slow-log entries containing queries with a column named Value. This is now fixed and PMM can now properly monitor all SQL queries, regardless of column naming.</p> </li> <li> <p>PMM-13757 - Fixed an issue where MySQL query fingerprints sometimes incorrectly showed the execution time limit number (from <code>/*+ MAX_EXECUTION_TIME(&lt;number&gt;) */</code>) instead of a <code>?</code>. These numbers are now always replaced with <code>?</code> for consistent query analysis. </p> </li> <li> <p>PMM-13966 - Checking the Explain plan in QAN for queries that themselves contained the <code>EXPLAIN</code> keyword would result in an error: invalid GetActionRequest.ActionId: value length must be at least 1 runes. PMM now detects this scenario and clearly informs you that running EXPLAIN on such queries isn\u2019t supported.</p> </li> <li> <p>PMM-13968 - Fixed a bug in QAN with MySQL Performance Schema where the same query run on different databases was only counted in one. Now, QAN correctly tracks these queries separately for each database.</p> </li> </ul>"},{"location":"release-notes/3.3.0.html","title":"Percona Monitoring and Management 3.3.0","text":"Release date July 9<sup>th</sup>, 2025 Installation Installing Percona Monitoring and Management Upgrade Migrate PMM 2 to PMM 3 <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB. PMM empowers you to: </p> <ul> <li>monitor the health and performance of your database systems</li> <li>identify patterns and trends in database behavior</li> <li>diagnose and resolve issues faster with actionable insights</li> <li>manage databases across on-premises, cloud, and hybrid environments</li> </ul>"},{"location":"release-notes/3.3.0.html#release-summary","title":"Release summary","text":"<p>This release delivers advanced PostgreSQL monitoring with five new dashboards and replication support, resolves MongoDB connection pool issues with the new <code>mongolog</code> query source, and adds label-based access control to Query Analytics to meet enterprise security needs.</p> <p>It\u2019s also removing support for Ubuntu 20.04 LTS following its end-of-life, and includes numerous bug fixes and performance improvements to enhance overall stability.</p>"},{"location":"release-notes/3.3.0.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/3.3.0.html#enhanced-postgresql-monitoring-with-replication-support","title":"Enhanced PostgreSQL monitoring with replication support","text":"<p>PMM 3.3.0 transforms PostgreSQL monitoring with enhanced existing dashboards, five new production-ready dashboards, replication monitoring and a redesigned menu structure for easier navigation.</p> <p>New PostgreSQL dashboards:</p> <ul> <li>Replication Overview: tracks replication lag and reveals primary-replica relationships in real-time</li> <li>Top Queries: identifies performance bottlenecks with advanced query analysis and customizable time-based filtering</li> <li>Checkpoints, Buffers and WAL Usage: monitors checkpoint performance and correlates I/O usage patterns</li> <li>Instances Overview Extended: delivers deep-dive performance analytics with advanced PostgreSQL metrics</li> <li>Patroni Details: monitors high-availability PostgreSQL clusters with cluster member status, replication health, and failover monitoring (promoted from experimental status)</li> </ul> <p>Enhanced PostgreSQL dashboards:</p> <ul> <li>Instance Summary: updated with wraparound metrics and top 10 database size analysis</li> <li>PostgreSQL Instances Overview: improved organization and additional metrics</li> </ul> <p>New capabilities:</p> <ul> <li>Transaction ID wraparound prevention with with wraparound metrics</li> <li>Custom metric collection for monitoring beyond standard PostgreSQL statistics</li> <li>Better dashboard grouping to quickly spot issues across your PostgreSQL infrastructure</li> <li>New organized left menu structure with dedicated High Availability (HA) section</li> </ul> <p></p>"},{"location":"release-notes/3.3.0.html#label-based-access-control-for-query-analytics","title":"Label-based access control for Query Analytics","text":"<p>Query Analytics (QAN) now supports label-based access control (LBAC).  This allows admins to associate label visibility with a role limiting visibility into query data. Users see only the databases and services permitted by their roles, with filter options automatically restricted based on assigned labels.</p> <p>This makes it easy to limit access by technology (e.g., MySQL-only), environment (e.g., production), or region, enhancing both security and clarity.</p> <p>To test it, set up a PMM Server, connect MySQL and PostgreSQL databases, enable access control, and define roles using LBAC selectors.</p>"},{"location":"release-notes/3.3.0.html#mongodb-monitoring-at-scale-with-new-log-based-query-source","title":"MongoDB monitoring at scale with new log-based query source","text":"<p>PMM 3.3.0 introduces mongolog, a new way to collect MongoDB metrics. This feature helps prevent connection issues in large-scale environments by reading metrics directly from MongoDB log files instead of using database queries.</p> <p>Traditionally, monitoring many MongoDB databases (100+) can lead to timeouts as monitoring queries compete for limited connections. mongolog avoids this by using zero database connections, delivering the same query analytics data without impacting your database\u2019s performance.</p> <p>This log-based approach reads from existing MongoDB log files (similar to MySQL\u2019s slow query log monitoring) which may increase disk I/O. Use it as an alternative to the default profiler-based method.</p> <p>In addition, mongolog provides unlimited database scalability and support for restricted environments like <code>mongos</code> routers where <code>system.profile</code> access is unavailable.</p> <p>To enable mongolog, add <code>--query-source=mongolog</code> when registering MongoDB services. For setup instructions, see Connect MongoDB databases to PMM.</p>"},{"location":"release-notes/3.3.0.html#pmm-330-available-on-aws-marketplace","title":"PMM 3.3.0 available on AWS Marketplace","text":"<p>PMM 3.3.0 is now available for deployment through the AWS Marketplace, making it easier to deploy Percona Monitoring and Management in your AWS environment. With AWS Marketplace you get:</p> <ul> <li>preconfigured AMI with optimized settings</li> <li>simple hourly pricing plus standard EC2 costs</li> <li>quick deployment with a few clicks directly from AWS Marketplace</li> </ul> <p>For instructions, see Deploy PMM Server on AWS.</p>"},{"location":"release-notes/3.3.0.html#platform-support-changes-and-deprecations","title":"Platform support changes and deprecations","text":""},{"location":"release-notes/3.3.0.html#removed-support-for-ubuntu-2004-lts-focal-fossa","title":"Removed support for Ubuntu 20.04 LTS (Focal Fossa)","text":"<p>Ubuntu 20.04 LTS (Focal Fossa) reached its End of Life on May 31, 2025. Consequently, we no longer build PMM Client packages for this platform. </p> <p>If your PMM Client is running on Ubuntu 20.04, upgrade your operating system to Ubuntu 22.04 LTS or a later version, and then reinstall PMM Client using the package version for your new Ubuntu release. </p> <p>Existing installations on Ubuntu 20.04 will continue to work but we will not release further updates. Source packages (.sdeb) are now built on Ubuntu 22.04 instead of Ubuntu 20.04. </p>"},{"location":"release-notes/3.3.0.html#improvements","title":"Improvements","text":"<ul> <li>PMM-13970 - Added <code>--tls-skip-verify</code> flag for <code>pmm-admin add external</code>, <code>pmm-admin add external-serverless</code>, and <code>pmm-admin add haproxy</code> commands. This flag skips TLS certificate validation, enabling you to monitor services with self-signed certificates or IP-based endpoints that lack proper certificate SANs, including PostgreSQL Operator deployments with HAProxy.</li> <li>PMM-14000, PMM-13861, PMM-13862, PMM-13863, PMM-13864, PMM-13865, PMM-13866, PMM-13867, PMM-13868 - Enhanced PostgreSQL monitoring with five new dashboards, improved existing dashboards, custom query support for specialized metrics, and a redesigned menu structure for better navigation.</li> <li>PMM-12548 - Added <code>mongolog</code> query source for MongoDB that reads slow query logs from disk, eliminating connection pool exhaustion in environments with 100+ databases.</li> <li>PMM-13596 - Improved access control for PMM Dump and PMM Logs by hiding these menu options for users without appropriate permissions. Non-admin users no longer see inaccessible links in the Help menu, preventing confusing 401 error messages.</li> <li>PMM-14059 - Improved the Mongos Routers graph in the MongoDB Sharded Cluster Summary dashboard to display individual router nodes with their status in hexagon format, providing consistency with Config Servers and shard displays instead of showing only a generic OK status.</li> <li>PMM-13786 - Upgraded PMM OVF specification to OVF 2.0 format for enhanced security (SHA256 hashing), better virtual hardware support, and improved cloud compatibility.</li> <li>PMM-13821 - Upgraded Go runtime to version 1.24.x for enhanced performance. This update includes the latest CVE fixes and improvements to maintain PMM\u2019s security.</li> </ul>"},{"location":"release-notes/3.3.0.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>PMM-14070 - The Top 5 Databases By Size chart was not displaying data due to an incorrect query configuration. The chart now correctly shows database size information.</li> <li>PMM-14066 - Fixed an issue where MySQL services were not collecting metrics when database passwords contained special characters (such as <code>#</code>), which caused connection failures and prevented MySQL metrics from appearing in dashboards.</li> <li>PMM-14047 - Fixed an issue in the MongoDB Sharded Cluster Summary dashboard where you could not select MongoDB clusters when other database types (such as Percona Server clusters) were also monitored by the same PMM instance. You can now select MongoDB sharded clusters regardless of what other database clusters are monitored by PMM.</li> <li>PMM-13794 - Fixed an issue in HA deployments where the <code>/v1/server/leaderHealthCheck</code> endpoint would cause server crashes with \u201cinvalid memory address\u201d errors. The health check endpoint now works correctly, preventing HAProxy health check failures.</li> <li>PMM-13963 - Clicking the Explain tab in the Query Analytics dashboard made the PMM unresponsive for Percona Server instances. This issue is now fixed.</li> <li>PMM-13881 - The mongodb_exporter would displayed the wrong version number when queried with <code>--version</code>. This issue is now fixed.</li> </ul>"},{"location":"release-notes/3.3.0.html#known-issues","title":"Known issues","text":""},{"location":"release-notes/3.3.0.html#incorrect-execution-times-with-postgresql-pg_stat_monitor","title":"Incorrect execution times with PostgreSQL <code>pg_stat_monitor</code>","text":"<p>When using <code>pg_stat_monitor</code> extension with <code>pg_stat_monitor.pgsm_enable_query_plan</code> enabled, Query Analytics (QAN) displays incorrect execution times that can be off by 1000x or more. For example, simple SELECT queries that should complete in milliseconds may appear to take 50,000+ seconds.</p> <p>This is because enabling query plans causes <code>pg_stat_monitor</code> to create multiple records for each query, leading to incorrect timing calculations.</p>"},{"location":"release-notes/3.3.0.html#workaround","title":"Workaround","text":"<p>Disable query plan collection to restore accurate timing metrics: <pre><code>-- Check current setting\nSHOW pg_stat_monitor.pgsm_enable_query_plan;\n\n-- Disable query plan collection\nALTER SYSTEM SET pg_stat_monitor.pgsm_enable_query_plan = off;\nSELECT pg_reload_conf();\n\n-- Verify the change\nSHOW pg_stat_monitor.pgsm_enable_query_plan;\n</code></pre></p>"},{"location":"release-notes/3.3.0.html#missing-qan-examples-with-mysql-performance-schema","title":"Missing QAN examples with MySQL Performance Schema","text":"<p>When using MySQL Performance Schema as the query source, query examples may be missing in the QAN dashboard, showing the message \u201cSorry, no examples found\u201d. This is caused by the limited size of MySQL\u2019s in-memory history tables, which can be quickly overwritten under high query load.</p>"},{"location":"release-notes/3.3.0.html#workaround_1","title":"Workaround","text":"<p>Use the <code>slowlog</code> query source to capture and retain full query examples. For details, see the About query analytics (QAN) topic.</p>"},{"location":"release-notes/3.3.0.html#incorrect-tls_skip_verify-values-in-api-responses","title":"Incorrect <code>tls_skip_verify</code> values in API responses","text":"<p>The <code>/v1/inventory/agents/{agent_id}</code> API endpoint incorrectly returns <code>tls_skip_verify: false</code> for external exporters, external-serverless services, and HAProxy services, even when the <code>--tls-skip-verify</code> flag was used when adding the service.</p> <p>This is only a display issue. TLS skip verification still works correctly. To confirm, run <code>pmm-admin status</code> and check that the services are running and collecting metrics as expected.</p>"},{"location":"release-notes/3.3.1.html","title":"Percona Monitoring and Management 3.3.1","text":"Release date July 30<sup>th</sup>, 2025 Installation Installing Percona Monitoring and Management Upgrade Migrate PMM 2 to PMM 3 <p>Percona Monitoring and Management (PMM) is an open source database monitoring, management, and observability solution for MySQL, PostgreSQL, and MongoDB. PMM empowers you to: </p> <ul> <li>monitor the health and performance of your database systems</li> <li>identify patterns and trends in database behavior</li> <li>diagnose and resolve issues faster with actionable insights</li> <li>manage databases across on-premises, cloud, and hybrid environments</li> </ul>"},{"location":"release-notes/3.3.1.html#rce-vulnerability-in-pmm-immediate-action-required","title":"RCE vulnerability in PMM - Immediate action required","text":"<p>We have identified a critical Remote Command Execution (RCE) vulnerability affecting all PMM 2.x and PMM 3.x installations. This vulnerability allows users with CLI access to PMM Client nodes or those with admin-level privileges to exploit the API and execute unauthorized commands on registered nodes.</p>"},{"location":"release-notes/3.3.1.html#affected-installations","title":"Affected installations","text":"<p>This vulnerability affects all PMM 2.x and 3.x deployments where PMM Client nodes are connected to the PMM Server. The security flaw originates from the <code>pt-mysql-summary</code> tool, a component of the Percona Toolkit that automatically collects MySQL system information and diagnostics from PMM Client installations.</p> Affected deployments Version Notes All PMM installations with connected PMM Client nodes PMM 2.x and PMM 3.x Remote Command Execution vulnerability through <code>pt-mysql-summary</code> tool deployed when setting up PMM Clients"},{"location":"release-notes/3.3.1.html#remediation-options","title":"Remediation options","text":"RECOMMENDED: Upgrade to PMM 3.3.1TEMPORARY WORKAROUND: If you cannot upgrade immediately <p>This release directly fixes the vulnerability and enhances overall security in all PMM deployments. To upgrade:</p> <ol> <li>Schedule a maintenance window to minimize disruption.</li> <li>Download the latest PMM release.</li> <li>Upgrade PMM Server, then upgrade PMM Client.</li> <li>Change all credentials for the services that PMM monitors, including database user accounts and any other credentials (e.g., API keys, SSH keys) PMM uses to connect to your infrastructure.</li> <li>Thoroughly check access logs for any potential unauthorized access attempts or suspicious activity.</li> </ol> <p>If you are unable to upgrade to PMM 3.3.1 immediately, implement one of the following temporary measures to reduce risk. These options do not eliminate the vulnerability entirely. Prioritize upgrading to PMM 3.3.1 as soon as possible.</p> <ol> <li> <p>Verify your PMM installation path:</p> <pre><code>find /usr/local/percona -name \"pt-mysql-summary\" 2&gt;/dev/null\n</code></pre> Expected paths <ul> <li>PMM 3.x default: <code>/usr/local/percona/pmm/tools/pt-mysql-summary</code></li> <li>PMM 2.x default: <code>/usr/local/percona/pmm2/tools/pt-mysql-summary</code></li> <li>Custom installations: May be in a different location</li> </ul> </li> <li> <p>Choose one of the following temporary mitigation options. Use the actual path returned by the command above:</p> <ul> <li>Make <code>pt-mysql-summary</code> script non-executable to keep the system information tool on disk but prevent it from being executed via the vulnerable path:</li> </ul> <pre><code>   sudo chmod -x /&lt;path to your PMM installation&gt;/pt-mysql-summary\n</code></pre> <ul> <li>Delete <code>pt-mysql-summary</code> to permanently remove the vulnerable tool from your system:</li> </ul> <pre><code>   sudo rm -f /&lt;path to your PMM installation&gt;/pt-mysql-summary\n</code></pre> </li> <li> <p>Change all credentials for the services that PMM monitors, including database user accounts and any other credentials (e.g., API keys, SSH keys) PMM uses to connect to your infrastructure.</p> </li> <li>Thoroughly check access logs for any potential unauthorized access attempts or suspicious activity.</li> </ol>"},{"location":"release-notes/3.3.1.html#dashboard-impact","title":"Dashboard impact","text":"<p>Both temporary options impact the MySQL Instance Summary dashboard. Since <code>pt-mysql-summary</code> collects system information, disabling or removing this tool will remove CPU, memory, disk, and OS version information from the dashboard. Other performance metrics continue to be collected normally.</p>"},{"location":"release-notes/3.3.1.html#upgrade-behavior","title":"Upgrade behavior","text":"<p>When upgrading to PMM 3.3.1 (which includes a security fix), the <code>pt-mysql-summary</code> tool will automatically be restored with executable permissions, even if it was previously removed or disabled. This is intentional and expected, as PMM 3.3.1 ships with the patched and secure version of the tool.</p>"},{"location":"release-notes/3.3.1.html#support-additional-resources","title":"Support &amp; additional resources","text":"<p>We are available to assist you 24/7 if you need further clarification or assistance: </p> <ul> <li>Technical support portal for customers</li> <li>Technical support for community</li> </ul> <p>We will continue to provide updates as new information becomes available.</p>"},{"location":"troubleshoot/index.html","title":"Troubleshoot PMM","text":"<p>This section provides comprehensive solutions to common issues and scenarios that may arise while using PMM, including a checklist.</p> <p>To quickly identify the issues and find the appropriate solution, the issues are categorized into distinct groups as follows:</p> <ul> <li>Upgrade issues</li> <li>Configuration issues</li> <li>Percona Alerting issues</li> <li>QAN issues</li> <li>Plugins issues</li> </ul>"},{"location":"troubleshoot/alerting_issues.html","title":"Percona Alerting issues","text":""},{"location":"troubleshoot/alerting_issues.html#no-alert-rule-templates-tab-on-the-alerting-page","title":"No Alert rule templates tab on the Alerting page","text":"<p>Percona Alerting option isn\u2019t active.</p> <ol> <li>Go to PMM Configuration &gt; Settings &gt; Advanced Settings.</li> <li>Enable Alerting.</li> </ol>"},{"location":"troubleshoot/alerting_issues.html#custom-alert-rule-templates-not-migrated-to-percona-alerting","title":"Custom alert rule templates not migrated to Percona Alerting","text":"<p>After upgrading from the latest PMM 2 version to PMM 3, you will find all your alert templates under Alerting &gt; Alert rule templates.</p> <p>If you have any templates available in the  <code>/srv/ia/templates</code> folder, make sure to transfer them to <code>/srv/alerting/templates</code> as PMM 3 will look for custom templates in this location.</p>"},{"location":"troubleshoot/alerting_issues.html#unreachable-external-ip-addresses","title":"Unreachable external IP addresses","text":"<p>If you get an email or page from your system that the IP is not reachable from outside my organization, do the following:</p> <p>To configure your PMM Server\u2019s Public Address, select  PMM Configuration &gt; Settings &gt; Advanced Settings, and supply an address to use in your alert notifications.</p>"},{"location":"troubleshoot/alerting_issues.html#alert-rule-templates-are-disabled","title":"Alert Rule Templates are disabled","text":"<p>Built-in alerts are not editable, but you can copy them and edit the copies. </p> <p>If you create a custom alert rule template, you will have access to edit.</p>"},{"location":"troubleshoot/checklist.html","title":"Troubleshooting checklist","text":"<p>The following questions might help you identify the origin of the problem while using Percona Monitoring and Management:</p> <ol> <li>Are you using the latest PMM version?</li> <li>Did you check the known issues section in the Release Notes for that particular PMM release?</li> <li>Are you receiving any error messages?</li> <li>Do the logs contain any messages about the problem? See Message logs and Trace logs for more information.</li> <li>Does the problem occur while configuring PMM, such as:<ul> <li>Does the problem occur while you configure a specific function?</li> <li>Does the problem occur when you perform a particular task?</li> </ul> </li> <li>Are you using the recommended authentication method?</li> <li>Does your system\u2019s firewall allow TCP traffic on the ports used by PMM?</li> <li>Have you allocated enough disk space for installing PMM? If not, check the disk allocation space.</li> <li>Are you using a Technical Preview feature? Technical Preview features are not production-ready and should only be used in testing environments. For more information, see the relevant Release Notes.</li> <li>For installing the PMM client, are you using a package other than a binary package without root permissions?</li> <li>Is your PMM Server installed and running with a known IP address accessible from the client node?</li> <li>Is the PMM Client installed, and is the node registered with PMM Server?</li> <li>Is PMM Client configured correctly and has access to the config file?</li> <li>For monitoring MongoDB, do you have adminUserAnyDatabase or superuser role privilege to any database servers you want to monitor?</li> <li>For monitoring Amazon RDS using PMM, is there too much latency between PMM Server and the Amazon RDS instance?</li> <li>Have you upgraded the PMM Server before you upgraded the PMM Client? If yes, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> <li>Is the PMM Server version higher than or equal to the PMM Client version? Otherwise, there might be configuration issues, thus leading to failure in the client-server communication, as PMM Server might not be able to identify all the parameters in the configuration.</li> </ol>"},{"location":"troubleshoot/components_issues.html","title":"External components issues","text":"<p>Important</p> <p>The content for this section is still under development.</p>"},{"location":"troubleshoot/components_issues.html#clickhouse-issues","title":"ClickHouse issues","text":""},{"location":"troubleshoot/components_issues.html#victoriametrics-issues","title":"VictoriaMetrics issues","text":""},{"location":"troubleshoot/config_issues.html","title":"Configuration issues","text":"<p>This section focuses on configuration issues, such as PMM-agent connection, adding and removing services for monitoring, and so on.</p>"},{"location":"troubleshoot/config_issues.html#client-server-connections","title":"Client-Server connections","text":"<p>There are many causes of broken network connectivity.</p> <p>The container is constrained by the host-level routing and firewall rules when using using Docker. For example, your hosting provider might have default <code>iptables</code> rules on their hosts that block communication between PMM Server and PMM Client, resulting in DOWN targets in VictoriaMetrics. If this happens, check the firewall and routing settings on the Docker host.</p> <p>PMM can also generate diagnostics data that can be examined and/or shared with our support team to help solve an issue. You can get collected logs from PMM Client using the pmm-admin summary command.</p> <p>Logs obtained in this way include PMM Client logs and logs received from the PMM Server, and stored separately in the <code>client</code> and <code>server</code> folders. The <code>server</code> folder also contains its <code>client</code> subfolder with the self-monitoring client information collected on the PMM Server.</p> <p>For additional debugging information, use the <code>--pprof</code> flag to include pprof debug profiles: <code>pmm-admin summary --pprof</code>.</p> <p>You can get PMM Server logs with either of these methods:</p> <p>Direct download</p> <p>In a browser, visit <code>https://&lt;address-of-your-pmm-server&gt;/logs.zip</code>.</p> <p>From Help menu</p> <p>To obtain the logs from the Help menu:</p> <ol> <li> <p>Select  Help \u2192  PMM Logs.</p> </li> <li> <p>Click PMM Logs to retrieve PMM diagnostics data which can be examined and shared with our support team should you need help.</p> </li> </ol>"},{"location":"troubleshoot/config_issues.html#connection-difficulties","title":"Connection difficulties","text":""},{"location":"troubleshoot/config_issues.html#passwords","title":"Passwords","text":"<p>When adding a service, the host might not be detected if the password contains special symbols (e.g., <code>@</code>, <code>%</code>, etc.).</p> <p>In such cases, you should convert any password, replacing special characters with their escape sequence equivalents.</p> <p>One way to do this is to use the <code>encodeURIComponent</code> JavaScript function in your browser\u2019s web console (commonly found under a Development Tools menu). Run the function with your password as the parameter. For example:</p> <pre><code>&gt; encodeURIComponent(\"s3cR#tpa$$worD\")\n</code></pre> <p>will give:</p> <pre><code>\"s3cR%23tpa%24%24worD\"\n</code></pre>"},{"location":"troubleshoot/config_issues.html#password-change","title":"Password change","text":"<p>When adding clients to the PMM Server, you use the <code>admin</code> user. However, if you change the password for the admin user from the PMM UI, then the clients will not be able to access PMM due to authentication issues. Also, Grafana will lock out the admin user due to multiple unsuccessful login attempts.</p> <p>In such a scenario, use Service Accounts for authentication. You can use Service Accounts as a replacement for basic authentication and API keys.</p>"},{"location":"troubleshoot/dashboard_issues.html","title":"Dashboard issues","text":"<p>Important</p> <p>The content for this section is still under development.</p>"},{"location":"troubleshoot/data_issues.html","title":"Missing data","text":"<p>Why don\u2019t I see any query-related information?</p> <p>There might be multiple places where the problem might come from:</p> <ul> <li>Connection problem between <code>pmm-agent</code> and <code>pmm-managed</code></li> <li>PMM-agent cannot connect to the database.</li> <li>Data source is not properly configured.</li> </ul> <p>Why don\u2019t I see the whole query?</p> <p>Long query examples and fingerprints can be truncated to 1024 symbols to reduce space usage. In this case, the query explains section will not work.</p>"},{"location":"troubleshoot/plugin_issues.html","title":"Plugin issues","text":""},{"location":"troubleshoot/plugin_issues.html#pmm-does-not-allow-to-install-upgrade-or-remove-plugins","title":"PMM does not allow to install, upgrade or remove plugins","text":"<p>Users have encountered issues with installing, updating and removing plugins from PMM. The cause of this issue is the incorrect permissions assigned to the <code>/srv/grafana/plugins</code> directory. These permissions are preventing the grafana component from writing to the directory.</p>"},{"location":"troubleshoot/plugin_issues.html#solution","title":"Solution","text":"<p>Set the ownership on the directory<code>/srv/grafana/plugins</code> to <code>grafana:grafana</code>.</p>"},{"location":"troubleshoot/pmm_dump.html","title":"Export PMM data with PMM Dump","text":"<p>PMM data dumps are compressed tarball files containing a comprehensive export of your PMM metrics and QAN data collected by PMM Server.</p> <p>You can download these dataset files locally, or share them with Percona Support via an SFTP server. This enables you to share PMM data securely, which is especially useful when you need to troubleshoot PMM issues without providing access to your PMM instance.</p> <p>PMM3 enables you to generate datasets straight from PMM UI. PMM 2.41 or older use the standalone PMM Dump utility instead.</p>"},{"location":"troubleshoot/pmm_dump.html#access-requirements","title":"Access requirements","text":"<p>PMM Dump access is restricted based on user roles:</p> User role Can access PMM Dump Can create datasets Admin (with or without Grafana Admin) Yes Yes Editor with Grafana Admin Yes Yes Editor without Grafana Admin No No Viewer with Grafana Admin Yes Yes Viewer without Grafana Admin No No <p>If you cannot see the PMM Dump option in the Help menu or receive access errors when trying to access it directly, check that your user account has the necessary permissions.</p>"},{"location":"troubleshoot/pmm_dump.html#dump-contents","title":"Dump contents","text":"<p>The dump.tar.gz dump file is a .TAR archive compressed via Gzip. Here\u2019s what\u2019s inside the folders it contains:</p> <ul> <li>meta.json: metadata about the data dump</li> <li>vm: Victoria Metrics data chunks in native VM format, organized by timeframe</li> <li>ch: Query Analytics (QAN) data stored in ClickHouse format, organized by row count</li> <li>log.json: logs detailing the export and archive creation process</li> </ul>"},{"location":"troubleshoot/pmm_dump.html#create-a-data-dump","title":"Create a data dump","text":"<p>To create a dump of your dataset:</p> <ol> <li>From the top-right corner of the PMM home page, click the question mark icon   and select  Help &gt; PMM Dump. If you don\u2019t see PMM Dump in the menu, your user account may not have sufficient permissions.</li> <li>Click Create dataset to go to the Export new dataset page.</li> <li>Choose the service for which you want to create the dataset or leave it empty to export all data.</li> <li>Define the time range for the dataset.</li> <li>Enable Export QAN to include Query Analytics (QAN) metrics alongside the core metrics.</li> <li>Click Create dataset. This will generate a data dump file and automatically record an entry in the PMM Dump table. From there, you can use the options available in the Options menu to send the dump file to Percona Support or download it locally for internal usage.</li> </ol>"},{"location":"troubleshoot/pmm_dump.html#send-a-data-dump-to-percona-support","title":"Send a data dump to Percona Support","text":"<p>If you are a Percona Customer, you can securely share PMM data dumps with Percona Support via SFTP.</p> <ol> <li>From the top-right corner of the PMM home page, go to  Help &gt; PMM Dump.</li> <li>Select the PMM dump entry which you want to send to Support.</li> <li>In the Options column, expand the table row to check the PMM Service associated with the dataset, click the ellipsis (three vertical dots) and select Send to Support.</li> <li>Fill in the details of the SFTP server, then click Send.</li> <li>Update your Support ticket to let Percona know that you\u2019ve uploaded the dataset on the SFTP server.</li> </ol>"},{"location":"troubleshoot/pmm_dump.html#troubleshoot-access-issues","title":"Troubleshoot access issues","text":"<p>If you experience issues accessing or using PMM Dump, consider the following:</p> <ul> <li>Cannot see PMM Dump in the Help menu: Verify that you have Admin role or Grafana Admin privileges. Editor and Viewer roles without Grafana Admin cannot access this feature.</li> <li>Error when creating dump datasets: If you encounter errors such as Failed to compose meta error when creating datasets, make sure that the Ignore load option is enabled on the PMM Dump &gt; Export new datasheet. </li> <li>Access denied messages: your user account lacks the necessary permissions to access PMM Dump.</li> </ul>"},{"location":"troubleshoot/qan_issues.html","title":"QAN issues","text":"<p>This section focuses on problems with QAN, such as queries not being retrieved so on.</p>"},{"location":"troubleshoot/qan_issues.html#missing-data","title":"Missing data","text":""},{"location":"troubleshoot/qan_issues.html#why-dont-i-see-any-query-related-information","title":"Why don\u2019t I see any query-related information?","text":"<p>There might be multiple places where the problem might come from:</p> <ul> <li>Connection problem between pmm-agent and pmm-managed</li> <li>PMM-agent cannot connect to the database.</li> <li>Data source is not properly configured.</li> </ul>"},{"location":"troubleshoot/qan_issues.html#why-dont-i-see-the-whole-query","title":"Why don\u2019t I see the whole query?","text":"<p>Long query examples and fingerprints is truncated to 2048 symbols by default to reduce space usage. In this case, the query explains section will not work. Max query size can be configured using flag <code>--max-query-length</code> while adding a service.</p>"},{"location":"troubleshoot/qan_issues.html#incorrect-metrics-unrealistic-query-execution-times","title":"Incorrect metrics: unrealistic query execution times","text":"<p>If you\u2019re seeing query execution times that seem impossible (like 50,000+ seconds for simple SELECT statements), this is typically caused by metric calculation errors rather than actual performance issues. </p> <p>This is because enabling query plans causes <code>pg_stat_monitor</code> to create multiple records for each query, leading to incorrect timing calculations.</p> <p>To fix the issue, disable query plan collection:</p> <pre><code>-- Check if query plan collection is enabled \nSHOW pg_stat_monitor.pgsm_enable_query_plan;\n\n-- If it shows 'on', disable it \nALTER SYSTEM SET pg_stat_monitor.pgsm_enable_query_plan = off;\nSELECT pg_reload_conf();\n\n-- Verify the change took effect\nSHOW pg_stat_monitor.pgsm_enable_query_plan;\n</code></pre> <p>After disabling query plan collection, new metrics should show realistic execution times within minutes.</p>"},{"location":"troubleshoot/upgrade_issues.html","title":"Troubleshoot upgrade issues","text":""},{"location":"troubleshoot/upgrade_issues.html#pmm-server-not-updating-correctly","title":"PMM Server not updating correctly","text":"<p>If the automatic update process isn\u2019t working, you can force an update using the API:</p> <ol> <li>Open your terminal.</li> <li>Run the update command, replacing : with your credentials and  with your PMM server address\u0416  <p><code>curl -X POST \\    --user &lt;username&gt;:&lt;password&gt; \\    'http://&lt;pmm-server-address&gt;/v1/server/updates:start' \\    -H 'Content-Type: application/json'</code> 3. Wait 2-5 minutes and refresh the PMM Home page to verify the update.</p>"},{"location":"uninstall-pmm/index.html","title":"About uninstalling PMM","text":"<p>To completely remove PMM from your system:</p> <ol> <li>Unregister PMM Client from PMM Server to disconnect from PMM Server and clean up monitoring</li> <li> <p>Uninstall PMM Client to remove the software using your installation method:</p> <ul> <li>Uninstall PMM client with Docker container</li> <li>Uninstall PMM using Helm</li> <li>Uninstall PMM client with package manager</li> </ul> </li> </ol> <p>Warning</p> <p>Always unregister before uninstalling to avoid orphaned monitoring data on your PMM Server.</p>"},{"location":"uninstall-pmm/uninstall_docker.html","title":"Uninstall PMM client using Docker container","text":"<p>Completely remove the PMM Client Docker container, image, and client services configuration data.</p> <p>Data loss warning</p> <p>This permanently removes PMM Server and all monitoring data. Ensure you have backed up any important data before uninstalling.</p>"},{"location":"uninstall-pmm/uninstall_docker.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Unregister PMM Client from PMM Server</li> <li>Docker access on the system</li> </ul> <p>To uninstall PMM Client with the Docker container:</p> <ol> <li> <p>Stop the pmm-client container:</p> <pre><code>docker stop pmm-client\n</code></pre> </li> <li> <p>Remove the container:</p> <pre><code>docker rm pmm-client\n</code></pre> </li> <li> <p>Remove the PMM Client image:</p> <pre><code>docker rmi $(docker images | grep \"percona/pmm-client\" | awk {'print $3'})\n</code></pre> </li> <li> <p>Remove the data volume:</p> <pre><code>docker volume rm pmm-client-data\n</code></pre> </li> </ol>"},{"location":"uninstall-pmm/uninstall_helm.html","title":"Uninstall PMM using Helm","text":"<p>Remove PMM Server deployed via Helm in a Kubernetes cluster.</p> <p>Data loss warning</p> <p>This permanently removes PMM Server and all monitoring data. Ensure you have backed up any important data before uninstalling.</p>"},{"location":"uninstall-pmm/uninstall_helm.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Unregister PMM Client from PMM Server</li> <li>Helm and kubectl access to the cluster</li> <li>Permissions to manage resources in the namespace where PMM is deployed</li> </ul>"},{"location":"uninstall-pmm/uninstall_helm.html#uninstall-steps","title":"Uninstall steps","text":"<p>Follow these steps to completely remove PMM Server from your Kubernetes cluster. While Helm handles most of the cleanup, some resources\u2014such as persistent volumes and secrets\u2014must be deleted manually.</p> <ol> <li> <p>Uninstall the <code>pmm</code> Helm release and remove all resources associated with the PMM release and the release history:</p> <pre><code>helm uninstall pmm\n</code></pre> </li> <li> <p>Manually remove remaining resources as Helm does not delete PVC, PV, and any snapshots: </p> </li> </ol> <pre><code># Delete persistent volume claims\nkubectl get pvc | grep pmm\nkubectl delete pvc &lt;pvc-name&gt;\n\n# Delete secrets (if no longer needed)\nkubectl delete secret pmm-secret\n\n# Delete any remaining config maps\nkubectl get configmap | grep pmm\nkubectl delete configmap &lt;configmap-name&gt;\n</code></pre>"},{"location":"uninstall-pmm/uninstall_package_manager.html","title":"Uninstall PMM Client using package manager","text":"<p>This removes PMM Client installed via system package managers (APT, YUM, etc.).</p> <p>Data loss warning</p> <p>This permanently removes PMM Server and all monitoring data. Ensure you have backed up any important data before uninstalling.</p>"},{"location":"uninstall-pmm/uninstall_package_manager.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Unregister PMM Client from PMM Server</li> <li>Root or sudo access to the system</li> </ul>"},{"location":"uninstall-pmm/uninstall_package_manager.html#uninstall-steps","title":"Uninstall steps","text":"<p>To uninstall PMM client with package manager:</p> Debian-based distributionsRed Hat-based distributions <p>To uninstall PMM client with Debian-based distributions:</p> <ol> <li> <p>Uninstall the PMM Client package.</p> <pre><code>sudo apt remove -y pmm-client\n</code></pre> </li> <li> <p>Remove the Percona repository</p> <pre><code>sudo dpkg -r percona-release\n</code></pre> </li> </ol> <p>To uninstall PMM client with Red Hat based distributions:</p> <ol> <li> <p>Uninstall the PMM Client package.</p> <pre><code>sudo yum remove -y pmm-client\n</code></pre> </li> <li> <p>Remove the Percona repository</p> <pre><code>sudo yum remove -y percona-release\n</code></pre> </li> </ol>"},{"location":"uninstall-pmm/unregister_client.html","title":"Unregister PMM Client from PMM Server","text":"<p>Unregistering disconnects your PMM Client from the PMM Server and removes all monitoring services for this node. This should be done before uninstalling the PMM Client.</p> <p>To unregister PMM Client from PMM Server, run the following command:</p> <pre><code>pmm-admin unregister --force\n</code></pre> <p>This command: </p> <ul> <li>stops all monitoring services on this node</li> <li>removes the node from PMM Server\u2019s inventory</li> <li>cleans up monitoring data collection</li> <li>prevents orphaned entries on the server</li> </ul> <p>Note</p> <p>The <code>--force</code> flag ensures unregistration even if the PMM Server is unreachable. The PMM Client software remains installed after unregistering.</p>"},{"location":"use/dashboard-inventory.html","title":"About PMM Inventory","text":"<p>The Inventory dashboard is a high-level overview of all objects registered in PMM.</p> <p>To check your inventory list, go to  Configuration &gt; Inventory.</p> <p></p> <p>Inventory objects form a hierarchy with Node at the top, then Service and Agents assigned to a Node. This information is detailed in the two tabs available on this page.</p>"},{"location":"use/dashboard-inventory.html#services-tab","title":"Services tab","text":"<p>The Services tab displays the individual services, the nodes on which they run, and the Agents that help collect the service metrics along with the following information:</p> Column Name Description Service name The name or identifier associated with the service being monitored. Node name Name or identifier associated with a specific node. Monitoring status The Monitoring column summarizes the status of all the Agents assigned to the service. Address The IP address or DNS where the service is currently running. Port The port number on which the service is running. Options * You can check QAN information and the Dashboard for each service by clicking on the  icon   * You can also check additional information about the service, by clicking on the  icon. This expands the service entry to show reference information like service labels and IDs. <p></p>"},{"location":"use/dashboard-inventory.html#attributes","title":"Attributes","text":"<p>These are some of the attributes for a service:</p> <ul> <li> <p>Each instance of a service gets a <code>service_type</code> attribute so one can clearly tell what type of database it is, for instance: <code>mysql</code>, <code>postgresql</code>, <code>mongodb</code>, etc. </p> </li> <li> <p>Every service is related to a certain node via its <code>node_id</code> attribute. This feature allows to support monitoring of multiple instances on a single node, with different service names, e.g. <code>mysql1-3306</code>, and <code>mysql1-3307</code>.</p> </li> <li> <p>Each instance of a service gets a <code>version</code> attribute to the response of the endpoint that provides a list of services being monitored by PMM. This makes it easy to visualize the database server version.</p> <p>However, following are the imitations:</p> <ul> <li>The version is not captured for the internal PostgreSQL database.</li> <li>The version is only captured when a new service is being added to PMM and the agent installed on the client side is equal to or greater than v2.41.0.</li> <li>When a database is upgraded, you will not see the database version updated automatically. It will be updated if you remove and then re-add the service.</li> </ul> </li> </ul>"},{"location":"use/dashboard-inventory.html#agents","title":"Agents","text":"<p>Each binary (exporter, agent) running on a client will get an <code>agent_type</code> value. </p> <p>Example</p> <ul> <li><code>pmm-agent</code> is at the top of the tree, assigned to pmm-agent itself</li> <li><code>node_exporter</code> is assigned to an agent that extracts the node metrics</li> <li><code>mysqld_exporter</code> and <code>qan-mysql-perfschema-agent</code> are assigned to agents that extract metrics from mysql and its performance schema respectively.</li> </ul> <p>To view the agents running on a service and their health status, click OK or Failed under the Monitoring column. Furthermore, you can also check the properties of a particular agent by clicking the  icon under the Options column.</p> <p></p>"},{"location":"use/dashboard-inventory.html#node-service-relationship","title":"Node-service relationship","text":"<p>Click on the link in the Node Name column to view the node on which a specific service is running and analyze how node-level resource utilization impacts the performance of those services.</p> <p>Understanding the relationship between nodes and services is key to gaining insights into the distribution and performance of individual services across nodes.</p> <ul> <li> <p>Deployment: Services within PMM are deployed on nodes and rely on them for resources, such as CPU, memory, and storage, to execute tasks.</p> </li> <li> <p>Resource allocation: It is essential to know which nodes host which services to allocate resources appropriately to avoid underuse or overload.</p> </li> <li> <p>Performance optimization: By analyzing node and service-level metrics, you can pinpoint and resolve issues that impede service performance, such as resource limitations and performance bottlenecks.</p> </li> <li> <p>Incident response: When an issue or incident occurs, understanding the node-service relationship helps in troubleshooting. You can quickly identify which nodes and services are affected and focus your efforts on resolving the problem.</p> </li> </ul>"},{"location":"use/dashboard-inventory.html#editing-labels-for-a-service","title":"Editing labels for a service","text":"<p>You can edit the labels as follows:</p> <ol> <li> <p>From the Main menu, go to PMM Configuration &gt; PMM Inventory &gt; Services.</p> </li> <li> <p>Click on the three dots next to the service you want to edit labels for.</p> </li> <li> <p>Click Edit to change the labels, then click Save Changes. </p> <p></p> </li> <li> <p>Click Confirm and save changes. You will be taken back to the Inventory/Services page.</p> </li> </ol>"},{"location":"use/dashboard-inventory.html#effect-of-editing-labels-for-a-service","title":"Effect of editing labels for a service","text":"<p>Editing existing labels can impact the following PMM functions:</p> <ul> <li> <p>Alerting </p> <p>Editing labels without updating alerting rules can lead to missed alerts. If an alert rule is based on specific labels that are changed or no longer apply, the alert may not trigger when it should.</p> <p>Update the alert rules promptly after editing the labels for a smooth alerting experience.</p> </li> <li> <p>Scheduled backups: Editing the cluster label will remove all scheduled backups for the impacted service or cluster.</p> <p>To prevent any issues, make sure to recreate your backups once you\u2019ve configured the cluster.</p> </li> <li> <p>Dashboard data: Edited labels do not affect the existing time-series(metrics). It will only affect the new time-series(metrics).</p> </li> </ul>"},{"location":"use/dashboard-inventory.html#cluster-view","title":"Cluster view","text":"<p>Disclaimer</p> <p>This feature is still technical preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Organize by Clusters toggle shows related services grouped into clusters based on their <code>cluster</code> label, giving you a consolidated view of your infrastructure.</p> <p></p> <p>Click the downward arrow to view cluster details, including the services running on that cluster, agents, and labels.</p> <p></p> <p>Furthermore, you can filter the clusters by criteria such as Cluster name, Status, Service name, Node name, Monitoring, Address, and Port. </p> <p></p>"},{"location":"use/dashboard-inventory.html#nodes-tab","title":"Nodes tab","text":"<p>The Nodes tab helps you monitor where services and agents are running across your infrastructure. Each node has:</p> <ul> <li>A unique <code>node_id</code> linked to its <code>machine_id</code> (from <code>/etc/machine-id</code>)</li> <li>A <code>node_type</code> attribute (e.g., generic, container, remote, remote_rds) indicating its nature</li> </ul> <p>To see node information: - Click the expand icon in the Options column to see node labels and attributes. - Click any node to view its connected agents. - Click links in the Services column to see running services.</p> <p>To see agent details:</p> <ol> <li> <p>In the Nodes tab, under the Monitoring column, click OK or Failed based on the node\u2019s status to view information about the total number of agents deployed on that node:</p> <p></p> </li> <li> <p>Click on the  icon under the Options column to view the properties of a specific agent.</p> </li> <li> <p>On the Nodes tab, under the Options column, click on the  icon for the selected node to check the properties and the current health status of an agent.       </p> <p></p> </li> </ol>"},{"location":"use/dashboard-inventory.html#remove-items-from-the-inventory","title":"Remove items from the inventory","text":"<p>To remove items from the inventory:</p> <ol> <li> <p>Go to  PMM Configuration &gt; PMM Inventory.</p> </li> <li> <p>In the first column, select the items to be removed.</p> <p></p> </li> <li> <p>Click Delete and confirm the removal.</p> </li> </ol>"},{"location":"use/monitor.html","title":"About monitoring in PMM","text":"<p>PMM continuously collects, stores, visualizes, and analyzes various metrics from database engines, such as MySQL, PostgreSQL, and MongoDB, amongst many others. With PMM, you can monitor your database environment and gain insights into its behavior. </p> <p>Some of the key functionalities of monitoring in PMM are:</p> <ul> <li>Performance monitoring: PMM collects metrics such as query execution times, throughput, latency, and resource utilization (CPU, memory, disk I/O). This helps identify performance bottlenecks and optimize query execution for better efficiency.</li> <li>Resource utilization: PMM monitors CPU usage, memory, disk I/O, and network traffic to optimize resource allocation.</li> <li>Database health checks:  PMM monitors various metrics, such as replication status, uptime, connections, server status, and error rates, to ensure system availability and identify potential issues.</li> </ul>"},{"location":"use/remove-services.html","title":"Remove services from monitoring","text":"<p>To stop monitoring a service, use the <code>pmm-admin remove</code> command with the appropriate service type and name:</p> <pre><code>pmm-admin remove &lt;service-type&gt; &lt;service-name&gt;\n</code></pre>"},{"location":"use/remove-services.html#command-reference","title":"Command reference","text":"<ul> <li><code>service-type</code>: The type of service to remove: mysql, mongodb, postgresql, proxysql, haproxy, or external</li> <li><code>service-name</code>: The name of the service as displayed in PMM inventory</li> </ul>"},{"location":"use/remove-services.html#example","title":"Example","text":"<p>To remove a MySQL service: <pre><code>pmm-admin remove mysql mysql-prod-db1\n</code></pre></p>"},{"location":"use/remove-services.html#verify-service-removal","title":"Verify service removal","text":"<p>After removing a service, you can verify it\u2019s no longer being monitored by listing all monitored services:</p> <pre><code>pmm-admin list\n</code></pre>"},{"location":"use/remove-services.html#related-topics","title":"Related topics","text":"<ul> <li>Percona release</li> <li>PMM Client architecture</li> </ul>"},{"location":"use/using-pmm.html","title":"About using PMM","text":"<p>After installing PMM, it provides a user-friendly web-based interface that enables you to monitor your database instances. It offers comprehensive insights into the performance metrics and query analytics, which helps you optimize your database performance and troubleshoot any underlying issues.</p> <ul> <li>Monitoring: PMM gathers and displays a broad range of metrics related to the performance of your database. These metrics include, but are not limited to, CPU usage, memory usage, query execution times, disk I/O, and more. </li> <li>Query Analytics: Query analytics facilitates the identification of slow queries, enabling you to optimize your database by pinpointing inefficient queries. </li> <li>Alerting and notifications: PMM enables you to set up alerts based on predefined thresholds. This way, you can be notified when specific metrics exceed specified limits, allowing you to address issues before they impact performance.</li> <li>Dashboards and reporting: PMM provides customizable dashboards and reporting features to visualize the collected data and create comprehensive reports for in-depth performance analysis.</li> </ul>"},{"location":"use/commands/index.html","title":"About PMM commands","text":"<ul> <li><code>pmm-admin</code> \u2013 Command line tool for configuring and administering PMM</li> <li><code>pmm-agent</code> \u2013 Daemon process, communicating between PMM Client and PMM Server</li> </ul>"},{"location":"use/commands/pmm-admin.html","title":"pmm-admin - PMM administration tool","text":"<p><code>pmm-admin</code> is a command-line tool for administering PMM using a set of COMMAND keywords and associated FLAGS. It communicates directly with the PMM Server.</p>"},{"location":"use/commands/pmm-admin.html#synopsis","title":"Synopsis","text":"<p><code>pmm-admin [FLAGS]</code></p> <p><code>pmm-admin config [FLAGS] --server-url=server-url</code></p> <p><code>pmm-admin add DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p>DATABASE:= MongoDB|MySQL|PostgreSQL|ProxySQL</p> <p><code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add haproxy [FLAGS] [NAME]</code></p> <p><code>pmm-admin add external [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin add external-serverless [FLAGS] [NAME] [ADDRESS]</code></p> <p><code>pmm-admin remove [FLAGS] service-type [service-name]</code></p> <p><code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]</code></p> <p><code>pmm-admin list [FLAGS] [node-address]</code></p> <p><code>pmm-admin status [FLAGS] [node-address]</code></p> <p><code>pmm-admin summary [FLAGS] [node-address]</code></p> <p><code>pmm-admin annotate [--node|--service] [--tags &lt;tags&gt;] [node-name|service-name]</code></p> <p><code>pmm-admin help [COMMAND]</code></p>"},{"location":"use/commands/pmm-admin.html#common-flags","title":"Common flags","text":"<code>-h</code>, <code>--help</code> Show help and exit. <code>--help-long</code> Show extended help and exit. <code>--help-man</code> Generate <code>man</code> page. (Use <code>pmm-admin --help-man | man -l -</code> to view.) <code>--debug</code> Enable debug logging. <code>--trace</code> Enable trace logging (implies debug). <code>--log-level</code> Set the level for the logs as per your requirement such as INFO, WARNING, ERROR, and FATAL. <code>--json</code> Enable JSON output. <code>--version</code> Show the application version and exit. <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--group=&lt;group-name&gt;</code> Group name for external services. Default: <code>external</code> <code>--expose-exporter</code> If you enable this flag, any IP address on the local network and anywhere on the internet can access exporter endpoints. If the flag is disabled/not present, exporter endpoints can be accessed only locally. The flag is disabled by default"},{"location":"use/commands/pmm-admin.html#commands","title":"Commands","text":""},{"location":"use/commands/pmm-admin.html#general-commands","title":"General commands","text":"<code>pmm-admin help [COMMAND]</code> Show help for <code>COMMAND</code>."},{"location":"use/commands/pmm-admin.html#information-commands","title":"Information commands","text":"<code>pmm-admin list --server-url=server-url [FLAGS]</code> Show Services and Agents running on this Node, and the agent mode (push/pull). <code>pmm-admin status --server-url=server-url [FLAGS]</code> <p>Show the following information about a local pmm-agent, and its connected server and clients:</p> <ul> <li>Agent: Agent ID, Node ID.</li> <li>PMM Server: URL and version.</li> <li>PMM Client: connection status, time drift, latency, <code>vmagent</code> status, <code>pmm-admin</code> version.</li> <li>Agents: Agent ID path and client name.</li> </ul> <p>FLAGS:</p> <code>--wait=&lt;period&gt;&lt;unit&gt;</code> Time to wait for a successful response from pmm-agent. period is an integer. unit is one of <code>ms</code> for milliseconds, <code>s</code> for seconds, <code>m</code> for minutes, <code>h</code> for hours. <code>pmm-admin summary --server-url=server-url [FLAGS]</code> <p>Creates an archive file in the current directory with default file name <code>summary_&lt;hostname&gt;_&lt;year&gt;_&lt;month&gt;_&lt;date&gt;_&lt;hour&gt;_&lt;minute&gt;_&lt;second&gt;.zip</code>. The contents are two directories, <code>client</code> and <code>server</code> containing diagnostic text files.</p> <p>FLAGS:</p> <code>--filename=\"filename\"</code> The Summary Archive filename. <code>--skip-server</code> Skip fetching <code>logs.zip</code> from PMM Server. <code>--pprof</code> Include performance profiling data in the summary."},{"location":"use/commands/pmm-admin.html#configuration-commands","title":"Configuration commands","text":""},{"location":"use/commands/pmm-admin.html#pmm-admin-config","title":"<code>pmm-admin config</code>","text":"<code>pmm-admin config [FLAGS] [node-address] [node-type] [node-name]</code> <p>Configure a local <code>pmm-agent</code>.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--node-model=node-model</code> Node model. <code>--region=region</code> Node region. <code>--az=availability-zone</code> Node availability zone. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--paths-base=dir</code> Base path where all binaries, tools and collectors of PMM client are located <code>--agent-password=password</code> Custom agent password."},{"location":"use/commands/pmm-admin.html#pmm-admin-register","title":"<code>pmm-admin register</code>","text":"<code>pmm-admin register [FLAGS] [node-address] [node-type] [node-name]</code> <p>Register the current Node with the PMM Server.</p> <code>--server-url=server-url</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--machine-id=\"9812826a1c45454a98ba45c56cc4f5b0\"</code> Node machine-id (default is auto-detected). <code>--distro=\"linux\"</code> Node OS distribution (default is auto-detected). <code>--container-id=container-id</code> Container ID. <code>--container-name=container-name</code> Container name. <code>--node-model=node-model</code> Node model. <code>--region=region</code> Node region. <code>--az=availability-zone</code> Node availability zone. <code>--custom-labels=labels</code> Custom user-assigned labels. <code>--agent-password=password</code> Custom agent password."},{"location":"use/commands/pmm-admin.html#pmm-admin-add-pmm-agent-listen-portlisten_port","title":"<code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT</code>","text":"<code>pmm-admin add --pmm-agent-listen-port=LISTEN_PORT DATABASE [FLAGS] [NAME] [ADDRESS]</code> <p>Configure the PMM agent with a listen port.</p> <code>--pmm-agent-listen-port=LISTEN_PORT</code> The PMM agent listen port. <p>DATABASE:= MongoDB|MySQL|PostgreSQL|ProxySQL</p>"},{"location":"use/commands/pmm-admin.html#pmm-admin-remove","title":"<code>pmm-admin remove</code>","text":"<code>pmm-admin remove [FLAGS] service-type [service-name]</code> <p>Remove Service from monitoring.</p> <code>--service-id=service-id</code> Service ID. <code>--force</code> Remove service with that name or ID and all dependent services and agents. <p>When you remove a service, collected data remains on PMM Server for the specified retention period.</p>"},{"location":"use/commands/pmm-admin.html#pmm-admin-annotate","title":"<code>pmm-admin annotate</code>","text":"<code>pmm-admin annotate [--node|--service] &lt;annotation&gt; [--tags &lt;tags&gt;] [--node-name=&lt;node&gt;] [--service-name=&lt;service&gt;]</code> <p>Annotate an event. (Read more)</p> <code>&lt;annotation&gt;</code> The annotation string. If it contains spaces, it should be quoted. <code>--node</code> Annotate the current node or that specified by <code>--node-name</code>. <code>--service</code> Annotate all services running on the current node, or that specified by <code>--service-name</code>. <code>--tags</code> A quoted string that defines one or more comma-separated tags for the annotation. Example: <code>\"tag 1,tag 2\"</code>. <code>--node-name</code> The node name being annotated. <code>--service-name</code> The service name being annotated. <p>Combining flags</p> <p>Flags may be combined as shown in the following examples.</p> <code>--node</code> Current node. <code>--node-name</code> Node with name. <code>--node --node-name=NODE_NAME</code> Node with name. <code>--node --service-name</code> Current node and service with name. <code>--node --node-name --service-name</code> Node with name and service with name. <code>--node --service</code> Current node and all services of current node. <code>-node --node-name --service --service-name</code> Service with name and node with name. <code>--service</code> All services of the current node. <code>--service-name</code> Service with name. <code>--service --service-name</code> Service with name. <code>--service --node-name</code> All services of current node and node with name. <code>--service-name --node-name</code> Service with name and node with name. <code>--service --service-name -node-name</code> Service with name and node with name. <p>Tip</p> <p>If node or service name is specified, they are used instead of other parameters.</p>"},{"location":"use/commands/pmm-admin.html#database-commands","title":"Database commands","text":"MongoDBMySQLPostgreSQLProxySQLHAProxy <code>pmm-admin add mongodb [FLAGS] [node-name] [node-address]</code> <p>Add MongoDB to monitoring.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> MongoDB username. <code>--password=password</code> MongoDB password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=profiler</code> <p>Source of queries, one of: <code>profiler</code>, <code>mongolog</code>, <code>none</code> (default: <code>profiler</code>).</p> <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-certificate-key-file=PATHTOCERT</code> Path to TLS certificate file. <code>--tls-certificate-key-file-password=IFPASSWORDTOCERTISSET</code> Password for TLS certificate file. <code>--tls-ca-file=PATHTOCACERT</code> Path to certificate authority file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 4096 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p>"},{"location":"use/commands/pmm-admin.html#advanced-options","title":"Advanced options","text":"<p>PMM starts the MongoDB exporter by default only with <code>diagnosticdata</code> and <code>replicasetstatus</code> collectors enabled.</p> <p>FLAGS:</p> <code>--enable-all-collectors</code> Enable all collectors. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter. <code>--max-collections-limit=-1</code> <p>Disable collstats, dbstats, topmetrics and indexstats if there are more than  collections. 0: No limit. Default is -1, PMM automatically sets this value. <p>A very high limit of <code>max-collections-limit</code> could impact the CPU and Memory usage. Check <code>--stats-collections</code> to limit the scope of collections and DB\u2019s metrics to be fetched.</p> <code>--stats-collections=db1,db2.col1</code> Collections for collstats &amp; indexstats."},{"location":"use/commands/pmm-admin.html#enable-all-collectors","title":"Enable all collectors","text":"<p>To enable all collectors, pass the parameter <code>--enable-all-collectors</code> in the <code>pmm-admin add mongodb</code> command. This will enable <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code> collectors.</p>"},{"location":"use/commands/pmm-admin.html#disable-some-collectors","title":"Disable some collectors","text":"<p>To enable only some collectors, pass the parameter <code>--enable-all-collectors</code> along with the parameter <code>--disable-collectors</code>.</p> <p>For example, if you want all collectors except <code>topmetrics</code>, specify:</p> <pre><code>--enable-all-collectors --disable-collectors=topmetrics\n</code></pre>"},{"location":"use/commands/pmm-admin.html#limit-dbstats-collstats-and-indexstats","title":"Limit <code>dbStats</code>, <code>collStats</code> and <code>indexStats</code>","text":"<p>By default, PMM decides the limit for the number of collections to monitor the <code>collStats</code> and <code>indexStats</code> collectors.</p> <p>You can also set an additional limit for the <code>collStats</code>, <code>indexStats</code>, <code>dbStats</code>, and <code>topmetrics</code> collectors with the <code>--max-collections-limit</code> parameter.</p> <p>Set the value of the parameter <code>--max-collections-limit</code> to:</p> <ul> <li>0: which indicates that <code>collStats</code> and <code>indexStats</code> can handle unlimited collections.</li> <li>n, which indicates that <code>collStats</code> and <code>indexStats</code> can handle &lt;=n collections. If the limit is crossed - exporter stops collecting monitoring data for the <code>collStats</code> and <code>indexStats</code> collectors.</li> <li>-1 (default) doesn\u2019t need to be explicitly set. It indicates that PMM decides how many collections it would monitor, currently &lt;=200 (subject to change).</li> </ul> <p>To further limit collections to monitor, enable <code>collStats</code> and <code>indexStats</code> for some databases or collections:</p> <ul> <li>Specify the databases and collections that <code>collStats</code> and <code>indexStats</code> will use to collect data using the parameter <code>--stats-collections</code>. This parameter receives a comma-separated list of name spaces in the form <code>database[.collection]</code>.</li> </ul>"},{"location":"use/commands/pmm-admin.html#examples","title":"Examples","text":"<p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code>) with default limit detected by PMM (currently &lt;=200 collections, but subject to change):</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors mongodb_srv_1 127.0.0.1:27017</code></p> <p>To add MongoDB with all collectors (<code>diagnosticdata</code>, <code>replicasetstatus</code>, <code>collstats</code>, <code>dbstats</code>, <code>indexstats</code>, and <code>topmetrics</code>) with <code>max-collections-limit</code> set to 1000:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=1000 mongodb_srv_1 127.0.0.1:27017</code></p> <p>To enable all the collectors with an unlimited number of collections monitored:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 mongodb_srv_1 127.0.0.1:27017</code></p> <p>To add MongoDB with default collectors (<code>diagnosticdata</code> and <code>replicasetstatus</code>):</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass mongodb_srv_1 127.0.0.1:27017</code></p> <p>Disable <code>collstats</code> collector and enable all the others without limiting <code>max-collections-limit</code>:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --disable-collectors=collstats mongodb_srv_1 127.0.0.1:27017</code></p> <p>If <code>--stats-collections=db1,db2.col1</code> then the collectors are run as follows:</p> Database Collector is run on <code>db1</code> All the collections <code>db2</code> Only for collection <code>col1</code> <p>Enable all collectors and limit monitoring for <code>dbstats</code>, <code>indexstats</code>, <code>collstats</code> and <code>topmetrics</code> for all collections in <code>db1</code> and <code>col1</code> collection in <code>db2</code>, without limiting <code>max-collections-limit</code> for a number of collections in <code>db1</code>:</p> <p><code>pmm-admin add mongodb --username=admin --password=admin_pass --enable-all-collectors --max-collections-limit=0 --stats-collections=db1,db2.col1 mongodb_srv_1 127.0.0.1:27017</code></p>"},{"location":"use/commands/pmm-admin.html#resolutions","title":"Resolutions","text":"<p>PMM collects metrics in two resolutions to decrease CPU and Memory usage: high and low resolutions.</p> <p>In high resolution we collect metrics from collectors which work fast: - <code>diagnosticdata</code> - <code>replicasetstatus</code> - <code>topmetrics</code></p> <p>In low resolution we collect metrics from collectors which could take some time: - <code>dbstats</code> - <code>indexstats</code> - <code>collstats</code></p> <code>pmm-admin add mysql [FLAGS] node-name node-address | [--name=service-name] --address=address[:port] | --socket</code> <p>Add MySQL to monitoring.</p> <p>FLAGS:</p> <code>--address</code> MySQL address and port (default: 127.0.0.1:3306). <code>--socket=socket</code> Path to MySQL socket. (Find the socket path with <code>mysql -u root -p -e \"select @@socket\"</code>.) <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> MySQL username. <code>--password=password</code> MySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=slowlog</code> Source of SQL queries, one of: <code>slowlog</code>, <code>perfschema</code>, <code>none</code> (default: <code>slowlog</code>). For <code>slowlog</code> query source, you need change permissions for specific files. Root permissions are needed for this. <code>--size-slow-logs=N</code> <p>Rotate slow log file at this size. If <code>0</code>, use server-defined default. Negative values disable log rotation. A unit suffix must be appended to the number and can be one of:</p> <ul> <li><code>KiB</code>, <code>MiB</code>, <code>GiB</code>, <code>TiB</code> for base 2 units (1024, 1048576, etc).</li> </ul> <code>--disable-queryexamples</code> Disable collection of query examples. <code>--disable-tablestats</code> <p>Disable table statistics collection.</p> <p>Excluded collectors for low-resolution time intervals:</p> <ul> <li><code>--collect.auto_increment.columns</code></li> <li><code>--collect.info_schema.tables</code></li> <li><code>--collect.info_schema.tablestats</code></li> <li><code>--collect.perf_schema.indexiowaits</code></li> <li><code>--collect.perf_schema.tableiowaits</code></li> <li><code>--collect.perf_schema.file_instances</code></li> </ul> <p>Excluded collectors for medium-resolution time intervals:</p> <ul> <li><code>--collect.perf_schema.tablelocks</code></li> </ul> <code>--disable-tablestats-limit=disable-tablestats-limit</code> Table statistics collection will be disabled if there are more than specified number of tables (default: server-defined). 0=no limit. Negative value disables collection. <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-cert=PATHTOCERT</code> Path to TLS client certificate file. <code>--tls-key=PATHTOCERTKEY</code> Key for TLS client certificate file. <code>--tls-ca=PATHTOCACERT</code> Path to certificate authority file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled. <code>pmm-admin add postgresql [FLAGS] [node-name] [node-address]</code> <p>Add PostgreSQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=&lt;node id&gt;</code> Node ID (default is auto-detected). <code>--pmm-agent-id=&lt;pmm agent id&gt;</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=&lt;username&gt;</code> PostgreSQL username. <code>--password=&lt;password&gt;</code> PostgreSQL password. <code>--database=&lt;database&gt;</code> PostgreSQL database (default: postgres). <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--query-source=&lt;query source&gt;</code> Source of SQL queries, one of: <code>pgstatements</code>, <code>pgstatmonitor</code>, <code>none</code> (default: <code>pgstatements</code>). <code>--disable-queryexamples</code> Disable collection of query examples. Applicable only if <code>query-source</code> is set to <code>pgstatmonitor</code>. <code>--environment=&lt;environment&gt;</code> Environment name. <code>--cluster=&lt;cluster&gt;</code> Cluster name. <code>--replication-set=&lt;replication set&gt;</code> Replication set name. <code>--custom-labels=&lt;custom labels&gt;</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--tls-ca-file</code> TLS CA certificate file. <code>--tls-cert-file</code> TLS certificate file. <code>--tls-key-file</code> TLS certificate key file. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--max-query-length=NUMBER</code> <p>Limit query length in QAN. Allowed values: - -1: No limit. -  0: Default value. The default value is 2048 chars. - &gt;0: Query will be truncated after  chars. <p>Ensure you do not set the value of <code>max-query-length</code> to 1, 2, or 3. Otherwise, the PMM agent will get terminated.</p> <code>--comments-parsing=off/on</code> Enable/disable parsing comments from queries into QAN filter groups: - off: Disabled. - on: Enabled. <code>pmm-admin add proxysql [FLAGS] [node-name] [node-address]</code> <p>Add ProxySQL to monitoring.</p> <p>FLAGS:</p> <code>--node-id=node-id</code> Node ID (default is auto-detected). <code>--pmm-agent-id=pmm-agent-id</code> The pmm-agent identifier which runs this instance (default is auto-detected). <code>--username=username</code> ProxySQL username. <code>--password=password</code> ProxySQL password. <code>--agent-password=password</code> <p>Override the default password for accessing the <code>/metrics</code> endpoint. (Username is <code>pmm</code> and default password is the agent ID.)</p> <p>Avoid using special characters like \u2018', \u2018;\u2019 and \u2018$\u2019 in the custom password.</p> <code>--environment=environment</code> Environment name. <code>--cluster=cluster</code> Cluster name. <code>--replication-set=replication-set</code> Replication set name. <code>--custom-labels=custom-labels</code> Custom user-assigned labels. <code>--skip-connection-check</code> Skip connection check. <code>--tls</code> Use TLS to connect to the database. <code>--tls-skip-verify</code> Skip TLS certificates validation. <code>--metrics-mode=mode</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--disable-collectors</code> Comma-separated list of collector names to exclude from exporter. <code>pmm-admin add haproxy [FLAGS] [NAME]</code> <p>Add HAProxy to monitoring.</p> <p>FLAGS:</p> <code>--server-url=SERVER-URL</code> PMM Server URL in <code>https://username:password@pmm-server-host/</code> format. <code>--server-insecure-tls</code> Skip PMM Server TLS certificate validation. <code>--username=USERNAME</code> HAProxy username. <code>--password=PASSWORD</code> HAProxy password. <code>--scheme=SCHEME</code> Scheme to generate URI to exporter metrics endpoints (http or https). <code>--metrics-path=METRICS-PATH</code> Path under which metrics are exposed, used to generate URI (default: /metrics). <code>--listen-port=LISTEN-PORT</code> Listen port of haproxy exposing the metrics for scraping metrics (Required). <code>--service-node-id=SERVICE-NODE-ID</code> Node ID where service runs (default is auto-detected). <code>--environment=ENVIRONMENT</code> Environment name like \u2018production\u2019 or \u2018qa\u2019. <code>--cluster=CLUSTER</code> Cluster name. <code>--replication-set=REPLICATION-SET</code> Replication set name. <code>--custom-labels=CUSTOM-LABELS</code> Custom user-assigned labels. Example: region=east,app=app1. <code>--metrics-mode=MODE</code> Metrics flow mode for agents node-exporter. Allowed values: - <code>auto</code>: chosen by server (default). - <code>push</code>: agent will push metrics. - <code>pull</code>: server scrapes metrics from agent. <code>--skip-connection-check</code> Skip connection check. <code>--tls-skip-verify</code> Skip TLS certificates validation when connecting to HAProxy endpoints with self-signed or invalid certificates."},{"location":"use/commands/pmm-admin.html#examples_1","title":"Examples","text":"<pre><code>pmm-admin add mysql --query-source=slowlog --username=pmm --password=pmm sl-mysql 127.0.0.1:3306\n</code></pre> <pre><code>MySQL Service added.\nService ID  : a89191d4-7d75-44a9-b37f-a528e2c4550f\nService name: sl-mysql\n</code></pre> <pre><code>pmm-admin add mysql --username=pmm --password=pmm --service-name=ps-mysql --host=127.0.0.1 --port=3306\n</code></pre> <pre><code># Add external service with self-signed certificate\npmm-admin add external --listen-port=8008 --scheme=https --tls-skip-verify\n\n# Add external serverless service with certificate issues\npmm-admin add external-serverless --url=https://host.docker.internal:9218 --tls-skip-verify\n\n# Add HAProxy with self-signed certificate\npmm-admin add haproxy --listen-port=8404 --scheme=https --tls-skip-verify\n</code></pre> <pre><code>pmm-admin status\npmm-admin status --wait=30s\n</code></pre> <pre><code>Agent ID: c2a55ac6-a12f-4172-8850-4101237a4236\nNode ID : 29b2cc24-3b90-4892-8d7e-4b44258d9309\nPMM Server:\n URL : https://x.x.x.x:443/\n Version: 2.5.0\nPMM Client:\n Connected : true\n Time drift: 2.152715ms\n Latency : 465.658\u00b5s\n pmm-admin version: 2.5.0\n pmm-agent version: 2.5.0\nAgents: aeb42475-486c-4f48-a906-9546fc7859e8 mysql_slowlog_agent Running\n</code></pre>"},{"location":"use/commands/pmm-admin.html#disable-collectors","title":"Disable collectors","text":"<pre><code>pmm-admin add mysql --disable-collectors='heartbeat,global_status,info_schema.innodb_cmp' --username=pmm --password=pmm --service-name=db1-mysql --host=127.0.0.1 --port=3306\n</code></pre> <p>For other collectors that you can disable with the <code>--disable-collectors</code> option, please visit the official repositories for each exporter:</p> <ul> <li><code>node_exporter</code></li> <li><code>mysqld_exporter</code></li> <li><code>mongodb_exporter</code></li> <li><code>postgres_exporter</code></li> <li><code>proxysql_exporter</code></li> </ul>"},{"location":"use/commands/pmm-agent.html","title":"pmm-agent - PMM Client agent","text":""},{"location":"use/commands/pmm-agent.html#name","title":"NAME","text":"<p><code>pmm-agent</code> - The PMM Client daemon program.</p>"},{"location":"use/commands/pmm-agent.html#synopsis","title":"SYNOPSIS","text":"<p><code>pmm-agent [command] [options]</code></p>"},{"location":"use/commands/pmm-agent.html#description","title":"DESCRIPTION","text":"<p><code>pmm-agent</code>, part of the PMM Client package, runs as a daemon process on all monitored hosts.</p>"},{"location":"use/commands/pmm-agent.html#commands","title":"COMMANDS","text":"<code>pmm-agent run</code> Run pmm-agent (default). <code>pmm-agent setup [node-address] [node-type] [node-name]</code> Configure local pmm-agent (requires root permissions) <code>pmm-agent help [command]</code> Show help (for command) and exit."},{"location":"use/commands/pmm-agent.html#options-and-environment","title":"OPTIONS AND ENVIRONMENT","text":"<p>Most options can be set via environment variables (shown in parentheses).</p> Option Environment variable Description <code>--server-password=SERVER-PASSWORD</code> <code>PMM_AGENT_SERVER_PASSWORD</code> Password to connect to PMM Server. <code>--server-username=SERVER-USERNAME</code> <code>PMM_AGENT_SERVER_USERNAME</code> Username to connect to PMM Server. <code>--server-address=host:port</code> <code>PMM_AGENT_SERVER_ADDRESS</code> PMM Server address and port number. <code>--server-insecure-tls</code> <code>PMM_AGENT_SERVER_INSECURE_TLS</code> Skip PMM Server TLS certificate validation. <code>--az=AZ</code> <code>PMM_AGENT_SETUP_AZ</code> Node availability zone. <code>--config-file=path_to/pmm-agent.yaml</code> <code>PMM_AGENT_CONFIG_FILE</code> Configuration file path and name. <code>--container-id=CONTAINER-ID</code> <code>PMM_AGENT_SETUP_CONTAINER_ID</code> Container ID. <code>--container-name=CONTAINER-NAME</code> <code>PMM_AGENT_SETUP_CONTAINER_NAME</code> Container name. <code>--debug</code> <code>PMM_AGENT_DEBUG</code> Enable debug output. <code>--distro=distro</code> <code>PMM_AGENT_SETUP_DISTRO</code> Node OS distribution (default is auto-detected). <code>--force</code> <code>PMM_AGENT_SETUP_FORCE</code> Remove Node with that name and all dependent Services and Agents (if existing). <code>--id=...</code> <code>PMM_AGENT_ID</code> ID of this pmm-agent. <code>--listen-address=LISTEN-ADDRESS</code> <code>PMM_AGENT_LISTEN_ADDRESS</code> Agent local API address. <code>--listen-port=LISTEN-PORT</code> <code>PMM_AGENT_LISTEN_PORT</code> Agent local API port. <code>--machine-id=machine-id</code> <code>PMM_AGENT_SETUP_MACHINE_ID</code> Node machine ID (default is auto-detected). <code>--metrics-mode=auto</code> <code>PMM_AGENT_SETUP_METRICS_MODE</code> Metrics flow mode for agents node-exporter. Can be <code>push</code> (agent will push metrics), <code>pull</code> (server scrapes metrics from agent) or <code>auto</code> (chosen by server). <code>--node-model=NODE-MODEL</code> <code>PMM_AGENT_SETUP_NODE_MODEL</code> Node model. <code>--paths-base=PATH</code> <code>PMM_AGENT_PATHS_BASE</code> Base path for PMM client, where all binaries, tools and collectors are located. If not set, default is <code>/usr/local/percona/pmm</code>. <code>--paths-exporters_base=PATH</code> <code>PMM_AGENT_PATHS_EXPORTERS_BASE</code> Base path for exporters to use. If not set, or set to a relative path, uses value of <code>--paths-base</code> prepended to it. <code>--paths-mongodb_exporter=PATH</code> <code>PMM_AGENT_PATHS_MONGODB_EXPORTER</code> Path to <code>mongodb_exporter</code>. <code>--paths-mysqld_exporter=PATH</code> <code>PMM_AGENT_PATHS_MYSQLD_EXPORTER</code> Path to <code>mysqld_exporter</code>. <code>--paths-node_exporter=PATH</code> <code>PMM_AGENT_PATHS_NODE_EXPORTER</code> Path to <code>node_exporter</code>. <code>--paths-postgres_exporter=PATH</code> <code>PMM_AGENT_PATHS_POSTGRES_EXPORTER</code> Path to <code>postgres_exporter</code>. <code>--paths-proxysql_exporter=PATH</code> <code>PMM_AGENT_PATHS_PROXYSQL_EXPORTER</code> Path to <code>proxysql_exporter</code>. <code>--paths-pt-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_SUMMARY</code> Path to <code>pt-summary</code>. <code>--paths-pt-mysql-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_MYSQL_SUMMARY</code> Path to <code>pt-mysql-summary</code>. <code>--paths-pt-pg-summary=PATH</code> <code>PMM_AGENT_PATHS_PT_PG_SUMMARY</code> Path to <code>pt-pg-summary</code>. <code>--paths-tempdir=PATH</code> <code>PMM_AGENT_PATHS_TEMPDIR</code> Temporary directory for exporters. <code>--ports-max=PORTS-MAX</code> <code>PMM_AGENT_PORTS_MAX</code> Highest allowed port number for listening sockets. <code>--ports-min=PORTS-MIN</code> <code>PMM_AGENT_PORTS_MIN</code> Lowest allowed port number for listening sockets. <code>--region=REGION</code> <code>PMM_AGENT_SETUP_REGION</code> Node region. <code>--skip-registration</code> <code>PMM_AGENT_SETUP_SKIP_REGISTRATION</code> Skip registration on PMM Server. <code>--trace</code> <code>PMM_AGENT_TRACE</code> Enable trace output (implies <code>--debug</code>). <code>-h</code>, <code>--help</code> Show help (synonym for <code>pmm-agent help</code>). <code>--version</code> Show application version, PMM version, time-stamp, git commit hash and branch. <code>--expose-exporter</code> If you enable this flag, any IP address on the local network and anywhere on the internet can access node exporter endpoints. If the flag is disabled, node exporter endpoints can be accessed only locally."},{"location":"use/commands/pmm-agent.html#config-file","title":"CONFIG FILE","text":"<p>PMM manages the configuration file, and it\u2019s not recommended to modify it manually. However, if necessary, you can make adjustments to specific properties in the config file, such as the username or password used for authorization through service accounts.</p> <p>To do this, set the username to <code>service_token</code> and add your service token as the password. For more information about service account authorization, see Service accounts authentication.</p>"},{"location":"use/commands/pmm-agent.html#usage-and-examples-of-paths-base-flag","title":"USAGE AND EXAMPLES OF <code>paths-base</code> FLAG","text":"<p>Since 2.23.0 this flag could be used for easier setup of PMM agent. With this flag the root permissions for PMM client aren\u2019t needed anymore and it will be fully working.</p> <p>Examples:</p> <ul> <li> <p>Case 1: There are no root permissions for <code>/usr/local/percona/pmm</code> folder or there is a need to change default folder for PMM files. Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: be568008-b1b4-4bd9-98c7-392d1f4b724e\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm\n    exporters_base: /home/user/custom/pmm/exporters\n    node_exporter: /home/user/custom/pmm/exporters/node_exporter\n    mysqld_exporter: /home/user/custom/pmm/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/custom/pmm/exporters/mongodb_exporter\n    postgres_exporter: /home/user/custom/pmm/exporters/postgres_exporter\n    proxysql_exporter: /home/user/custom/pmm/exporters/proxysql_exporter\n    rds_exporter: /home/user/custom/pmm/exporters/rds_exporter\n    azure_exporter: /home/user/custom/pmm/exporters/azure_exporter\n    vmagent: /home/user/custom/pmm/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above, base for all exporters and tools was changed only by setting <code>--paths-base</code>. With this tag the folder for PMM that doesn\u2019t require root access could be specified.</p> </li> <li> <p>Case 2: The older <code>--paths-exporters_base</code> flag could be passed along with the <code>--paths-base</code> Command: <pre><code>pmm-agent setup --paths-base=/home/user/custom/pmm --paths-exporters_base=/home/user/exporters --config-file=pmm-agent-dev.yaml --server-insecure-tls --server-address=127.0.0.1:443 --server-username=admin --server-password=admin\n</code></pre> Config output: <pre><code># Updated by `pmm-agent setup`.\n---\nid: afce1917-8836-4857-b3e5-ad372c2ddbe5\nlisten-address: 127.0.0.1\nlisten-port: 7777\nserver:\n    address: 127.0.0.1:443\n    username: admin\n    password: admin\n    insecure-tls: true\npaths:\n    paths_base: /home/user/custom/pmm\n    exporters_base: /home/user/exporters\n    node_exporter: /home/user/exporters/node_exporter\n    mysqld_exporter: /home/user/exporters/mysqld_exporter\n    mongodb_exporter: /home/user/exporters/mongodb_exporter\n    postgres_exporter: /home/user/exporters/postgres_exporter\n    proxysql_exporter: /home/user/exporters/proxysql_exporter\n    rds_exporter: /home/user/exporters/rds_exporter\n    azure_exporter: /home/user/exporters/azure_exporter\n    vmagent: /home/user/exporters/vmagent\n    tempdir: /tmp\n    pt_summary: /home/user/custom/pmm/tools/pt-summary\n    pt_pg_summary: /home/user/custom/pmm/tools/pt-pg-summary\n    pt_mysql_summary: /home/user/custom/pmm/tools/pt-mysql-summary\n    pt_mongodb_summary: /home/user/custom/pmm/tools/pt-mongodb-summary\nports:\n    min: 42000\n    max: 51999\ndebug: false\ntrace: false\n</code></pre> As could be seen above the behavior for the <code>--paths-base</code> was the same, but paths for all exporters were overwritten by the <code>--paths-exporter_base</code> flag.</p> </li> </ul> <p>Summary: Flag <code>--paths-base</code> will set path for all exporters and tools, but each one could be overridden by specific flag (like <code>--paths-mongodb_exporter</code>, <code>--paths-pt-mysql-summary</code> and etc).</p>"},{"location":"use/commands/pmm-agent.html#logging","title":"LOGGING","text":"<p>By default, pmm-agent sends messages to stderr and to the system log (<code>syslogd</code> or <code>journald</code> on Linux).</p> <p>To get a separate log file, edit the <code>pmm-agent</code> start-up script.</p> <p><code>systemd</code>-based systems</p> <ul> <li>Script file: <code>/usr/lib/systemd/system/pmm-agent.service</code></li> <li>Parameter: <code>StandardError</code></li> <li>Default value: <code>file:/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>StandardError=file:/var/log/pmm-agent.log\n</code></pre> <p><code>initd</code>-based systems</p> <ul> <li>Script file: <code>/etc/init.d/pmm-agent</code></li> <li>Parameter: <code>pmm_log</code></li> <li>Default value: <code>/var/log/pmm-agent.log</code></li> </ul> <p>Example:</p> <pre><code>pmm_log=\"/var/log/pmm-agent.log\"\n</code></pre>"},{"location":"use/dashboards-panels/index.html","title":"Dashboards overview","text":"<p>Dashboards are a compilation of visualizations, including charts and metrics, that enable you to view performance metrics from node to single query for multiple databases in a centralized location.</p> <p>A dashboard is a group of one or more panels organized and arranged into rows. Panels refer to individual components or visual elements that display specific data or visualizations within the dashboard\u2019s layout. These panels are the building blocks that collectively form a dashboard, providing a means to present and visualize data in various formats. Dashboards are grouped into folders. You can customize these by renaming them or creating new ones.</p> <p>Dashboards provide insightful and actionable data, enabling you to gain an overview of your system status quickly. These dashboards enable you to drill down into specific time frames, apply filters, and analyze data trends for troubleshooting and performance optimization. Customizable dashboards and real-time alerting facilitate seamless monitoring of database performance.</p>"},{"location":"use/dashboards-panels/index.html#available-dashboards","title":"Available dashboards","text":"<p>Performance Monitoring and Management (PMM) offers a range of dashboards you can access. Some of these dashboards are as follows:</p> Category Dashboard Elements Insight Advanced Data Exploration 7 Insight Home Dashboard 26 Insight Prometheus Exporter Status 57 Insight Prometheus Exporters Overview 27 Insight VictoriaMetrics 52 Insight VictoriaMetrics Agents Overview 58 PMM PMM Inventory 3 PMM Environment Overview 0 PMM Environment Summary 0 OS CPU Utilization Details 21 OS Disk Details 34 OS Network Details 70 OS Memory Details 116 OS Node Temperature Details 6 OS Nodes Compare 74 OS Nodes Overview 115 OS Node Summary 67 OS NUMA Details 72 OS Processes Details 35 Prometheus Prometheus Exporter Status 57 Prometheus Prometheus Exporters Overview 27 MySQL MySQL Amazon Aurora Details 20 MySQL MySQL Command/Handler Counters Compare 11 MySQL MySQL InnoDB Compression Details 41 MySQL MySQL InnoDB Details 339 MySQL MySQL MyISAM/Aria Details 55 MySQL MySQL MyRocks Details 101 MySQL MySQL Instance Summary 90 MySQL MySQL Instances Compare 70 MySQL MySQL Instances Overview 96 MySQL MySQL Wait Event Analyses Details 42 MySQL MySQL Performance Schema Details 48 MySQL MySQL Query Response Time Details 49 MySQL MySQL Replication Summary 50 MySQL MySQL Group Replication Summary 18 MySQL MySQL Table Details 45 MySQL MySQL User Details 62 MongoDB Experimental MongoDB Collection Overview 100 MongoDB Experimental MongoDB Collection Details 100 MongoDB Experimental MongoDB Oplog Details 100 MongoDB MongoDB Cluster Summary 55 MongoDB MongoDB Instance Summary 42 MongoDB MongoDB Instances Compare 19 MongoDB MongoDB ReplSet Summary 130 MongoDB MongoDB InMemory Details 46 MongoDB MongoDB MMAPv1 Details 52 MongoDB MongoDB WiredTiger Details 54 PostgreSQL PostgreSQL Instances Overview 114 PostgreSQL Experimental PostgreSQL Vacuum Monitoring 114 PostgreSQL PostgreSQL Instance Summary 67 PostgreSQL PostgreSQL Instances Compare 89 ProxySQL ProxySQL Instance Summary 55 High-availability PXC/Galera Node Summary 32 High-availability PXC/Galera Cluster Summary 19 High-availability Experimental PXC/Galera Cluster Summary 7 High-availability PXC/Galera Nodes Compare 55 High-availability HAProxy Instance Summary 113"},{"location":"use/dashboards-panels/annotate/annotate.html","title":"Annotation in dashboards","text":"<p>Annotations mark a moment in time. They are useful for marking system changes or other significant application events. They can be set globally or for specific nodes or services.</p> <p>You create them on the command line with the <code>pmm-admin annotate</code> command.</p> <p>Annotations show as a vertical dashed line on a dashboard graph. Reveal the annotation text by mousing over the caret indicator below the line.</p> <p></p> <p>You turn annotations on or off with the PMM Annotations switch in the second row menu bar.</p> <p></p>"},{"location":"use/dashboards-panels/export-dashboards/export_dashboards.html","title":"Export a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/dashboards-panels/export-dashboards/import_dashboards.html","title":"Import a dashboard","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/dashboards-panels/manage-dashboards/create-folders.html","title":"Create dashboard folders","text":"<p>Folders help you organize and group PMM dashboards, which is crucial when you have multiple dashboards or teams using the same PMM instance.</p> <p>Note</p> <p>To create a dashboard folder, you must have PMM\u2019s Admin privileges.</p> <p>To create a dashboard folder:</p> <ol> <li> <p>On the PMM dashboards page, from the side menu, go to  Dashboards &gt;  New &gt; New folder.</p> </li> <li> <p>Enter a unique name for your folder and click Create.</p> </li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html","title":"Manage dashboard folders","text":"<p>This section describes how to delete multiple dashboards, move dashboards from one folder to another and navigate to a folder page where you can assign folder and dashboard permissions.</p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#delete-multiple-dashboards","title":"Delete multiple dashboards","text":"<p>To delete multiple dashboards at once:</p> <p>From the side menu, go to  Dashboards, browse for the dashboards that you want to delete, and click Delete.</p> <p></p>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#move-dashboards-from-one-folder-to-another","title":"Move dashboards from one folder to another","text":"<p>Note</p> <p>You should have at least an Editor role to move a dashboard.</p> <p>You can move dashboards from one folder to another in the following two ways:</p> <ol> <li>From the side menu, go to  Dashboards, select the dashboards that you want to move then click Move.</li> </ol> <p>The other way of moving dashboards from one folder to another is:</p> <ol> <li>On the Dashboards page, click on the dashboard that you want to move to another folder.</li> <li>Click on  Dashboard settings icon at the top of the page.</li> <li>On the General tab, use the Folder drop-down menu to select the new target folder.</li> <li>Click Save Dashboard on the the left to save the change.    </li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/manage-folders.html#navigate-to-a-dashboard-folder-page-to-assign-permissions","title":"Navigate to a dashboard folder page to assign permissions","text":"<p>To navigate to a dashboard folder page to assign permissions:</p> <ol> <li>From the side menu, go to  Dashboards and click on the main folder whose permissions you want to set.</li> <li> <p>Click the Folder actions &gt; Manage permissions button at the top-right of the page and select the requisite permission from the drop-down for the various roles.</p> <p></p> </li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html","title":"Setting custom Home dashboard","text":"<p>The home dashboard you set is the dashboard all the users will see after logging in to PMM UI. You can set the home dashboard for a server, an organization, a team, or your user account. </p>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html#set-home-dashboard-for-your-organization","title":"Set home dashboard for your organization","text":"<p>Organization Admins can set the home dashboard for their organization. For information on managing users in an organization, see Manage Users</p> <p>{.power-number}</p> <ol> <li>From the side menu, go to  Dashboards and click on the dashboard that you want to set as the home dashboard.</li> <li>Click the  star on top of the page to mark the dashboard as a favorite.</li> <li>From the main menu on the left, go to  Administration &gt; Default preferences.</li> <li>In the Home Dashboard field, select the dashboard that you want to set as your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"use/dashboards-panels/manage-dashboards/set-custom-dashboard.html#set-home-dashboard-for-your-team","title":"Set home dashboard for your team","text":"<p>Organization and team Admins can set the home dashboard for their team as follows:</p> <ol> <li>Navigate to the dashboard that you want to set as your home dashboard.</li> <li>Click  star next to the dashboard title to mark the dashboard as a favorite.</li> <li>From the main menu on the left, go to  Administration &gt; Users and access &gt; Teams.</li> <li>Click on the team for whom you want to set the home dashboard and then navigate to the Settings tab.</li> <li>In the Home Dashboard field, select the dashboard that you want to use for your home dashboard.</li> <li>Click Save.</li> </ol>"},{"location":"use/dashboards-panels/share-dashboards/publish_snapshot.html","title":"Publish snapshot","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html","title":"Share dashboards and panels","text":"<p>When you need to share a dashboard with your team members, you can either send them a direct link to the dashboard, or render and send each panel as a .PNG image.</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#share-panel-via-direct-link","title":"Share panel via direct link","text":"<p>To share a panel via direct link:</p> <ol> <li>Go to the dashboard with the panel that you want to share.</li> <li> <p>Click at the top of the panel to display the panel menu:     </p> </li> <li> <p>Select Share to reveal the Share Panel window and either:</p> <ul> <li>copy and send the full URL for the dashboard, OR</li> <li>toggle the Shorten URL option to generate a simple link with a unique identifier</li> </ul> </li> </ol> <p>Tip</p> <p>If your current domain is different than the one specified in the Grafana .INI configuration file, PMM will ask you to correct this mismatch before you can generate a short URL.</p>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#share-a-panel-as-a-png-file","title":"Share a panel as a PNG file","text":"<p>To enable image rendering:</p> <ol> <li> <p>Deploy the Grafana Image Renderer container alongside PMM Server:</p> <pre><code>docker run -d \\\n--name renderer \\\n--network=pmm-network \\\n-e IGNORE_HTTPS_ERRORS=true \\\ngrafana/grafana-image-renderer:latest\n</code></pre> </li> <li> <p>Stop your existing PMM Server container:</p> <pre><code>docker stop pmm-server\ndocker rm pmm-server\n</code></pre> </li> <li> <p>Start a new PMM Server container with the required environment variables:</p> <pre><code>docker run -d \\\n--name pmm-server \\\n--network=pmm-network \\\n-p 443:8443 \\\n-e GF_RENDERING_SERVER_URL=http://renderer:8081/render \\\n-e GF_RENDERING_CALLBACK_URL=https://pmm-server:8443/graph/ \\\npercona/pmm-server:3\n</code></pre> </li> </ol>"},{"location":"use/dashboards-panels/share-dashboards/share_dashboard.html#render-panel-image","title":"Render panel image","text":"<p>To Render a panel image:</p> <ol> <li>Go to the dashboard with the panel that you want to share.</li> <li>Click at the top of the panel to display the panel menu.</li> <li>Select Share to reveal the Share Panel window.</li> <li>In the Link tab, click Direct link rendered image. This opens a new browser tab.</li> <li>Wait for the image to be rendered, then use your browser\u2019s Image Save function to download the image.</li> </ol>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-feature.html","title":"Dashboard feature overview","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-settings.html","title":"Dashboard settings","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/dashboards-panels/use-dashboards/dashboard-time-range.html","title":"Set dashboard time range","text":""},{"location":"use/dashboards-panels/use-dashboards/dashboard-time-range.html#time-units-and-relative-ranges","title":"Time units and relative ranges","text":"<p>Important</p> <p>The content for this topic is under development.</p>"},{"location":"use/metrics/index.html","title":"About PMM metrics","text":"<p>Percona Monitoring and Management (PMM) collects a range of metrics across database systems to provide comprehensive monitoring and analysis capabilities. </p> <p>PMM supports monitoring for databases such as MySQL, PostgreSQL,  MongoDB, among many others. It gathers metrics related to database performance, resource utilization, health, and other important aspects. </p> <p>These metrics power the PMM dashboards to help you monitor, troubleshoot, and optimize your database environments.</p>"},{"location":"use/metrics/extend_metrics.html","title":"Extend metrics","text":"<p>When you need a metric that\u2019s not present in the default list of <code>node_exporter</code> metrics you may be able to use the <code>textfile</code> collector. The textfile collector allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has.</p>"},{"location":"use/metrics/extend_metrics.html#enable-the-textfile-collector","title":"Enable the textfile collector","text":"<p>The collector is enabled by default. The following folders are used for different resolutions:</p> Resolution Folder High <code>/usr/local/percona/pmm/collectors/textfile-collector/high-resolution</code> Medium <code>/usr/local/percona/pmm/collectors/textfile-collector/medium-resolution</code> Low <code>/usr/local/percona/pmm/collectors/textfile-collector/low-resolution</code> <p></p> <p>The exporter parses all files in these directories that match the filename wildcard expression <code>*.prom</code> using a simple text-based exposition format. Metrics are stored on the PMM Server-side with additional labels related to this Node.</p>"},{"location":"use/metrics/extend_metrics.html#examples-of-shell-commands-for-custom-metrics","title":"Examples of shell commands for custom metrics","text":"<p>To statically set roles for a machine using labels:</p> <pre><code>echo 'node_role{role=\"my_monitored_server_1\"} 1' &gt; /usr/local/percona/pmm/collectors/textfile-collector/low-resolution/node_role.prom\n</code></pre> <p>Here\u2019s an example of a <code>cron</code> job that automatically pushes logged-in users:</p> <pre><code>$ cat /etc/cron.d/loggedin_users\n*/1 * * * *     root    /usr/bin/who | /usr/bin/wc -l | sed -ne 's/^/node_loggedin_users /p' &gt; /usr/local/percona/pmm/collectors/textfile-collector/high-resolution/node_users.prom\n</code></pre> <p></p>"},{"location":"use/qan/index.html","title":"About Query Analytics (QAN)","text":"<p>The Query Analytics dashboard shows how queries are executed and where they spend their time. It helps you analyze database queries over time, optimize database performance, and find and remedy the source of problems.</p> <p></p> <p>Query Analytics supports MySQL, MongoDB and PostgreSQL with the following minimum requirements:</p> MySQL requirementsPostgreSQL requirementsMongoDB requirements <ul> <li>MySQL 5.1 or later (if using the slow query log)</li> <li>MySQL 5.6.9 or later (if using Performance Schema)</li> <li>Percona Server 5.6+ (all Performance Schema and slow log features)</li> <li>MariaDB 5.2+ (for user statistics), 10.0+ (for Performance Schema)</li> </ul> <ul> <li>PostgreSQL 11 or later</li> <li><code>pg_stat_monitor</code> extension (recommended) or <code>pg_stat_statements</code> extension</li> <li>Appropriate <code>shared_preload_libraries</code> configuration</li> <li>Superuser privileges for PMM monitoring account</li> </ul> <ul> <li>MongoDB 6.0 or later (4.4+ may work with limited features)</li> </ul>"},{"location":"use/qan/index.html#requirements-for-profiler","title":"Requirements for Profiler","text":"<ul> <li>Profiling enabled for Query Analytics</li> <li>Appropriate user roles: <code>clusterMonitor</code>, <code>read</code> (local), and custom monitoring roles. For MongoDB 8.0+: Additional <code>directShardOperations</code> role required for sharded clusters</li> </ul>"},{"location":"use/qan/index.html#requirements-for-mongolog","title":"Requirements for Mongolog","text":"<ul> <li>MongoDB configured to log slow operations to a file</li> <li>MongoDB server has write permissions to the log directory and file</li> <li>PMM agent has read permissions to the MongoDB log file</li> <li>Appropriate user roles: <code>clusterMonitor</code>, or custom monitoring roles (<code>getCmdLineOpts</code> privilege on <code>{ cluster: true }</code>)</li> </ul>"},{"location":"use/qan/index.html#dashboard-components","title":"Dashboard components","text":"<p>Query Analytics displays metrics in both visual and numeric form. Performance-related characteristics appear as plotted graphics with summaries.</p>"},{"location":"use/qan/index.html#dashboard-layout","title":"Dashboard layout","text":"<p>The dashboard contains three panels:</p> <ul> <li>the Filters panel</li> <li>the Overview panel</li> <li>the Details panel</li> </ul>"},{"location":"use/qan/index.html#data-retrieval-delays","title":"Data retrieval delays","text":"<p>Query Analytics data retrieval is not instantaneous because metrics are collected once per minute. When collection delays occur, no data is reported and gaps will appear in the sparkline.</p>"},{"location":"use/qan/index.html#label-based-access-control","title":"Label-based access control","text":"<p>Query Analytics integrates with PMM\u2019slabel-based access control (LBAC) to enforce data security and user permissions. </p> <p>When LBAC is enabled:</p> <ul> <li>users see only queries from databases and services permitted by their assigned roles</li> <li>filter dropdown options are dynamically restricted based on user permissions</li> <li>data visibility is controlled through Prometheus-style label selectors</li> </ul>"},{"location":"use/qan/index.html#limitation-missing-query-examples-in-mysql-performance-schema","title":"Limitation: Missing query examples in MySQL Performance Schema","text":"<p>When using MySQL\u2019s Performance Schema as the query source, you may encounter the message \u201cSorry, no examples found\u201d in the QAN dashboard. This typically occurs due to the way MySQL handles query sampling and can be influenced by the volume of unique queries, and Performance Schema settings.</p> <p>Despite the absence of query examples, all other query metrics are still collected and displayed as expected.</p>"},{"location":"use/qan/index.html#why-this-happens","title":"Why this happens","text":"<p>MySQL Performance Schema manages query data across two different tables, which can lead to missing query examples:</p> <ul> <li> <p>Summary table (<code>events_statements_summary_by_digest</code>): stores aggregated metrics for each normalized query (digest) in a limited buffer. Each unique query appears only once, regardless of how many times it runs.</p> </li> <li> <p>History table (<code>events_statements_history</code> or <code>events_statements_history_long</code> in MariaDB): stores individual query executions in a limited rolling buffer. Multiple entries may exist for the same query, but older ones are overwritten as new queries are executed.</p> </li> </ul> <p>A query may appear in the digest summary but not in the history table when:</p> <ul> <li>it was executed frequently enough to appear in the digest summary</li> <li>all its individual executions were overwritten in the history buffer due to high query volume overwhelming the buffer and ongoing activity</li> </ul> <p>When this happens, QAN can still display the query\u2019s metrics, but cannot show an example query because it\u2019s no longer available in <code>events_statements_history</code> table when PMM tries to capture it.</p>"},{"location":"use/qan/index.html#performance-schema-refresh-rate-tuning","title":"Performance Schema refresh rate tuning","text":"<p>PMM Agent includes a configurable Performance Schema Refresh Rate that can help capture more query examples. This setting controls how often PMM scrapes data from the history table. Using a shorter interval increases the likelihood that query examples will be captured before being overwritten.</p>"},{"location":"use/qan/index.html#configuration-options","title":"Configuration options","text":"<ul> <li>Default value: 5 seconds</li> <li>Minimum value: 1 second</li> <li>Value of 0 uses the default (5 seconds)</li> </ul>"},{"location":"use/qan/index.html#how-to-configure","title":"How to configure","text":"<ul> <li>environment variable: <code>PMM_AGENT_PERFSCHEMA_REFRESH_RATE</code>. </li> <li>flag for PMM agent binary: <code>--perfschema-refresh-rate=NUMBER</code>. </li> <li>property in PMM agent config: <code>perfschema-refresh-rate: NUMBER</code>. </li> </ul>"},{"location":"use/qan/index.html#workaround","title":"Workaround","text":"<p>If you\u2019re still missing some query examples, consider using the slow query log (<code>slowlog</code>) as the query source instead.  The <code>slowlog</code> retains actual query texts over time and can help capture examples even when Performance Schema history buffers are exhausted.</p>"},{"location":"use/qan/qan_mongo.html","title":"Query Analytics for MongoDB","text":"<p>MongoDB is conceptually different from relational database management systems, such as MySQL and MariaDB.</p> <p>Relational database management systems store data in tables that represent single entities. Complex objects are represented by linking tables.</p> <p>In contrast, MongoDB uses the concept of a document where all essential information for a complex object is stored in one place.</p> <p>Query Analytics can monitor MongoDB queries. Although MongoDB is not a relational database management system, you analyze its databases and collections in the same interface using the same tools.</p>"},{"location":"use/qan/share_link.html","title":"Share a link for Query Analytics","text":"<p>To share a link for Query Analytics, use Copy Link. It copies the link to the clipboard with all the relevant information such as selected query, table page, selected filters, details tab, and time range. Thus, when you open the link, it will display the exact information.</p> <p>Important</p> <p>Ensure that you use Copy Link to copy the link instead of using the browser address bar or the standard Grafana functionality (to share a dashboard). Otherwise, Query Analytics might not display the exact information that existed while sharing the link.</p> <p>By default, Grafana uses a relative time range and not an absolute range, so it will have a different timestamp when this link is opened.</p> <p></p>"},{"location":"use/qan/panels/details.html","title":"Details panel","text":"<ul> <li>Selecting an item in the Overview panel opens the Details panel with a Details Tab.</li> <li>If the dimension is Query, the panel also contains the Examples Tab, Explain Tab, and Tables Tab.</li> </ul>"},{"location":"use/qan/panels/details.html#details-tab","title":"Details Tab","text":"<p>The Details tab contains a Query time distribution bar (only for MySQL databases) and a set of Metrics in collapsible subpanels.</p> <p></p> <ul> <li> <p>The Query time distribution bar shows a query\u2019s total time made up of colored segments, each segment representing the proportion of time spent on a named activity.</p> <ul> <li><code>query_time</code>: Statement execution time.</li> <li><code>lock_time</code>: Time to acquire locks.</li> <li><code>blk_read_time</code>: Total time the statement spent reading blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>blk_write_time</code>: Total time the statement spent writing blocks (if <code>track_io_timing</code> is enabled, otherwise zero).</li> <li><code>innodb_io_r_wait</code>: Time for InnoDB to read the data from storage.</li> <li><code>innodb_queue_wait</code>: Time the query spent either waiting to enter the InnoDB queue, or in it pending execution.</li> <li><code>innodb_rec_lock_wait</code>: Time the query waited for row locks.</li> <li><code>other</code>: Remaining uncategorized query time.</li> </ul> </li> <li> <p>Metrics is a table with headings:</p> <ul> <li>Metric: The Metric name, with a question-mark tool-tip that reveals a description of the metric on mouse-over;</li> <li>Rate/Second: A sparkline chart of real-time values per unit time;</li> <li>Sum: A summation of the metric for the selected query, and the percentage of the total;</li> <li>Per Query Stats: The value of the metric per query.</li> </ul> </li> <li> <p>Each row in the table is a metric. The contents depends on the chosen dimension.</p> </li> </ul> <p>For PostgreSQL queries (when using <code>pg_stat_monitor</code>) the top query will also be shown in the details section if the query was called by an outer query.</p> <p></p> <p>Other useful metrics (when using pg_stat_monitor) to monitor PostgreSQL Server performance are Histograms.  Histograms provide more explicit information about number of queries for fingerprint (<code>queryid</code>). Ranges are from 0 seconds up to 100 seconds.  </p> <p>Here is picture of histogram in graph:</p> <p></p>"},{"location":"use/qan/panels/details.html#examples-tab","title":"Examples Tab","text":"<p>(For Query dimension.)</p> <p>The Examples tab shows an example of the selected query\u2019s fingerprint or table element.</p> <p></p> <p>Query example and fingerprint can be truncated to 1024 long to reduce space usage. In this case, the query explains section will not work.</p>"},{"location":"use/qan/panels/details.html#explain-tab","title":"Explain Tab","text":"<p>(For Query dimension.)</p> <p>The Explain tab shows the <code>explain</code> output for the selected query, in Classic or JSON formats.</p> <ul> <li>MySQL: Classic and JSON.</li> <li>MongoDB: JSON only.</li> <li>PostgreSQL: Not supported.</li> </ul> <p>The Explain tab for MySQL queries works without enabling Examples. For security, sensitive data appears as placeholders that you must fill in before running Explain:</p> <p></p> <p>Below is an illustration of the same query using values instead of placeholders.</p> <p></p> <p>The image shown above illustrates a query with two placeholders. Therefore, you must enter the correct values in both fields. After filling in these values, click Explain to get the results like in the previous PMM versions without data leaks. You will get result like in previous PMM versions. This method of <code>explain</code> prevents data leak.</p> <p>\u2018Explain\u2019 for MongoDB</p> <p>To run Explain you need the same permissions as for executing the original query. For example, to run explain on <code>updates</code> you need update permissions.  </p> <p>Example: Grant the <code>explainRole</code> with update permissions.</p> <pre><code>db.grantPrivilegesToRole( \"explainRole\", [ { resource: { db: \"\", collection: \"\" }, actions: [ \"update\" ] } ])\n</code></pre> <p></p>"},{"location":"use/qan/panels/details.html#tables-tab","title":"Tables Tab","text":"<p>(For Query dimension.)</p> <p>The Tables tab shows information on the tables and indexes involved in the selected query.</p> <p></p>"},{"location":"use/qan/panels/details.html#plan-tab","title":"Plan Tab","text":"<p>(For Query dimension.)</p> <p>The Plan tab shows the plan for PostgreSQL queries (only available when using pg_stat_monitor).</p> <p></p>"},{"location":"use/qan/panels/filters.html","title":"QAN Filters panel","text":"<p>The Filters panel on the left hand side of the QAN dashboard helps you narrow down query data to focus on specific metrics, database instances, or performance issues.</p> <p></p>"},{"location":"use/qan/panels/filters.html#understanding-filters","title":"Understanding filters","text":"<ul> <li>The Filter panel lists the filters grouped by category. It also shows the percentage of the main metrics (explained below). If you select a different metric, the percentages on the left panel will change as per this metric. When you select a metric, it reduces the overview list as per the matching filter.</li> <li>When label-based access control (LBAC) is enabled, filter options are automatically limited to match your role\u2019s permissions. You will only see databases, services, and environments you have access to.</li> <li>The first five of each category are shown. If there are more, the list is expanded by clicking Show all beside the category name, and collapsed again with Show top 5.</li> <li>Applying a filter may make other filters inapplicable. These become grayed out and inactive.</li> <li>Click the chart symbol  to navigate directly to an item\u2019s associated dashboard.</li> <li>Separately, the global Time range setting filters results by time, either your choice of Absolute time range, or one of the predefined Relative time ranges.</li> </ul>"},{"location":"use/qan/panels/filters.html#available-filter-groups","title":"Available filter groups","text":"<p>The available filter groups depend on the database type you\u2019re monitoring.</p>"},{"location":"use/qan/panels/filters.html#common-filter-groups","title":"Common filter groups","text":"<p>These filter groups are available for all database types:</p> <ul> <li>Command Type: filters by SQL command class (SELECT, INSERT, UPDATE, etc.) </li> <li>Fingerprint: filters by normalized query pattern</li> <li>Node Type</li> <li>Environment</li> <li>Availability Zone</li> <li>Cluster</li> <li>Replication Set</li> <li>Database</li> <li>Schema</li> <li>Node Name</li> <li>Service Name</li> <li>Client Host</li> <li>User Name</li> <li>Service Type</li> </ul>"},{"location":"use/qan/panels/filters.html#mysql-specific-filter-groups","title":"MySQL-specific filter groups","text":"<ul> <li>Command Type: filters by SQL command class (SELECT, INSERT, UPDATE, etc.)</li> <li>Fingerprint: Filters by normalized query pattern</li> </ul>"},{"location":"use/qan/panels/filters.html#mongodb-specific-filter-groups","title":"MongoDB-specific filter groups","text":"<ul> <li>Plan Summary: filters queries by execution plan type (COLLSCAN, IXSCAN, etc.) to easily identify inefficient full collection scans</li> </ul>"},{"location":"use/qan/panels/filters.html#postgresql-specific-filter-groups","title":"PostgreSQL-specific filter groups","text":"<ul> <li>Application: filters queries by the application name that generated them</li> <li>Command Type</li> </ul>"},{"location":"use/qan/panels/filters.html#custom-filter-groups","title":"Custom filter groups","text":"<p>Important/Caution</p> <p>This feature is still in Technical Preview and is subject to change. We recommend that early adopters use this feature for testing purposes only.</p> <p>Filter queries using custom key=value pairs from query comments. This feature is disabled by default.</p>"},{"location":"use/qan/panels/filters.html#supported-technologies-and-agents","title":"Supported technologies and agents","text":"<ul> <li>MySQL (<code>perfschema</code>, <code>slowlog</code>),</li> <li>PostgreSQL (<code>pg_stat_statements</code>, <code>pg_stat_monitor</code>)</li> </ul> <p>Example</p> <p></p> <p>In the image above we have tagged queries running databases on Windows using the following comment: </p> <p><pre><code>comment: /* OperationSystem='windows' */. \n</code></pre> Queries from the database running on Linux are tagged with:</p> <pre><code>/* OperationSystem='linux' */. \n</code></pre> <p>All types of comments and multicomments are supported <code>(/* */, --, # etc)</code>. </p> <p>So the queries are as follows:</p> <pre><code>SELECT * /* OperationSystem='windows' */ FROM city;\nSELECT city /* OperationSystem='linux' */ FROM world;\n</code></pre> <p>In the output, you can see another custom group in the <code>OperationSystem</code> filter. Use this to easily filter by any custom key or value.</p>"},{"location":"use/qan/panels/filters.html#enabling-custom-filter-groups","title":"Enabling custom filter groups","text":"<ul> <li> <p>via CLI: While adding a service through CLI use the flag <code>comments-parsing</code>. Possible values are <code>on/off</code>. </p> <p>Example for adding MySQL with comments parsing on:</p> <pre><code>pmm-admin add mysql --username=root --password=root-password --comments-parsing=\"on\"\n</code></pre> </li> <li> <p>via UI: While adding a service through the UI you will see new checkbox to <code>enable/disable</code> comments parsing for current service.</p> <p></p> </li> </ul> <p>MySQL CLI</p> <ul> <li>If you are using official MySQL CLI to trigger queries, start mysql with <code>--comments</code> flag. Otherwise comments will not be parsed.</li> <li>In case of PGSM (<code>pg_stat_monitor</code>), set the DB variable <code>pgsm_extract_comments=yes</code></li> </ul>"},{"location":"use/qan/panels/overview.html","title":"Overview Panel","text":"<p>To the right of the Filters panel and occupying the upper part of the dashboard is the Overview panel.</p> <p></p> <p>Each row of the table represents the metrics for a chosen object type, one of:</p> <ul> <li>Query;</li> <li>Service Name;</li> <li>Database;</li> <li>Schema;</li> <li>User Name;</li> <li>Client Host.</li> </ul> <p>At the top of the second column is the dimension menu. Use this to choose the object type.</p> <p></p> <p>On the right side of the dimension column is the Dimension Search bar.</p> <p></p> <p>Enter a string and press Enter to limit the view to queries containing only the specified keywords.</p> <p>Delete the search text and press Enter to see the full list again.</p>"},{"location":"use/qan/panels/overview.html#columns","title":"Columns","text":"<ul> <li>The first column is the object\u2019s identifier. For Query, it is the query\u2019s Fingerprint.</li> <li>The second column is the Main metric, containing a reduced graphical representation of the metric over time, called a sparkline, and a horizontal meter, filled to reflect a percentage of the total value.</li> <li>Additional values are revealed as mouse-over tooltips.</li> </ul>"},{"location":"use/qan/panels/overview.html#tooltips","title":"Tooltips","text":"<ul> <li>For the Query dimension, hovering over the information icon  reveals the query ID and its example.</li> <li>Hovering on a column header reveals an informative tooltip for that column.</li> <li>Hovering on the main metric sparkline highlights the data point and a tooltip shows the data value under the cursor.</li> </ul> <ul> <li> <p>Hovering on the main metric meter reveals the percentage of the total, and other details specific to the main metric.</p> <p></p> </li> <li> <p>Hovering on column values reveals more details on the value. The contents depends on the type of value.</p> <p></p> </li> </ul>"},{"location":"use/qan/panels/overview.html#adding-and-removing-columns","title":"Adding and removing columns","text":"<ul> <li> <p>Metrics columns are added with the Add column button.</p> <p></p> </li> <li> <p>When clicked, a text field and list of available metrics are revealed. Select a metric or enter a search string to reduce the list. Selecting a metric adds it to the panel.</p> </li> <li>A metric column is removed by clicking on the column heading and selecting Remove column.</li> <li>The value plotted in the main metric column can be changed by clicking a metric column heading and selecting Swap with main metric.</li> </ul>"},{"location":"use/qan/panels/overview.html#sorting","title":"Sorting","text":"<ul> <li>The entire list is sorted by one of the columns.</li> <li>Click either the up or down caret to sort the list by that column\u2019s ascending or descending values.</li> </ul>"},{"location":"use/qan/panels/overview.html#pagination","title":"Pagination","text":"<ul> <li> <p>The pagination device lets you move forwards or backwards through pages, jump to a specific page, and choose how many items are listed per page.</p> <p></p> </li> <li> <p>Queries are grouped into pages of 25, 50 or 100 items.</p> </li> </ul>"}]}